--- Emails for Year 2026 ---

=== Thread: [PATCH 1/2] RISC-V: Stop warning about Zabha and Zacas ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: [PATCH 1/2] RISC-V: Stop warning about Zabha and Zacas
Date: Fri, 02 Jan 2026 11:44:48 +0000
Message-ID: <20260102114449.535597-2-ben.dooks () codethink ! co ! uk>
--------------------
The zabha (atomic byte and halfword) and zacas (atomic compare/swap)
are now being used by the kernel, so parse these and stop the warnings
when running make C=1 on current kernels.

WARNING: invalid argument to '-march': '_zacas_zabha'

Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
---
 target-riscv.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/target-riscv.c b/target-riscv.c
index d30be04b..80c25285 100644
--- a/target-riscv.c
+++ b/target-riscv.c
@@ -22,6 +22,8 @@
 #define RISCV_ZICBOM	(1 << 12)
 #define RISCV_ZIHINTPAUSE	(1 << 13)
 #define RISCV_VECTOR	(1 << 14)
+#define RISCV_ATOMIC_CAS (1 << 15)
+#define RISCV_ATOMIC_BH	 (1 << 16)
 
 static unsigned int riscv_flags;
 
@@ -43,6 +45,8 @@ static void parse_march_riscv(const char *arg)
 		{ "d",		RISCV_DOUBLE|RISCV_FDIV|RISCV_ZICSR },
 		{ "c",		RISCV_COMP },
 		{ "v",		RISCV_VECTOR|RISCV_FPU|RISCV_ZICSR },
+		{ "_zacas",	RISCV_ATOMIC_CAS },
+		{ "_zabha",	RISCV_ATOMIC_BH },
 		{ "_zicsr",	RISCV_ZICSR },
 		{ "_zifencei",	RISCV_ZIFENCEI },
 		{ "_zicbom",	RISCV_ZICBOM },
-- 
2.37.2.352.g3c44437643


================================================================================

From: Paul Walmsley <pjw () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] RISC-V: Stop warning about Zabha and Zacas
Date: Wed, 07 Jan 2026 20:41:18 +0000
Message-ID: <c5021639-ca56-67cc-ccb5-e074e60bb19d () kernel ! org>
--------------------
On Fri, 2 Jan 2026, Ben Dooks wrote:

> The zabha (atomic byte and halfword) and zacas (atomic compare/swap)
> are now being used by the kernel, so parse these and stop the warnings
> when running make C=1 on current kernels.
> 
> WARNING: invalid argument to '-march': '_zacas_zabha'
> 
> Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>

Thanks Ben.  This saved me some time!

Tested-by: Paul Walmsley <pjw@kernel.org>


- Paul

================================================================================


################################################################################

=== Thread: [PATCH 2/2] RISC-V: restart extension search on match ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: [PATCH 2/2] RISC-V: restart extension search on match
Date: Fri, 02 Jan 2026 11:44:49 +0000
Message-ID: <20260102114449.535597-3-ben.dooks () codethink ! co ! uk>
--------------------
If we are passed multiple extensions in -march, don't assume these will
be in any sort of order. If we do match, then restart the loop by setting
the search back to 0, and retrying.

This sorts out issues with the current kernel build where there are now
lots of extensions for the rv64i and even adding zacas doesn't silence the
warnings generated.

Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
---
 target-riscv.c | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/target-riscv.c b/target-riscv.c
index 80c25285..ddf50e61 100644
--- a/target-riscv.c
+++ b/target-riscv.c
@@ -56,7 +56,7 @@ static void parse_march_riscv(const char *arg)
 
 	// Each -march=.. options entirely overrides previous ones
 	riscv_flags = 0;
-
+	
 	for (i = 0; i < ARRAY_SIZE(basic_sets); i++) {
 		const char *pat = basic_sets[i].pattern;
 		size_t len = strlen(pat);
@@ -80,6 +80,7 @@ ext:
 		if (!strncmp(arg, pat, len)) {
 			riscv_flags |= extensions[i].flags;
 			arg += len;
+			i = 0;
 		}
 	}
 	if (arg[0])
-- 
2.37.2.352.g3c44437643


================================================================================

From: Paul Walmsley <pjw () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 2/2] RISC-V: restart extension search on match
Date: Wed, 07 Jan 2026 20:42:24 +0000
Message-ID: <a273a46c-c90b-3895-c019-09a624ba43a4 () kernel ! org>
--------------------
On Fri, 2 Jan 2026, Ben Dooks wrote:

> If we are passed multiple extensions in -march, don't assume these will
> be in any sort of order. If we do match, then restart the loop by setting
> the search back to 0, and retrying.
> 
> This sorts out issues with the current kernel build where there are now
> lots of extensions for the rv64i and even adding zacas doesn't silence the
> warnings generated.
> 
> Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
> ---
>  target-riscv.c | 3 ++-
>  1 file changed, 2 insertions(+), 1 deletion(-)
> 
> diff --git a/target-riscv.c b/target-riscv.c
> index 80c25285..ddf50e61 100644
> --- a/target-riscv.c
> +++ b/target-riscv.c
> @@ -56,7 +56,7 @@ static void parse_march_riscv(const char *arg)
>  
>  	// Each -march=.. options entirely overrides previous ones
>  	riscv_flags = 0;
> -
> +	

Looks like some horizontal whitespace was inadvertently added here.

>  	for (i = 0; i < ARRAY_SIZE(basic_sets); i++) {
>  		const char *pat = basic_sets[i].pattern;
>  		size_t len = strlen(pat);
> @@ -80,6 +80,7 @@ ext:
>  		if (!strncmp(arg, pat, len)) {
>  			riscv_flags |= extensions[i].flags;
>  			arg += len;
> +			i = 0;
>  		}
>  	}
>  	if (arg[0])


Tested-by: Paul Walmsley <pjw@kernel.org>


- Paul

================================================================================


################################################################################

=== Thread: [PATCH RESEND2 1/4] parse: initial parsing of __attribute__((format)) ===

From: Chris Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH RESEND2 1/4] parse: initial parsing of __attribute__((format))
Date: Sat, 17 Jan 2026 00:14:50 +0000
Message-ID: <CACePvbWpTrKpFXLr4=vkVpDqhU7wd=RMOy4Wm1gAKhVtEv9=wQ () mail ! gmail ! com>
--------------------
On Mon, Dec 22, 2025 at 3:49=E2=80=AFAM Ben Dooks <ben.dooks@codethink.co.u=
k> wrote:
>
> On 01/12/2025 19:23, Chris Li wrote:
> > Hi Ben,
> >
> > Thanks for the patch and sorry for the late reply.
> >
> > Your format attribute series work applies to the sparse-dev tree fine
> > and "make check" runs fine as well. Thank you so much.
> >
> > I have some trivial coding style of feedback for you, see the comments
> > below. Mostly just nitpicks, does not impact the coding behavior. Let
> > me know if you want to update a new series or I can be lazy and just
> > apply your current series.
>
> Thank you. I've implemented most of your parse.c/symbol.h changes now.

Great.

>
> I am not actually back at work until 2nd-Jan 2026 so may not get
> all the other changes sorted.
>
No problem. I just started catching up on my backlogs from the holiday.

Chris

================================================================================


################################################################################

=== Thread: [PATCH v2 3/3] module: Add compile-time check for embedded NUL characters ===

From: Chris Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH v2 3/3] module: Add compile-time check for embedded NUL characters
Date: Fri, 16 Jan 2026 23:35:06 +0000
Message-ID: <CACePvbU5Pqo=bw_j8arOq16o1JBOSwPtuMZBVozy4FV7YsSLGw () mail ! gmail ! com>
--------------------
On Fri, Dec 19, 2025 at 6:59=E2=80=AFAM Matthieu Baerts <matttbe@kernel.org=
> wrote:
>
> Hi Dan, Daniel
>
> On 19/12/2025 13:44, Dan Carpenter wrote:
> > On Fri, Dec 19, 2025 at 01:29:21PM +0100, Matthieu Baerts wrote:
> >> net/mptcp/crypto_test.c:72:1: error: bad integer constant expression
> >> net/mptcp/crypto_test.c:72:1: error: static assertion failed: "MODULE_=
INFO(license, ...) contains embedded NUL byte"
> >> net/mptcp/crypto_test.c:73:1: error: bad integer constant expression
> >> net/mptcp/crypto_test.c:73:1: error: static assertion failed: "MODULE_=
INFO(description, ...) contains embedded NUL byte"
> >
> > There was a fix for that posted.  Let me ping them to see if anyone is
> > planning to send an actual patch.

Should I wait for the actual patch for sparse?

> >
> > https://lore.kernel.org/all/20251211175101.GA3405942@google.com/
>
> Thank you both for your reply! I didn't think about looking at the v1.
>
> I confirm that Sami's patch silences the errors on my side. Thanks!

Thanks for the report.

Chris

================================================================================


################################################################################

=== Thread: [PATCH v3 0/3] kbuild: remove gcc's -Wtype-limits ===

From: Nathan Chancellor <nathan () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH v3 0/3] kbuild: remove gcc's -Wtype-limits
Date: Mon, 05 Jan 2026 23:56:46 +0000
Message-ID: <176765740692.3236304.10853846154010651497.b4-ty () kernel ! org>
--------------------
On Sat, 20 Dec 2025 12:02:18 +0100, Vincent Mailhol wrote:
> I often read on the mailing list people saying "who cares about W=2
> builds anyway?". At least I do. Not that I want to fix all of them,
> but on some occasions, such as new driver submissions, I have often
> found a couple valid diagnostics in the W=2 output.
> 
> That said, the annoying thing is that W=2 is heavily polluted by one
> warning: -Wtype-limits. Try a gcc W=2 build on any file and see the
> results for yourself. I suspect this to be the reason why so few
> people are using W=2.
> 
> [...]

Applied to

  https://git.kernel.org/pub/scm/linux/kernel/git/kbuild/linux.git kbuild-next

Thanks!

[1/3] kbuild: remove gcc's -Wtype-limits
      https://git.kernel.org/kbuild/c/660e899103e29
[2/3] kbuild: cleanup local -Wno-type-limits exceptions
      https://git.kernel.org/kbuild/c/34a1bd0b6b2c0
[3/3] overflow: Remove is_non_negative() and is_negative()
      https://git.kernel.org/kbuild/c/5ce3218d4f102

Please look out for regression or issue reports or other follow up
comments, as they may result in the patch/series getting dropped or
reverted.

Best regards,
-- 
Nathan Chancellor <nathan@kernel.org>


================================================================================


################################################################################

=== Thread: [PATCH v3 1/4] parse: initial parsing of __attribute__((format)) ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: [PATCH v3 1/4] parse: initial parsing of __attribute__((format))
Date: Fri, 16 Jan 2026 17:58:06 +0000
Message-ID: <20260116175809.6849-2-ben.dooks () codethink ! co ! uk>
--------------------
Add code to parse the __attribute__((format)) used to indicate that
a variadic function takes a printf-style format string and where
those are. Save the data in ctype ready for checking when such an
function is encoutered.

Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
--
v2:
  - apply comments about arg names and early-exit from function
  - remove the KW_UNUSED
---
 parse.c  | 83 +++++++++++++++++++++++++++++++++++++++++++++++++++++++-
 symbol.h | 10 +++++--
 2 files changed, 90 insertions(+), 3 deletions(-)

diff --git a/parse.c b/parse.c
index 3f67451e..8d587c07 100644
--- a/parse.c
+++ b/parse.c
@@ -86,7 +86,7 @@ static attr_t
 	attribute_cleanup,
 	attribute_designated_init,
 	attribute_transparent_union, ignore_attribute,
-	attribute_mode, attribute_force;
+	attribute_mode, attribute_force, attribute_format;
 
 typedef struct symbol *to_mode_t(struct symbol *);
 
@@ -121,6 +121,12 @@ static void asm_modifier(struct token *token, unsigned long *mods, unsigned long
 	*mods |= mod;
 }
 
+/* the types of formatting from __attribute__((format)) */
+enum {
+	FMT_PRINTF = 0,
+	FMT_SCANF,
+};
+
 static struct symbol_op typedef_op = {
 	.type = KW_MODIFIER,
 	.declarator = storage_specifier,
@@ -382,6 +388,10 @@ static struct symbol_op attr_force_op = {
 	.attribute = attribute_force,
 };
 
+static struct symbol_op attr_format_op = {
+	.attribute = attribute_format,
+};
+
 static struct symbol_op address_space_op = {
 	.attribute = attribute_address_space,
 };
@@ -441,6 +451,16 @@ static struct symbol_op mode_word_op = {
 	.to_mode = to_word_mode
 };
 
+static struct symbol_op attr_printf_op = {
+	.type	= KW_FORMAT,
+	.class	= FMT_PRINTF,
+};
+
+static struct symbol_op attr_scanf_op = {
+	.type	= KW_FORMAT,
+	.class	= FMT_SCANF,
+};
+
 /*
  * Define the keyword and their effects.
  * The entries in the 'typedef' and put in NS_TYPEDEF and
@@ -557,6 +577,9 @@ static struct init_keyword {
 	D("pure",		&attr_fun_op,		.mods = MOD_PURE),
 	A("const",		&attr_fun_op,		.mods = MOD_PURE),
 	D("gnu_inline",		&attr_fun_op,		.mods = MOD_GNU_INLINE),
+	D("format",		&attr_format_op),
+	D("printf",		&attr_printf_op),
+	D("scanf",		&attr_scanf_op),
 
 	/* Modes */
 	D("mode",		&mode_op),
@@ -1217,6 +1240,62 @@ static struct token *attribute_address_space(struct token *token, struct symbol
 	return token;
 }
 
+static int invalid_format_args(long long start, long long at)
+{
+	return start < 0 || at < 0 || start > USHRT_MAX || at > USHRT_MAX ||
+		(start == at && start > 0) ||
+		(start == 0 && at == 0);
+}
+
+static struct token *attribute_format(struct token *token, struct symbol *attr, struct decl_state *ctx)
+{
+	struct expression *arg_type, *arg_fmt, *arg_argpos;
+	struct symbol *fmt_sym = NULL;
+	long long start, at;
+
+	/* expecting format ( type, fmt, va_args at) */
+
+	token = expect(token, '(', "after format attribute");
+	if (token_type(token) == TOKEN_IDENT)
+		fmt_sym = lookup_keyword(token->ident, NS_KEYWORD);
+	if (fmt_sym && (!fmt_sym->op || fmt_sym->op->type != KW_FORMAT))
+		fmt_sym = NULL;
+
+	token = conditional_expression(token, &arg_type);
+	token = expect(token, ',', "format attribute type");
+	token = conditional_expression(token, &arg_fmt);
+	token = expect(token, ',', "format attribute type position");
+	token = conditional_expression(token, &arg_argpos);
+	token = expect(token, ')', "format attribute arg position");
+
+	if (!fmt_sym || !arg_type || !arg_fmt || !arg_argpos) {
+		warning(token->pos, "missing format attribute argument(s)");
+		return token;
+	}
+
+	if (fmt_sym->op->class != FMT_PRINTF) {
+		/* skip anything that isn't printf for the moment */
+		warning(token->pos, "only printf format attribute supported");
+		return token;
+	}
+
+	start = get_expression_value(arg_argpos);
+	at = get_expression_value(arg_fmt);
+
+	if (invalid_format_args(start, at)) {
+		warning(token->pos, "bad format positions");
+	} else if (start == 0) {
+		/* nothing to do here, is va_list function */
+	} else if (start < at) {
+		warning(token->pos, "format cannot be after va_args");
+	} else {
+		ctx->ctype.format.index = at;
+		ctx->ctype.format.first = start;
+	}
+
+	return token;
+}
+
 static struct symbol *to_QI_mode(struct symbol *ctype)
 {
 	if (ctype->ctype.base_type != &int_type)
@@ -3007,6 +3086,8 @@ struct token *external_declaration(struct token *token, struct symbol_list **lis
 
 		if (!(decl->ctype.modifiers & MOD_STATIC))
 			decl->ctype.modifiers |= MOD_EXTERN;
+
+		base_type->ctype.format = decl->ctype.format;
 	} else if (base_type == &void_ctype && !(decl->ctype.modifiers & MOD_EXTERN)) {
 		sparse_error(token->pos, "void declaration");
 	}
diff --git a/symbol.h b/symbol.h
index 88130c15..8cc61cdb 100644
--- a/symbol.h
+++ b/symbol.h
@@ -82,8 +82,8 @@ enum keyword {
 	KW_ASM		= 1 << 5,
 	KW_MODE		= 1 << 6,
 	KW_STATIC	= 1 << 7,
-     // KW UNUSED	= 1 << 8,
-	KW_EXACT	= 1 << 9,
+	KW_EXACT	= 1 << 8,
+	KW_FORMAT	= 1 << 9,
 };
 
 struct context {
@@ -95,12 +95,18 @@ extern struct context *alloc_context(void);
 
 DECLARE_PTR_LIST(context_list, struct context);
 
+struct attr_format {
+	unsigned short index;	/* index in argument list for format string */
+	unsigned short first;	/* where first variadic argument is */
+};
+
 struct ctype {
 	struct symbol *base_type;
 	unsigned long modifiers;
 	unsigned long alignment;
 	struct context_list *contexts;
 	struct ident *as;
+	struct attr_format format;
 };
 
 struct decl_state {
-- 
2.37.2.352.g3c44437643


================================================================================


################################################################################

=== Thread: [PATCH v3 2/4] add -Wformat ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: [PATCH v3 2/4] add -Wformat
Date: Fri, 16 Jan 2026 17:58:07 +0000
Message-ID: <20260116175809.6849-3-ben.dooks () codethink ! co ! uk>
--------------------
Add option to enable/disable format checking (and default it to off)

Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
---
 options.c | 2 ++
 options.h | 1 +
 sparse.1  | 8 ++++++++
 3 files changed, 11 insertions(+)

diff --git a/options.c b/options.c
index 6ee4d878..54ac00b4 100644
--- a/options.c
+++ b/options.c
@@ -106,6 +106,7 @@ int Wflexible_array_array = 1;
 int Wflexible_array_nested = 0;
 int Wflexible_array_sizeof = 0;
 int Wflexible_array_union = 0;
+int Wformat = 0;
 int Wimplicit_int = 1;
 int Winit_cstring = 0;
 int Wint_to_pointer_cast = 1;
@@ -865,6 +866,7 @@ static const struct flag warnings[] = {
 	{ "flexible-array-nested", &Wflexible_array_nested },
 	{ "flexible-array-sizeof", &Wflexible_array_sizeof },
 	{ "flexible-array-union", &Wflexible_array_union },
+	{ "format", &Wformat },
 	{ "implicit-int", &Wimplicit_int },
 	{ "init-cstring", &Winit_cstring },
 	{ "int-to-pointer-cast", &Wint_to_pointer_cast },
diff --git a/options.h b/options.h
index c2a9551a..105c45d0 100644
--- a/options.h
+++ b/options.h
@@ -106,6 +106,7 @@ extern int Wflexible_array_array;
 extern int Wflexible_array_nested;
 extern int Wflexible_array_sizeof;
 extern int Wflexible_array_union;
+extern int Wformat;
 extern int Wimplicit_int;
 extern int Winit_cstring;
 extern int Wint_to_pointer_cast;
diff --git a/sparse.1 b/sparse.1
index 2fba7e7a..64b0571e 100644
--- a/sparse.1
+++ b/sparse.1
@@ -285,6 +285,14 @@ To have any effect, at least one of \fB-Wflexible-array-array\fR,
 be enabled.
 
 Sparse does issue these warnings by default.
+.B \-Wformat
+Warn about parameter mismatch to any variadic function which specifies
+where the format string is specified with the 
+.BI __attribute__((format( type, message, va_start )))
+attribute.
+
+Sparse does not issue these warnings by default. To turn them on, use
+\fB\-W-format\fR.
 .
 .TP
 .B \-Winit\-cstring
-- 
2.37.2.352.g3c44437643


================================================================================


################################################################################

=== Thread: [PATCH v3 3/4] evaluate: check variadic argument types against formatting info ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: [PATCH v3 3/4] evaluate: check variadic argument types against formatting info
Date: Fri, 16 Jan 2026 17:58:08 +0000
Message-ID: <20260116175809.6849-4-ben.dooks () codethink ! co ! uk>
--------------------
The variadic argumebt code did not check any of the variadic arguments
as it did not previously know the possible type. Now we have the possible
formatting information stored in the ctype, we can do some checks on the
printf formatting types.

Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
--
V2:
  - try and reduce size/if nesting of parse_printf_get_fmt()
  - change return for parse_format_printf() and try and simplify
  - reworked the test code to reduce numner of test functions
  - bailed out early if verification isn't ok
V3:
  - fixed issue with kernel testing
  - fixed logic error in one check
---
 Makefile        |   1 +
 builtin.c       |   4 +-
 evaluate.c      |  14 +-
 evaluate.h      |  10 +-
 verify-format.c | 461 ++++++++++++++++++++++++++++++++++++++++++++++++
 verify-format.h |   6 +
 6 files changed, 489 insertions(+), 7 deletions(-)
 create mode 100644 verify-format.c
 create mode 100644 verify-format.h

diff --git a/Makefile b/Makefile
index e172758b..670e95aa 100644
--- a/Makefile
+++ b/Makefile
@@ -90,6 +90,7 @@ LIB_OBJS += tokenize.o
 LIB_OBJS += unssa.o
 LIB_OBJS += utils.o
 LIB_OBJS += version.o
+LIB_OBJS += verify-format.o
 
 PROGRAMS :=
 PROGRAMS += compile
diff --git a/builtin.c b/builtin.c
index 3a29c3ae..e4751445 100644
--- a/builtin.c
+++ b/builtin.c
@@ -438,7 +438,7 @@ static int evaluate_generic_int_op(struct expression *expr)
 		NEXT_PTR_LIST(t);
 	} END_FOR_EACH_PTR(arg);
 	FINISH_PTR_LIST(t);
-	return evaluate_arguments(types, expr->args);
+	return evaluate_arguments(NULL, types, expr->args);
 
 err:
 	sparse_error(arg->pos, "non-integer type for argument %d:", n);
@@ -502,7 +502,7 @@ static int eval_atomic_common(struct expression *expr)
 
 	if (!expr->ctype)	// set the return type, if needed
 		expr->ctype = ctype;
-	return evaluate_arguments(types, expr->args);
+	return evaluate_arguments(NULL, types, expr->args);
 
 err:
 	sparse_error(arg->pos, "invalid type for argument %d:", n);
diff --git a/evaluate.c b/evaluate.c
index fe716f63..4ffbba73 100644
--- a/evaluate.c
+++ b/evaluate.c
@@ -42,6 +42,7 @@
 #include "symbol.h"
 #include "target.h"
 #include "expression.h"
+#include "verify-format.h"
 
 struct symbol *current_fn;
 
@@ -1386,8 +1387,8 @@ static int whitelist_pointers(struct symbol *t1, struct symbol *t2)
 	return !Wtypesign;
 }
 
-static int check_assignment_types(struct symbol *target, struct expression **rp,
-	const char **typediff)
+int check_assignment_types(struct symbol *target, struct expression **rp,
+			   const char **typediff)
 {
 	struct symbol *source = degenerate(*rp);
 	struct symbol *t, *s;
@@ -2324,7 +2325,8 @@ static struct symbol *evaluate_alignof(struct expression *expr)
 	return size_t_ctype;
 }
 
-int evaluate_arguments(struct symbol_list *argtypes, struct expression_list *head)
+int evaluate_arguments(struct symbol *fn, struct symbol_list *argtypes,
+		       struct expression_list *head)
 {
 	struct expression *expr;
 	struct symbol *argtype;
@@ -2365,6 +2367,10 @@ int evaluate_arguments(struct symbol_list *argtypes, struct expression_list *hea
 		NEXT_PTR_LIST(argtype);
 	} END_FOR_EACH_PTR(expr);
 	FINISH_PTR_LIST(argtype);
+
+	if (fn && Wformat)
+		verify_format_attribute(fn, head);
+
 	return 1;
 }
 
@@ -3191,7 +3197,7 @@ static struct symbol *evaluate_call(struct expression *expr)
 		if (!sym->op->args(expr))
 			return NULL;
 	} else {
-		if (!evaluate_arguments(ctype->arguments, arglist))
+		if (!evaluate_arguments(ctype, ctype->arguments, arglist))
 			return NULL;
 		args = expression_list_size(expr->args);
 		fnargs = symbol_list_size(ctype->arguments);
diff --git a/evaluate.h b/evaluate.h
index a16e9703..3f51129d 100644
--- a/evaluate.h
+++ b/evaluate.h
@@ -28,8 +28,16 @@ void evaluate_symbol_list(struct symbol_list *list);
 
 ///
 // evaluate the arguments of a function
+// @fn: the symbol of the prototype
 // @argtypes: the list of the types in the prototype
 // @args: the list of the effective arguments
-int evaluate_arguments(struct symbol_list *argtypes, struct expression_list *args);
+int evaluate_arguments(struct symbol *fn, struct symbol_list *argtypes, struct expression_list *args);
 
+///
+// check if assignment types are compatible
+// @target: the target assignment
+// @rp: the expression
+// @typediff: the resulant message if different type
+int check_assignment_types(struct symbol *target, struct expression **rp,
+			   const char **typediff);
 #endif
diff --git a/verify-format.c b/verify-format.c
new file mode 100644
index 00000000..f7e6c20b
--- /dev/null
+++ b/verify-format.c
@@ -0,0 +1,461 @@
+/*
+ * sparse/verify-format.c
+ *
+ * Copyright (C) 2019 Codethink Ltd.
+ *	Written by Ben Dooks <ben.dooks@codethink.co.uk>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ *
+ * Verification code for format-attributes (currently printf)
+ */
+#include <stdlib.h>
+#include <stdarg.h>
+#include <stddef.h>
+#include <stdio.h>
+#include <string.h>
+#include <ctype.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <limits.h>
+
+#include "evaluate.h"
+#include "lib.h"
+#include "allocate.h"
+#include "parse.h"
+#include "token.h"
+#include "symbol.h"
+#include "target.h"
+#include "expression.h"
+#include "verify-format.h"
+
+struct format_type {
+	const char	*format;
+	int		(*test)(struct format_type *fmt,
+				struct expression **expr,
+				struct symbol *ctype,
+				struct symbol **target,
+				const char **typediff);
+	struct symbol	*data;
+};
+
+struct format_state {
+	struct expression	*expr;
+	unsigned int		first;
+	unsigned int		fmt_index;
+	unsigned int		arg_index;
+	unsigned int		used_position: 1;
+};
+
+static int printf_fmt_type(struct format_type *fmt,
+			   struct expression **expr,
+			   struct symbol *ctype,
+			   struct symbol **target, const char **typediff)
+{
+	struct symbol *type = fmt->data;
+	*target = type;
+	return check_assignment_types(*target, expr, typediff);
+}
+
+static int printf_fmt_print_pointer(struct format_type *fmt,
+				    struct expression **expr,
+				    struct symbol *ctype,
+				    struct symbol **target,
+				    const char **typediff)
+{
+	int ret;
+	*target = &const_ptr_ctype;
+	ret = check_assignment_types(*target, expr, typediff);
+	if (ret == 0) {
+		/* if just printing, ignore address-space mismatches */
+		if (strcmp(*typediff, "different address spaces") == 0)
+			ret = 1;
+	}
+	return ret;
+}
+static struct expression *get_nth_expression(struct expression_list *args, int nr)
+{
+	return ptr_list_nth_entry((struct ptr_list *)args, nr);
+}
+
+static struct format_type *parse_printf_get_fmt(struct format_type *type,
+						const char *msg,
+						const char **msgout)
+{
+	const char *ptr = msg;
+	int szmod = 0;
+
+	type->test = NULL;
+	*msgout = ptr;
+
+retry:
+	switch (*ptr++) {
+	case 's':
+		type->test = printf_fmt_type;
+		type->data = &const_string_ctype;
+		break;
+	case 'c':
+		type->test = printf_fmt_type;
+		type->data = &char_ctype;
+		break;
+	case 'p':
+		type->test = printf_fmt_print_pointer;
+		/* check for pointer being printed as hex explicitly */
+		if (*ptr == 'x' || *ptr == 'X') {
+			ptr++;
+		} else if (isalpha(*ptr)) {
+			/* probably some extra specifiers after %p or some
+			 * linux kernel extension */
+			ptr++;
+			type->data = &const_ptr_ctype;
+			type->test = printf_fmt_type;
+		}
+		break;
+	case 'z':
+		if (*ptr == 'd' || *ptr == 'i') {
+			ptr++;
+			type->test = printf_fmt_type;
+			type->data = ssize_t_ctype;
+		} else if (*ptr == 'u' || *ptr == 'x' || *ptr == 'X' ||
+			   *ptr == 'o') {
+			ptr++;
+			type->test = printf_fmt_type;
+			type->data = size_t_ctype;
+		}
+		break;
+
+	case 'n':
+		/* pointer to an interger to write count into */
+		type->data = intptr_ctype;
+		type->test = printf_fmt_type;
+		break;
+	case 'l':
+		szmod++;
+		goto retry;
+
+	case 'h':
+		szmod = -1;
+		if (*ptr == 'h')  // promotion from char
+			ptr++;
+		goto retry;
+	case 't':
+		szmod = 2;
+		goto retry;
+
+	case 'j':
+		szmod = 3;
+		goto retry;
+	case 'x':
+	case 'X':
+	case 'u':
+	case 'o':
+		type->test = printf_fmt_type;
+		switch (szmod) {
+		case -1:
+			type->data = &ushort_ctype;
+			break;
+		case 0:
+			type->data = &uint_ctype;
+			break;
+		case 1:
+			type->data = &ulong_ctype;
+			break;
+		case 2:
+			type->data = &ullong_ctype;
+			break;
+		case 3:
+			type->data = uintmax_ctype;
+			break;
+		}
+		break;
+	case 'i':
+	case 'd':
+		type->test = printf_fmt_type;
+		switch (szmod) {
+		case -1:
+			type->data = &short_ctype;
+			break;
+		case 0:
+			type->data = &int_ctype;
+			break;
+		case 1:
+			type->data = &long_ctype;
+			break;
+		case 2:
+			type->data = &llong_ctype;
+			break;
+		case 3:
+			type->data = intmax_ctype;
+			break;
+		}
+		break;
+	case 'L':
+		szmod = 1;
+		goto retry;
+	case 'f':
+	case 'F':
+	case 'g':
+	case 'G':
+		type->test = printf_fmt_type;
+		type->data = szmod == 1 ? &ldouble_ctype :  &double_ctype;
+		break;
+
+	default:
+		return NULL;
+	}
+
+	*msgout = ptr;
+	return type;
+}
+
+static int is_printf_flag(char ch)
+{
+	return ch == '0' || ch == '+' || ch == '-' || ch == ' ' || ch == '#';
+}
+
+static int printf_check_position(const char **fmt)
+{
+	const char *ptr= *fmt;
+
+	if (!isdigit(*ptr))
+		return -1;
+	while (isdigit(*ptr))
+		ptr++;
+	if (*ptr == '$') {
+		const char *pos = *fmt;
+		*fmt = ptr+1;
+		return strtoul(pos, NULL, 10);
+	}
+	return -1;
+}
+
+static void parse_format_printf_checkpos(struct format_state *state,
+					 const char *which)
+{
+	if (state->used_position) {
+		warning(state->expr->pos,
+			"format %d: %s: no position specified",
+			state->arg_index-1, which);
+	}
+}
+
+static int parse_format_printf_argfield(const char **fmtptr,
+					struct format_state *state,
+					struct expression_list *args,
+					int *pos, const char *which)
+{
+	struct expression *expr;
+	struct symbol *ctype;
+	const char *fmt = *fmtptr;
+	int argpos = -1;
+
+	/* check for simple digit-string width/precision specifier first */
+	if (*fmt != '*') {
+		while (isdigit(*fmt))
+			fmt++;
+		*fmtptr = fmt;
+		return 0;
+	}
+
+	fmt++;
+	argpos = printf_check_position(&fmt);
+
+	if (argpos > 0) {
+		argpos += state->first - 1;
+		state->used_position = 1;
+	} else {
+		argpos = (*pos)++;
+		state->arg_index++;
+		parse_format_printf_checkpos(state, which);
+	}
+
+	*fmtptr = fmt;
+	expr = get_nth_expression(args, argpos-1);
+	if (!expr) {
+		warning(state->expr->pos, "%s: no argument at position %d",
+			which, argpos);
+		return 1;
+	}
+
+	/* check the value we got was int/uint type */
+	ctype = expr->ctype;
+	if (ctype) {
+		struct symbol *target = &int_ctype;
+
+		if (ctype != &int_ctype && ctype != &uint_ctype) {
+			warning(expr->pos, "incorrect type for %s argument %d", which, argpos);
+			info(expr->pos, "   expected %s", show_typename(target));
+			info(expr->pos, "   got %s", show_typename(ctype));
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * printf format parsing code
+ *
+ * this code currently does not:
+ * - check castable types (such as int vs long vs long long)
+ * - validate all arguments specified are also used...
+ */
+static int parse_format_printf(const char **fmtstring,
+			       struct format_state *state,
+			       struct expression_list *args)
+{
+	struct symbol *ctype, *target = NULL;
+	const char *typediff = "different types";
+	struct format_type ftype;	/* temp storage for format info */
+	struct format_type *type;	/* type found from the parse */
+	struct expression *expr;
+	const char *fmt = *fmtstring;	/* pointer to parse position */
+	const char *fmtpost = NULL;	/* moved to end of the parsed format */
+	int pos = state->arg_index;	/* position of the argument */
+	int error = 0;
+	int ret;
+
+	if (!fmt) {
+		warning(state->expr->pos, "no format string passed");
+		return -1;
+	}
+
+	/* trivial check for %% */
+	fmt++;
+	if (fmt[0] == '%') {
+		*fmtstring = fmt+1;
+		return 0;
+	}
+
+	state->arg_index++;
+	state->fmt_index++;
+
+	ret = printf_check_position(&fmt);
+	if (ret == 0) {
+		/* we got an invalid position argument */
+		error++;
+	} else if (ret < 0) {
+		parse_format_printf_checkpos(state, "position");
+	} else {
+		state->used_position = 1;
+		pos = ret + state->first - 1;
+	}
+
+	/* get rid of any formatting flag bits */
+	while (is_printf_flag(*fmt))
+		fmt++;
+
+	/* now there is the posibility of a width specifier */
+	if (parse_format_printf_argfield(&fmt, state, args, &pos, "width"))
+		error++;
+
+	/* now we might have the precision specifier */
+	if (*fmt == '.') {
+		fmt++;
+		if (parse_format_printf_argfield(&fmt, state, args, &pos, "position"))
+			error++;
+	}
+
+	type = parse_printf_get_fmt(&ftype, fmt, &fmtpost);
+	if (!type) {
+		/* assume it's a single character we just don't know about
+		 * such as a linux-kernel extended format.
+		 */
+		fmtpost = *fmtstring + 2;
+		warning(state->expr->pos, "cannot evaluate type '%.*s'",
+			(int)(fmtpost - *fmtstring), *fmtstring);
+		*fmtstring += 1;
+		return -1;
+	}
+
+	*fmtstring = fmtpost;
+	expr = get_nth_expression(args, pos-1);
+	if (!expr) {
+		/* no argument, but otherwise valid argument string */
+		warning(state->expr->pos, "no argument at position '%d'", pos);
+		return 0;
+	}
+
+	ctype = expr->ctype;
+	if (!ctype)
+		return -1;
+
+	ret = type->test(type, &expr, ctype, &target, &typediff);
+	if (!target)	/* shouldn't happen, but catch anyway */
+		return -1;
+	if (ret)
+		return 0;
+
+	warning(expr->pos, "incorrect type in argument %d (%s)", pos, typediff);
+	info(expr->pos, "   expected %s", show_typename(target));
+	info(expr->pos, "   got %s", show_typename(ctype));
+	return 1;
+}
+
+/*
+ * attempt to run through a printf format string and work out the types
+ * it specifies. The format is parsed from the __attribute__(format())
+ * in the parser code which stores the positions of the message and arg
+ * start in the ctype.
+ */
+void verify_format_attribute(struct symbol *fn, struct expression_list *args)
+{
+	struct format_state state = { };
+	struct expression *expr;
+	struct expression *init;
+	const char *string, *fmt_string;
+	int fail = 0;
+
+	if (!fn->ctype.format.index)
+		return;
+
+	expr = get_nth_expression(args, fn->ctype.format.index-1);
+	if (!expr)
+		return;
+
+	if (expr->type != EXPR_SYMBOL || expr->symbol->ident)
+		return;			// not a literal
+	init = expr->symbol->initializer;
+	if (!init || init->type != EXPR_STRING)
+		return;			// not a string
+	fmt_string = init->string->data;
+
+	state.expr = expr;
+	state.first = fn->ctype.format.first;
+	state.arg_index = fn->ctype.format.first;
+
+	if (!fmt_string) {
+		warning(expr->pos, "not a format string?");
+		return;
+	}
+
+	string = fmt_string;
+	while (string[0]) {
+		if (string[0] != '%') {
+			/* strip anything before the '%' */
+			string++;
+			continue;
+		}
+
+		if (parse_format_printf(&string, &state, args) < 0)
+			fail++;
+	}
+
+	if (fail > 0)
+		/* format string may have '\n' etc embedded in it */
+		warning(expr->pos, "cannot evaluate format string");
+}
diff --git a/verify-format.h b/verify-format.h
new file mode 100644
index 00000000..4a7ef79d
--- /dev/null
+++ b/verify-format.h
@@ -0,0 +1,6 @@
+#ifndef VERIFY_FORMAT_H
+#define VERIFY_FORMAT_H
+
+void verify_format_attribute(struct symbol *fn, struct expression_list *args);
+
+#endif
-- 
2.37.2.352.g3c44437643


================================================================================


################################################################################

=== Thread: [PATCH v3 4/4] tests: add varargs printf format tests ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: [PATCH v3 4/4] tests: add varargs printf format tests
Date: Fri, 16 Jan 2026 17:58:09 +0000
Message-ID: <20260116175809.6849-5-ben.dooks () codethink ! co ! uk>
--------------------
Add some tests for the new printf format checking code.
Note, these do not all pass yet.

Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
---
 validation/varargs-format-addrspace1.c |  36 ++++++++
 validation/varargs-format-bad.c        |  18 ++++
 validation/varargs-format-checking.c   |  21 +++++
 validation/varargs-format-position.c   |  32 +++++++
 validation/varargs-format-prefix.c     |  19 ++++
 validation/varargs-format-tests.c      |  55 ++++++++++++
 validation/varargs-type-formattest.c   | 117 +++++++++++++++++++++++++
 7 files changed, 298 insertions(+)
 create mode 100644 validation/varargs-format-addrspace1.c
 create mode 100644 validation/varargs-format-bad.c
 create mode 100644 validation/varargs-format-checking.c
 create mode 100644 validation/varargs-format-position.c
 create mode 100644 validation/varargs-format-prefix.c
 create mode 100644 validation/varargs-format-tests.c
 create mode 100644 validation/varargs-type-formattest.c

diff --git a/validation/varargs-format-addrspace1.c b/validation/varargs-format-addrspace1.c
new file mode 100644
index 00000000..3370ac67
--- /dev/null
+++ b/validation/varargs-format-addrspace1.c
@@ -0,0 +1,36 @@
+
+extern int variadic(char *msg, ...) __attribute__((format (printf, 1, 2)));
+extern int variadic2(char *msg, int , ...) __attribute__((format (printf, 1, 3)));
+extern int variadic3(int, char *msg,  ...) __attribute__((format (printf, 2, 3)));
+
+static void test(void) {
+	void __attribute__((noderef, address_space(1))) *a;
+	void *b;
+
+	variadic("%s\n", a);
+	variadic("%s\n", b);
+	variadic("%s %s\n", b, a);
+	variadic2("%s %s\n", 1, b, a);
+	variadic3(1, "%s %s\n", b, a);
+	variadic3(1, "%s %p\n", b, a);
+}
+
+/*
+ * check-name: variadic formatting test with address-space to %s
+ * check-command: sparse -Wformat $file
+ *
+ * check-error-start
+varargs-format-addrspace1.c:10:26: warning: incorrect type in argument 2 (different address spaces)
+varargs-format-addrspace1.c:10:26:    expected char const *
+varargs-format-addrspace1.c:10:26:    got void [noderef] <asn:1> *a
+varargs-format-addrspace1.c:12:32: warning: incorrect type in argument 3 (different address spaces)
+varargs-format-addrspace1.c:12:32:    expected char const *
+varargs-format-addrspace1.c:12:32:    got void [noderef] <asn:1> *a
+varargs-format-addrspace1.c:13:36: warning: incorrect type in argument 4 (different address spaces)
+varargs-format-addrspace1.c:13:36:    expected char const *
+varargs-format-addrspace1.c:13:36:    got void [noderef] <asn:1> *a
+varargs-format-addrspace1.c:14:36: warning: incorrect type in argument 4 (different address spaces)
+varargs-format-addrspace1.c:14:36:    expected char const *
+varargs-format-addrspace1.c:14:36:    got void [noderef] <asn:1> *a
+ * check-error-end
+ */
diff --git a/validation/varargs-format-bad.c b/validation/varargs-format-bad.c
new file mode 100644
index 00000000..82ae357c
--- /dev/null
+++ b/validation/varargs-format-bad.c
@@ -0,0 +1,18 @@
+
+extern int variadic(char *msg, ...) __attribute__((format (printf, 0, 0)));
+extern int variadic2(char *msg, int , ...) __attribute__((format (printf, 2, 2)));
+extern int variadic3(char *msg, int , ...) __attribute__((format (printf, 2, 1)));
+
+static void test(void) {
+}
+
+/*
+ * check-name: variadic formatting test with bad formatting parameters
+ * check-command: sparse -Wformat $file
+ *
+ * check-error-start
+varargs-format-bad.c:2:73: warning: bad format positions
+varargs-format-bad.c:3:80: warning: bad format positions
+varargs-format-bad.c:4:80: warning: format cannot be after va_args
+* check-error-end
+ */
diff --git a/validation/varargs-format-checking.c b/validation/varargs-format-checking.c
new file mode 100644
index 00000000..9f3e5ac2
--- /dev/null
+++ b/validation/varargs-format-checking.c
@@ -0,0 +1,21 @@
+
+extern void pf(char *msg, ...) __attribute__((format (printf, 1, 2)));
+
+static void test(void) {
+	pf("%u %lu %llu\n", 1U, 1UL, 1ULL);
+	pf("%d %ld %lld\n", 1, 1L, 1LL);
+	pf("%x %lx %llx\n", 1U, 1UL, 1ULL);
+	pf("%d %ld %lld\n", 1, 1L, 1L);
+}
+
+/*
+ * check-name: variadic formatting test type checking
+ * check-command: sparse -Wformat $file
+ * check-known-to-fail
+ *
+ * check-error-start
+varargs-format-checking.c:8:36: warning: incorrect type in argument 4 (different types)
+varargs-format-checking.c:8:36:    expected long long
+varargs-format-checking.c:8:36:    got long
+ * check-error-end
+ */
diff --git a/validation/varargs-format-position.c b/validation/varargs-format-position.c
new file mode 100644
index 00000000..88a4dbc2
--- /dev/null
+++ b/validation/varargs-format-position.c
@@ -0,0 +1,32 @@
+
+extern void pf(char *msg, ...) __attribute__((format (printf, 1, 2)));
+
+static void test(void) {
+	pf("%2$d %u\n", 1U, 1L);
+	pf("%3$d %2$u\n", 1U, 1);
+	pf("%1$d %2$d\n", 1L, 1);
+}
+
+/*
+ * check-name: variadic formatting test position checking
+ * check-command: sparse -Wformat $file
+ * check-known-to-fail
+ *
+ * check-error-start
+varargs-format-position.c:5:29: warning: incorrect type in argument 3 (different types)
+varargs-format-position.c:5:29:    expected int
+varargs-format-position.c:5:29:    got long
+varargs-format-position.c:5:12: warning: format 3: position: no position specified
+varargs-format-position.c:5:29: warning: incorrect type in argument 3 (different types)
+varargs-format-position.c:5:29:    expected unsigned int
+varargs-format-position.c:5:29:    got long
+varargs-format-position.c:6:12: warning: no argument at position '4'
+varargs-format-position.c:6:31: warning: incorrect type in argument 3 (different types)
+varargs-format-position.c:6:31:    expected unsigned int
+varargs-format-position.c:6:31:    got int
+varargs-format-position.c:7:27: warning: incorrect type in argument 2 (different types)
+varargs-format-position.c:7:27:    expected int
+varargs-format-position.c:7:27:    got long
+ * check-error-end
+ *
+ */
diff --git a/validation/varargs-format-prefix.c b/validation/varargs-format-prefix.c
new file mode 100644
index 00000000..8e2456e6
--- /dev/null
+++ b/validation/varargs-format-prefix.c
@@ -0,0 +1,19 @@
+
+extern int __attribute__((format (printf, 1, 2))) variadic(char *msg, ...);
+
+static int test(void) {
+	void __attribute__((noderef, address_space(1))) *a;
+
+	variadic("%s\n", a);
+}
+
+/*
+ * check-name: variadic formatting test prefix based __attribute__
+ * check-command: sparse -Wformat $file
+ *
+ * check-error-start
+varargs-format-prefix.c:7:26: warning: incorrect type in argument 2 (different address spaces)
+varargs-format-prefix.c:7:26:    expected char const *
+varargs-format-prefix.c:7:26:    got void [noderef] <asn:1> *a
+ * check-error-end
+ */
diff --git a/validation/varargs-format-tests.c b/validation/varargs-format-tests.c
new file mode 100644
index 00000000..659bbe94
--- /dev/null
+++ b/validation/varargs-format-tests.c
@@ -0,0 +1,55 @@
+
+extern void pf(char *msg, ...) __attribute__((format (printf, 1, 2)));
+
+static int test(void)
+{
+	pf("%*d\n", 5, 10);		/* value 10, print width is 5 */
+	pf("%2$*1$d\n", 5, 10);		/* value 10, print width is 5 */
+	pf("%3$*2$d\n", 1, 5, 10);	/* ok, skipping the '1' */
+	pf("%3$-*2$d\n", 1, 5, 10);	/* ok, skipping the '1' */
+	pf("%3$*2$-d\n", 1, 5, 10);	/* bad, the "-" shouldn't be before the 'd' */
+	pf("%3$ *2$d\n", 1, 5, 10);	/* ok, skipping the '1' */
+	pf("%3$+*2$d\n", 1, 5, 10);	/* ok, skipping the '1' */
+	pf("%3$0+*2$d\n", 1, 5, 10);	/* ok, skipping the '1' */
+	pf("%3$+0*2$d\n", 1, 5, 10);	/* ok, skipping the '1' */
+	pf("%3$+#*2$d\n", 1, 5, 10);	/* ok, skipping the '1' */
+	pf("%3$+#*2$.5d\n", 1, 5, 10);	/* ok, skipping the '1' */
+
+	/* go with some precision as well as width strings */
+	pf("%2$+*1$.6d\n", 5, 10);	/* ok */
+	pf("%2$+*1$.*3$d\n", 5, 10, 6);	/* ok */
+	pf("%2$+*3$.*1$d\n", 6, 10, 5);	/* ok */
+	pf("%2$+*1$.*d\n", 5, 10, 6);	/* not ok */
+
+	pf("%s", "msg");
+	return 0;
+}
+
+static void test2(int x, int y, const void *p)
+{
+	pf("%02x%02x %8p\n", x, y, p);
+}
+
+static inline void fn(int x) { pf("%08x\n", x); }
+static void test3(int x)
+{
+	fn;
+	fn(x);
+}
+
+static void test4(int i, unsigned int u)
+{
+	pf("%d\n", i);
+	pf("%x\n", u);
+}
+
+/*
+ * check-name: variadic formatting tests for width/precisions
+ * check-command: sparse -Wformat $file
+ *
+ * check-error-start
+varargs-format-tests.c:10:12: warning: cannot evaluate type '%3$*2$-d'
+varargs-format-tests.c:10:12: warning: cannot evaluate format string
+varargs-format-tests.c:22:12: warning: format 3: position: no position specified
+ * check-error-end
+ */
diff --git a/validation/varargs-type-formattest.c b/validation/varargs-type-formattest.c
new file mode 100644
index 00000000..f01c6d89
--- /dev/null
+++ b/validation/varargs-type-formattest.c
@@ -0,0 +1,117 @@
+
+extern void pf1(char *msg, ...) __attribute__((format (printf, 1, 2)));
+extern void pf2(int m, char *msg, ...) __attribute__((format (printf, 2, 3)));
+
+/* run all the tests with both of these printf formatted types */
+#define pf(x...) do { pf1(x); pf2(1, x); } while(0);
+
+static void test(void) {
+	/* first two are valid */
+	pf("%*d", 5, 10);	/* value 10, print width is 5 */
+	pf("%2$*1$d", 5, 10);	/* value 10, print width is 5 */
+	pf("%2$*3$d", 5, 10);	/* value 10, print width is ?? */
+
+	pf("%*d", 5, 10);	/* value 10, print width is 5 */
+	pf("%*d", 5, 10L);	/* value 10, print width is 5 (bad type) */
+	pf("%*d", 5UL, 10L);	/* value 10, print width is 5 (bad type) */
+
+	pf("%3$*2$d", 1, 5, 10);	/* ok, skipping the '1' */
+	pf("%3$*2$d", 1, 5, 10L);	/* bad print type */
+	pf("%2$*3$d", 1UL, 10, 5);	/* ok, try with swapping width/val */
+	pf("%2$*3$d", 1UL, 10L, 5);	/* bad, try with swapping width/val */
+
+	/* and now try with precision specifiers */
+
+	pf("%*.6d", 5, 10);	/* value 10, print width is 5 */
+	pf("%*.6d", 5, 10L);	/* value 10, print width is 5 (bad type) */
+	pf("%*.6d", 5UL, 10L);	/* value 10, print width is 5 (bad type) */
+
+	pf("%*.*d", 5, 6, 10);	/* value 10, print width is 5 */
+	pf("%*.*d", 5, 6, 10L);	/* value 10, print width is 5 (bad type) */
+	pf("%*.*d", 5UL, 6, 10L); /* value 10, print width is 5 (bad type) */
+	pf("%*.*d", 5, 6UL, 10); /* value 10, print width is 5 (bad type) */
+}
+
+/*
+ * check-name: variadic formatting test position checking types
+ * check-command: sparse -Wformat $file
+ * check-known-to-fail
+ *
+ * check-error-start
+varargs-type-formattest.c:12:9: warning: width: no argument at position 4
+varargs-type-formattest.c:12:9: warning: width: no argument at position 5
+varargs-type-formattest.c:15:9: warning: incorrect type in argument 3 (different types)
+varargs-type-formattest.c:15:9:    expected int
+varargs-type-formattest.c:15:9:    got long
+varargs-type-formattest.c:15:9: warning: incorrect type in argument 4 (different types)
+varargs-type-formattest.c:15:9:    expected int
+varargs-type-formattest.c:15:9:    got long
+varargs-type-formattest.c:16:9: warning: incorrect type for width argument 2
+varargs-type-formattest.c:16:9:    expected int
+varargs-type-formattest.c:16:9:    got unsigned long
+varargs-type-formattest.c:16:9: warning: incorrect type in argument 3 (different types)
+varargs-type-formattest.c:16:9:    expected int
+varargs-type-formattest.c:16:9:    got long
+varargs-type-formattest.c:16:9: warning: incorrect type for width argument 3
+varargs-type-formattest.c:16:9:    expected int
+varargs-type-formattest.c:16:9:    got unsigned long
+varargs-type-formattest.c:16:9: warning: incorrect type in argument 4 (different types)
+varargs-type-formattest.c:16:9:    expected int
+varargs-type-formattest.c:16:9:    got long
+varargs-type-formattest.c:19:9: warning: incorrect type in argument 4 (different types)
+varargs-type-formattest.c:19:9:    expected int
+varargs-type-formattest.c:19:9:    got long
+varargs-type-formattest.c:19:9: warning: incorrect type in argument 5 (different types)
+varargs-type-formattest.c:19:9:    expected int
+varargs-type-formattest.c:19:9:    got long
+varargs-type-formattest.c:21:9: warning: incorrect type in argument 3 (different types)
+varargs-type-formattest.c:21:9:    expected int
+varargs-type-formattest.c:21:9:    got long
+varargs-type-formattest.c:21:9: warning: incorrect type in argument 4 (different types)
+varargs-type-formattest.c:21:9:    expected int
+varargs-type-formattest.c:21:9:    got long
+varargs-type-formattest.c:26:9: warning: incorrect type in argument 3 (different types)
+varargs-type-formattest.c:26:9:    expected int
+varargs-type-formattest.c:26:9:    got long
+varargs-type-formattest.c:26:9: warning: incorrect type in argument 4 (different types)
+varargs-type-formattest.c:26:9:    expected int
+varargs-type-formattest.c:26:9:    got long
+varargs-type-formattest.c:27:9: warning: incorrect type for width argument 2
+varargs-type-formattest.c:27:9:    expected int
+varargs-type-formattest.c:27:9:    got unsigned long
+varargs-type-formattest.c:27:9: warning: incorrect type in argument 3 (different types)
+varargs-type-formattest.c:27:9:    expected int
+varargs-type-formattest.c:27:9:    got long
+varargs-type-formattest.c:27:9: warning: incorrect type for width argument 3
+varargs-type-formattest.c:27:9:    expected int
+varargs-type-formattest.c:27:9:    got unsigned long
+varargs-type-formattest.c:27:9: warning: incorrect type in argument 4 (different types)
+varargs-type-formattest.c:27:9:    expected int
+varargs-type-formattest.c:27:9:    got long
+varargs-type-formattest.c:30:9: warning: incorrect type in argument 4 (different types)
+varargs-type-formattest.c:30:9:    expected int
+varargs-type-formattest.c:30:9:    got long
+varargs-type-formattest.c:30:9: warning: incorrect type in argument 5 (different types)
+varargs-type-formattest.c:30:9:    expected int
+varargs-type-formattest.c:30:9:    got long
+varargs-type-formattest.c:31:9: warning: incorrect type for width argument 2
+varargs-type-formattest.c:31:9:    expected int
+varargs-type-formattest.c:31:9:    got unsigned long
+varargs-type-formattest.c:31:9: warning: incorrect type in argument 4 (different types)
+varargs-type-formattest.c:31:9:    expected int
+varargs-type-formattest.c:31:9:    got long
+varargs-type-formattest.c:31:9: warning: incorrect type for width argument 3
+varargs-type-formattest.c:31:9:    expected int
+varargs-type-formattest.c:31:9:    got unsigned long
+varargs-type-formattest.c:31:9: warning: incorrect type in argument 5 (different types)
+varargs-type-formattest.c:31:9:    expected int
+varargs-type-formattest.c:31:9:    got long
+varargs-type-formattest.c:32:9: warning: incorrect type for position argument 3
+varargs-type-formattest.c:32:9:    expected int
+varargs-type-formattest.c:32:9:    got unsigned long
+varargs-type-formattest.c:32:9: warning: incorrect type for position argument 4
+varargs-type-formattest.c:32:9:    expected int
+varargs-type-formattest.c:32:9:    got unsigned long
+ * check-error-end
+ *
+ */
-- 
2.37.2.352.g3c44437643


================================================================================


################################################################################

=== Thread: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis ===

From: Tetsuo Handa <penguin-kernel () I-love ! SAKURA ! ne ! jp>
To: linux-kernel
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 13:21:38 +0000
Message-ID: <993d381a-c24e-41d2-a0be-c1b0b5d8cbe9 () I-love ! SAKURA ! ne ! jp>
--------------------
On 2025/12/20 0:39, Marco Elver wrote:
> Introduce basic compatibility with cleanup.h infrastructure.

Can Compiler-Based Context- and Locking-Analysis work with conditional guards
(unlock only if lock succeeded) ?

I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
frequency of hung tasks under heavy load where many processes are preempted waiting
for the same mutex to become available (e.g.
https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).

But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
(Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
 if Compiler-Based Context- and Locking-Analysis cannot work) ?


================================================================================

From: Tetsuo Handa <penguin-kernel () I-love ! SAKURA ! ne ! jp>
To: linux-crypto-vger
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 13:21:38 +0000
Message-ID: <993d381a-c24e-41d2-a0be-c1b0b5d8cbe9 () I-love ! SAKURA ! ne ! jp>
--------------------
On 2025/12/20 0:39, Marco Elver wrote:
> Introduce basic compatibility with cleanup.h infrastructure.

Can Compiler-Based Context- and Locking-Analysis work with conditional guards
(unlock only if lock succeeded) ?

I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
frequency of hung tasks under heavy load where many processes are preempted waiting
for the same mutex to become available (e.g.
https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).

But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
(Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
 if Compiler-Based Context- and Locking-Analysis cannot work) ?


================================================================================

From: Tetsuo Handa <penguin-kernel () I-love ! SAKURA ! ne ! jp>
To: linux-sparse
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 13:21:38 +0000
Message-ID: <993d381a-c24e-41d2-a0be-c1b0b5d8cbe9 () I-love ! SAKURA ! ne ! jp>
--------------------
On 2025/12/20 0:39, Marco Elver wrote:
> Introduce basic compatibility with cleanup.h infrastructure.

Can Compiler-Based Context- and Locking-Analysis work with conditional guards
(unlock only if lock succeeded) ?

I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
frequency of hung tasks under heavy load where many processes are preempted waiting
for the same mutex to become available (e.g.
https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).

But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
(Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
 if Compiler-Based Context- and Locking-Analysis cannot work) ?


================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kernel
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 17:34:39 +0000
Message-ID: <aV1HrwZm6xg8PnRU () elver ! google ! com>
--------------------
On Tue, Jan 06, 2026 at 10:21PM +0900, Tetsuo Handa wrote:
> On 2025/12/20 0:39, Marco Elver wrote:
> > Introduce basic compatibility with cleanup.h infrastructure.
> 
> Can Compiler-Based Context- and Locking-Analysis work with conditional guards
> (unlock only if lock succeeded) ?
> 
> I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
> frequency of hung tasks under heavy load where many processes are preempted waiting
> for the same mutex to become available (e.g.
> https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).
> 
> But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
> plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
> replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
> (Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
>  if Compiler-Based Context- and Locking-Analysis cannot work) ?

It works for cond guards, so yes. But, only if support for
mutex_lock_killable() is added. At the moment mutex.h only has:

	...
	DEFINE_LOCK_GUARD_1(mutex, struct mutex, mutex_lock(_T->lock), mutex_unlock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _try, mutex_trylock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _intr, mutex_lock_interruptible(_T->lock), _RET == 0)

	DECLARE_LOCK_GUARD_1_ATTRS(mutex,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_try,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_try_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_try, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_intr,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_intr_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_intr, _T)
	...

And we also have a test in lib/test_context-analysis.c checking it
actually works:

	...
	scoped_cond_guard(mutex_try, return, &d->mtx) {
		d->counter++;
	}
	scoped_cond_guard(mutex_intr, return, &d->mtx) {
		d->counter++;
	}
	...

What's missing is a variant for mutex_lock_killable(), but that should
be similar to the mutex_lock_interruptible() variant.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 17:34:39 +0000
Message-ID: <aV1HrwZm6xg8PnRU () elver ! google ! com>
--------------------
On Tue, Jan 06, 2026 at 10:21PM +0900, Tetsuo Handa wrote:
> On 2025/12/20 0:39, Marco Elver wrote:
> > Introduce basic compatibility with cleanup.h infrastructure.
> 
> Can Compiler-Based Context- and Locking-Analysis work with conditional guards
> (unlock only if lock succeeded) ?
> 
> I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
> frequency of hung tasks under heavy load where many processes are preempted waiting
> for the same mutex to become available (e.g.
> https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).
> 
> But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
> plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
> replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
> (Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
>  if Compiler-Based Context- and Locking-Analysis cannot work) ?

It works for cond guards, so yes. But, only if support for
mutex_lock_killable() is added. At the moment mutex.h only has:

	...
	DEFINE_LOCK_GUARD_1(mutex, struct mutex, mutex_lock(_T->lock), mutex_unlock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _try, mutex_trylock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _intr, mutex_lock_interruptible(_T->lock), _RET == 0)

	DECLARE_LOCK_GUARD_1_ATTRS(mutex,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_try,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_try_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_try, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_intr,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_intr_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_intr, _T)
	...

And we also have a test in lib/test_context-analysis.c checking it
actually works:

	...
	scoped_cond_guard(mutex_try, return, &d->mtx) {
		d->counter++;
	}
	scoped_cond_guard(mutex_intr, return, &d->mtx) {
		d->counter++;
	}
	...

What's missing is a variant for mutex_lock_killable(), but that should
be similar to the mutex_lock_interruptible() variant.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-doc
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 17:34:39 +0000
Message-ID: <aV1HrwZm6xg8PnRU () elver ! google ! com>
--------------------
On Tue, Jan 06, 2026 at 10:21PM +0900, Tetsuo Handa wrote:
> On 2025/12/20 0:39, Marco Elver wrote:
> > Introduce basic compatibility with cleanup.h infrastructure.
> 
> Can Compiler-Based Context- and Locking-Analysis work with conditional guards
> (unlock only if lock succeeded) ?
> 
> I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
> frequency of hung tasks under heavy load where many processes are preempted waiting
> for the same mutex to become available (e.g.
> https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).
> 
> But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
> plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
> replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
> (Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
>  if Compiler-Based Context- and Locking-Analysis cannot work) ?

It works for cond guards, so yes. But, only if support for
mutex_lock_killable() is added. At the moment mutex.h only has:

	...
	DEFINE_LOCK_GUARD_1(mutex, struct mutex, mutex_lock(_T->lock), mutex_unlock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _try, mutex_trylock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _intr, mutex_lock_interruptible(_T->lock), _RET == 0)

	DECLARE_LOCK_GUARD_1_ATTRS(mutex,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_try,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_try_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_try, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_intr,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_intr_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_intr, _T)
	...

And we also have a test in lib/test_context-analysis.c checking it
actually works:

	...
	scoped_cond_guard(mutex_try, return, &d->mtx) {
		d->counter++;
	}
	scoped_cond_guard(mutex_intr, return, &d->mtx) {
		d->counter++;
	}
	...

What's missing is a variant for mutex_lock_killable(), but that should
be similar to the mutex_lock_interruptible() variant.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-wireless
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 17:34:39 +0000
Message-ID: <aV1HrwZm6xg8PnRU () elver ! google ! com>
--------------------
On Tue, Jan 06, 2026 at 10:21PM +0900, Tetsuo Handa wrote:
> On 2025/12/20 0:39, Marco Elver wrote:
> > Introduce basic compatibility with cleanup.h infrastructure.
> 
> Can Compiler-Based Context- and Locking-Analysis work with conditional guards
> (unlock only if lock succeeded) ?
> 
> I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
> frequency of hung tasks under heavy load where many processes are preempted waiting
> for the same mutex to become available (e.g.
> https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).
> 
> But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
> plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
> replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
> (Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
>  if Compiler-Based Context- and Locking-Analysis cannot work) ?

It works for cond guards, so yes. But, only if support for
mutex_lock_killable() is added. At the moment mutex.h only has:

	...
	DEFINE_LOCK_GUARD_1(mutex, struct mutex, mutex_lock(_T->lock), mutex_unlock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _try, mutex_trylock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _intr, mutex_lock_interruptible(_T->lock), _RET == 0)

	DECLARE_LOCK_GUARD_1_ATTRS(mutex,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_try,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_try_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_try, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_intr,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_intr_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_intr, _T)
	...

And we also have a test in lib/test_context-analysis.c checking it
actually works:

	...
	scoped_cond_guard(mutex_try, return, &d->mtx) {
		d->counter++;
	}
	scoped_cond_guard(mutex_intr, return, &d->mtx) {
		d->counter++;
	}
	...

What's missing is a variant for mutex_lock_killable(), but that should
be similar to the mutex_lock_interruptible() variant.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-sparse
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 17:34:39 +0000
Message-ID: <aV1HrwZm6xg8PnRU () elver ! google ! com>
--------------------
On Tue, Jan 06, 2026 at 10:21PM +0900, Tetsuo Handa wrote:
> On 2025/12/20 0:39, Marco Elver wrote:
> > Introduce basic compatibility with cleanup.h infrastructure.
> 
> Can Compiler-Based Context- and Locking-Analysis work with conditional guards
> (unlock only if lock succeeded) ?
> 
> I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
> frequency of hung tasks under heavy load where many processes are preempted waiting
> for the same mutex to become available (e.g.
> https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).
> 
> But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
> plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
> replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
> (Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
>  if Compiler-Based Context- and Locking-Analysis cannot work) ?

It works for cond guards, so yes. But, only if support for
mutex_lock_killable() is added. At the moment mutex.h only has:

	...
	DEFINE_LOCK_GUARD_1(mutex, struct mutex, mutex_lock(_T->lock), mutex_unlock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _try, mutex_trylock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _intr, mutex_lock_interruptible(_T->lock), _RET == 0)

	DECLARE_LOCK_GUARD_1_ATTRS(mutex,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_try,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_try_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_try, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_intr,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_intr_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_intr, _T)
	...

And we also have a test in lib/test_context-analysis.c checking it
actually works:

	...
	scoped_cond_guard(mutex_try, return, &d->mtx) {
		d->counter++;
	}
	scoped_cond_guard(mutex_intr, return, &d->mtx) {
		d->counter++;
	}
	...

What's missing is a variant for mutex_lock_killable(), but that should
be similar to the mutex_lock_interruptible() variant.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 17:34:39 +0000
Message-ID: <aV1HrwZm6xg8PnRU () elver ! google ! com>
--------------------
On Tue, Jan 06, 2026 at 10:21PM +0900, Tetsuo Handa wrote:
> On 2025/12/20 0:39, Marco Elver wrote:
> > Introduce basic compatibility with cleanup.h infrastructure.
> 
> Can Compiler-Based Context- and Locking-Analysis work with conditional guards
> (unlock only if lock succeeded) ?
> 
> I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
> frequency of hung tasks under heavy load where many processes are preempted waiting
> for the same mutex to become available (e.g.
> https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).
> 
> But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
> plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
> replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
> (Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
>  if Compiler-Based Context- and Locking-Analysis cannot work) ?

It works for cond guards, so yes. But, only if support for
mutex_lock_killable() is added. At the moment mutex.h only has:

	...
	DEFINE_LOCK_GUARD_1(mutex, struct mutex, mutex_lock(_T->lock), mutex_unlock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _try, mutex_trylock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _intr, mutex_lock_interruptible(_T->lock), _RET == 0)

	DECLARE_LOCK_GUARD_1_ATTRS(mutex,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_try,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_try_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_try, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_intr,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_intr_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_intr, _T)
	...

And we also have a test in lib/test_context-analysis.c checking it
actually works:

	...
	scoped_cond_guard(mutex_try, return, &d->mtx) {
		d->counter++;
	}
	scoped_cond_guard(mutex_intr, return, &d->mtx) {
		d->counter++;
	}
	...

What's missing is a variant for mutex_lock_killable(), but that should
be similar to the mutex_lock_interruptible() variant.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-mm
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 06 Jan 2026 17:34:39 +0000
Message-ID: <aV1HrwZm6xg8PnRU () elver ! google ! com>
--------------------
On Tue, Jan 06, 2026 at 10:21PM +0900, Tetsuo Handa wrote:
> On 2025/12/20 0:39, Marco Elver wrote:
> > Introduce basic compatibility with cleanup.h infrastructure.
> 
> Can Compiler-Based Context- and Locking-Analysis work with conditional guards
> (unlock only if lock succeeded) ?
> 
> I consider that replacing mutex_lock() with mutex_lock_killable() helps reducing
> frequency of hung tasks under heavy load where many processes are preempted waiting
> for the same mutex to become available (e.g.
> https://syzkaller.appspot.com/bug?extid=8f41dccfb6c03cc36fd6 ).
> 
> But e.g. commit f49573f2f53e ("tty: use lock guard()s in tty_io") already replaced
> plain mutex_lock()/mutex_unlock() with plain guard(mutex). If I propose a patch for
> replacing mutex_lock() with mutex_lock_killable(), can I use conditional guards?
> (Would be yes if Compiler-Based Context- and Locking-Analysis can work, would be no
>  if Compiler-Based Context- and Locking-Analysis cannot work) ?

It works for cond guards, so yes. But, only if support for
mutex_lock_killable() is added. At the moment mutex.h only has:

	...
	DEFINE_LOCK_GUARD_1(mutex, struct mutex, mutex_lock(_T->lock), mutex_unlock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _try, mutex_trylock(_T->lock))
	DEFINE_LOCK_GUARD_1_COND(mutex, _intr, mutex_lock_interruptible(_T->lock), _RET == 0)

	DECLARE_LOCK_GUARD_1_ATTRS(mutex,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_try,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_try_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_try, _T)
	DECLARE_LOCK_GUARD_1_ATTRS(mutex_intr,	__acquires(_T), __releases(*(struct mutex **)_T))
	#define class_mutex_intr_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(mutex_intr, _T)
	...

And we also have a test in lib/test_context-analysis.c checking it
actually works:

	...
	scoped_cond_guard(mutex_try, return, &d->mtx) {
		d->counter++;
	}
	scoped_cond_guard(mutex_intr, return, &d->mtx) {
		d->counter++;
	}
	...

What's missing is a variant for mutex_lock_killable(), but that should
be similar to the mutex_lock_interruptible() variant.

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-kernel
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:14:23 +0000
Message-ID: <0c2d9b69-c052-4075-8a4b-023d277b8509 () lucifer ! local>
--------------------
+cc Sid for awareness

Hi,

This patch breaks the radix tree and VMA userland tests. The next bots didn't
catch it but it seems now they're building the userland VMA tests
(e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
not caught up to the issue this one caused (fails build in tools/testing/vma and
tools/testing/radix-tree).

Anyway it's a really easy fix, just need to stub out __no_context_analysis in
the tools/include copy of compiler_types.h, fix-patch provided below.

To avoid bisection hazard it'd be nice if it could be folded into this series
before this patch, but if we're too late in the cycle for that I can submit a
fix separately.

Thanks, Lorenzo

----8<----

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-doc
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:14:23 +0000
Message-ID: <0c2d9b69-c052-4075-8a4b-023d277b8509 () lucifer ! local>
--------------------
+cc Sid for awareness

Hi,

This patch breaks the radix tree and VMA userland tests. The next bots didn't
catch it but it seems now they're building the userland VMA tests
(e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
not caught up to the issue this one caused (fails build in tools/testing/vma and
tools/testing/radix-tree).

Anyway it's a really easy fix, just need to stub out __no_context_analysis in
the tools/include copy of compiler_types.h, fix-patch provided below.

To avoid bisection hazard it'd be nice if it could be folded into this series
before this patch, but if we're too late in the cycle for that I can submit a
fix separately.

Thanks, Lorenzo

----8<----

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-mm
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:14:23 +0000
Message-ID: <0c2d9b69-c052-4075-8a4b-023d277b8509 () lucifer ! local>
--------------------
+cc Sid for awareness

Hi,

This patch breaks the radix tree and VMA userland tests. The next bots didn't
catch it but it seems now they're building the userland VMA tests
(e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
not caught up to the issue this one caused (fails build in tools/testing/vma and
tools/testing/radix-tree).

Anyway it's a really easy fix, just need to stub out __no_context_analysis in
the tools/include copy of compiler_types.h, fix-patch provided below.

To avoid bisection hazard it'd be nice if it could be folded into this series
before this patch, but if we're too late in the cycle for that I can submit a
fix separately.

Thanks, Lorenzo

----8<----

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-wireless
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:14:23 +0000
Message-ID: <0c2d9b69-c052-4075-8a4b-023d277b8509 () lucifer ! local>
--------------------
+cc Sid for awareness

Hi,

This patch breaks the radix tree and VMA userland tests. The next bots didn't
catch it but it seems now they're building the userland VMA tests
(e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
not caught up to the issue this one caused (fails build in tools/testing/vma and
tools/testing/radix-tree).

Anyway it's a really easy fix, just need to stub out __no_context_analysis in
the tools/include copy of compiler_types.h, fix-patch provided below.

To avoid bisection hazard it'd be nice if it could be folded into this series
before this patch, but if we're too late in the cycle for that I can submit a
fix separately.

Thanks, Lorenzo

----8<----

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:14:23 +0000
Message-ID: <0c2d9b69-c052-4075-8a4b-023d277b8509 () lucifer ! local>
--------------------
+cc Sid for awareness

Hi,

This patch breaks the radix tree and VMA userland tests. The next bots didn't
catch it but it seems now they're building the userland VMA tests
(e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
not caught up to the issue this one caused (fails build in tools/testing/vma and
tools/testing/radix-tree).

Anyway it's a really easy fix, just need to stub out __no_context_analysis in
the tools/include copy of compiler_types.h, fix-patch provided below.

To avoid bisection hazard it'd be nice if it could be folded into this series
before this patch, but if we're too late in the cycle for that I can submit a
fix separately.

Thanks, Lorenzo

----8<----

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-sparse
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:14:23 +0000
Message-ID: <0c2d9b69-c052-4075-8a4b-023d277b8509 () lucifer ! local>
--------------------
+cc Sid for awareness

Hi,

This patch breaks the radix tree and VMA userland tests. The next bots didn't
catch it but it seems now they're building the userland VMA tests
(e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
not caught up to the issue this one caused (fails build in tools/testing/vma and
tools/testing/radix-tree).

Anyway it's a really easy fix, just need to stub out __no_context_analysis in
the tools/include copy of compiler_types.h, fix-patch provided below.

To avoid bisection hazard it'd be nice if it could be folded into this series
before this patch, but if we're too late in the cycle for that I can submit a
fix separately.

Thanks, Lorenzo

----8<----

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:14:23 +0000
Message-ID: <0c2d9b69-c052-4075-8a4b-023d277b8509 () lucifer ! local>
--------------------
+cc Sid for awareness

Hi,

This patch breaks the radix tree and VMA userland tests. The next bots didn't
catch it but it seems now they're building the userland VMA tests
(e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
not caught up to the issue this one caused (fails build in tools/testing/vma and
tools/testing/radix-tree).

Anyway it's a really easy fix, just need to stub out __no_context_analysis in
the tools/include copy of compiler_types.h, fix-patch provided below.

To avoid bisection hazard it'd be nice if it could be folded into this series
before this patch, but if we're too late in the cycle for that I can submit a
fix separately.

Thanks, Lorenzo

----8<----

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:17:24 +0000
Message-ID: <CANpmjNNHmOzaCSc9hQJNuzNVHXA=LRgXB4Q69FNk6wBuuJGdAg () mail ! gmail ! com>
--------------------
On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
<lorenzo.stoakes@oracle.com> wrote:
>
> +cc Sid for awareness
>
> Hi,
>
> This patch breaks the radix tree and VMA userland tests. The next bots didn't
> catch it but it seems now they're building the userland VMA tests
> (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> not caught up to the issue this one caused (fails build in tools/testing/vma and
> tools/testing/radix-tree).
>
> Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> the tools/include copy of compiler_types.h, fix-patch provided below.
>
> To avoid bisection hazard it'd be nice if it could be folded into this series
> before this patch, but if we're too late in the cycle for that I can submit a
> fix separately.

Thanks, I saw. I have a more complete fix I'm about to send.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kernel
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:17:24 +0000
Message-ID: <CANpmjNNHmOzaCSc9hQJNuzNVHXA=LRgXB4Q69FNk6wBuuJGdAg () mail ! gmail ! com>
--------------------
On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
<lorenzo.stoakes@oracle.com> wrote:
>
> +cc Sid for awareness
>
> Hi,
>
> This patch breaks the radix tree and VMA userland tests. The next bots didn't
> catch it but it seems now they're building the userland VMA tests
> (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> not caught up to the issue this one caused (fails build in tools/testing/vma and
> tools/testing/radix-tree).
>
> Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> the tools/include copy of compiler_types.h, fix-patch provided below.
>
> To avoid bisection hazard it'd be nice if it could be folded into this series
> before this patch, but if we're too late in the cycle for that I can submit a
> fix separately.

Thanks, I saw. I have a more complete fix I'm about to send.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-sparse
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:17:24 +0000
Message-ID: <CANpmjNNHmOzaCSc9hQJNuzNVHXA=LRgXB4Q69FNk6wBuuJGdAg () mail ! gmail ! com>
--------------------
On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
<lorenzo.stoakes@oracle.com> wrote:
>
> +cc Sid for awareness
>
> Hi,
>
> This patch breaks the radix tree and VMA userland tests. The next bots didn't
> catch it but it seems now they're building the userland VMA tests
> (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> not caught up to the issue this one caused (fails build in tools/testing/vma and
> tools/testing/radix-tree).
>
> Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> the tools/include copy of compiler_types.h, fix-patch provided below.
>
> To avoid bisection hazard it'd be nice if it could be folded into this series
> before this patch, but if we're too late in the cycle for that I can submit a
> fix separately.

Thanks, I saw. I have a more complete fix I'm about to send.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-doc
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:17:24 +0000
Message-ID: <CANpmjNNHmOzaCSc9hQJNuzNVHXA=LRgXB4Q69FNk6wBuuJGdAg () mail ! gmail ! com>
--------------------
On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
<lorenzo.stoakes@oracle.com> wrote:
>
> +cc Sid for awareness
>
> Hi,
>
> This patch breaks the radix tree and VMA userland tests. The next bots didn't
> catch it but it seems now they're building the userland VMA tests
> (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> not caught up to the issue this one caused (fails build in tools/testing/vma and
> tools/testing/radix-tree).
>
> Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> the tools/include copy of compiler_types.h, fix-patch provided below.
>
> To avoid bisection hazard it'd be nice if it could be folded into this series
> before this patch, but if we're too late in the cycle for that I can submit a
> fix separately.

Thanks, I saw. I have a more complete fix I'm about to send.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-mm
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:17:24 +0000
Message-ID: <CANpmjNNHmOzaCSc9hQJNuzNVHXA=LRgXB4Q69FNk6wBuuJGdAg () mail ! gmail ! com>
--------------------
On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
<lorenzo.stoakes@oracle.com> wrote:
>
> +cc Sid for awareness
>
> Hi,
>
> This patch breaks the radix tree and VMA userland tests. The next bots didn't
> catch it but it seems now they're building the userland VMA tests
> (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> not caught up to the issue this one caused (fails build in tools/testing/vma and
> tools/testing/radix-tree).
>
> Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> the tools/include copy of compiler_types.h, fix-patch provided below.
>
> To avoid bisection hazard it'd be nice if it could be folded into this series
> before this patch, but if we're too late in the cycle for that I can submit a
> fix separately.

Thanks, I saw. I have a more complete fix I'm about to send.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-wireless
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:17:24 +0000
Message-ID: <CANpmjNNHmOzaCSc9hQJNuzNVHXA=LRgXB4Q69FNk6wBuuJGdAg () mail ! gmail ! com>
--------------------
On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
<lorenzo.stoakes@oracle.com> wrote:
>
> +cc Sid for awareness
>
> Hi,
>
> This patch breaks the radix tree and VMA userland tests. The next bots didn't
> catch it but it seems now they're building the userland VMA tests
> (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> not caught up to the issue this one caused (fails build in tools/testing/vma and
> tools/testing/radix-tree).
>
> Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> the tools/include copy of compiler_types.h, fix-patch provided below.
>
> To avoid bisection hazard it'd be nice if it could be folded into this series
> before this patch, but if we're too late in the cycle for that I can submit a
> fix separately.

Thanks, I saw. I have a more complete fix I'm about to send.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:17:24 +0000
Message-ID: <CANpmjNNHmOzaCSc9hQJNuzNVHXA=LRgXB4Q69FNk6wBuuJGdAg () mail ! gmail ! com>
--------------------
On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
<lorenzo.stoakes@oracle.com> wrote:
>
> +cc Sid for awareness
>
> Hi,
>
> This patch breaks the radix tree and VMA userland tests. The next bots didn't
> catch it but it seems now they're building the userland VMA tests
> (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> not caught up to the issue this one caused (fails build in tools/testing/vma and
> tools/testing/radix-tree).
>
> Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> the tools/include copy of compiler_types.h, fix-patch provided below.
>
> To avoid bisection hazard it'd be nice if it could be folded into this series
> before this patch, but if we're too late in the cycle for that I can submit a
> fix separately.

Thanks, I saw. I have a more complete fix I'm about to send.

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:21:28 +0000
Message-ID: <599729a5-da4c-473a-bd07-4459639c95c7 () lucifer ! local>
--------------------
On Tue, Jan 27, 2026 at 11:17:24AM +0100, Marco Elver wrote:
> On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
> <lorenzo.stoakes@oracle.com> wrote:
> >
> > +cc Sid for awareness
> >
> > Hi,
> >
> > This patch breaks the radix tree and VMA userland tests. The next bots didn't
> > catch it but it seems now they're building the userland VMA tests
> > (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> > not caught up to the issue this one caused (fails build in tools/testing/vma and
> > tools/testing/radix-tree).
> >
> > Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> > the tools/include copy of compiler_types.h, fix-patch provided below.
> >
> > To avoid bisection hazard it'd be nice if it could be folded into this series
> > before this patch, but if we're too late in the cycle for that I can submit a
> > fix separately.
>
> Thanks, I saw. I have a more complete fix I'm about to send.

Great, thanks!

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-mm
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:21:28 +0000
Message-ID: <599729a5-da4c-473a-bd07-4459639c95c7 () lucifer ! local>
--------------------
On Tue, Jan 27, 2026 at 11:17:24AM +0100, Marco Elver wrote:
> On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
> <lorenzo.stoakes@oracle.com> wrote:
> >
> > +cc Sid for awareness
> >
> > Hi,
> >
> > This patch breaks the radix tree and VMA userland tests. The next bots didn't
> > catch it but it seems now they're building the userland VMA tests
> > (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> > not caught up to the issue this one caused (fails build in tools/testing/vma and
> > tools/testing/radix-tree).
> >
> > Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> > the tools/include copy of compiler_types.h, fix-patch provided below.
> >
> > To avoid bisection hazard it'd be nice if it could be folded into this series
> > before this patch, but if we're too late in the cycle for that I can submit a
> > fix separately.
>
> Thanks, I saw. I have a more complete fix I'm about to send.

Great, thanks!

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-doc
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:21:28 +0000
Message-ID: <599729a5-da4c-473a-bd07-4459639c95c7 () lucifer ! local>
--------------------
On Tue, Jan 27, 2026 at 11:17:24AM +0100, Marco Elver wrote:
> On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
> <lorenzo.stoakes@oracle.com> wrote:
> >
> > +cc Sid for awareness
> >
> > Hi,
> >
> > This patch breaks the radix tree and VMA userland tests. The next bots didn't
> > catch it but it seems now they're building the userland VMA tests
> > (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> > not caught up to the issue this one caused (fails build in tools/testing/vma and
> > tools/testing/radix-tree).
> >
> > Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> > the tools/include copy of compiler_types.h, fix-patch provided below.
> >
> > To avoid bisection hazard it'd be nice if it could be folded into this series
> > before this patch, but if we're too late in the cycle for that I can submit a
> > fix separately.
>
> Thanks, I saw. I have a more complete fix I'm about to send.

Great, thanks!

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-kernel
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:21:28 +0000
Message-ID: <599729a5-da4c-473a-bd07-4459639c95c7 () lucifer ! local>
--------------------
On Tue, Jan 27, 2026 at 11:17:24AM +0100, Marco Elver wrote:
> On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
> <lorenzo.stoakes@oracle.com> wrote:
> >
> > +cc Sid for awareness
> >
> > Hi,
> >
> > This patch breaks the radix tree and VMA userland tests. The next bots didn't
> > catch it but it seems now they're building the userland VMA tests
> > (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> > not caught up to the issue this one caused (fails build in tools/testing/vma and
> > tools/testing/radix-tree).
> >
> > Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> > the tools/include copy of compiler_types.h, fix-patch provided below.
> >
> > To avoid bisection hazard it'd be nice if it could be folded into this series
> > before this patch, but if we're too late in the cycle for that I can submit a
> > fix separately.
>
> Thanks, I saw. I have a more complete fix I'm about to send.

Great, thanks!

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:21:28 +0000
Message-ID: <599729a5-da4c-473a-bd07-4459639c95c7 () lucifer ! local>
--------------------
On Tue, Jan 27, 2026 at 11:17:24AM +0100, Marco Elver wrote:
> On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
> <lorenzo.stoakes@oracle.com> wrote:
> >
> > +cc Sid for awareness
> >
> > Hi,
> >
> > This patch breaks the radix tree and VMA userland tests. The next bots didn't
> > catch it but it seems now they're building the userland VMA tests
> > (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> > not caught up to the issue this one caused (fails build in tools/testing/vma and
> > tools/testing/radix-tree).
> >
> > Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> > the tools/include copy of compiler_types.h, fix-patch provided below.
> >
> > To avoid bisection hazard it'd be nice if it could be folded into this series
> > before this patch, but if we're too late in the cycle for that I can submit a
> > fix separately.
>
> Thanks, I saw. I have a more complete fix I'm about to send.

Great, thanks!

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-sparse
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:21:28 +0000
Message-ID: <599729a5-da4c-473a-bd07-4459639c95c7 () lucifer ! local>
--------------------
On Tue, Jan 27, 2026 at 11:17:24AM +0100, Marco Elver wrote:
> On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
> <lorenzo.stoakes@oracle.com> wrote:
> >
> > +cc Sid for awareness
> >
> > Hi,
> >
> > This patch breaks the radix tree and VMA userland tests. The next bots didn't
> > catch it but it seems now they're building the userland VMA tests
> > (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> > not caught up to the issue this one caused (fails build in tools/testing/vma and
> > tools/testing/radix-tree).
> >
> > Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> > the tools/include copy of compiler_types.h, fix-patch provided below.
> >
> > To avoid bisection hazard it'd be nice if it could be folded into this series
> > before this patch, but if we're too late in the cycle for that I can submit a
> > fix separately.
>
> Thanks, I saw. I have a more complete fix I'm about to send.

Great, thanks!

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes () oracle ! com>
To: linux-wireless
Subject: Re: [PATCH v5 06/36] cleanup: Basic compatibility with context analysis
Date: Tue, 27 Jan 2026 10:21:28 +0000
Message-ID: <599729a5-da4c-473a-bd07-4459639c95c7 () lucifer ! local>
--------------------
On Tue, Jan 27, 2026 at 11:17:24AM +0100, Marco Elver wrote:
> On Tue, 27 Jan 2026 at 11:14, Lorenzo Stoakes
> <lorenzo.stoakes@oracle.com> wrote:
> >
> > +cc Sid for awareness
> >
> > Hi,
> >
> > This patch breaks the radix tree and VMA userland tests. The next bots didn't
> > catch it but it seems now they're building the userland VMA tests
> > (e.g. https://lore.kernel.all/202601271308.b8d3fcb6-lkp@intel.com/) but maybe
> > not caught up to the issue this one caused (fails build in tools/testing/vma and
> > tools/testing/radix-tree).
> >
> > Anyway it's a really easy fix, just need to stub out __no_context_analysis in
> > the tools/include copy of compiler_types.h, fix-patch provided below.
> >
> > To avoid bisection hazard it'd be nice if it could be folded into this series
> > before this patch, but if we're too late in the cycle for that I can submit a
> > fix separately.
>
> Thanks, I saw. I have a more complete fix I'm about to send.

Great, thanks!

================================================================================


################################################################################

=== Thread: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis ===

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-wireless
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 22:10:25 +0000
Message-ID: <57062131-e79e-42c2-aa0b-8f931cb8cac2 () acm ! org>
--------------------
On 12/19/25 8:39 AM, Marco Elver wrote:
> diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> index bf535f0118bb..89977c215cbd 100644
> --- a/include/linux/mutex.h
> +++ b/include/linux/mutex.h
> @@ -62,6 +62,7 @@ do {									\
>   	static struct lock_class_key __key;				\
>   									\
>   	__mutex_init((mutex), #mutex, &__key);				\
> +	__assume_ctx_lock(mutex);					\
>   } while (0)

The above type of change probably will have to be reverted. If I enable
context analysis for the entire kernel tree, drivers/base/devcoredump.c
doesn't build. The following error is reported:

drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' 
that is already held [-Werror,-Wthread-safety-analysis]
   406 |         mutex_lock(&devcd->mutex);
       |         ^

dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the 
same function. The above type of change breaks compilation of all code
that initializes and locks a synchronization object from the same
function. My understanding of dev_coredumpm_timeout() is that there is a
good reason for calling both mutex_init() and mutex_lock() from that
function. Possible solutions are disabling context analysis for that
function or removing __assume_ctx_lock() again from mutex_init(). Does
anyone want to share their opinion about this?

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-sparse
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 22:10:25 +0000
Message-ID: <57062131-e79e-42c2-aa0b-8f931cb8cac2 () acm ! org>
--------------------
On 12/19/25 8:39 AM, Marco Elver wrote:
> diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> index bf535f0118bb..89977c215cbd 100644
> --- a/include/linux/mutex.h
> +++ b/include/linux/mutex.h
> @@ -62,6 +62,7 @@ do {									\
>   	static struct lock_class_key __key;				\
>   									\
>   	__mutex_init((mutex), #mutex, &__key);				\
> +	__assume_ctx_lock(mutex);					\
>   } while (0)

The above type of change probably will have to be reverted. If I enable
context analysis for the entire kernel tree, drivers/base/devcoredump.c
doesn't build. The following error is reported:

drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' 
that is already held [-Werror,-Wthread-safety-analysis]
   406 |         mutex_lock(&devcd->mutex);
       |         ^

dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the 
same function. The above type of change breaks compilation of all code
that initializes and locks a synchronization object from the same
function. My understanding of dev_coredumpm_timeout() is that there is a
good reason for calling both mutex_init() and mutex_lock() from that
function. Possible solutions are disabling context analysis for that
function or removing __assume_ctx_lock() again from mutex_init(). Does
anyone want to share their opinion about this?

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-kernel
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 22:10:25 +0000
Message-ID: <57062131-e79e-42c2-aa0b-8f931cb8cac2 () acm ! org>
--------------------
On 12/19/25 8:39 AM, Marco Elver wrote:
> diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> index bf535f0118bb..89977c215cbd 100644
> --- a/include/linux/mutex.h
> +++ b/include/linux/mutex.h
> @@ -62,6 +62,7 @@ do {									\
>   	static struct lock_class_key __key;				\
>   									\
>   	__mutex_init((mutex), #mutex, &__key);				\
> +	__assume_ctx_lock(mutex);					\
>   } while (0)

The above type of change probably will have to be reverted. If I enable
context analysis for the entire kernel tree, drivers/base/devcoredump.c
doesn't build. The following error is reported:

drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' 
that is already held [-Werror,-Wthread-safety-analysis]
   406 |         mutex_lock(&devcd->mutex);
       |         ^

dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the 
same function. The above type of change breaks compilation of all code
that initializes and locks a synchronization object from the same
function. My understanding of dev_coredumpm_timeout() is that there is a
good reason for calling both mutex_init() and mutex_lock() from that
function. Possible solutions are disabling context analysis for that
function or removing __assume_ctx_lock() again from mutex_init(). Does
anyone want to share their opinion about this?

Thanks,

Bart.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-wireless
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 23:26:55 +0000
Message-ID: <aWA9P3_oI7JFTdkC () elver ! google ! com>
--------------------
On Thu, Jan 08, 2026 at 02:10PM -0800, 'Bart Van Assche' via kasan-dev wrote:
> On 12/19/25 8:39 AM, Marco Elver wrote:
> > diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> > index bf535f0118bb..89977c215cbd 100644
> > --- a/include/linux/mutex.h
> > +++ b/include/linux/mutex.h
> > @@ -62,6 +62,7 @@ do {									\
> >   	static struct lock_class_key __key;				\
> >   									\
> >   	__mutex_init((mutex), #mutex, &__key);				\
> > +	__assume_ctx_lock(mutex);					\
> >   } while (0)
> 
> The above type of change probably will have to be reverted. If I enable
> context analysis for the entire kernel tree, drivers/base/devcoredump.c
> doesn't build. The following error is reported:
> 
> drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' that
> is already held [-Werror,-Wthread-safety-analysis]
>   406 |         mutex_lock(&devcd->mutex);
>       |         ^
> 
> dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the same
> function. The above type of change breaks compilation of all code
> that initializes and locks a synchronization object from the same
> function. My understanding of dev_coredumpm_timeout() is that there is a
> good reason for calling both mutex_init() and mutex_lock() from that
> function. Possible solutions are disabling context analysis for that
> function or removing __assume_ctx_lock() again from mutex_init(). Does
> anyone want to share their opinion about this?

Probably the most idiomatic option is to just factor out construction.
Clearly separating complex object construction from use also helps
readability regardless, esp. where concurrency is involved. We could
document such advice somewhere.

For the above case, this seems cleanest and also clearer to me:

diff --git a/drivers/base/devcoredump.c b/drivers/base/devcoredump.c
index 55bdc7f5e59d..56ac8aa41608 100644
--- a/drivers/base/devcoredump.c
+++ b/drivers/base/devcoredump.c
@@ -339,6 +339,40 @@ void dev_coredump_put(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(dev_coredump_put);
 
+static struct devcd_entry *
+dev_coredumpm_init(struct device *dev, struct module *owner, void *data,
+		   size_t datalen, gfp_t gfp,
+		   ssize_t (*read)(char *buffer, loff_t offset, size_t count,
+				   void *data, size_t datalen),
+		   void (*free)(void *data))
+{
+	static atomic_t devcd_count = ATOMIC_INIT(0);
+	struct devcd_entry *devcd;
+
+	devcd = kzalloc(sizeof(*devcd), gfp);
+	if (!devcd)
+		return NULL;
+
+	devcd->owner = owner;
+	devcd->data = data;
+	devcd->datalen = datalen;
+	devcd->read = read;
+	devcd->free = free;
+	devcd->failing_dev = get_device(dev);
+	devcd->deleted = false;
+
+	mutex_init(&devcd->mutex);
+	device_initialize(&devcd->devcd_dev);
+
+	dev_set_name(&devcd->devcd_dev, "devcd%d",
+		     atomic_inc_return(&devcd_count));
+	devcd->devcd_dev.class = &devcd_class;
+
+	dev_set_uevent_suppress(&devcd->devcd_dev, true);
+
+	return devcd;
+}
+
 /**
  * dev_coredumpm_timeout - create device coredump with read/free methods with a
  * custom timeout.
@@ -364,7 +398,6 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 			   void (*free)(void *data),
 			   unsigned long timeout)
 {
-	static atomic_t devcd_count = ATOMIC_INIT(0);
 	struct devcd_entry *devcd;
 	struct device *existing;
 
@@ -381,27 +414,10 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 	if (!try_module_get(owner))
 		goto free;
 
-	devcd = kzalloc(sizeof(*devcd), gfp);
+	devcd = dev_coredumpm_init(dev, owner, data, datalen, gfp, read, free);
 	if (!devcd)
 		goto put_module;
 
-	devcd->owner = owner;
-	devcd->data = data;
-	devcd->datalen = datalen;
-	devcd->read = read;
-	devcd->free = free;
-	devcd->failing_dev = get_device(dev);
-	devcd->deleted = false;
-
-	mutex_init(&devcd->mutex);
-	device_initialize(&devcd->devcd_dev);
-
-	dev_set_name(&devcd->devcd_dev, "devcd%d",
-		     atomic_inc_return(&devcd_count));
-	devcd->devcd_dev.class = &devcd_class;
-
-	dev_set_uevent_suppress(&devcd->devcd_dev, true);
-
 	/* devcd->mutex prevents devcd_del() completing until init finishes */
 	mutex_lock(&devcd->mutex);
 	devcd->init_completed = false;

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 23:26:55 +0000
Message-ID: <aWA9P3_oI7JFTdkC () elver ! google ! com>
--------------------
On Thu, Jan 08, 2026 at 02:10PM -0800, 'Bart Van Assche' via kasan-dev wrote:
> On 12/19/25 8:39 AM, Marco Elver wrote:
> > diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> > index bf535f0118bb..89977c215cbd 100644
> > --- a/include/linux/mutex.h
> > +++ b/include/linux/mutex.h
> > @@ -62,6 +62,7 @@ do {									\
> >   	static struct lock_class_key __key;				\
> >   									\
> >   	__mutex_init((mutex), #mutex, &__key);				\
> > +	__assume_ctx_lock(mutex);					\
> >   } while (0)
> 
> The above type of change probably will have to be reverted. If I enable
> context analysis for the entire kernel tree, drivers/base/devcoredump.c
> doesn't build. The following error is reported:
> 
> drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' that
> is already held [-Werror,-Wthread-safety-analysis]
>   406 |         mutex_lock(&devcd->mutex);
>       |         ^
> 
> dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the same
> function. The above type of change breaks compilation of all code
> that initializes and locks a synchronization object from the same
> function. My understanding of dev_coredumpm_timeout() is that there is a
> good reason for calling both mutex_init() and mutex_lock() from that
> function. Possible solutions are disabling context analysis for that
> function or removing __assume_ctx_lock() again from mutex_init(). Does
> anyone want to share their opinion about this?

Probably the most idiomatic option is to just factor out construction.
Clearly separating complex object construction from use also helps
readability regardless, esp. where concurrency is involved. We could
document such advice somewhere.

For the above case, this seems cleanest and also clearer to me:

diff --git a/drivers/base/devcoredump.c b/drivers/base/devcoredump.c
index 55bdc7f5e59d..56ac8aa41608 100644
--- a/drivers/base/devcoredump.c
+++ b/drivers/base/devcoredump.c
@@ -339,6 +339,40 @@ void dev_coredump_put(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(dev_coredump_put);
 
+static struct devcd_entry *
+dev_coredumpm_init(struct device *dev, struct module *owner, void *data,
+		   size_t datalen, gfp_t gfp,
+		   ssize_t (*read)(char *buffer, loff_t offset, size_t count,
+				   void *data, size_t datalen),
+		   void (*free)(void *data))
+{
+	static atomic_t devcd_count = ATOMIC_INIT(0);
+	struct devcd_entry *devcd;
+
+	devcd = kzalloc(sizeof(*devcd), gfp);
+	if (!devcd)
+		return NULL;
+
+	devcd->owner = owner;
+	devcd->data = data;
+	devcd->datalen = datalen;
+	devcd->read = read;
+	devcd->free = free;
+	devcd->failing_dev = get_device(dev);
+	devcd->deleted = false;
+
+	mutex_init(&devcd->mutex);
+	device_initialize(&devcd->devcd_dev);
+
+	dev_set_name(&devcd->devcd_dev, "devcd%d",
+		     atomic_inc_return(&devcd_count));
+	devcd->devcd_dev.class = &devcd_class;
+
+	dev_set_uevent_suppress(&devcd->devcd_dev, true);
+
+	return devcd;
+}
+
 /**
  * dev_coredumpm_timeout - create device coredump with read/free methods with a
  * custom timeout.
@@ -364,7 +398,6 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 			   void (*free)(void *data),
 			   unsigned long timeout)
 {
-	static atomic_t devcd_count = ATOMIC_INIT(0);
 	struct devcd_entry *devcd;
 	struct device *existing;
 
@@ -381,27 +414,10 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 	if (!try_module_get(owner))
 		goto free;
 
-	devcd = kzalloc(sizeof(*devcd), gfp);
+	devcd = dev_coredumpm_init(dev, owner, data, datalen, gfp, read, free);
 	if (!devcd)
 		goto put_module;
 
-	devcd->owner = owner;
-	devcd->data = data;
-	devcd->datalen = datalen;
-	devcd->read = read;
-	devcd->free = free;
-	devcd->failing_dev = get_device(dev);
-	devcd->deleted = false;
-
-	mutex_init(&devcd->mutex);
-	device_initialize(&devcd->devcd_dev);
-
-	dev_set_name(&devcd->devcd_dev, "devcd%d",
-		     atomic_inc_return(&devcd_count));
-	devcd->devcd_dev.class = &devcd_class;
-
-	dev_set_uevent_suppress(&devcd->devcd_dev, true);
-
 	/* devcd->mutex prevents devcd_del() completing until init finishes */
 	mutex_lock(&devcd->mutex);
 	devcd->init_completed = false;

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-mm
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 23:26:55 +0000
Message-ID: <aWA9P3_oI7JFTdkC () elver ! google ! com>
--------------------
On Thu, Jan 08, 2026 at 02:10PM -0800, 'Bart Van Assche' via kasan-dev wrote:
> On 12/19/25 8:39 AM, Marco Elver wrote:
> > diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> > index bf535f0118bb..89977c215cbd 100644
> > --- a/include/linux/mutex.h
> > +++ b/include/linux/mutex.h
> > @@ -62,6 +62,7 @@ do {									\
> >   	static struct lock_class_key __key;				\
> >   									\
> >   	__mutex_init((mutex), #mutex, &__key);				\
> > +	__assume_ctx_lock(mutex);					\
> >   } while (0)
> 
> The above type of change probably will have to be reverted. If I enable
> context analysis for the entire kernel tree, drivers/base/devcoredump.c
> doesn't build. The following error is reported:
> 
> drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' that
> is already held [-Werror,-Wthread-safety-analysis]
>   406 |         mutex_lock(&devcd->mutex);
>       |         ^
> 
> dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the same
> function. The above type of change breaks compilation of all code
> that initializes and locks a synchronization object from the same
> function. My understanding of dev_coredumpm_timeout() is that there is a
> good reason for calling both mutex_init() and mutex_lock() from that
> function. Possible solutions are disabling context analysis for that
> function or removing __assume_ctx_lock() again from mutex_init(). Does
> anyone want to share their opinion about this?

Probably the most idiomatic option is to just factor out construction.
Clearly separating complex object construction from use also helps
readability regardless, esp. where concurrency is involved. We could
document such advice somewhere.

For the above case, this seems cleanest and also clearer to me:

diff --git a/drivers/base/devcoredump.c b/drivers/base/devcoredump.c
index 55bdc7f5e59d..56ac8aa41608 100644
--- a/drivers/base/devcoredump.c
+++ b/drivers/base/devcoredump.c
@@ -339,6 +339,40 @@ void dev_coredump_put(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(dev_coredump_put);
 
+static struct devcd_entry *
+dev_coredumpm_init(struct device *dev, struct module *owner, void *data,
+		   size_t datalen, gfp_t gfp,
+		   ssize_t (*read)(char *buffer, loff_t offset, size_t count,
+				   void *data, size_t datalen),
+		   void (*free)(void *data))
+{
+	static atomic_t devcd_count = ATOMIC_INIT(0);
+	struct devcd_entry *devcd;
+
+	devcd = kzalloc(sizeof(*devcd), gfp);
+	if (!devcd)
+		return NULL;
+
+	devcd->owner = owner;
+	devcd->data = data;
+	devcd->datalen = datalen;
+	devcd->read = read;
+	devcd->free = free;
+	devcd->failing_dev = get_device(dev);
+	devcd->deleted = false;
+
+	mutex_init(&devcd->mutex);
+	device_initialize(&devcd->devcd_dev);
+
+	dev_set_name(&devcd->devcd_dev, "devcd%d",
+		     atomic_inc_return(&devcd_count));
+	devcd->devcd_dev.class = &devcd_class;
+
+	dev_set_uevent_suppress(&devcd->devcd_dev, true);
+
+	return devcd;
+}
+
 /**
  * dev_coredumpm_timeout - create device coredump with read/free methods with a
  * custom timeout.
@@ -364,7 +398,6 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 			   void (*free)(void *data),
 			   unsigned long timeout)
 {
-	static atomic_t devcd_count = ATOMIC_INIT(0);
 	struct devcd_entry *devcd;
 	struct device *existing;
 
@@ -381,27 +414,10 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 	if (!try_module_get(owner))
 		goto free;
 
-	devcd = kzalloc(sizeof(*devcd), gfp);
+	devcd = dev_coredumpm_init(dev, owner, data, datalen, gfp, read, free);
 	if (!devcd)
 		goto put_module;
 
-	devcd->owner = owner;
-	devcd->data = data;
-	devcd->datalen = datalen;
-	devcd->read = read;
-	devcd->free = free;
-	devcd->failing_dev = get_device(dev);
-	devcd->deleted = false;
-
-	mutex_init(&devcd->mutex);
-	device_initialize(&devcd->devcd_dev);
-
-	dev_set_name(&devcd->devcd_dev, "devcd%d",
-		     atomic_inc_return(&devcd_count));
-	devcd->devcd_dev.class = &devcd_class;
-
-	dev_set_uevent_suppress(&devcd->devcd_dev, true);
-
 	/* devcd->mutex prevents devcd_del() completing until init finishes */
 	mutex_lock(&devcd->mutex);
 	devcd->init_completed = false;

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-sparse
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 23:26:55 +0000
Message-ID: <aWA9P3_oI7JFTdkC () elver ! google ! com>
--------------------
On Thu, Jan 08, 2026 at 02:10PM -0800, 'Bart Van Assche' via kasan-dev wrote:
> On 12/19/25 8:39 AM, Marco Elver wrote:
> > diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> > index bf535f0118bb..89977c215cbd 100644
> > --- a/include/linux/mutex.h
> > +++ b/include/linux/mutex.h
> > @@ -62,6 +62,7 @@ do {									\
> >   	static struct lock_class_key __key;				\
> >   									\
> >   	__mutex_init((mutex), #mutex, &__key);				\
> > +	__assume_ctx_lock(mutex);					\
> >   } while (0)
> 
> The above type of change probably will have to be reverted. If I enable
> context analysis for the entire kernel tree, drivers/base/devcoredump.c
> doesn't build. The following error is reported:
> 
> drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' that
> is already held [-Werror,-Wthread-safety-analysis]
>   406 |         mutex_lock(&devcd->mutex);
>       |         ^
> 
> dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the same
> function. The above type of change breaks compilation of all code
> that initializes and locks a synchronization object from the same
> function. My understanding of dev_coredumpm_timeout() is that there is a
> good reason for calling both mutex_init() and mutex_lock() from that
> function. Possible solutions are disabling context analysis for that
> function or removing __assume_ctx_lock() again from mutex_init(). Does
> anyone want to share their opinion about this?

Probably the most idiomatic option is to just factor out construction.
Clearly separating complex object construction from use also helps
readability regardless, esp. where concurrency is involved. We could
document such advice somewhere.

For the above case, this seems cleanest and also clearer to me:

diff --git a/drivers/base/devcoredump.c b/drivers/base/devcoredump.c
index 55bdc7f5e59d..56ac8aa41608 100644
--- a/drivers/base/devcoredump.c
+++ b/drivers/base/devcoredump.c
@@ -339,6 +339,40 @@ void dev_coredump_put(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(dev_coredump_put);
 
+static struct devcd_entry *
+dev_coredumpm_init(struct device *dev, struct module *owner, void *data,
+		   size_t datalen, gfp_t gfp,
+		   ssize_t (*read)(char *buffer, loff_t offset, size_t count,
+				   void *data, size_t datalen),
+		   void (*free)(void *data))
+{
+	static atomic_t devcd_count = ATOMIC_INIT(0);
+	struct devcd_entry *devcd;
+
+	devcd = kzalloc(sizeof(*devcd), gfp);
+	if (!devcd)
+		return NULL;
+
+	devcd->owner = owner;
+	devcd->data = data;
+	devcd->datalen = datalen;
+	devcd->read = read;
+	devcd->free = free;
+	devcd->failing_dev = get_device(dev);
+	devcd->deleted = false;
+
+	mutex_init(&devcd->mutex);
+	device_initialize(&devcd->devcd_dev);
+
+	dev_set_name(&devcd->devcd_dev, "devcd%d",
+		     atomic_inc_return(&devcd_count));
+	devcd->devcd_dev.class = &devcd_class;
+
+	dev_set_uevent_suppress(&devcd->devcd_dev, true);
+
+	return devcd;
+}
+
 /**
  * dev_coredumpm_timeout - create device coredump with read/free methods with a
  * custom timeout.
@@ -364,7 +398,6 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 			   void (*free)(void *data),
 			   unsigned long timeout)
 {
-	static atomic_t devcd_count = ATOMIC_INIT(0);
 	struct devcd_entry *devcd;
 	struct device *existing;
 
@@ -381,27 +414,10 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 	if (!try_module_get(owner))
 		goto free;
 
-	devcd = kzalloc(sizeof(*devcd), gfp);
+	devcd = dev_coredumpm_init(dev, owner, data, datalen, gfp, read, free);
 	if (!devcd)
 		goto put_module;
 
-	devcd->owner = owner;
-	devcd->data = data;
-	devcd->datalen = datalen;
-	devcd->read = read;
-	devcd->free = free;
-	devcd->failing_dev = get_device(dev);
-	devcd->deleted = false;
-
-	mutex_init(&devcd->mutex);
-	device_initialize(&devcd->devcd_dev);
-
-	dev_set_name(&devcd->devcd_dev, "devcd%d",
-		     atomic_inc_return(&devcd_count));
-	devcd->devcd_dev.class = &devcd_class;
-
-	dev_set_uevent_suppress(&devcd->devcd_dev, true);
-
 	/* devcd->mutex prevents devcd_del() completing until init finishes */
 	mutex_lock(&devcd->mutex);
 	devcd->init_completed = false;

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kernel
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 23:26:55 +0000
Message-ID: <aWA9P3_oI7JFTdkC () elver ! google ! com>
--------------------
On Thu, Jan 08, 2026 at 02:10PM -0800, 'Bart Van Assche' via kasan-dev wrote:
> On 12/19/25 8:39 AM, Marco Elver wrote:
> > diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> > index bf535f0118bb..89977c215cbd 100644
> > --- a/include/linux/mutex.h
> > +++ b/include/linux/mutex.h
> > @@ -62,6 +62,7 @@ do {									\
> >   	static struct lock_class_key __key;				\
> >   									\
> >   	__mutex_init((mutex), #mutex, &__key);				\
> > +	__assume_ctx_lock(mutex);					\
> >   } while (0)
> 
> The above type of change probably will have to be reverted. If I enable
> context analysis for the entire kernel tree, drivers/base/devcoredump.c
> doesn't build. The following error is reported:
> 
> drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' that
> is already held [-Werror,-Wthread-safety-analysis]
>   406 |         mutex_lock(&devcd->mutex);
>       |         ^
> 
> dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the same
> function. The above type of change breaks compilation of all code
> that initializes and locks a synchronization object from the same
> function. My understanding of dev_coredumpm_timeout() is that there is a
> good reason for calling both mutex_init() and mutex_lock() from that
> function. Possible solutions are disabling context analysis for that
> function or removing __assume_ctx_lock() again from mutex_init(). Does
> anyone want to share their opinion about this?

Probably the most idiomatic option is to just factor out construction.
Clearly separating complex object construction from use also helps
readability regardless, esp. where concurrency is involved. We could
document such advice somewhere.

For the above case, this seems cleanest and also clearer to me:

diff --git a/drivers/base/devcoredump.c b/drivers/base/devcoredump.c
index 55bdc7f5e59d..56ac8aa41608 100644
--- a/drivers/base/devcoredump.c
+++ b/drivers/base/devcoredump.c
@@ -339,6 +339,40 @@ void dev_coredump_put(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(dev_coredump_put);
 
+static struct devcd_entry *
+dev_coredumpm_init(struct device *dev, struct module *owner, void *data,
+		   size_t datalen, gfp_t gfp,
+		   ssize_t (*read)(char *buffer, loff_t offset, size_t count,
+				   void *data, size_t datalen),
+		   void (*free)(void *data))
+{
+	static atomic_t devcd_count = ATOMIC_INIT(0);
+	struct devcd_entry *devcd;
+
+	devcd = kzalloc(sizeof(*devcd), gfp);
+	if (!devcd)
+		return NULL;
+
+	devcd->owner = owner;
+	devcd->data = data;
+	devcd->datalen = datalen;
+	devcd->read = read;
+	devcd->free = free;
+	devcd->failing_dev = get_device(dev);
+	devcd->deleted = false;
+
+	mutex_init(&devcd->mutex);
+	device_initialize(&devcd->devcd_dev);
+
+	dev_set_name(&devcd->devcd_dev, "devcd%d",
+		     atomic_inc_return(&devcd_count));
+	devcd->devcd_dev.class = &devcd_class;
+
+	dev_set_uevent_suppress(&devcd->devcd_dev, true);
+
+	return devcd;
+}
+
 /**
  * dev_coredumpm_timeout - create device coredump with read/free methods with a
  * custom timeout.
@@ -364,7 +398,6 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 			   void (*free)(void *data),
 			   unsigned long timeout)
 {
-	static atomic_t devcd_count = ATOMIC_INIT(0);
 	struct devcd_entry *devcd;
 	struct device *existing;
 
@@ -381,27 +414,10 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 	if (!try_module_get(owner))
 		goto free;
 
-	devcd = kzalloc(sizeof(*devcd), gfp);
+	devcd = dev_coredumpm_init(dev, owner, data, datalen, gfp, read, free);
 	if (!devcd)
 		goto put_module;
 
-	devcd->owner = owner;
-	devcd->data = data;
-	devcd->datalen = datalen;
-	devcd->read = read;
-	devcd->free = free;
-	devcd->failing_dev = get_device(dev);
-	devcd->deleted = false;
-
-	mutex_init(&devcd->mutex);
-	device_initialize(&devcd->devcd_dev);
-
-	dev_set_name(&devcd->devcd_dev, "devcd%d",
-		     atomic_inc_return(&devcd_count));
-	devcd->devcd_dev.class = &devcd_class;
-
-	dev_set_uevent_suppress(&devcd->devcd_dev, true);
-
 	/* devcd->mutex prevents devcd_del() completing until init finishes */
 	mutex_lock(&devcd->mutex);
 	devcd->init_completed = false;

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-doc
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 23:26:55 +0000
Message-ID: <aWA9P3_oI7JFTdkC () elver ! google ! com>
--------------------
On Thu, Jan 08, 2026 at 02:10PM -0800, 'Bart Van Assche' via kasan-dev wrote:
> On 12/19/25 8:39 AM, Marco Elver wrote:
> > diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> > index bf535f0118bb..89977c215cbd 100644
> > --- a/include/linux/mutex.h
> > +++ b/include/linux/mutex.h
> > @@ -62,6 +62,7 @@ do {									\
> >   	static struct lock_class_key __key;				\
> >   									\
> >   	__mutex_init((mutex), #mutex, &__key);				\
> > +	__assume_ctx_lock(mutex);					\
> >   } while (0)
> 
> The above type of change probably will have to be reverted. If I enable
> context analysis for the entire kernel tree, drivers/base/devcoredump.c
> doesn't build. The following error is reported:
> 
> drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' that
> is already held [-Werror,-Wthread-safety-analysis]
>   406 |         mutex_lock(&devcd->mutex);
>       |         ^
> 
> dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the same
> function. The above type of change breaks compilation of all code
> that initializes and locks a synchronization object from the same
> function. My understanding of dev_coredumpm_timeout() is that there is a
> good reason for calling both mutex_init() and mutex_lock() from that
> function. Possible solutions are disabling context analysis for that
> function or removing __assume_ctx_lock() again from mutex_init(). Does
> anyone want to share their opinion about this?

Probably the most idiomatic option is to just factor out construction.
Clearly separating complex object construction from use also helps
readability regardless, esp. where concurrency is involved. We could
document such advice somewhere.

For the above case, this seems cleanest and also clearer to me:

diff --git a/drivers/base/devcoredump.c b/drivers/base/devcoredump.c
index 55bdc7f5e59d..56ac8aa41608 100644
--- a/drivers/base/devcoredump.c
+++ b/drivers/base/devcoredump.c
@@ -339,6 +339,40 @@ void dev_coredump_put(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(dev_coredump_put);
 
+static struct devcd_entry *
+dev_coredumpm_init(struct device *dev, struct module *owner, void *data,
+		   size_t datalen, gfp_t gfp,
+		   ssize_t (*read)(char *buffer, loff_t offset, size_t count,
+				   void *data, size_t datalen),
+		   void (*free)(void *data))
+{
+	static atomic_t devcd_count = ATOMIC_INIT(0);
+	struct devcd_entry *devcd;
+
+	devcd = kzalloc(sizeof(*devcd), gfp);
+	if (!devcd)
+		return NULL;
+
+	devcd->owner = owner;
+	devcd->data = data;
+	devcd->datalen = datalen;
+	devcd->read = read;
+	devcd->free = free;
+	devcd->failing_dev = get_device(dev);
+	devcd->deleted = false;
+
+	mutex_init(&devcd->mutex);
+	device_initialize(&devcd->devcd_dev);
+
+	dev_set_name(&devcd->devcd_dev, "devcd%d",
+		     atomic_inc_return(&devcd_count));
+	devcd->devcd_dev.class = &devcd_class;
+
+	dev_set_uevent_suppress(&devcd->devcd_dev, true);
+
+	return devcd;
+}
+
 /**
  * dev_coredumpm_timeout - create device coredump with read/free methods with a
  * custom timeout.
@@ -364,7 +398,6 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 			   void (*free)(void *data),
 			   unsigned long timeout)
 {
-	static atomic_t devcd_count = ATOMIC_INIT(0);
 	struct devcd_entry *devcd;
 	struct device *existing;
 
@@ -381,27 +414,10 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 	if (!try_module_get(owner))
 		goto free;
 
-	devcd = kzalloc(sizeof(*devcd), gfp);
+	devcd = dev_coredumpm_init(dev, owner, data, datalen, gfp, read, free);
 	if (!devcd)
 		goto put_module;
 
-	devcd->owner = owner;
-	devcd->data = data;
-	devcd->datalen = datalen;
-	devcd->read = read;
-	devcd->free = free;
-	devcd->failing_dev = get_device(dev);
-	devcd->deleted = false;
-
-	mutex_init(&devcd->mutex);
-	device_initialize(&devcd->devcd_dev);
-
-	dev_set_name(&devcd->devcd_dev, "devcd%d",
-		     atomic_inc_return(&devcd_count));
-	devcd->devcd_dev.class = &devcd_class;
-
-	dev_set_uevent_suppress(&devcd->devcd_dev, true);
-
 	/* devcd->mutex prevents devcd_del() completing until init finishes */
 	mutex_lock(&devcd->mutex);
 	devcd->init_completed = false;

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Thu, 08 Jan 2026 23:26:55 +0000
Message-ID: <aWA9P3_oI7JFTdkC () elver ! google ! com>
--------------------
On Thu, Jan 08, 2026 at 02:10PM -0800, 'Bart Van Assche' via kasan-dev wrote:
> On 12/19/25 8:39 AM, Marco Elver wrote:
> > diff --git a/include/linux/mutex.h b/include/linux/mutex.h
> > index bf535f0118bb..89977c215cbd 100644
> > --- a/include/linux/mutex.h
> > +++ b/include/linux/mutex.h
> > @@ -62,6 +62,7 @@ do {									\
> >   	static struct lock_class_key __key;				\
> >   									\
> >   	__mutex_init((mutex), #mutex, &__key);				\
> > +	__assume_ctx_lock(mutex);					\
> >   } while (0)
> 
> The above type of change probably will have to be reverted. If I enable
> context analysis for the entire kernel tree, drivers/base/devcoredump.c
> doesn't build. The following error is reported:
> 
> drivers/base/devcoredump.c:406:2: error: acquiring mutex '_res->mutex' that
> is already held [-Werror,-Wthread-safety-analysis]
>   406 |         mutex_lock(&devcd->mutex);
>       |         ^
> 
> dev_coredumpm_timeout() calls mutex_init() and mutex_lock() from the same
> function. The above type of change breaks compilation of all code
> that initializes and locks a synchronization object from the same
> function. My understanding of dev_coredumpm_timeout() is that there is a
> good reason for calling both mutex_init() and mutex_lock() from that
> function. Possible solutions are disabling context analysis for that
> function or removing __assume_ctx_lock() again from mutex_init(). Does
> anyone want to share their opinion about this?

Probably the most idiomatic option is to just factor out construction.
Clearly separating complex object construction from use also helps
readability regardless, esp. where concurrency is involved. We could
document such advice somewhere.

For the above case, this seems cleanest and also clearer to me:

diff --git a/drivers/base/devcoredump.c b/drivers/base/devcoredump.c
index 55bdc7f5e59d..56ac8aa41608 100644
--- a/drivers/base/devcoredump.c
+++ b/drivers/base/devcoredump.c
@@ -339,6 +339,40 @@ void dev_coredump_put(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(dev_coredump_put);
 
+static struct devcd_entry *
+dev_coredumpm_init(struct device *dev, struct module *owner, void *data,
+		   size_t datalen, gfp_t gfp,
+		   ssize_t (*read)(char *buffer, loff_t offset, size_t count,
+				   void *data, size_t datalen),
+		   void (*free)(void *data))
+{
+	static atomic_t devcd_count = ATOMIC_INIT(0);
+	struct devcd_entry *devcd;
+
+	devcd = kzalloc(sizeof(*devcd), gfp);
+	if (!devcd)
+		return NULL;
+
+	devcd->owner = owner;
+	devcd->data = data;
+	devcd->datalen = datalen;
+	devcd->read = read;
+	devcd->free = free;
+	devcd->failing_dev = get_device(dev);
+	devcd->deleted = false;
+
+	mutex_init(&devcd->mutex);
+	device_initialize(&devcd->devcd_dev);
+
+	dev_set_name(&devcd->devcd_dev, "devcd%d",
+		     atomic_inc_return(&devcd_count));
+	devcd->devcd_dev.class = &devcd_class;
+
+	dev_set_uevent_suppress(&devcd->devcd_dev, true);
+
+	return devcd;
+}
+
 /**
  * dev_coredumpm_timeout - create device coredump with read/free methods with a
  * custom timeout.
@@ -364,7 +398,6 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 			   void (*free)(void *data),
 			   unsigned long timeout)
 {
-	static atomic_t devcd_count = ATOMIC_INIT(0);
 	struct devcd_entry *devcd;
 	struct device *existing;
 
@@ -381,27 +414,10 @@ void dev_coredumpm_timeout(struct device *dev, struct module *owner,
 	if (!try_module_get(owner))
 		goto free;
 
-	devcd = kzalloc(sizeof(*devcd), gfp);
+	devcd = dev_coredumpm_init(dev, owner, data, datalen, gfp, read, free);
 	if (!devcd)
 		goto put_module;
 
-	devcd->owner = owner;
-	devcd->data = data;
-	devcd->datalen = datalen;
-	devcd->read = read;
-	devcd->free = free;
-	devcd->failing_dev = get_device(dev);
-	devcd->deleted = false;
-
-	mutex_init(&devcd->mutex);
-	device_initialize(&devcd->devcd_dev);
-
-	dev_set_name(&devcd->devcd_dev, "devcd%d",
-		     atomic_inc_return(&devcd_count));
-	devcd->devcd_dev.class = &devcd_class;
-
-	dev_set_uevent_suppress(&devcd->devcd_dev, true);
-
 	/* devcd->mutex prevents devcd_del() completing until init finishes */
 	mutex_lock(&devcd->mutex);
 	devcd->init_completed = false;

================================================================================

From: Christoph Hellwig <hch () lst ! de>
To: linux-kbuild
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 06:02:49 +0000
Message-ID: <20260109060249.GA5259 () lst ! de>
--------------------
On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> Probably the most idiomatic option is to just factor out construction.
> Clearly separating complex object construction from use also helps
> readability regardless, esp. where concurrency is involved. We could
> document such advice somewhere.

Initializing and locking a mutex (or spinlock, or other primitive) is a
not too unusual pattern, often used when inserting an object into a
hash table or other lookup data structure.  So supporting it without
creating pointless wrapper functions would be really useful.  One thing
that would be nice to have and probably help here is to have lock
initializers that create the lock in a held state.


================================================================================

From: Christoph Hellwig <hch () lst ! de>
To: linux-kernel
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 06:02:49 +0000
Message-ID: <20260109060249.GA5259 () lst ! de>
--------------------
On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> Probably the most idiomatic option is to just factor out construction.
> Clearly separating complex object construction from use also helps
> readability regardless, esp. where concurrency is involved. We could
> document such advice somewhere.

Initializing and locking a mutex (or spinlock, or other primitive) is a
not too unusual pattern, often used when inserting an object into a
hash table or other lookup data structure.  So supporting it without
creating pointless wrapper functions would be really useful.  One thing
that would be nice to have and probably help here is to have lock
initializers that create the lock in a held state.


================================================================================

From: Christoph Hellwig <hch () lst ! de>
To: linux-doc
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 06:02:49 +0000
Message-ID: <20260109060249.GA5259 () lst ! de>
--------------------
On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> Probably the most idiomatic option is to just factor out construction.
> Clearly separating complex object construction from use also helps
> readability regardless, esp. where concurrency is involved. We could
> document such advice somewhere.

Initializing and locking a mutex (or spinlock, or other primitive) is a
not too unusual pattern, often used when inserting an object into a
hash table or other lookup data structure.  So supporting it without
creating pointless wrapper functions would be really useful.  One thing
that would be nice to have and probably help here is to have lock
initializers that create the lock in a held state.


================================================================================

From: Christoph Hellwig <hch () lst ! de>
To: linux-crypto-vger
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 06:02:49 +0000
Message-ID: <20260109060249.GA5259 () lst ! de>
--------------------
On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> Probably the most idiomatic option is to just factor out construction.
> Clearly separating complex object construction from use also helps
> readability regardless, esp. where concurrency is involved. We could
> document such advice somewhere.

Initializing and locking a mutex (or spinlock, or other primitive) is a
not too unusual pattern, often used when inserting an object into a
hash table or other lookup data structure.  So supporting it without
creating pointless wrapper functions would be really useful.  One thing
that would be nice to have and probably help here is to have lock
initializers that create the lock in a held state.


================================================================================

From: Christoph Hellwig <hch () lst ! de>
To: linux-mm
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 06:02:49 +0000
Message-ID: <20260109060249.GA5259 () lst ! de>
--------------------
On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> Probably the most idiomatic option is to just factor out construction.
> Clearly separating complex object construction from use also helps
> readability regardless, esp. where concurrency is involved. We could
> document such advice somewhere.

Initializing and locking a mutex (or spinlock, or other primitive) is a
not too unusual pattern, often used when inserting an object into a
hash table or other lookup data structure.  So supporting it without
creating pointless wrapper functions would be really useful.  One thing
that would be nice to have and probably help here is to have lock
initializers that create the lock in a held state.


================================================================================

From: Christoph Hellwig <hch () lst ! de>
To: linux-wireless
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 06:02:49 +0000
Message-ID: <20260109060249.GA5259 () lst ! de>
--------------------
On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> Probably the most idiomatic option is to just factor out construction.
> Clearly separating complex object construction from use also helps
> readability regardless, esp. where concurrency is involved. We could
> document such advice somewhere.

Initializing and locking a mutex (or spinlock, or other primitive) is a
not too unusual pattern, often used when inserting an object into a
hash table or other lookup data structure.  So supporting it without
creating pointless wrapper functions would be really useful.  One thing
that would be nice to have and probably help here is to have lock
initializers that create the lock in a held state.


================================================================================

From: Christoph Hellwig <hch () lst ! de>
To: linux-sparse
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 06:02:49 +0000
Message-ID: <20260109060249.GA5259 () lst ! de>
--------------------
On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> Probably the most idiomatic option is to just factor out construction.
> Clearly separating complex object construction from use also helps
> readability regardless, esp. where concurrency is involved. We could
> document such advice somewhere.

Initializing and locking a mutex (or spinlock, or other primitive) is a
not too unusual pattern, often used when inserting an object into a
hash table or other lookup data structure.  So supporting it without
creating pointless wrapper functions would be really useful.  One thing
that would be nice to have and probably help here is to have lock
initializers that create the lock in a held state.


================================================================================

From: Steven Rostedt <rostedt () goodmis ! org>
To: linux-kernel
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 13:07:15 +0000
Message-ID: <20260109080715.0a390f6b () gandalf ! local ! home>
--------------------
On Fri, 9 Jan 2026 07:02:49 +0100
Christoph Hellwig <hch@lst.de> wrote:

> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.  
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Right. If tooling can't handle a simple pattern of initializing a lock than
taking it, that's a hard show stopper of adding that tooling.

-- Steve

================================================================================

From: Steven Rostedt <rostedt () goodmis ! org>
To: linux-mm
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 13:07:15 +0000
Message-ID: <20260109080715.0a390f6b () gandalf ! local ! home>
--------------------
On Fri, 9 Jan 2026 07:02:49 +0100
Christoph Hellwig <hch@lst.de> wrote:

> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.  
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Right. If tooling can't handle a simple pattern of initializing a lock than
taking it, that's a hard show stopper of adding that tooling.

-- Steve

================================================================================

From: Steven Rostedt <rostedt () goodmis ! org>
To: linux-sparse
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 13:07:15 +0000
Message-ID: <20260109080715.0a390f6b () gandalf ! local ! home>
--------------------
On Fri, 9 Jan 2026 07:02:49 +0100
Christoph Hellwig <hch@lst.de> wrote:

> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.  
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Right. If tooling can't handle a simple pattern of initializing a lock than
taking it, that's a hard show stopper of adding that tooling.

-- Steve

================================================================================

From: Steven Rostedt <rostedt () goodmis ! org>
To: linux-crypto-vger
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 13:07:15 +0000
Message-ID: <20260109080715.0a390f6b () gandalf ! local ! home>
--------------------
On Fri, 9 Jan 2026 07:02:49 +0100
Christoph Hellwig <hch@lst.de> wrote:

> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.  
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Right. If tooling can't handle a simple pattern of initializing a lock than
taking it, that's a hard show stopper of adding that tooling.

-- Steve

================================================================================

From: Steven Rostedt <rostedt () goodmis ! org>
To: linux-doc
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 13:07:15 +0000
Message-ID: <20260109080715.0a390f6b () gandalf ! local ! home>
--------------------
On Fri, 9 Jan 2026 07:02:49 +0100
Christoph Hellwig <hch@lst.de> wrote:

> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.  
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Right. If tooling can't handle a simple pattern of initializing a lock than
taking it, that's a hard show stopper of adding that tooling.

-- Steve

================================================================================

From: Steven Rostedt <rostedt () goodmis ! org>
To: linux-wireless
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 13:07:15 +0000
Message-ID: <20260109080715.0a390f6b () gandalf ! local ! home>
--------------------
On Fri, 9 Jan 2026 07:02:49 +0100
Christoph Hellwig <hch@lst.de> wrote:

> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.  
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Right. If tooling can't handle a simple pattern of initializing a lock than
taking it, that's a hard show stopper of adding that tooling.

-- Steve

================================================================================

From: Steven Rostedt <rostedt () goodmis ! org>
To: linux-kbuild
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 13:07:15 +0000
Message-ID: <20260109080715.0a390f6b () gandalf ! local ! home>
--------------------
On Fri, 9 Jan 2026 07:02:49 +0100
Christoph Hellwig <hch@lst.de> wrote:

> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.  
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Right. If tooling can't handle a simple pattern of initializing a lock than
taking it, that's a hard show stopper of adding that tooling.

-- Steve

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-mm
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Sat, 10 Jan 2026 03:23:16 +0000
Message-ID: <aWHGJA8imMgELQrA () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 07:02AM +0100, Christoph Hellwig wrote:
> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Fair point. Without new APIs, we can fix it with the below patch;
essentially "promoting" the context lock to "reentrant" during
initialization scope. It's not exactly well documented on the Clang
side, but is a side-effect of how reentrancy works in the analysis:
https://github.com/llvm/llvm-project/pull/175267

------ >8 ------


================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kernel
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Sat, 10 Jan 2026 03:23:16 +0000
Message-ID: <aWHGJA8imMgELQrA () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 07:02AM +0100, Christoph Hellwig wrote:
> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Fair point. Without new APIs, we can fix it with the below patch;
essentially "promoting" the context lock to "reentrant" during
initialization scope. It's not exactly well documented on the Clang
side, but is a side-effect of how reentrancy works in the analysis:
https://github.com/llvm/llvm-project/pull/175267

------ >8 ------


================================================================================

From: Marco Elver <elver () google ! com>
To: linux-sparse
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Sat, 10 Jan 2026 03:23:16 +0000
Message-ID: <aWHGJA8imMgELQrA () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 07:02AM +0100, Christoph Hellwig wrote:
> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Fair point. Without new APIs, we can fix it with the below patch;
essentially "promoting" the context lock to "reentrant" during
initialization scope. It's not exactly well documented on the Clang
side, but is a side-effect of how reentrancy works in the analysis:
https://github.com/llvm/llvm-project/pull/175267

------ >8 ------


================================================================================

From: Marco Elver <elver () google ! com>
To: linux-wireless
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Sat, 10 Jan 2026 03:23:16 +0000
Message-ID: <aWHGJA8imMgELQrA () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 07:02AM +0100, Christoph Hellwig wrote:
> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Fair point. Without new APIs, we can fix it with the below patch;
essentially "promoting" the context lock to "reentrant" during
initialization scope. It's not exactly well documented on the Clang
side, but is a side-effect of how reentrancy works in the analysis:
https://github.com/llvm/llvm-project/pull/175267

------ >8 ------


================================================================================

From: Marco Elver <elver () google ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Sat, 10 Jan 2026 03:23:16 +0000
Message-ID: <aWHGJA8imMgELQrA () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 07:02AM +0100, Christoph Hellwig wrote:
> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Fair point. Without new APIs, we can fix it with the below patch;
essentially "promoting" the context lock to "reentrant" during
initialization scope. It's not exactly well documented on the Clang
side, but is a side-effect of how reentrancy works in the analysis:
https://github.com/llvm/llvm-project/pull/175267

------ >8 ------


================================================================================

From: Marco Elver <elver () google ! com>
To: linux-doc
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Sat, 10 Jan 2026 03:23:16 +0000
Message-ID: <aWHGJA8imMgELQrA () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 07:02AM +0100, Christoph Hellwig wrote:
> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Fair point. Without new APIs, we can fix it with the below patch;
essentially "promoting" the context lock to "reentrant" during
initialization scope. It's not exactly well documented on the Clang
side, but is a side-effect of how reentrancy works in the analysis:
https://github.com/llvm/llvm-project/pull/175267

------ >8 ------


================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 10/36] locking/mutex: Support Clang's context analysis
Date: Sat, 10 Jan 2026 03:23:16 +0000
Message-ID: <aWHGJA8imMgELQrA () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 07:02AM +0100, Christoph Hellwig wrote:
> On Fri, Jan 09, 2026 at 12:26:55AM +0100, Marco Elver wrote:
> > Probably the most idiomatic option is to just factor out construction.
> > Clearly separating complex object construction from use also helps
> > readability regardless, esp. where concurrency is involved. We could
> > document such advice somewhere.
> 
> Initializing and locking a mutex (or spinlock, or other primitive) is a
> not too unusual pattern, often used when inserting an object into a
> hash table or other lookup data structure.  So supporting it without
> creating pointless wrapper functions would be really useful.  One thing
> that would be nice to have and probably help here is to have lock
> initializers that create the lock in a held state.

Fair point. Without new APIs, we can fix it with the below patch;
essentially "promoting" the context lock to "reentrant" during
initialization scope. It's not exactly well documented on the Clang
side, but is a side-effect of how reentrancy works in the analysis:
https://github.com/llvm/llvm-project/pull/175267

------ >8 ------


================================================================================


################################################################################

=== Thread: [PATCH v5 15/36] srcu: Support Clang's context analysis ===

From: Marco Elver <elver () google ! com>
To: linux-kbuild
Subject: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Fri, 19 Dec 2025 15:40:04 +0000
Message-ID: <20251219154418.3592607-16-elver () google ! com>
--------------------
Add support for Clang's context analysis for SRCU.

Signed-off-by: Marco Elver <elver@google.com>
Acked-by: Paul E. McKenney <paulmck@kernel.org>
---
v5:
* Fix up annotation for recently added SRCU interfaces.
* Rename "context guard" -> "context lock".
* Use new cleanup.h helpers to properly support scoped lock guards.

v4:
* Rename capability -> context analysis.

v3:
* Switch to DECLARE_LOCK_GUARD_1_ATTRS() (suggested by Peter)
* Support SRCU being reentrant.
---
 Documentation/dev-tools/context-analysis.rst |  2 +-
 include/linux/srcu.h                         | 73 ++++++++++++++------
 include/linux/srcutiny.h                     |  6 ++
 include/linux/srcutree.h                     | 10 ++-
 lib/test_context-analysis.c                  | 25 +++++++
 5 files changed, 91 insertions(+), 25 deletions(-)

diff --git a/Documentation/dev-tools/context-analysis.rst b/Documentation/dev-tools/context-analysis.rst
index 3bc72f71fe25..f7736f1c0767 100644
--- a/Documentation/dev-tools/context-analysis.rst
+++ b/Documentation/dev-tools/context-analysis.rst
@@ -80,7 +80,7 @@ Supported Kernel Primitives
 
 Currently the following synchronization primitives are supported:
 `raw_spinlock_t`, `spinlock_t`, `rwlock_t`, `mutex`, `seqlock_t`,
-`bit_spinlock`, RCU.
+`bit_spinlock`, RCU, SRCU (`srcu_struct`).
 
 For context locks with an initialization function (e.g., `spin_lock_init()`),
 calling this function before initializing any guarded members or globals
diff --git a/include/linux/srcu.h b/include/linux/srcu.h
index 344ad51c8f6c..bb44a0bd7696 100644
--- a/include/linux/srcu.h
+++ b/include/linux/srcu.h
@@ -21,7 +21,7 @@
 #include <linux/workqueue.h>
 #include <linux/rcu_segcblist.h>
 
-struct srcu_struct;
+context_lock_struct(srcu_struct, __reentrant_ctx_lock);
 
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 
@@ -77,7 +77,7 @@ int init_srcu_struct_fast_updown(struct srcu_struct *ssp);
 #define SRCU_READ_FLAVOR_SLOWGP		(SRCU_READ_FLAVOR_FAST | SRCU_READ_FLAVOR_FAST_UPDOWN)
 						// Flavors requiring synchronize_rcu()
 						// instead of smp_mb().
-void __srcu_read_unlock(struct srcu_struct *ssp, int idx) __releases(ssp);
+void __srcu_read_unlock(struct srcu_struct *ssp, int idx) __releases_shared(ssp);
 
 #ifdef CONFIG_TINY_SRCU
 #include <linux/srcutiny.h>
@@ -131,14 +131,16 @@ static inline bool same_state_synchronize_srcu(unsigned long oldstate1, unsigned
 }
 
 #ifdef CONFIG_NEED_SRCU_NMI_SAFE
-int __srcu_read_lock_nmisafe(struct srcu_struct *ssp) __acquires(ssp);
-void __srcu_read_unlock_nmisafe(struct srcu_struct *ssp, int idx) __releases(ssp);
+int __srcu_read_lock_nmisafe(struct srcu_struct *ssp) __acquires_shared(ssp);
+void __srcu_read_unlock_nmisafe(struct srcu_struct *ssp, int idx) __releases_shared(ssp);
 #else
 static inline int __srcu_read_lock_nmisafe(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	return __srcu_read_lock(ssp);
 }
 static inline void __srcu_read_unlock_nmisafe(struct srcu_struct *ssp, int idx)
+	__releases_shared(ssp)
 {
 	__srcu_read_unlock(ssp, idx);
 }
@@ -210,6 +212,14 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
 
 #endif /* #else #ifdef CONFIG_DEBUG_LOCK_ALLOC */
 
+/*
+ * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
+ * should still be marked with __rcu_guarded, and we do not want to mark them
+ * with __guarded_by(ssp) as it would complicate annotations for writers, we
+ * choose the following strategy: srcu_dereference_check() calls this helper
+ * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
+ */
+static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
 
 /**
  * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
@@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
  * to 1.  The @c argument will normally be a logical expression containing
  * lockdep_is_held() calls.
  */
-#define srcu_dereference_check(p, ssp, c) \
-	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
-				(c) || srcu_read_lock_held(ssp), __rcu)
+#define srcu_dereference_check(p, ssp, c)					\
+({										\
+	__srcu_read_lock_must_hold(ssp);					\
+	__acquire_shared_ctx_lock(RCU);					\
+	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
+				(c) || srcu_read_lock_held(ssp), __rcu);	\
+	__release_shared_ctx_lock(RCU);					\
+	__v;									\
+})
 
 /**
  * srcu_dereference - fetch SRCU-protected pointer for later dereferencing
@@ -268,7 +284,8 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
  * invoke srcu_read_unlock() from one task and the matching srcu_read_lock()
  * from another.
  */
-static inline int srcu_read_lock(struct srcu_struct *ssp) __acquires(ssp)
+static inline int srcu_read_lock(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	int retval;
 
@@ -304,7 +321,8 @@ static inline int srcu_read_lock(struct srcu_struct *ssp) __acquires(ssp)
  * contexts where RCU is watching, that is, from contexts where it would
  * be legal to invoke rcu_read_lock().  Otherwise, lockdep will complain.
  */
-static inline struct srcu_ctr __percpu *srcu_read_lock_fast(struct srcu_struct *ssp) __acquires(ssp)
+static inline struct srcu_ctr __percpu *srcu_read_lock_fast(struct srcu_struct *ssp) __acquires_shared(ssp)
+	__acquires_shared(ssp)
 {
 	struct srcu_ctr __percpu *retval;
 
@@ -344,7 +362,7 @@ static inline struct srcu_ctr __percpu *srcu_read_lock_fast(struct srcu_struct *
  * complain.
  */
 static inline struct srcu_ctr __percpu *srcu_read_lock_fast_updown(struct srcu_struct *ssp)
-__acquires(ssp)
+	__acquires_shared(ssp)
 {
 	struct srcu_ctr __percpu *retval;
 
@@ -360,7 +378,7 @@ __acquires(ssp)
  * See srcu_read_lock_fast() for more information.
  */
 static inline struct srcu_ctr __percpu *srcu_read_lock_fast_notrace(struct srcu_struct *ssp)
-	__acquires(ssp)
+	__acquires_shared(ssp)
 {
 	struct srcu_ctr __percpu *retval;
 
@@ -381,7 +399,7 @@ static inline struct srcu_ctr __percpu *srcu_read_lock_fast_notrace(struct srcu_
  * and srcu_read_lock_fast().  However, the same definition/initialization
  * requirements called out for srcu_read_lock_safe() apply.
  */
-static inline struct srcu_ctr __percpu *srcu_down_read_fast(struct srcu_struct *ssp) __acquires(ssp)
+static inline struct srcu_ctr __percpu *srcu_down_read_fast(struct srcu_struct *ssp) __acquires_shared(ssp)
 {
 	WARN_ON_ONCE(IS_ENABLED(CONFIG_PROVE_RCU) && in_nmi());
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "RCU must be watching srcu_down_read_fast().");
@@ -400,7 +418,8 @@ static inline struct srcu_ctr __percpu *srcu_down_read_fast(struct srcu_struct *
  * then none of the other flavors may be used, whether before, during,
  * or after.
  */
-static inline int srcu_read_lock_nmisafe(struct srcu_struct *ssp) __acquires(ssp)
+static inline int srcu_read_lock_nmisafe(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	int retval;
 
@@ -412,7 +431,8 @@ static inline int srcu_read_lock_nmisafe(struct srcu_struct *ssp) __acquires(ssp
 
 /* Used by tracing, cannot be traced and cannot invoke lockdep. */
 static inline notrace int
-srcu_read_lock_notrace(struct srcu_struct *ssp) __acquires(ssp)
+srcu_read_lock_notrace(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	int retval;
 
@@ -443,7 +463,8 @@ srcu_read_lock_notrace(struct srcu_struct *ssp) __acquires(ssp)
  * which calls to down_read() may be nested.  The same srcu_struct may be
  * used concurrently by srcu_down_read() and srcu_read_lock().
  */
-static inline int srcu_down_read(struct srcu_struct *ssp) __acquires(ssp)
+static inline int srcu_down_read(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	WARN_ON_ONCE(in_nmi());
 	srcu_check_read_flavor(ssp, SRCU_READ_FLAVOR_NORMAL);
@@ -458,7 +479,7 @@ static inline int srcu_down_read(struct srcu_struct *ssp) __acquires(ssp)
  * Exit an SRCU read-side critical section.
  */
 static inline void srcu_read_unlock(struct srcu_struct *ssp, int idx)
-	__releases(ssp)
+	__releases_shared(ssp)
 {
 	WARN_ON_ONCE(idx & ~0x1);
 	srcu_check_read_flavor(ssp, SRCU_READ_FLAVOR_NORMAL);
@@ -474,7 +495,7 @@ static inline void srcu_read_unlock(struct srcu_struct *ssp, int idx)
  * Exit a light-weight SRCU read-side critical section.
  */
 static inline void srcu_read_unlock_fast(struct srcu_struct *ssp, struct srcu_ctr __percpu *scp)
-	__releases(ssp)
+	__releases_shared(ssp)
 {
 	srcu_check_read_flavor(ssp, SRCU_READ_FLAVOR_FAST);
 	srcu_lock_release(&ssp->dep_map);
@@ -490,7 +511,7 @@ static inline void srcu_read_unlock_fast(struct srcu_struct *ssp, struct srcu_ct
  * Exit an SRCU-fast-updown read-side critical section.
  */
 static inline void
-srcu_read_unlock_fast_updown(struct srcu_struct *ssp, struct srcu_ctr __percpu *scp) __releases(ssp)
+srcu_read_unlock_fast_updown(struct srcu_struct *ssp, struct srcu_ctr __percpu *scp) __releases_shared(ssp)
 {
 	srcu_check_read_flavor(ssp, SRCU_READ_FLAVOR_FAST_UPDOWN);
 	srcu_lock_release(&ssp->dep_map);
@@ -504,7 +525,7 @@ srcu_read_unlock_fast_updown(struct srcu_struct *ssp, struct srcu_ctr __percpu *
  * See srcu_read_unlock_fast() for more information.
  */
 static inline void srcu_read_unlock_fast_notrace(struct srcu_struct *ssp,
-						 struct srcu_ctr __percpu *scp) __releases(ssp)
+						 struct srcu_ctr __percpu *scp) __releases_shared(ssp)
 {
 	srcu_check_read_flavor(ssp, SRCU_READ_FLAVOR_FAST);
 	__srcu_read_unlock_fast(ssp, scp);
@@ -519,7 +540,7 @@ static inline void srcu_read_unlock_fast_notrace(struct srcu_struct *ssp,
  * the same context as the maching srcu_down_read_fast().
  */
 static inline void srcu_up_read_fast(struct srcu_struct *ssp, struct srcu_ctr __percpu *scp)
-	__releases(ssp)
+	__releases_shared(ssp)
 {
 	WARN_ON_ONCE(IS_ENABLED(CONFIG_PROVE_RCU) && in_nmi());
 	srcu_check_read_flavor(ssp, SRCU_READ_FLAVOR_FAST_UPDOWN);
@@ -535,7 +556,7 @@ static inline void srcu_up_read_fast(struct srcu_struct *ssp, struct srcu_ctr __
  * Exit an SRCU read-side critical section, but in an NMI-safe manner.
  */
 static inline void srcu_read_unlock_nmisafe(struct srcu_struct *ssp, int idx)
-	__releases(ssp)
+	__releases_shared(ssp)
 {
 	WARN_ON_ONCE(idx & ~0x1);
 	srcu_check_read_flavor(ssp, SRCU_READ_FLAVOR_NMI);
@@ -545,7 +566,7 @@ static inline void srcu_read_unlock_nmisafe(struct srcu_struct *ssp, int idx)
 
 /* Used by tracing, cannot be traced and cannot call lockdep. */
 static inline notrace void
-srcu_read_unlock_notrace(struct srcu_struct *ssp, int idx) __releases(ssp)
+srcu_read_unlock_notrace(struct srcu_struct *ssp, int idx) __releases_shared(ssp)
 {
 	srcu_check_read_flavor(ssp, SRCU_READ_FLAVOR_NORMAL);
 	__srcu_read_unlock(ssp, idx);
@@ -560,7 +581,7 @@ srcu_read_unlock_notrace(struct srcu_struct *ssp, int idx) __releases(ssp)
  * the same context as the maching srcu_down_read().
  */
 static inline void srcu_up_read(struct srcu_struct *ssp, int idx)
-	__releases(ssp)
+	__releases_shared(ssp)
 {
 	WARN_ON_ONCE(idx & ~0x1);
 	WARN_ON_ONCE(in_nmi());
@@ -600,15 +621,21 @@ DEFINE_LOCK_GUARD_1(srcu, struct srcu_struct,
 		    _T->idx = srcu_read_lock(_T->lock),
 		    srcu_read_unlock(_T->lock, _T->idx),
 		    int idx)
+DECLARE_LOCK_GUARD_1_ATTRS(srcu, __acquires_shared(_T), __releases_shared(*(struct srcu_struct **)_T))
+#define class_srcu_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(srcu, _T)
 
 DEFINE_LOCK_GUARD_1(srcu_fast, struct srcu_struct,
 		    _T->scp = srcu_read_lock_fast(_T->lock),
 		    srcu_read_unlock_fast(_T->lock, _T->scp),
 		    struct srcu_ctr __percpu *scp)
+DECLARE_LOCK_GUARD_1_ATTRS(srcu_fast, __acquires_shared(_T), __releases_shared(*(struct srcu_struct **)_T))
+#define class_srcu_fast_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(srcu_fast, _T)
 
 DEFINE_LOCK_GUARD_1(srcu_fast_notrace, struct srcu_struct,
 		    _T->scp = srcu_read_lock_fast_notrace(_T->lock),
 		    srcu_read_unlock_fast_notrace(_T->lock, _T->scp),
 		    struct srcu_ctr __percpu *scp)
+DECLARE_LOCK_GUARD_1_ATTRS(srcu_fast_notrace, __acquires_shared(_T), __releases_shared(*(struct srcu_struct **)_T))
+#define class_srcu_fast_notrace_constructor(_T) WITH_LOCK_GUARD_1_ATTRS(srcu_fast_notrace, _T)
 
 #endif
diff --git a/include/linux/srcutiny.h b/include/linux/srcutiny.h
index e0698024667a..dec7cbe015aa 100644
--- a/include/linux/srcutiny.h
+++ b/include/linux/srcutiny.h
@@ -73,6 +73,7 @@ void synchronize_srcu(struct srcu_struct *ssp);
  * index that must be passed to the matching srcu_read_unlock().
  */
 static inline int __srcu_read_lock(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	int idx;
 
@@ -80,6 +81,7 @@ static inline int __srcu_read_lock(struct srcu_struct *ssp)
 	idx = ((READ_ONCE(ssp->srcu_idx) + 1) & 0x2) >> 1;
 	WRITE_ONCE(ssp->srcu_lock_nesting[idx], READ_ONCE(ssp->srcu_lock_nesting[idx]) + 1);
 	preempt_enable();
+	__acquire_shared(ssp);
 	return idx;
 }
 
@@ -96,22 +98,26 @@ static inline struct srcu_ctr __percpu *__srcu_ctr_to_ptr(struct srcu_struct *ss
 }
 
 static inline struct srcu_ctr __percpu *__srcu_read_lock_fast(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	return __srcu_ctr_to_ptr(ssp, __srcu_read_lock(ssp));
 }
 
 static inline void __srcu_read_unlock_fast(struct srcu_struct *ssp, struct srcu_ctr __percpu *scp)
+	__releases_shared(ssp)
 {
 	__srcu_read_unlock(ssp, __srcu_ptr_to_ctr(ssp, scp));
 }
 
 static inline struct srcu_ctr __percpu *__srcu_read_lock_fast_updown(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	return __srcu_ctr_to_ptr(ssp, __srcu_read_lock(ssp));
 }
 
 static inline
 void __srcu_read_unlock_fast_updown(struct srcu_struct *ssp, struct srcu_ctr __percpu *scp)
+	__releases_shared(ssp)
 {
 	__srcu_read_unlock(ssp, __srcu_ptr_to_ctr(ssp, scp));
 }
diff --git a/include/linux/srcutree.h b/include/linux/srcutree.h
index d6f978b50472..958cb7ef41cb 100644
--- a/include/linux/srcutree.h
+++ b/include/linux/srcutree.h
@@ -233,7 +233,7 @@ struct srcu_struct {
 #define DEFINE_STATIC_SRCU_FAST_UPDOWN(name) \
 					__DEFINE_SRCU(name, SRCU_READ_FLAVOR_FAST_UPDOWN, static)
 
-int __srcu_read_lock(struct srcu_struct *ssp) __acquires(ssp);
+int __srcu_read_lock(struct srcu_struct *ssp) __acquires_shared(ssp);
 void synchronize_srcu_expedited(struct srcu_struct *ssp);
 void srcu_barrier(struct srcu_struct *ssp);
 void srcu_expedite_current(struct srcu_struct *ssp);
@@ -286,6 +286,7 @@ static inline struct srcu_ctr __percpu *__srcu_ctr_to_ptr(struct srcu_struct *ss
  * implementations of this_cpu_inc().
  */
 static inline struct srcu_ctr __percpu notrace *__srcu_read_lock_fast(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	struct srcu_ctr __percpu *scp = READ_ONCE(ssp->srcu_ctrp);
 
@@ -294,6 +295,7 @@ static inline struct srcu_ctr __percpu notrace *__srcu_read_lock_fast(struct src
 	else
 		atomic_long_inc(raw_cpu_ptr(&scp->srcu_locks));  // Y, and implicit RCU reader.
 	barrier(); /* Avoid leaking the critical section. */
+	__acquire_shared(ssp);
 	return scp;
 }
 
@@ -308,7 +310,9 @@ static inline struct srcu_ctr __percpu notrace *__srcu_read_lock_fast(struct src
  */
 static inline void notrace
 __srcu_read_unlock_fast(struct srcu_struct *ssp, struct srcu_ctr __percpu *scp)
+	__releases_shared(ssp)
 {
+	__release_shared(ssp);
 	barrier();  /* Avoid leaking the critical section. */
 	if (!IS_ENABLED(CONFIG_NEED_SRCU_NMI_SAFE))
 		this_cpu_inc(scp->srcu_unlocks.counter);  // Z, and implicit RCU reader.
@@ -326,6 +330,7 @@ __srcu_read_unlock_fast(struct srcu_struct *ssp, struct srcu_ctr __percpu *scp)
  */
 static inline
 struct srcu_ctr __percpu notrace *__srcu_read_lock_fast_updown(struct srcu_struct *ssp)
+	__acquires_shared(ssp)
 {
 	struct srcu_ctr __percpu *scp = READ_ONCE(ssp->srcu_ctrp);
 
@@ -334,6 +339,7 @@ struct srcu_ctr __percpu notrace *__srcu_read_lock_fast_updown(struct srcu_struc
 	else
 		atomic_long_inc(raw_cpu_ptr(&scp->srcu_locks));  // Y, and implicit RCU reader.
 	barrier(); /* Avoid leaking the critical section. */
+	__acquire_shared(ssp);
 	return scp;
 }
 
@@ -348,7 +354,9 @@ struct srcu_ctr __percpu notrace *__srcu_read_lock_fast_updown(struct srcu_struc
  */
 static inline void notrace
 __srcu_read_unlock_fast_updown(struct srcu_struct *ssp, struct srcu_ctr __percpu *scp)
+	__releases_shared(ssp)
 {
+	__release_shared(ssp);
 	barrier();  /* Avoid leaking the critical section. */
 	if (!IS_ENABLED(CONFIG_NEED_SRCU_NMI_SAFE))
 		this_cpu_inc(scp->srcu_unlocks.counter);  // Z, and implicit RCU reader.
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 559df32fb5f8..39e03790c0f6 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -10,6 +10,7 @@
 #include <linux/rcupdate.h>
 #include <linux/seqlock.h>
 #include <linux/spinlock.h>
+#include <linux/srcu.h>
 
 /*
  * Test that helper macros work as expected.
@@ -369,3 +370,27 @@ static void __used test_rcu_assert_variants(void)
 	lockdep_assert_in_rcu_read_lock_sched();
 	wants_rcu_held_sched();
 }
+
+struct test_srcu_data {
+	struct srcu_struct srcu;
+	long __rcu_guarded *data;
+};
+
+static void __used test_srcu(struct test_srcu_data *d)
+{
+	init_srcu_struct(&d->srcu);
+
+	int idx = srcu_read_lock(&d->srcu);
+	long *data = srcu_dereference(d->data, &d->srcu);
+	(void)data;
+	srcu_read_unlock(&d->srcu, idx);
+
+	rcu_assign_pointer(d->data, NULL);
+}
+
+static void __used test_srcu_guard(struct test_srcu_data *d)
+{
+	{ guard(srcu)(&d->srcu); (void)srcu_dereference(d->data, &d->srcu); }
+	{ guard(srcu_fast)(&d->srcu); (void)srcu_dereference(d->data, &d->srcu); }
+	{ guard(srcu_fast_notrace)(&d->srcu); (void)srcu_dereference(d->data, &d->srcu); }
+}
-- 
2.52.0.322.g1dd061c0dc-goog


================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-sparse
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 17:31:09 +0000
Message-ID: <dd65bb7b-0dac-437a-a370-38efeb4737ba () acm ! org>
--------------------
On 12/19/25 7:40 AM, Marco Elver wrote:
> +/*
> + * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
> + * should still be marked with __rcu_guarded, and we do not want to mark them
> + * with __guarded_by(ssp) as it would complicate annotations for writers, we
> + * choose the following strategy: srcu_dereference_check() calls this helper
> + * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
> + */
> +static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
>   
>   /**
>    * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
> @@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
>    * to 1.  The @c argument will normally be a logical expression containing
>    * lockdep_is_held() calls.
>    */
> -#define srcu_dereference_check(p, ssp, c) \
> -	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
> -				(c) || srcu_read_lock_held(ssp), __rcu)
> +#define srcu_dereference_check(p, ssp, c)					\
> +({										\
> +	__srcu_read_lock_must_hold(ssp);					\
> +	__acquire_shared_ctx_lock(RCU);					\
> +	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
> +				(c) || srcu_read_lock_held(ssp), __rcu);	\
> +	__release_shared_ctx_lock(RCU);					\
> +	__v;									\
> +})

Hi Marco,

The above change is something I'm not happy about. The original
implementation of the srcu_dereference_check() macro shows that it is
sufficient to either hold an SRCU reader lock or the updater lock ('c').
The addition of "__srcu_read_lock_must_hold()" will cause compilation to
fail if the caller doesn't hold an SRCU reader lock. I'm concerned that
this will either lead to adding __no_context_analysis to SRCU updater
code that uses srcu_dereference_check() or to adding misleading
__assume_ctx_lock(ssp) annotations in SRCU updater code.

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-kernel
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 17:31:09 +0000
Message-ID: <dd65bb7b-0dac-437a-a370-38efeb4737ba () acm ! org>
--------------------
On 12/19/25 7:40 AM, Marco Elver wrote:
> +/*
> + * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
> + * should still be marked with __rcu_guarded, and we do not want to mark them
> + * with __guarded_by(ssp) as it would complicate annotations for writers, we
> + * choose the following strategy: srcu_dereference_check() calls this helper
> + * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
> + */
> +static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
>   
>   /**
>    * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
> @@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
>    * to 1.  The @c argument will normally be a logical expression containing
>    * lockdep_is_held() calls.
>    */
> -#define srcu_dereference_check(p, ssp, c) \
> -	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
> -				(c) || srcu_read_lock_held(ssp), __rcu)
> +#define srcu_dereference_check(p, ssp, c)					\
> +({										\
> +	__srcu_read_lock_must_hold(ssp);					\
> +	__acquire_shared_ctx_lock(RCU);					\
> +	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
> +				(c) || srcu_read_lock_held(ssp), __rcu);	\
> +	__release_shared_ctx_lock(RCU);					\
> +	__v;									\
> +})

Hi Marco,

The above change is something I'm not happy about. The original
implementation of the srcu_dereference_check() macro shows that it is
sufficient to either hold an SRCU reader lock or the updater lock ('c').
The addition of "__srcu_read_lock_must_hold()" will cause compilation to
fail if the caller doesn't hold an SRCU reader lock. I'm concerned that
this will either lead to adding __no_context_analysis to SRCU updater
code that uses srcu_dereference_check() or to adding misleading
__assume_ctx_lock(ssp) annotations in SRCU updater code.

Thanks,

Bart.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kernel
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:35:33 +0000
Message-ID: <aXez9fSxdfu5-Boo () elver ! google ! com>
--------------------
On Mon, Jan 26, 2026 at 09:31AM -0800, Bart Van Assche wrote:
> On 12/19/25 7:40 AM, Marco Elver wrote:
> > +/*
> > + * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
> > + * should still be marked with __rcu_guarded, and we do not want to mark them
> > + * with __guarded_by(ssp) as it would complicate annotations for writers, we
> > + * choose the following strategy: srcu_dereference_check() calls this helper
> > + * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
> > + */
> > +static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
> >   /**
> >    * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
> > @@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
> >    * to 1.  The @c argument will normally be a logical expression containing
> >    * lockdep_is_held() calls.
> >    */
> > -#define srcu_dereference_check(p, ssp, c) \
> > -	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
> > -				(c) || srcu_read_lock_held(ssp), __rcu)
> > +#define srcu_dereference_check(p, ssp, c)					\
> > +({										\
> > +	__srcu_read_lock_must_hold(ssp);					\
> > +	__acquire_shared_ctx_lock(RCU);					\
> > +	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
> > +				(c) || srcu_read_lock_held(ssp), __rcu);	\
> > +	__release_shared_ctx_lock(RCU);					\
> > +	__v;									\
> > +})
> 
> Hi Marco,
> 
> The above change is something I'm not happy about. The original
> implementation of the srcu_dereference_check() macro shows that it is
> sufficient to either hold an SRCU reader lock or the updater lock ('c').
> The addition of "__srcu_read_lock_must_hold()" will cause compilation to
> fail if the caller doesn't hold an SRCU reader lock. I'm concerned that
> this will either lead to adding __no_context_analysis to SRCU updater
> code that uses srcu_dereference_check() or to adding misleading
> __assume_ctx_lock(ssp) annotations in SRCU updater code.

Right, and it doesn't help 'c' is an arbitrary condition. But it's
fundamentally difficult to say "hold either this or that lock".

That being said, I don't think it's wrong to write e.g.:

	spin_lock(&updater_lock);
	__acquire_shared(ssp);
	...
	// writes happen through rcu_assign_pointer()
	// reads can happen through srcu_dereference_check()
	...
	__release_shared(ssp);
	spin_unlock(&updater_lock);

, given holding the updater lock implies reader access.

And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
it's a manageable problem.

If you have a different idea how we can solve this, please let us know.

One final note, usage of srcu_dereference_check() is rare enough:

	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,

, that I think it's easy enough to annotate these places with the above
suggestions in case you're trying out global enablement.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:35:33 +0000
Message-ID: <aXez9fSxdfu5-Boo () elver ! google ! com>
--------------------
On Mon, Jan 26, 2026 at 09:31AM -0800, Bart Van Assche wrote:
> On 12/19/25 7:40 AM, Marco Elver wrote:
> > +/*
> > + * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
> > + * should still be marked with __rcu_guarded, and we do not want to mark them
> > + * with __guarded_by(ssp) as it would complicate annotations for writers, we
> > + * choose the following strategy: srcu_dereference_check() calls this helper
> > + * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
> > + */
> > +static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
> >   /**
> >    * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
> > @@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
> >    * to 1.  The @c argument will normally be a logical expression containing
> >    * lockdep_is_held() calls.
> >    */
> > -#define srcu_dereference_check(p, ssp, c) \
> > -	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
> > -				(c) || srcu_read_lock_held(ssp), __rcu)
> > +#define srcu_dereference_check(p, ssp, c)					\
> > +({										\
> > +	__srcu_read_lock_must_hold(ssp);					\
> > +	__acquire_shared_ctx_lock(RCU);					\
> > +	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
> > +				(c) || srcu_read_lock_held(ssp), __rcu);	\
> > +	__release_shared_ctx_lock(RCU);					\
> > +	__v;									\
> > +})
> 
> Hi Marco,
> 
> The above change is something I'm not happy about. The original
> implementation of the srcu_dereference_check() macro shows that it is
> sufficient to either hold an SRCU reader lock or the updater lock ('c').
> The addition of "__srcu_read_lock_must_hold()" will cause compilation to
> fail if the caller doesn't hold an SRCU reader lock. I'm concerned that
> this will either lead to adding __no_context_analysis to SRCU updater
> code that uses srcu_dereference_check() or to adding misleading
> __assume_ctx_lock(ssp) annotations in SRCU updater code.

Right, and it doesn't help 'c' is an arbitrary condition. But it's
fundamentally difficult to say "hold either this or that lock".

That being said, I don't think it's wrong to write e.g.:

	spin_lock(&updater_lock);
	__acquire_shared(ssp);
	...
	// writes happen through rcu_assign_pointer()
	// reads can happen through srcu_dereference_check()
	...
	__release_shared(ssp);
	spin_unlock(&updater_lock);

, given holding the updater lock implies reader access.

And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
it's a manageable problem.

If you have a different idea how we can solve this, please let us know.

One final note, usage of srcu_dereference_check() is rare enough:

	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,

, that I think it's easy enough to annotate these places with the above
suggestions in case you're trying out global enablement.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-doc
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:35:33 +0000
Message-ID: <aXez9fSxdfu5-Boo () elver ! google ! com>
--------------------
On Mon, Jan 26, 2026 at 09:31AM -0800, Bart Van Assche wrote:
> On 12/19/25 7:40 AM, Marco Elver wrote:
> > +/*
> > + * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
> > + * should still be marked with __rcu_guarded, and we do not want to mark them
> > + * with __guarded_by(ssp) as it would complicate annotations for writers, we
> > + * choose the following strategy: srcu_dereference_check() calls this helper
> > + * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
> > + */
> > +static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
> >   /**
> >    * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
> > @@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
> >    * to 1.  The @c argument will normally be a logical expression containing
> >    * lockdep_is_held() calls.
> >    */
> > -#define srcu_dereference_check(p, ssp, c) \
> > -	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
> > -				(c) || srcu_read_lock_held(ssp), __rcu)
> > +#define srcu_dereference_check(p, ssp, c)					\
> > +({										\
> > +	__srcu_read_lock_must_hold(ssp);					\
> > +	__acquire_shared_ctx_lock(RCU);					\
> > +	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
> > +				(c) || srcu_read_lock_held(ssp), __rcu);	\
> > +	__release_shared_ctx_lock(RCU);					\
> > +	__v;									\
> > +})
> 
> Hi Marco,
> 
> The above change is something I'm not happy about. The original
> implementation of the srcu_dereference_check() macro shows that it is
> sufficient to either hold an SRCU reader lock or the updater lock ('c').
> The addition of "__srcu_read_lock_must_hold()" will cause compilation to
> fail if the caller doesn't hold an SRCU reader lock. I'm concerned that
> this will either lead to adding __no_context_analysis to SRCU updater
> code that uses srcu_dereference_check() or to adding misleading
> __assume_ctx_lock(ssp) annotations in SRCU updater code.

Right, and it doesn't help 'c' is an arbitrary condition. But it's
fundamentally difficult to say "hold either this or that lock".

That being said, I don't think it's wrong to write e.g.:

	spin_lock(&updater_lock);
	__acquire_shared(ssp);
	...
	// writes happen through rcu_assign_pointer()
	// reads can happen through srcu_dereference_check()
	...
	__release_shared(ssp);
	spin_unlock(&updater_lock);

, given holding the updater lock implies reader access.

And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
it's a manageable problem.

If you have a different idea how we can solve this, please let us know.

One final note, usage of srcu_dereference_check() is rare enough:

	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,

, that I think it's easy enough to annotate these places with the above
suggestions in case you're trying out global enablement.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:35:33 +0000
Message-ID: <aXez9fSxdfu5-Boo () elver ! google ! com>
--------------------
On Mon, Jan 26, 2026 at 09:31AM -0800, Bart Van Assche wrote:
> On 12/19/25 7:40 AM, Marco Elver wrote:
> > +/*
> > + * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
> > + * should still be marked with __rcu_guarded, and we do not want to mark them
> > + * with __guarded_by(ssp) as it would complicate annotations for writers, we
> > + * choose the following strategy: srcu_dereference_check() calls this helper
> > + * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
> > + */
> > +static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
> >   /**
> >    * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
> > @@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
> >    * to 1.  The @c argument will normally be a logical expression containing
> >    * lockdep_is_held() calls.
> >    */
> > -#define srcu_dereference_check(p, ssp, c) \
> > -	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
> > -				(c) || srcu_read_lock_held(ssp), __rcu)
> > +#define srcu_dereference_check(p, ssp, c)					\
> > +({										\
> > +	__srcu_read_lock_must_hold(ssp);					\
> > +	__acquire_shared_ctx_lock(RCU);					\
> > +	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
> > +				(c) || srcu_read_lock_held(ssp), __rcu);	\
> > +	__release_shared_ctx_lock(RCU);					\
> > +	__v;									\
> > +})
> 
> Hi Marco,
> 
> The above change is something I'm not happy about. The original
> implementation of the srcu_dereference_check() macro shows that it is
> sufficient to either hold an SRCU reader lock or the updater lock ('c').
> The addition of "__srcu_read_lock_must_hold()" will cause compilation to
> fail if the caller doesn't hold an SRCU reader lock. I'm concerned that
> this will either lead to adding __no_context_analysis to SRCU updater
> code that uses srcu_dereference_check() or to adding misleading
> __assume_ctx_lock(ssp) annotations in SRCU updater code.

Right, and it doesn't help 'c' is an arbitrary condition. But it's
fundamentally difficult to say "hold either this or that lock".

That being said, I don't think it's wrong to write e.g.:

	spin_lock(&updater_lock);
	__acquire_shared(ssp);
	...
	// writes happen through rcu_assign_pointer()
	// reads can happen through srcu_dereference_check()
	...
	__release_shared(ssp);
	spin_unlock(&updater_lock);

, given holding the updater lock implies reader access.

And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
it's a manageable problem.

If you have a different idea how we can solve this, please let us know.

One final note, usage of srcu_dereference_check() is rare enough:

	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,

, that I think it's easy enough to annotate these places with the above
suggestions in case you're trying out global enablement.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-mm
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:35:33 +0000
Message-ID: <aXez9fSxdfu5-Boo () elver ! google ! com>
--------------------
On Mon, Jan 26, 2026 at 09:31AM -0800, Bart Van Assche wrote:
> On 12/19/25 7:40 AM, Marco Elver wrote:
> > +/*
> > + * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
> > + * should still be marked with __rcu_guarded, and we do not want to mark them
> > + * with __guarded_by(ssp) as it would complicate annotations for writers, we
> > + * choose the following strategy: srcu_dereference_check() calls this helper
> > + * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
> > + */
> > +static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
> >   /**
> >    * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
> > @@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
> >    * to 1.  The @c argument will normally be a logical expression containing
> >    * lockdep_is_held() calls.
> >    */
> > -#define srcu_dereference_check(p, ssp, c) \
> > -	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
> > -				(c) || srcu_read_lock_held(ssp), __rcu)
> > +#define srcu_dereference_check(p, ssp, c)					\
> > +({										\
> > +	__srcu_read_lock_must_hold(ssp);					\
> > +	__acquire_shared_ctx_lock(RCU);					\
> > +	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
> > +				(c) || srcu_read_lock_held(ssp), __rcu);	\
> > +	__release_shared_ctx_lock(RCU);					\
> > +	__v;									\
> > +})
> 
> Hi Marco,
> 
> The above change is something I'm not happy about. The original
> implementation of the srcu_dereference_check() macro shows that it is
> sufficient to either hold an SRCU reader lock or the updater lock ('c').
> The addition of "__srcu_read_lock_must_hold()" will cause compilation to
> fail if the caller doesn't hold an SRCU reader lock. I'm concerned that
> this will either lead to adding __no_context_analysis to SRCU updater
> code that uses srcu_dereference_check() or to adding misleading
> __assume_ctx_lock(ssp) annotations in SRCU updater code.

Right, and it doesn't help 'c' is an arbitrary condition. But it's
fundamentally difficult to say "hold either this or that lock".

That being said, I don't think it's wrong to write e.g.:

	spin_lock(&updater_lock);
	__acquire_shared(ssp);
	...
	// writes happen through rcu_assign_pointer()
	// reads can happen through srcu_dereference_check()
	...
	__release_shared(ssp);
	spin_unlock(&updater_lock);

, given holding the updater lock implies reader access.

And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
it's a manageable problem.

If you have a different idea how we can solve this, please let us know.

One final note, usage of srcu_dereference_check() is rare enough:

	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,

, that I think it's easy enough to annotate these places with the above
suggestions in case you're trying out global enablement.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-sparse
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:35:33 +0000
Message-ID: <aXez9fSxdfu5-Boo () elver ! google ! com>
--------------------
On Mon, Jan 26, 2026 at 09:31AM -0800, Bart Van Assche wrote:
> On 12/19/25 7:40 AM, Marco Elver wrote:
> > +/*
> > + * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
> > + * should still be marked with __rcu_guarded, and we do not want to mark them
> > + * with __guarded_by(ssp) as it would complicate annotations for writers, we
> > + * choose the following strategy: srcu_dereference_check() calls this helper
> > + * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
> > + */
> > +static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
> >   /**
> >    * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
> > @@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
> >    * to 1.  The @c argument will normally be a logical expression containing
> >    * lockdep_is_held() calls.
> >    */
> > -#define srcu_dereference_check(p, ssp, c) \
> > -	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
> > -				(c) || srcu_read_lock_held(ssp), __rcu)
> > +#define srcu_dereference_check(p, ssp, c)					\
> > +({										\
> > +	__srcu_read_lock_must_hold(ssp);					\
> > +	__acquire_shared_ctx_lock(RCU);					\
> > +	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
> > +				(c) || srcu_read_lock_held(ssp), __rcu);	\
> > +	__release_shared_ctx_lock(RCU);					\
> > +	__v;									\
> > +})
> 
> Hi Marco,
> 
> The above change is something I'm not happy about. The original
> implementation of the srcu_dereference_check() macro shows that it is
> sufficient to either hold an SRCU reader lock or the updater lock ('c').
> The addition of "__srcu_read_lock_must_hold()" will cause compilation to
> fail if the caller doesn't hold an SRCU reader lock. I'm concerned that
> this will either lead to adding __no_context_analysis to SRCU updater
> code that uses srcu_dereference_check() or to adding misleading
> __assume_ctx_lock(ssp) annotations in SRCU updater code.

Right, and it doesn't help 'c' is an arbitrary condition. But it's
fundamentally difficult to say "hold either this or that lock".

That being said, I don't think it's wrong to write e.g.:

	spin_lock(&updater_lock);
	__acquire_shared(ssp);
	...
	// writes happen through rcu_assign_pointer()
	// reads can happen through srcu_dereference_check()
	...
	__release_shared(ssp);
	spin_unlock(&updater_lock);

, given holding the updater lock implies reader access.

And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
it's a manageable problem.

If you have a different idea how we can solve this, please let us know.

One final note, usage of srcu_dereference_check() is rare enough:

	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,

, that I think it's easy enough to annotate these places with the above
suggestions in case you're trying out global enablement.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-wireless
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:35:33 +0000
Message-ID: <aXez9fSxdfu5-Boo () elver ! google ! com>
--------------------
On Mon, Jan 26, 2026 at 09:31AM -0800, Bart Van Assche wrote:
> On 12/19/25 7:40 AM, Marco Elver wrote:
> > +/*
> > + * No-op helper to denote that ssp must be held. Because SRCU-protected pointers
> > + * should still be marked with __rcu_guarded, and we do not want to mark them
> > + * with __guarded_by(ssp) as it would complicate annotations for writers, we
> > + * choose the following strategy: srcu_dereference_check() calls this helper
> > + * that checks that the passed ssp is held, and then fake-acquires 'RCU'.
> > + */
> > +static inline void __srcu_read_lock_must_hold(const struct srcu_struct *ssp) __must_hold_shared(ssp) { }
> >   /**
> >    * srcu_dereference_check - fetch SRCU-protected pointer for later dereferencing
> > @@ -223,9 +233,15 @@ static inline int srcu_read_lock_held(const struct srcu_struct *ssp)
> >    * to 1.  The @c argument will normally be a logical expression containing
> >    * lockdep_is_held() calls.
> >    */
> > -#define srcu_dereference_check(p, ssp, c) \
> > -	__rcu_dereference_check((p), __UNIQUE_ID(rcu), \
> > -				(c) || srcu_read_lock_held(ssp), __rcu)
> > +#define srcu_dereference_check(p, ssp, c)					\
> > +({										\
> > +	__srcu_read_lock_must_hold(ssp);					\
> > +	__acquire_shared_ctx_lock(RCU);					\
> > +	__auto_type __v = __rcu_dereference_check((p), __UNIQUE_ID(rcu),	\
> > +				(c) || srcu_read_lock_held(ssp), __rcu);	\
> > +	__release_shared_ctx_lock(RCU);					\
> > +	__v;									\
> > +})
> 
> Hi Marco,
> 
> The above change is something I'm not happy about. The original
> implementation of the srcu_dereference_check() macro shows that it is
> sufficient to either hold an SRCU reader lock or the updater lock ('c').
> The addition of "__srcu_read_lock_must_hold()" will cause compilation to
> fail if the caller doesn't hold an SRCU reader lock. I'm concerned that
> this will either lead to adding __no_context_analysis to SRCU updater
> code that uses srcu_dereference_check() or to adding misleading
> __assume_ctx_lock(ssp) annotations in SRCU updater code.

Right, and it doesn't help 'c' is an arbitrary condition. But it's
fundamentally difficult to say "hold either this or that lock".

That being said, I don't think it's wrong to write e.g.:

	spin_lock(&updater_lock);
	__acquire_shared(ssp);
	...
	// writes happen through rcu_assign_pointer()
	// reads can happen through srcu_dereference_check()
	...
	__release_shared(ssp);
	spin_unlock(&updater_lock);

, given holding the updater lock implies reader access.

And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
it's a manageable problem.

If you have a different idea how we can solve this, please let us know.

One final note, usage of srcu_dereference_check() is rare enough:

	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,

, that I think it's easy enough to annotate these places with the above
suggestions in case you're trying out global enablement.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-kbuild
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:54:56 +0000
Message-ID: <8c1bbab4-4615-4518-b773-a006d1402b8b () acm ! org>
--------------------
On 1/26/26 10:35 AM, Marco Elver wrote:
> That being said, I don't think it's wrong to write e.g.:
> 
> 	spin_lock(&updater_lock);
> 	__acquire_shared(ssp);
> 	...
> 	// writes happen through rcu_assign_pointer()
> 	// reads can happen through srcu_dereference_check()
> 	...
> 	__release_shared(ssp);
> 	spin_unlock(&updater_lock);
> 
> , given holding the updater lock implies reader access.
> 
> And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
> it's a manageable problem.

I'd like to make context-analysis mandatory for the entire kernel tree.

> If you have a different idea how we can solve this, please let us know.
> 
> One final note, usage of srcu_dereference_check() is rare enough:
> 
> 	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
> 	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
> 	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
> 	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
> 	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
> 	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
> 	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
> 	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
> 	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
> 	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 
> , that I think it's easy enough to annotate these places with the above
> suggestions in case you're trying out global enablement.

Has it ever been considered to add support in the clang compiler for a
variant of __must_hold() that expresses that one of two capabilities
must be held by the caller? I think that would remove the need to
annotate SRCU update-side code with __acquire_shared(ssp) and
__release_shared(ssp).

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-sparse
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:54:56 +0000
Message-ID: <8c1bbab4-4615-4518-b773-a006d1402b8b () acm ! org>
--------------------
On 1/26/26 10:35 AM, Marco Elver wrote:
> That being said, I don't think it's wrong to write e.g.:
> 
> 	spin_lock(&updater_lock);
> 	__acquire_shared(ssp);
> 	...
> 	// writes happen through rcu_assign_pointer()
> 	// reads can happen through srcu_dereference_check()
> 	...
> 	__release_shared(ssp);
> 	spin_unlock(&updater_lock);
> 
> , given holding the updater lock implies reader access.
> 
> And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
> it's a manageable problem.

I'd like to make context-analysis mandatory for the entire kernel tree.

> If you have a different idea how we can solve this, please let us know.
> 
> One final note, usage of srcu_dereference_check() is rare enough:
> 
> 	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
> 	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
> 	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
> 	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
> 	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
> 	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
> 	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
> 	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
> 	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
> 	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 
> , that I think it's easy enough to annotate these places with the above
> suggestions in case you're trying out global enablement.

Has it ever been considered to add support in the clang compiler for a
variant of __must_hold() that expresses that one of two capabilities
must be held by the caller? I think that would remove the need to
annotate SRCU update-side code with __acquire_shared(ssp) and
__release_shared(ssp).

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-mm
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:54:56 +0000
Message-ID: <8c1bbab4-4615-4518-b773-a006d1402b8b () acm ! org>
--------------------
On 1/26/26 10:35 AM, Marco Elver wrote:
> That being said, I don't think it's wrong to write e.g.:
> 
> 	spin_lock(&updater_lock);
> 	__acquire_shared(ssp);
> 	...
> 	// writes happen through rcu_assign_pointer()
> 	// reads can happen through srcu_dereference_check()
> 	...
> 	__release_shared(ssp);
> 	spin_unlock(&updater_lock);
> 
> , given holding the updater lock implies reader access.
> 
> And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
> it's a manageable problem.

I'd like to make context-analysis mandatory for the entire kernel tree.

> If you have a different idea how we can solve this, please let us know.
> 
> One final note, usage of srcu_dereference_check() is rare enough:
> 
> 	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
> 	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
> 	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
> 	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
> 	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
> 	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
> 	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
> 	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
> 	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
> 	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 
> , that I think it's easy enough to annotate these places with the above
> suggestions in case you're trying out global enablement.

Has it ever been considered to add support in the clang compiler for a
variant of __must_hold() that expresses that one of two capabilities
must be held by the caller? I think that would remove the need to
annotate SRCU update-side code with __acquire_shared(ssp) and
__release_shared(ssp).

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-doc
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:54:56 +0000
Message-ID: <8c1bbab4-4615-4518-b773-a006d1402b8b () acm ! org>
--------------------
On 1/26/26 10:35 AM, Marco Elver wrote:
> That being said, I don't think it's wrong to write e.g.:
> 
> 	spin_lock(&updater_lock);
> 	__acquire_shared(ssp);
> 	...
> 	// writes happen through rcu_assign_pointer()
> 	// reads can happen through srcu_dereference_check()
> 	...
> 	__release_shared(ssp);
> 	spin_unlock(&updater_lock);
> 
> , given holding the updater lock implies reader access.
> 
> And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
> it's a manageable problem.

I'd like to make context-analysis mandatory for the entire kernel tree.

> If you have a different idea how we can solve this, please let us know.
> 
> One final note, usage of srcu_dereference_check() is rare enough:
> 
> 	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
> 	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
> 	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
> 	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
> 	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
> 	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
> 	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
> 	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
> 	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
> 	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 
> , that I think it's easy enough to annotate these places with the above
> suggestions in case you're trying out global enablement.

Has it ever been considered to add support in the clang compiler for a
variant of __must_hold() that expresses that one of two capabilities
must be held by the caller? I think that would remove the need to
annotate SRCU update-side code with __acquire_shared(ssp) and
__release_shared(ssp).

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-crypto-vger
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:54:56 +0000
Message-ID: <8c1bbab4-4615-4518-b773-a006d1402b8b () acm ! org>
--------------------
On 1/26/26 10:35 AM, Marco Elver wrote:
> That being said, I don't think it's wrong to write e.g.:
> 
> 	spin_lock(&updater_lock);
> 	__acquire_shared(ssp);
> 	...
> 	// writes happen through rcu_assign_pointer()
> 	// reads can happen through srcu_dereference_check()
> 	...
> 	__release_shared(ssp);
> 	spin_unlock(&updater_lock);
> 
> , given holding the updater lock implies reader access.
> 
> And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
> it's a manageable problem.

I'd like to make context-analysis mandatory for the entire kernel tree.

> If you have a different idea how we can solve this, please let us know.
> 
> One final note, usage of srcu_dereference_check() is rare enough:
> 
> 	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
> 	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
> 	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
> 	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
> 	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
> 	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
> 	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
> 	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
> 	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
> 	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 
> , that I think it's easy enough to annotate these places with the above
> suggestions in case you're trying out global enablement.

Has it ever been considered to add support in the clang compiler for a
variant of __must_hold() that expresses that one of two capabilities
must be held by the caller? I think that would remove the need to
annotate SRCU update-side code with __acquire_shared(ssp) and
__release_shared(ssp).

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-wireless
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:54:56 +0000
Message-ID: <8c1bbab4-4615-4518-b773-a006d1402b8b () acm ! org>
--------------------
On 1/26/26 10:35 AM, Marco Elver wrote:
> That being said, I don't think it's wrong to write e.g.:
> 
> 	spin_lock(&updater_lock);
> 	__acquire_shared(ssp);
> 	...
> 	// writes happen through rcu_assign_pointer()
> 	// reads can happen through srcu_dereference_check()
> 	...
> 	__release_shared(ssp);
> 	spin_unlock(&updater_lock);
> 
> , given holding the updater lock implies reader access.
> 
> And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
> it's a manageable problem.

I'd like to make context-analysis mandatory for the entire kernel tree.

> If you have a different idea how we can solve this, please let us know.
> 
> One final note, usage of srcu_dereference_check() is rare enough:
> 
> 	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
> 	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
> 	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
> 	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
> 	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
> 	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
> 	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
> 	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
> 	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
> 	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 
> , that I think it's easy enough to annotate these places with the above
> suggestions in case you're trying out global enablement.

Has it ever been considered to add support in the clang compiler for a
variant of __must_hold() that expresses that one of two capabilities
must be held by the caller? I think that would remove the need to
annotate SRCU update-side code with __acquire_shared(ssp) and
__release_shared(ssp).

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-kernel
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 18:54:56 +0000
Message-ID: <8c1bbab4-4615-4518-b773-a006d1402b8b () acm ! org>
--------------------
On 1/26/26 10:35 AM, Marco Elver wrote:
> That being said, I don't think it's wrong to write e.g.:
> 
> 	spin_lock(&updater_lock);
> 	__acquire_shared(ssp);
> 	...
> 	// writes happen through rcu_assign_pointer()
> 	// reads can happen through srcu_dereference_check()
> 	...
> 	__release_shared(ssp);
> 	spin_unlock(&updater_lock);
> 
> , given holding the updater lock implies reader access.
> 
> And given the analysis is opt-in (CONTEXT_ANALYSIS := y), I think
> it's a manageable problem.

I'd like to make context-analysis mandatory for the entire kernel tree.

> If you have a different idea how we can solve this, please let us know.
> 
> One final note, usage of srcu_dereference_check() is rare enough:
> 
> 	arch/x86/kvm/hyperv.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 	arch/x86/kvm/x86.c:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
> 	arch/x86/kvm/x86.c:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
> 	drivers/gpio/gpiolib.c:	label = srcu_dereference_check(desc->label, &desc->gdev->desc_srcu,
> 	drivers/hv/mshv_irq.c:	girq_tbl = srcu_dereference_check(partition->pt_girq_tbl,
> 	drivers/hwtracing/stm/core.c:	link = srcu_dereference_check(src->link, &stm_source_srcu, 1);
> 	drivers/infiniband/hw/hfi1/user_sdma.c:	pq = srcu_dereference_check(fd->pq, &fd->pq_srcu,
> 	fs/quota/dquot.c:			struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:				struct dquot *dquot = srcu_dereference_check(
> 	fs/quota/dquot.c:		put[cnt] = srcu_dereference_check(dquots[cnt], &dquot_srcu,
> 	fs/quota/dquot.c:		transfer_from[cnt] = srcu_dereference_check(dquots[cnt],
> 	include/linux/kvm_host.h:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
> 	virt/kvm/irqchip.c:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
> 
> , that I think it's easy enough to annotate these places with the above
> suggestions in case you're trying out global enablement.

Has it ever been considered to add support in the clang compiler for a
variant of __must_hold() that expresses that one of two capabilities
must be held by the caller? I think that would remove the need to
annotate SRCU update-side code with __acquire_shared(ssp) and
__release_shared(ssp).

Thanks,

Bart.

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-crypto-vger
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 21:35:56 +0000
Message-ID: <20260126213556.GQ171111 () noisy ! programming ! kicks-ass ! net>
--------------------
On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:

> Has it ever been considered to add support in the clang compiler for a
> variant of __must_hold() that expresses that one of two capabilities
> must be held by the caller? I think that would remove the need to
> annotate SRCU update-side code with __acquire_shared(ssp) and
> __release_shared(ssp).

Right, I think I've asked for logical operators like that. Although I
think it was in the __guarded_by() clause rather than the __must_hold().
Both || and && would be nice to have ;-)

Specifically, I think I asked for something like:

        cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
                                     __guarded_shared_by(pi_lock || rq->__lock);


I think Marco's suggestion was to use 'fake' locks to mimic those
semantics.

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-sparse
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 21:35:56 +0000
Message-ID: <20260126213556.GQ171111 () noisy ! programming ! kicks-ass ! net>
--------------------
On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:

> Has it ever been considered to add support in the clang compiler for a
> variant of __must_hold() that expresses that one of two capabilities
> must be held by the caller? I think that would remove the need to
> annotate SRCU update-side code with __acquire_shared(ssp) and
> __release_shared(ssp).

Right, I think I've asked for logical operators like that. Although I
think it was in the __guarded_by() clause rather than the __must_hold().
Both || and && would be nice to have ;-)

Specifically, I think I asked for something like:

        cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
                                     __guarded_shared_by(pi_lock || rq->__lock);


I think Marco's suggestion was to use 'fake' locks to mimic those
semantics.

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-wireless
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 21:35:56 +0000
Message-ID: <20260126213556.GQ171111 () noisy ! programming ! kicks-ass ! net>
--------------------
On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:

> Has it ever been considered to add support in the clang compiler for a
> variant of __must_hold() that expresses that one of two capabilities
> must be held by the caller? I think that would remove the need to
> annotate SRCU update-side code with __acquire_shared(ssp) and
> __release_shared(ssp).

Right, I think I've asked for logical operators like that. Although I
think it was in the __guarded_by() clause rather than the __must_hold().
Both || and && would be nice to have ;-)

Specifically, I think I asked for something like:

        cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
                                     __guarded_shared_by(pi_lock || rq->__lock);


I think Marco's suggestion was to use 'fake' locks to mimic those
semantics.

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-mm
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 21:35:56 +0000
Message-ID: <20260126213556.GQ171111 () noisy ! programming ! kicks-ass ! net>
--------------------
On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:

> Has it ever been considered to add support in the clang compiler for a
> variant of __must_hold() that expresses that one of two capabilities
> must be held by the caller? I think that would remove the need to
> annotate SRCU update-side code with __acquire_shared(ssp) and
> __release_shared(ssp).

Right, I think I've asked for logical operators like that. Although I
think it was in the __guarded_by() clause rather than the __must_hold().
Both || and && would be nice to have ;-)

Specifically, I think I asked for something like:

        cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
                                     __guarded_shared_by(pi_lock || rq->__lock);


I think Marco's suggestion was to use 'fake' locks to mimic those
semantics.

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-kbuild
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 21:35:56 +0000
Message-ID: <20260126213556.GQ171111 () noisy ! programming ! kicks-ass ! net>
--------------------
On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:

> Has it ever been considered to add support in the clang compiler for a
> variant of __must_hold() that expresses that one of two capabilities
> must be held by the caller? I think that would remove the need to
> annotate SRCU update-side code with __acquire_shared(ssp) and
> __release_shared(ssp).

Right, I think I've asked for logical operators like that. Although I
think it was in the __guarded_by() clause rather than the __must_hold().
Both || and && would be nice to have ;-)

Specifically, I think I asked for something like:

        cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
                                     __guarded_shared_by(pi_lock || rq->__lock);


I think Marco's suggestion was to use 'fake' locks to mimic those
semantics.

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-kernel
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 21:35:56 +0000
Message-ID: <20260126213556.GQ171111 () noisy ! programming ! kicks-ass ! net>
--------------------
On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:

> Has it ever been considered to add support in the clang compiler for a
> variant of __must_hold() that expresses that one of two capabilities
> must be held by the caller? I think that would remove the need to
> annotate SRCU update-side code with __acquire_shared(ssp) and
> __release_shared(ssp).

Right, I think I've asked for logical operators like that. Although I
think it was in the __guarded_by() clause rather than the __must_hold().
Both || and && would be nice to have ;-)

Specifically, I think I asked for something like:

        cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
                                     __guarded_shared_by(pi_lock || rq->__lock);


I think Marco's suggestion was to use 'fake' locks to mimic those
semantics.

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-doc
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 21:35:56 +0000
Message-ID: <20260126213556.GQ171111 () noisy ! programming ! kicks-ass ! net>
--------------------
On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:

> Has it ever been considered to add support in the clang compiler for a
> variant of __must_hold() that expresses that one of two capabilities
> must be held by the caller? I think that would remove the need to
> annotate SRCU update-side code with __acquire_shared(ssp) and
> __release_shared(ssp).

Right, I think I've asked for logical operators like that. Although I
think it was in the __guarded_by() clause rather than the __must_hold().
Both || and && would be nice to have ;-)

Specifically, I think I asked for something like:

        cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
                                     __guarded_shared_by(pi_lock || rq->__lock);


I think Marco's suggestion was to use 'fake' locks to mimic those
semantics.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-mm
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 23:46:49 +0000
Message-ID: <CANpmjNPs9CtY1w1-MqL1-CnHVFLxXoA2rbd6d2w4wfxT8AP0ew () mail ! gmail ! com>
--------------------
On Mon, 26 Jan 2026 at 22:36, Peter Zijlstra <peterz@infradead.org> wrote:
>
> On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:
>
> > Has it ever been considered to add support in the clang compiler for a
> > variant of __must_hold() that expresses that one of two capabilities
> > must be held by the caller? I think that would remove the need to
> > annotate SRCU update-side code with __acquire_shared(ssp) and
> > __release_shared(ssp).
>
> Right, I think I've asked for logical operators like that. Although I
> think it was in the __guarded_by() clause rather than the __must_hold().
> Both || and && would be nice to have ;-)

Some attributes take multiple arguments (__must_hold does), though
__guarded_by doesn't. Yet, && can still be had with adding it multiple
times e.g. '__guarded_by(pi_lock) __guarded_by(rq->__lock)'.

Only thing that doesn't exist is ||. I think the syntax you ask for
won't fly, but I can add it to the backlog to investigate an _any
variant of these attributes. Don't hold your breath though, given the
time it takes to land all that in a released Clang version.

> Specifically, I think I asked for something like:
>
>         cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
>                                      __guarded_shared_by(pi_lock || rq->__lock);
>
>
> I think Marco's suggestion was to use 'fake' locks to mimic those
> semantics.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 23:46:49 +0000
Message-ID: <CANpmjNPs9CtY1w1-MqL1-CnHVFLxXoA2rbd6d2w4wfxT8AP0ew () mail ! gmail ! com>
--------------------
On Mon, 26 Jan 2026 at 22:36, Peter Zijlstra <peterz@infradead.org> wrote:
>
> On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:
>
> > Has it ever been considered to add support in the clang compiler for a
> > variant of __must_hold() that expresses that one of two capabilities
> > must be held by the caller? I think that would remove the need to
> > annotate SRCU update-side code with __acquire_shared(ssp) and
> > __release_shared(ssp).
>
> Right, I think I've asked for logical operators like that. Although I
> think it was in the __guarded_by() clause rather than the __must_hold().
> Both || and && would be nice to have ;-)

Some attributes take multiple arguments (__must_hold does), though
__guarded_by doesn't. Yet, && can still be had with adding it multiple
times e.g. '__guarded_by(pi_lock) __guarded_by(rq->__lock)'.

Only thing that doesn't exist is ||. I think the syntax you ask for
won't fly, but I can add it to the backlog to investigate an _any
variant of these attributes. Don't hold your breath though, given the
time it takes to land all that in a released Clang version.

> Specifically, I think I asked for something like:
>
>         cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
>                                      __guarded_shared_by(pi_lock || rq->__lock);
>
>
> I think Marco's suggestion was to use 'fake' locks to mimic those
> semantics.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-doc
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 23:46:49 +0000
Message-ID: <CANpmjNPs9CtY1w1-MqL1-CnHVFLxXoA2rbd6d2w4wfxT8AP0ew () mail ! gmail ! com>
--------------------
On Mon, 26 Jan 2026 at 22:36, Peter Zijlstra <peterz@infradead.org> wrote:
>
> On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:
>
> > Has it ever been considered to add support in the clang compiler for a
> > variant of __must_hold() that expresses that one of two capabilities
> > must be held by the caller? I think that would remove the need to
> > annotate SRCU update-side code with __acquire_shared(ssp) and
> > __release_shared(ssp).
>
> Right, I think I've asked for logical operators like that. Although I
> think it was in the __guarded_by() clause rather than the __must_hold().
> Both || and && would be nice to have ;-)

Some attributes take multiple arguments (__must_hold does), though
__guarded_by doesn't. Yet, && can still be had with adding it multiple
times e.g. '__guarded_by(pi_lock) __guarded_by(rq->__lock)'.

Only thing that doesn't exist is ||. I think the syntax you ask for
won't fly, but I can add it to the backlog to investigate an _any
variant of these attributes. Don't hold your breath though, given the
time it takes to land all that in a released Clang version.

> Specifically, I think I asked for something like:
>
>         cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
>                                      __guarded_shared_by(pi_lock || rq->__lock);
>
>
> I think Marco's suggestion was to use 'fake' locks to mimic those
> semantics.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 23:46:49 +0000
Message-ID: <CANpmjNPs9CtY1w1-MqL1-CnHVFLxXoA2rbd6d2w4wfxT8AP0ew () mail ! gmail ! com>
--------------------
On Mon, 26 Jan 2026 at 22:36, Peter Zijlstra <peterz@infradead.org> wrote:
>
> On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:
>
> > Has it ever been considered to add support in the clang compiler for a
> > variant of __must_hold() that expresses that one of two capabilities
> > must be held by the caller? I think that would remove the need to
> > annotate SRCU update-side code with __acquire_shared(ssp) and
> > __release_shared(ssp).
>
> Right, I think I've asked for logical operators like that. Although I
> think it was in the __guarded_by() clause rather than the __must_hold().
> Both || and && would be nice to have ;-)

Some attributes take multiple arguments (__must_hold does), though
__guarded_by doesn't. Yet, && can still be had with adding it multiple
times e.g. '__guarded_by(pi_lock) __guarded_by(rq->__lock)'.

Only thing that doesn't exist is ||. I think the syntax you ask for
won't fly, but I can add it to the backlog to investigate an _any
variant of these attributes. Don't hold your breath though, given the
time it takes to land all that in a released Clang version.

> Specifically, I think I asked for something like:
>
>         cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
>                                      __guarded_shared_by(pi_lock || rq->__lock);
>
>
> I think Marco's suggestion was to use 'fake' locks to mimic those
> semantics.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-sparse
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 23:46:49 +0000
Message-ID: <CANpmjNPs9CtY1w1-MqL1-CnHVFLxXoA2rbd6d2w4wfxT8AP0ew () mail ! gmail ! com>
--------------------
On Mon, 26 Jan 2026 at 22:36, Peter Zijlstra <peterz@infradead.org> wrote:
>
> On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:
>
> > Has it ever been considered to add support in the clang compiler for a
> > variant of __must_hold() that expresses that one of two capabilities
> > must be held by the caller? I think that would remove the need to
> > annotate SRCU update-side code with __acquire_shared(ssp) and
> > __release_shared(ssp).
>
> Right, I think I've asked for logical operators like that. Although I
> think it was in the __guarded_by() clause rather than the __must_hold().
> Both || and && would be nice to have ;-)

Some attributes take multiple arguments (__must_hold does), though
__guarded_by doesn't. Yet, && can still be had with adding it multiple
times e.g. '__guarded_by(pi_lock) __guarded_by(rq->__lock)'.

Only thing that doesn't exist is ||. I think the syntax you ask for
won't fly, but I can add it to the backlog to investigate an _any
variant of these attributes. Don't hold your breath though, given the
time it takes to land all that in a released Clang version.

> Specifically, I think I asked for something like:
>
>         cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
>                                      __guarded_shared_by(pi_lock || rq->__lock);
>
>
> I think Marco's suggestion was to use 'fake' locks to mimic those
> semantics.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kernel
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 23:46:49 +0000
Message-ID: <CANpmjNPs9CtY1w1-MqL1-CnHVFLxXoA2rbd6d2w4wfxT8AP0ew () mail ! gmail ! com>
--------------------
On Mon, 26 Jan 2026 at 22:36, Peter Zijlstra <peterz@infradead.org> wrote:
>
> On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:
>
> > Has it ever been considered to add support in the clang compiler for a
> > variant of __must_hold() that expresses that one of two capabilities
> > must be held by the caller? I think that would remove the need to
> > annotate SRCU update-side code with __acquire_shared(ssp) and
> > __release_shared(ssp).
>
> Right, I think I've asked for logical operators like that. Although I
> think it was in the __guarded_by() clause rather than the __must_hold().
> Both || and && would be nice to have ;-)

Some attributes take multiple arguments (__must_hold does), though
__guarded_by doesn't. Yet, && can still be had with adding it multiple
times e.g. '__guarded_by(pi_lock) __guarded_by(rq->__lock)'.

Only thing that doesn't exist is ||. I think the syntax you ask for
won't fly, but I can add it to the backlog to investigate an _any
variant of these attributes. Don't hold your breath though, given the
time it takes to land all that in a released Clang version.

> Specifically, I think I asked for something like:
>
>         cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
>                                      __guarded_shared_by(pi_lock || rq->__lock);
>
>
> I think Marco's suggestion was to use 'fake' locks to mimic those
> semantics.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-wireless
Subject: Re: [PATCH v5 15/36] srcu: Support Clang's context analysis
Date: Mon, 26 Jan 2026 23:46:49 +0000
Message-ID: <CANpmjNPs9CtY1w1-MqL1-CnHVFLxXoA2rbd6d2w4wfxT8AP0ew () mail ! gmail ! com>
--------------------
On Mon, 26 Jan 2026 at 22:36, Peter Zijlstra <peterz@infradead.org> wrote:
>
> On Mon, Jan 26, 2026 at 10:54:56AM -0800, Bart Van Assche wrote:
>
> > Has it ever been considered to add support in the clang compiler for a
> > variant of __must_hold() that expresses that one of two capabilities
> > must be held by the caller? I think that would remove the need to
> > annotate SRCU update-side code with __acquire_shared(ssp) and
> > __release_shared(ssp).
>
> Right, I think I've asked for logical operators like that. Although I
> think it was in the __guarded_by() clause rather than the __must_hold().
> Both || and && would be nice to have ;-)

Some attributes take multiple arguments (__must_hold does), though
__guarded_by doesn't. Yet, && can still be had with adding it multiple
times e.g. '__guarded_by(pi_lock) __guarded_by(rq->__lock)'.

Only thing that doesn't exist is ||. I think the syntax you ask for
won't fly, but I can add it to the backlog to investigate an _any
variant of these attributes. Don't hold your breath though, given the
time it takes to land all that in a released Clang version.

> Specifically, I think I asked for something like:
>
>         cpumask_t       cpus_allowed __guarded_by(pi_lock && rq->__lock)
>                                      __guarded_shared_by(pi_lock || rq->__lock);
>
>
> I think Marco's suggestion was to use 'fake' locks to mimic those
> semantics.

================================================================================


################################################################################

=== Thread: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis ===

From: Marco Elver <elver () google ! com>
To: linux-crypto-vger
Subject: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 19 Dec 2025 15:40:09 +0000
Message-ID: <20251219154418.3592607-21-elver () google ! com>
--------------------
Add support for Clang's context analysis for ww_mutex.

The programming model for ww_mutex is subtly more complex than other
locking primitives when using ww_acquire_ctx. Encoding the respective
pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
using Clang's context analysis makes incorrect use of the API harder.

Signed-off-by: Marco Elver <elver@google.com>
---
v5:
* Rename "context guard" -> "context lock".

v4:
* Rename capability -> context analysis.

v3:
* __assert -> __assume rename

v2:
* New patch.
---
 Documentation/dev-tools/context-analysis.rst |  3 +-
 include/linux/ww_mutex.h                     | 22 +++++--
 lib/test_context-analysis.c                  | 69 ++++++++++++++++++++
 3 files changed, 87 insertions(+), 7 deletions(-)

diff --git a/Documentation/dev-tools/context-analysis.rst b/Documentation/dev-tools/context-analysis.rst
index a48b75f45e79..8dd6c0d695aa 100644
--- a/Documentation/dev-tools/context-analysis.rst
+++ b/Documentation/dev-tools/context-analysis.rst
@@ -80,7 +80,8 @@ Supported Kernel Primitives
 
 Currently the following synchronization primitives are supported:
 `raw_spinlock_t`, `spinlock_t`, `rwlock_t`, `mutex`, `seqlock_t`,
-`bit_spinlock`, RCU, SRCU (`srcu_struct`), `rw_semaphore`, `local_lock_t`.
+`bit_spinlock`, RCU, SRCU (`srcu_struct`), `rw_semaphore`, `local_lock_t`,
+`ww_mutex`.
 
 For context locks with an initialization function (e.g., `spin_lock_init()`),
 calling this function before initializing any guarded members or globals
diff --git a/include/linux/ww_mutex.h b/include/linux/ww_mutex.h
index 45ff6f7a872b..58e959ee10e9 100644
--- a/include/linux/ww_mutex.h
+++ b/include/linux/ww_mutex.h
@@ -44,7 +44,7 @@ struct ww_class {
 	unsigned int is_wait_die;
 };
 
-struct ww_mutex {
+context_lock_struct(ww_mutex) {
 	struct WW_MUTEX_BASE base;
 	struct ww_acquire_ctx *ctx;
 #ifdef DEBUG_WW_MUTEXES
@@ -52,7 +52,7 @@ struct ww_mutex {
 #endif
 };
 
-struct ww_acquire_ctx {
+context_lock_struct(ww_acquire_ctx) {
 	struct task_struct *task;
 	unsigned long stamp;
 	unsigned int acquired;
@@ -107,6 +107,7 @@ struct ww_acquire_ctx {
  */
 static inline void ww_mutex_init(struct ww_mutex *lock,
 				 struct ww_class *ww_class)
+	__assumes_ctx_lock(lock)
 {
 	ww_mutex_base_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 	lock->ctx = NULL;
@@ -141,6 +142,7 @@ static inline void ww_mutex_init(struct ww_mutex *lock,
  */
 static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
 				   struct ww_class *ww_class)
+	__acquires(ctx) __no_context_analysis
 {
 	ctx->task = current;
 	ctx->stamp = atomic_long_inc_return_relaxed(&ww_class->stamp);
@@ -179,6 +181,7 @@ static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
  * data structures.
  */
 static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
+	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
 {
 #ifdef DEBUG_WW_MUTEXES
 	lockdep_assert_held(ctx);
@@ -196,6 +199,7 @@ static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
  * mutexes have been released with ww_mutex_unlock.
  */
 static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
+	__releases_shared(ctx) __no_context_analysis
 {
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 	mutex_release(&ctx->first_lock_dep_map, _THIS_IP_);
@@ -245,7 +249,8 @@ static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
  *
  * A mutex acquired with this function must be released with ww_mutex_unlock.
  */
-extern int /* __must_check */ ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx);
+extern int /* __must_check */ ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
+	__cond_acquires(0, lock) __must_hold(ctx);
 
 /**
  * ww_mutex_lock_interruptible - acquire the w/w mutex, interruptible
@@ -278,7 +283,8 @@ extern int /* __must_check */ ww_mutex_lock(struct ww_mutex *lock, struct ww_acq
  * A mutex acquired with this function must be released with ww_mutex_unlock.
  */
 extern int __must_check ww_mutex_lock_interruptible(struct ww_mutex *lock,
-						    struct ww_acquire_ctx *ctx);
+						    struct ww_acquire_ctx *ctx)
+	__cond_acquires(0, lock) __must_hold(ctx);
 
 /**
  * ww_mutex_lock_slow - slowpath acquiring of the w/w mutex
@@ -305,6 +311,7 @@ extern int __must_check ww_mutex_lock_interruptible(struct ww_mutex *lock,
  */
 static inline void
 ww_mutex_lock_slow(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
+	__acquires(lock) __must_hold(ctx) __no_context_analysis
 {
 	int ret;
 #ifdef DEBUG_WW_MUTEXES
@@ -342,6 +349,7 @@ ww_mutex_lock_slow(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
 static inline int __must_check
 ww_mutex_lock_slow_interruptible(struct ww_mutex *lock,
 				 struct ww_acquire_ctx *ctx)
+	__cond_acquires(0, lock) __must_hold(ctx)
 {
 #ifdef DEBUG_WW_MUTEXES
 	DEBUG_LOCKS_WARN_ON(!ctx->contending_lock);
@@ -349,10 +357,11 @@ ww_mutex_lock_slow_interruptible(struct ww_mutex *lock,
 	return ww_mutex_lock_interruptible(lock, ctx);
 }
 
-extern void ww_mutex_unlock(struct ww_mutex *lock);
+extern void ww_mutex_unlock(struct ww_mutex *lock) __releases(lock);
 
 extern int __must_check ww_mutex_trylock(struct ww_mutex *lock,
-					 struct ww_acquire_ctx *ctx);
+					 struct ww_acquire_ctx *ctx)
+	__cond_acquires(true, lock) __must_hold(ctx);
 
 /***
  * ww_mutex_destroy - mark a w/w mutex unusable
@@ -363,6 +372,7 @@ extern int __must_check ww_mutex_trylock(struct ww_mutex *lock,
  * this function is called.
  */
 static inline void ww_mutex_destroy(struct ww_mutex *lock)
+	__must_not_hold(lock)
 {
 #ifndef CONFIG_PREEMPT_RT
 	mutex_destroy(&lock->base);
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 003e64cac540..2dc404456497 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -14,6 +14,7 @@
 #include <linux/seqlock.h>
 #include <linux/spinlock.h>
 #include <linux/srcu.h>
+#include <linux/ww_mutex.h>
 
 /*
  * Test that helper macros work as expected.
@@ -531,3 +532,71 @@ static void __used test_local_trylock(void)
 		local_unlock(&test_local_trylock_data.lock);
 	}
 }
+
+static DEFINE_WD_CLASS(ww_class);
+
+struct test_ww_mutex_data {
+	struct ww_mutex mtx;
+	int counter __guarded_by(&mtx);
+};
+
+static void __used test_ww_mutex_init(struct test_ww_mutex_data *d)
+{
+	ww_mutex_init(&d->mtx, &ww_class);
+	d->counter = 0;
+}
+
+static void __used test_ww_mutex_lock_noctx(struct test_ww_mutex_data *d)
+{
+	if (!ww_mutex_lock(&d->mtx, NULL)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	if (!ww_mutex_lock_interruptible(&d->mtx, NULL)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	if (ww_mutex_trylock(&d->mtx, NULL)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	ww_mutex_lock_slow(&d->mtx, NULL);
+	d->counter++;
+	ww_mutex_unlock(&d->mtx);
+
+	ww_mutex_destroy(&d->mtx);
+}
+
+static void __used test_ww_mutex_lock_ctx(struct test_ww_mutex_data *d)
+{
+	struct ww_acquire_ctx ctx;
+
+	ww_acquire_init(&ctx, &ww_class);
+
+	if (!ww_mutex_lock(&d->mtx, &ctx)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	if (!ww_mutex_lock_interruptible(&d->mtx, &ctx)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	if (ww_mutex_trylock(&d->mtx, &ctx)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	ww_mutex_lock_slow(&d->mtx, &ctx);
+	d->counter++;
+	ww_mutex_unlock(&d->mtx);
+
+	ww_acquire_done(&ctx);
+	ww_acquire_fini(&ctx);
+
+	ww_mutex_destroy(&d->mtx);
+}
-- 
2.52.0.322.g1dd061c0dc-goog


================================================================================

From: Marco Elver <elver () google ! com>
To: linux-wireless
Subject: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 19 Dec 2025 15:40:09 +0000
Message-ID: <20251219154418.3592607-21-elver () google ! com>
--------------------
Add support for Clang's context analysis for ww_mutex.

The programming model for ww_mutex is subtly more complex than other
locking primitives when using ww_acquire_ctx. Encoding the respective
pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
using Clang's context analysis makes incorrect use of the API harder.

Signed-off-by: Marco Elver <elver@google.com>
---
v5:
* Rename "context guard" -> "context lock".

v4:
* Rename capability -> context analysis.

v3:
* __assert -> __assume rename

v2:
* New patch.
---
 Documentation/dev-tools/context-analysis.rst |  3 +-
 include/linux/ww_mutex.h                     | 22 +++++--
 lib/test_context-analysis.c                  | 69 ++++++++++++++++++++
 3 files changed, 87 insertions(+), 7 deletions(-)

diff --git a/Documentation/dev-tools/context-analysis.rst b/Documentation/dev-tools/context-analysis.rst
index a48b75f45e79..8dd6c0d695aa 100644
--- a/Documentation/dev-tools/context-analysis.rst
+++ b/Documentation/dev-tools/context-analysis.rst
@@ -80,7 +80,8 @@ Supported Kernel Primitives
 
 Currently the following synchronization primitives are supported:
 `raw_spinlock_t`, `spinlock_t`, `rwlock_t`, `mutex`, `seqlock_t`,
-`bit_spinlock`, RCU, SRCU (`srcu_struct`), `rw_semaphore`, `local_lock_t`.
+`bit_spinlock`, RCU, SRCU (`srcu_struct`), `rw_semaphore`, `local_lock_t`,
+`ww_mutex`.
 
 For context locks with an initialization function (e.g., `spin_lock_init()`),
 calling this function before initializing any guarded members or globals
diff --git a/include/linux/ww_mutex.h b/include/linux/ww_mutex.h
index 45ff6f7a872b..58e959ee10e9 100644
--- a/include/linux/ww_mutex.h
+++ b/include/linux/ww_mutex.h
@@ -44,7 +44,7 @@ struct ww_class {
 	unsigned int is_wait_die;
 };
 
-struct ww_mutex {
+context_lock_struct(ww_mutex) {
 	struct WW_MUTEX_BASE base;
 	struct ww_acquire_ctx *ctx;
 #ifdef DEBUG_WW_MUTEXES
@@ -52,7 +52,7 @@ struct ww_mutex {
 #endif
 };
 
-struct ww_acquire_ctx {
+context_lock_struct(ww_acquire_ctx) {
 	struct task_struct *task;
 	unsigned long stamp;
 	unsigned int acquired;
@@ -107,6 +107,7 @@ struct ww_acquire_ctx {
  */
 static inline void ww_mutex_init(struct ww_mutex *lock,
 				 struct ww_class *ww_class)
+	__assumes_ctx_lock(lock)
 {
 	ww_mutex_base_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 	lock->ctx = NULL;
@@ -141,6 +142,7 @@ static inline void ww_mutex_init(struct ww_mutex *lock,
  */
 static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
 				   struct ww_class *ww_class)
+	__acquires(ctx) __no_context_analysis
 {
 	ctx->task = current;
 	ctx->stamp = atomic_long_inc_return_relaxed(&ww_class->stamp);
@@ -179,6 +181,7 @@ static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
  * data structures.
  */
 static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
+	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
 {
 #ifdef DEBUG_WW_MUTEXES
 	lockdep_assert_held(ctx);
@@ -196,6 +199,7 @@ static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
  * mutexes have been released with ww_mutex_unlock.
  */
 static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
+	__releases_shared(ctx) __no_context_analysis
 {
 #ifdef CONFIG_DEBUG_LOCK_ALLOC
 	mutex_release(&ctx->first_lock_dep_map, _THIS_IP_);
@@ -245,7 +249,8 @@ static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
  *
  * A mutex acquired with this function must be released with ww_mutex_unlock.
  */
-extern int /* __must_check */ ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx);
+extern int /* __must_check */ ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
+	__cond_acquires(0, lock) __must_hold(ctx);
 
 /**
  * ww_mutex_lock_interruptible - acquire the w/w mutex, interruptible
@@ -278,7 +283,8 @@ extern int /* __must_check */ ww_mutex_lock(struct ww_mutex *lock, struct ww_acq
  * A mutex acquired with this function must be released with ww_mutex_unlock.
  */
 extern int __must_check ww_mutex_lock_interruptible(struct ww_mutex *lock,
-						    struct ww_acquire_ctx *ctx);
+						    struct ww_acquire_ctx *ctx)
+	__cond_acquires(0, lock) __must_hold(ctx);
 
 /**
  * ww_mutex_lock_slow - slowpath acquiring of the w/w mutex
@@ -305,6 +311,7 @@ extern int __must_check ww_mutex_lock_interruptible(struct ww_mutex *lock,
  */
 static inline void
 ww_mutex_lock_slow(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
+	__acquires(lock) __must_hold(ctx) __no_context_analysis
 {
 	int ret;
 #ifdef DEBUG_WW_MUTEXES
@@ -342,6 +349,7 @@ ww_mutex_lock_slow(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)
 static inline int __must_check
 ww_mutex_lock_slow_interruptible(struct ww_mutex *lock,
 				 struct ww_acquire_ctx *ctx)
+	__cond_acquires(0, lock) __must_hold(ctx)
 {
 #ifdef DEBUG_WW_MUTEXES
 	DEBUG_LOCKS_WARN_ON(!ctx->contending_lock);
@@ -349,10 +357,11 @@ ww_mutex_lock_slow_interruptible(struct ww_mutex *lock,
 	return ww_mutex_lock_interruptible(lock, ctx);
 }
 
-extern void ww_mutex_unlock(struct ww_mutex *lock);
+extern void ww_mutex_unlock(struct ww_mutex *lock) __releases(lock);
 
 extern int __must_check ww_mutex_trylock(struct ww_mutex *lock,
-					 struct ww_acquire_ctx *ctx);
+					 struct ww_acquire_ctx *ctx)
+	__cond_acquires(true, lock) __must_hold(ctx);
 
 /***
  * ww_mutex_destroy - mark a w/w mutex unusable
@@ -363,6 +372,7 @@ extern int __must_check ww_mutex_trylock(struct ww_mutex *lock,
  * this function is called.
  */
 static inline void ww_mutex_destroy(struct ww_mutex *lock)
+	__must_not_hold(lock)
 {
 #ifndef CONFIG_PREEMPT_RT
 	mutex_destroy(&lock->base);
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 003e64cac540..2dc404456497 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -14,6 +14,7 @@
 #include <linux/seqlock.h>
 #include <linux/spinlock.h>
 #include <linux/srcu.h>
+#include <linux/ww_mutex.h>
 
 /*
  * Test that helper macros work as expected.
@@ -531,3 +532,71 @@ static void __used test_local_trylock(void)
 		local_unlock(&test_local_trylock_data.lock);
 	}
 }
+
+static DEFINE_WD_CLASS(ww_class);
+
+struct test_ww_mutex_data {
+	struct ww_mutex mtx;
+	int counter __guarded_by(&mtx);
+};
+
+static void __used test_ww_mutex_init(struct test_ww_mutex_data *d)
+{
+	ww_mutex_init(&d->mtx, &ww_class);
+	d->counter = 0;
+}
+
+static void __used test_ww_mutex_lock_noctx(struct test_ww_mutex_data *d)
+{
+	if (!ww_mutex_lock(&d->mtx, NULL)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	if (!ww_mutex_lock_interruptible(&d->mtx, NULL)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	if (ww_mutex_trylock(&d->mtx, NULL)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	ww_mutex_lock_slow(&d->mtx, NULL);
+	d->counter++;
+	ww_mutex_unlock(&d->mtx);
+
+	ww_mutex_destroy(&d->mtx);
+}
+
+static void __used test_ww_mutex_lock_ctx(struct test_ww_mutex_data *d)
+{
+	struct ww_acquire_ctx ctx;
+
+	ww_acquire_init(&ctx, &ww_class);
+
+	if (!ww_mutex_lock(&d->mtx, &ctx)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	if (!ww_mutex_lock_interruptible(&d->mtx, &ctx)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	if (ww_mutex_trylock(&d->mtx, &ctx)) {
+		d->counter++;
+		ww_mutex_unlock(&d->mtx);
+	}
+
+	ww_mutex_lock_slow(&d->mtx, &ctx);
+	d->counter++;
+	ww_mutex_unlock(&d->mtx);
+
+	ww_acquire_done(&ctx);
+	ww_acquire_fini(&ctx);
+
+	ww_mutex_destroy(&d->mtx);
+}
-- 
2.52.0.322.g1dd061c0dc-goog


================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-mm
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 20:16:33 +0000
Message-ID: <05c77ca1-7618-43c5-b259-d89741808479 () acm ! org>
--------------------
On 12/19/25 8:40 AM, Marco Elver wrote:
> Add support for Clang's context analysis for ww_mutex.
> 
> The programming model for ww_mutex is subtly more complex than other
> locking primitives when using ww_acquire_ctx. Encoding the respective
> pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> using Clang's context analysis makes incorrect use of the API harder.

That's a very short description. It should have been explained in the
patch description how the ww_acquire_ctx changes affect callers of the
ww_acquire_{init,done,fini}() functions.

>   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
>   				   struct ww_class *ww_class)
> +	__acquires(ctx) __no_context_analysis
> [ ... ]
>   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
>   {
> [ ... ]
>   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> +	__releases_shared(ctx) __no_context_analysis

The above changes make it mandatory to call ww_acquire_done() before
calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
there is an example where there is no ww_acquire_done() call between
ww_acquire_init() and ww_acquire_fini() (see also line 202). The
function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
ww_acquire_done() at all. Does this mean that the above annotations are
wrong? Is there a better solution than removing the __acquire() and
__release() annotations from the above three functions?

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-wireless
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 20:16:33 +0000
Message-ID: <05c77ca1-7618-43c5-b259-d89741808479 () acm ! org>
--------------------
On 12/19/25 8:40 AM, Marco Elver wrote:
> Add support for Clang's context analysis for ww_mutex.
> 
> The programming model for ww_mutex is subtly more complex than other
> locking primitives when using ww_acquire_ctx. Encoding the respective
> pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> using Clang's context analysis makes incorrect use of the API harder.

That's a very short description. It should have been explained in the
patch description how the ww_acquire_ctx changes affect callers of the
ww_acquire_{init,done,fini}() functions.

>   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
>   				   struct ww_class *ww_class)
> +	__acquires(ctx) __no_context_analysis
> [ ... ]
>   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
>   {
> [ ... ]
>   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> +	__releases_shared(ctx) __no_context_analysis

The above changes make it mandatory to call ww_acquire_done() before
calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
there is an example where there is no ww_acquire_done() call between
ww_acquire_init() and ww_acquire_fini() (see also line 202). The
function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
ww_acquire_done() at all. Does this mean that the above annotations are
wrong? Is there a better solution than removing the __acquire() and
__release() annotations from the above three functions?

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-kbuild
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 20:16:33 +0000
Message-ID: <05c77ca1-7618-43c5-b259-d89741808479 () acm ! org>
--------------------
On 12/19/25 8:40 AM, Marco Elver wrote:
> Add support for Clang's context analysis for ww_mutex.
> 
> The programming model for ww_mutex is subtly more complex than other
> locking primitives when using ww_acquire_ctx. Encoding the respective
> pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> using Clang's context analysis makes incorrect use of the API harder.

That's a very short description. It should have been explained in the
patch description how the ww_acquire_ctx changes affect callers of the
ww_acquire_{init,done,fini}() functions.

>   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
>   				   struct ww_class *ww_class)
> +	__acquires(ctx) __no_context_analysis
> [ ... ]
>   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
>   {
> [ ... ]
>   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> +	__releases_shared(ctx) __no_context_analysis

The above changes make it mandatory to call ww_acquire_done() before
calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
there is an example where there is no ww_acquire_done() call between
ww_acquire_init() and ww_acquire_fini() (see also line 202). The
function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
ww_acquire_done() at all. Does this mean that the above annotations are
wrong? Is there a better solution than removing the __acquire() and
__release() annotations from the above three functions?

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-kernel
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 20:16:33 +0000
Message-ID: <05c77ca1-7618-43c5-b259-d89741808479 () acm ! org>
--------------------
On 12/19/25 8:40 AM, Marco Elver wrote:
> Add support for Clang's context analysis for ww_mutex.
> 
> The programming model for ww_mutex is subtly more complex than other
> locking primitives when using ww_acquire_ctx. Encoding the respective
> pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> using Clang's context analysis makes incorrect use of the API harder.

That's a very short description. It should have been explained in the
patch description how the ww_acquire_ctx changes affect callers of the
ww_acquire_{init,done,fini}() functions.

>   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
>   				   struct ww_class *ww_class)
> +	__acquires(ctx) __no_context_analysis
> [ ... ]
>   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
>   {
> [ ... ]
>   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> +	__releases_shared(ctx) __no_context_analysis

The above changes make it mandatory to call ww_acquire_done() before
calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
there is an example where there is no ww_acquire_done() call between
ww_acquire_init() and ww_acquire_fini() (see also line 202). The
function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
ww_acquire_done() at all. Does this mean that the above annotations are
wrong? Is there a better solution than removing the __acquire() and
__release() annotations from the above three functions?

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-sparse
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 20:16:33 +0000
Message-ID: <05c77ca1-7618-43c5-b259-d89741808479 () acm ! org>
--------------------
On 12/19/25 8:40 AM, Marco Elver wrote:
> Add support for Clang's context analysis for ww_mutex.
> 
> The programming model for ww_mutex is subtly more complex than other
> locking primitives when using ww_acquire_ctx. Encoding the respective
> pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> using Clang's context analysis makes incorrect use of the API harder.

That's a very short description. It should have been explained in the
patch description how the ww_acquire_ctx changes affect callers of the
ww_acquire_{init,done,fini}() functions.

>   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
>   				   struct ww_class *ww_class)
> +	__acquires(ctx) __no_context_analysis
> [ ... ]
>   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
>   {
> [ ... ]
>   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> +	__releases_shared(ctx) __no_context_analysis

The above changes make it mandatory to call ww_acquire_done() before
calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
there is an example where there is no ww_acquire_done() call between
ww_acquire_init() and ww_acquire_fini() (see also line 202). The
function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
ww_acquire_done() at all. Does this mean that the above annotations are
wrong? Is there a better solution than removing the __acquire() and
__release() annotations from the above three functions?

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-doc
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 20:16:33 +0000
Message-ID: <05c77ca1-7618-43c5-b259-d89741808479 () acm ! org>
--------------------
On 12/19/25 8:40 AM, Marco Elver wrote:
> Add support for Clang's context analysis for ww_mutex.
> 
> The programming model for ww_mutex is subtly more complex than other
> locking primitives when using ww_acquire_ctx. Encoding the respective
> pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> using Clang's context analysis makes incorrect use of the API harder.

That's a very short description. It should have been explained in the
patch description how the ww_acquire_ctx changes affect callers of the
ww_acquire_{init,done,fini}() functions.

>   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
>   				   struct ww_class *ww_class)
> +	__acquires(ctx) __no_context_analysis
> [ ... ]
>   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
>   {
> [ ... ]
>   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> +	__releases_shared(ctx) __no_context_analysis

The above changes make it mandatory to call ww_acquire_done() before
calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
there is an example where there is no ww_acquire_done() call between
ww_acquire_init() and ww_acquire_fini() (see also line 202). The
function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
ww_acquire_done() at all. Does this mean that the above annotations are
wrong? Is there a better solution than removing the __acquire() and
__release() annotations from the above three functions?

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-crypto-vger
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 20:16:33 +0000
Message-ID: <05c77ca1-7618-43c5-b259-d89741808479 () acm ! org>
--------------------
On 12/19/25 8:40 AM, Marco Elver wrote:
> Add support for Clang's context analysis for ww_mutex.
> 
> The programming model for ww_mutex is subtly more complex than other
> locking primitives when using ww_acquire_ctx. Encoding the respective
> pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> using Clang's context analysis makes incorrect use of the API harder.

That's a very short description. It should have been explained in the
patch description how the ww_acquire_ctx changes affect callers of the
ww_acquire_{init,done,fini}() functions.

>   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
>   				   struct ww_class *ww_class)
> +	__acquires(ctx) __no_context_analysis
> [ ... ]
>   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
>   {
> [ ... ]
>   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> +	__releases_shared(ctx) __no_context_analysis

The above changes make it mandatory to call ww_acquire_done() before
calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
there is an example where there is no ww_acquire_done() call between
ww_acquire_init() and ww_acquire_fini() (see also line 202). The
function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
ww_acquire_done() at all. Does this mean that the above annotations are
wrong? Is there a better solution than removing the __acquire() and
__release() annotations from the above three functions?

Bart.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-sparse
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:06:50 +0000
Message-ID: <aWFt6hcLaCjQQu2c () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 12:16PM -0800, Bart Van Assche wrote:
> On 12/19/25 8:40 AM, Marco Elver wrote:
> > Add support for Clang's context analysis for ww_mutex.
> > 
> > The programming model for ww_mutex is subtly more complex than other
> > locking primitives when using ww_acquire_ctx. Encoding the respective
> > pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> > using Clang's context analysis makes incorrect use of the API harder.
> 
> That's a very short description. It should have been explained in the
> patch description how the ww_acquire_ctx changes affect callers of the
> ww_acquire_{init,done,fini}() functions.

How so? The API is the same (now statically enforced), and there's no
functional change at runtime. Or did I miss something?

> >   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
> >   				   struct ww_class *ww_class)
> > +	__acquires(ctx) __no_context_analysis
> > [ ... ]
> >   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> > +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
> >   {
> > [ ... ]
> >   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> > +	__releases_shared(ctx) __no_context_analysis
> 
> The above changes make it mandatory to call ww_acquire_done() before
> calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
> there is an example where there is no ww_acquire_done() call between
> ww_acquire_init() and ww_acquire_fini() (see also line 202).

It might be worth updating the example with what the kernel-doc
documentation recommends (below).

> The
> function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
> ww_acquire_done() at all. Does this mean that the above annotations are
> wrong?

If there's 1 out of N ww_mutex users that missed ww_acquire_done()
there's a good chance that 1 case is wrong.

But generally, depends if we want to enforce ww_acquire_done() or not
which itself is no-op in non-lockdep builds, however, with
DEBUG_WW_MUTEXES it's no longer no-op so it might be a good idea to
enforce it to get proper lockdep checking.

> Is there a better solution than removing the __acquire() and
> __release() annotations from the above three functions?

The kernel-doc comment for ww_acquire_done() says:

	/**
	 * ww_acquire_done - marks the end of the acquire phase
	 * @ctx: the acquire context
	 *
>>	 * Marks the end of the acquire phase, any further w/w mutex lock calls using
>>	 * this context are forbidden.
>>	 *
>>	 * Calling this function is optional, it is just useful to document w/w mutex
>>	 * code and clearly designated the acquire phase from actually using the locked
>>	 * data structures.
	 */
	static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
		__releases(ctx) __acquires_shared(ctx) __no_context_analysis
	{
	#ifdef DEBUG_WW_MUTEXES
		lockdep_assert_held(ctx);

		DEBUG_LOCKS_WARN_ON(ctx->done_acquire);
		ctx->done_acquire = 1;
	#endif
	}

It states it's optional, but it's unclear if that's true with
DEBUG_WW_MUTEXES builds. I'd vote for enforcing use of
ww_acquire_done(). If there's old code that's not using it, it should be
added there to get proper lockdep checking.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-wireless
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:06:50 +0000
Message-ID: <aWFt6hcLaCjQQu2c () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 12:16PM -0800, Bart Van Assche wrote:
> On 12/19/25 8:40 AM, Marco Elver wrote:
> > Add support for Clang's context analysis for ww_mutex.
> > 
> > The programming model for ww_mutex is subtly more complex than other
> > locking primitives when using ww_acquire_ctx. Encoding the respective
> > pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> > using Clang's context analysis makes incorrect use of the API harder.
> 
> That's a very short description. It should have been explained in the
> patch description how the ww_acquire_ctx changes affect callers of the
> ww_acquire_{init,done,fini}() functions.

How so? The API is the same (now statically enforced), and there's no
functional change at runtime. Or did I miss something?

> >   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
> >   				   struct ww_class *ww_class)
> > +	__acquires(ctx) __no_context_analysis
> > [ ... ]
> >   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> > +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
> >   {
> > [ ... ]
> >   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> > +	__releases_shared(ctx) __no_context_analysis
> 
> The above changes make it mandatory to call ww_acquire_done() before
> calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
> there is an example where there is no ww_acquire_done() call between
> ww_acquire_init() and ww_acquire_fini() (see also line 202).

It might be worth updating the example with what the kernel-doc
documentation recommends (below).

> The
> function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
> ww_acquire_done() at all. Does this mean that the above annotations are
> wrong?

If there's 1 out of N ww_mutex users that missed ww_acquire_done()
there's a good chance that 1 case is wrong.

But generally, depends if we want to enforce ww_acquire_done() or not
which itself is no-op in non-lockdep builds, however, with
DEBUG_WW_MUTEXES it's no longer no-op so it might be a good idea to
enforce it to get proper lockdep checking.

> Is there a better solution than removing the __acquire() and
> __release() annotations from the above three functions?

The kernel-doc comment for ww_acquire_done() says:

	/**
	 * ww_acquire_done - marks the end of the acquire phase
	 * @ctx: the acquire context
	 *
>>	 * Marks the end of the acquire phase, any further w/w mutex lock calls using
>>	 * this context are forbidden.
>>	 *
>>	 * Calling this function is optional, it is just useful to document w/w mutex
>>	 * code and clearly designated the acquire phase from actually using the locked
>>	 * data structures.
	 */
	static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
		__releases(ctx) __acquires_shared(ctx) __no_context_analysis
	{
	#ifdef DEBUG_WW_MUTEXES
		lockdep_assert_held(ctx);

		DEBUG_LOCKS_WARN_ON(ctx->done_acquire);
		ctx->done_acquire = 1;
	#endif
	}

It states it's optional, but it's unclear if that's true with
DEBUG_WW_MUTEXES builds. I'd vote for enforcing use of
ww_acquire_done(). If there's old code that's not using it, it should be
added there to get proper lockdep checking.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kernel
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:06:50 +0000
Message-ID: <aWFt6hcLaCjQQu2c () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 12:16PM -0800, Bart Van Assche wrote:
> On 12/19/25 8:40 AM, Marco Elver wrote:
> > Add support for Clang's context analysis for ww_mutex.
> > 
> > The programming model for ww_mutex is subtly more complex than other
> > locking primitives when using ww_acquire_ctx. Encoding the respective
> > pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> > using Clang's context analysis makes incorrect use of the API harder.
> 
> That's a very short description. It should have been explained in the
> patch description how the ww_acquire_ctx changes affect callers of the
> ww_acquire_{init,done,fini}() functions.

How so? The API is the same (now statically enforced), and there's no
functional change at runtime. Or did I miss something?

> >   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
> >   				   struct ww_class *ww_class)
> > +	__acquires(ctx) __no_context_analysis
> > [ ... ]
> >   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> > +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
> >   {
> > [ ... ]
> >   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> > +	__releases_shared(ctx) __no_context_analysis
> 
> The above changes make it mandatory to call ww_acquire_done() before
> calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
> there is an example where there is no ww_acquire_done() call between
> ww_acquire_init() and ww_acquire_fini() (see also line 202).

It might be worth updating the example with what the kernel-doc
documentation recommends (below).

> The
> function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
> ww_acquire_done() at all. Does this mean that the above annotations are
> wrong?

If there's 1 out of N ww_mutex users that missed ww_acquire_done()
there's a good chance that 1 case is wrong.

But generally, depends if we want to enforce ww_acquire_done() or not
which itself is no-op in non-lockdep builds, however, with
DEBUG_WW_MUTEXES it's no longer no-op so it might be a good idea to
enforce it to get proper lockdep checking.

> Is there a better solution than removing the __acquire() and
> __release() annotations from the above three functions?

The kernel-doc comment for ww_acquire_done() says:

	/**
	 * ww_acquire_done - marks the end of the acquire phase
	 * @ctx: the acquire context
	 *
>>	 * Marks the end of the acquire phase, any further w/w mutex lock calls using
>>	 * this context are forbidden.
>>	 *
>>	 * Calling this function is optional, it is just useful to document w/w mutex
>>	 * code and clearly designated the acquire phase from actually using the locked
>>	 * data structures.
	 */
	static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
		__releases(ctx) __acquires_shared(ctx) __no_context_analysis
	{
	#ifdef DEBUG_WW_MUTEXES
		lockdep_assert_held(ctx);

		DEBUG_LOCKS_WARN_ON(ctx->done_acquire);
		ctx->done_acquire = 1;
	#endif
	}

It states it's optional, but it's unclear if that's true with
DEBUG_WW_MUTEXES builds. I'd vote for enforcing use of
ww_acquire_done(). If there's old code that's not using it, it should be
added there to get proper lockdep checking.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-doc
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:06:50 +0000
Message-ID: <aWFt6hcLaCjQQu2c () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 12:16PM -0800, Bart Van Assche wrote:
> On 12/19/25 8:40 AM, Marco Elver wrote:
> > Add support for Clang's context analysis for ww_mutex.
> > 
> > The programming model for ww_mutex is subtly more complex than other
> > locking primitives when using ww_acquire_ctx. Encoding the respective
> > pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> > using Clang's context analysis makes incorrect use of the API harder.
> 
> That's a very short description. It should have been explained in the
> patch description how the ww_acquire_ctx changes affect callers of the
> ww_acquire_{init,done,fini}() functions.

How so? The API is the same (now statically enforced), and there's no
functional change at runtime. Or did I miss something?

> >   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
> >   				   struct ww_class *ww_class)
> > +	__acquires(ctx) __no_context_analysis
> > [ ... ]
> >   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> > +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
> >   {
> > [ ... ]
> >   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> > +	__releases_shared(ctx) __no_context_analysis
> 
> The above changes make it mandatory to call ww_acquire_done() before
> calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
> there is an example where there is no ww_acquire_done() call between
> ww_acquire_init() and ww_acquire_fini() (see also line 202).

It might be worth updating the example with what the kernel-doc
documentation recommends (below).

> The
> function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
> ww_acquire_done() at all. Does this mean that the above annotations are
> wrong?

If there's 1 out of N ww_mutex users that missed ww_acquire_done()
there's a good chance that 1 case is wrong.

But generally, depends if we want to enforce ww_acquire_done() or not
which itself is no-op in non-lockdep builds, however, with
DEBUG_WW_MUTEXES it's no longer no-op so it might be a good idea to
enforce it to get proper lockdep checking.

> Is there a better solution than removing the __acquire() and
> __release() annotations from the above three functions?

The kernel-doc comment for ww_acquire_done() says:

	/**
	 * ww_acquire_done - marks the end of the acquire phase
	 * @ctx: the acquire context
	 *
>>	 * Marks the end of the acquire phase, any further w/w mutex lock calls using
>>	 * this context are forbidden.
>>	 *
>>	 * Calling this function is optional, it is just useful to document w/w mutex
>>	 * code and clearly designated the acquire phase from actually using the locked
>>	 * data structures.
	 */
	static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
		__releases(ctx) __acquires_shared(ctx) __no_context_analysis
	{
	#ifdef DEBUG_WW_MUTEXES
		lockdep_assert_held(ctx);

		DEBUG_LOCKS_WARN_ON(ctx->done_acquire);
		ctx->done_acquire = 1;
	#endif
	}

It states it's optional, but it's unclear if that's true with
DEBUG_WW_MUTEXES builds. I'd vote for enforcing use of
ww_acquire_done(). If there's old code that's not using it, it should be
added there to get proper lockdep checking.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:06:50 +0000
Message-ID: <aWFt6hcLaCjQQu2c () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 12:16PM -0800, Bart Van Assche wrote:
> On 12/19/25 8:40 AM, Marco Elver wrote:
> > Add support for Clang's context analysis for ww_mutex.
> > 
> > The programming model for ww_mutex is subtly more complex than other
> > locking primitives when using ww_acquire_ctx. Encoding the respective
> > pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> > using Clang's context analysis makes incorrect use of the API harder.
> 
> That's a very short description. It should have been explained in the
> patch description how the ww_acquire_ctx changes affect callers of the
> ww_acquire_{init,done,fini}() functions.

How so? The API is the same (now statically enforced), and there's no
functional change at runtime. Or did I miss something?

> >   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
> >   				   struct ww_class *ww_class)
> > +	__acquires(ctx) __no_context_analysis
> > [ ... ]
> >   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> > +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
> >   {
> > [ ... ]
> >   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> > +	__releases_shared(ctx) __no_context_analysis
> 
> The above changes make it mandatory to call ww_acquire_done() before
> calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
> there is an example where there is no ww_acquire_done() call between
> ww_acquire_init() and ww_acquire_fini() (see also line 202).

It might be worth updating the example with what the kernel-doc
documentation recommends (below).

> The
> function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
> ww_acquire_done() at all. Does this mean that the above annotations are
> wrong?

If there's 1 out of N ww_mutex users that missed ww_acquire_done()
there's a good chance that 1 case is wrong.

But generally, depends if we want to enforce ww_acquire_done() or not
which itself is no-op in non-lockdep builds, however, with
DEBUG_WW_MUTEXES it's no longer no-op so it might be a good idea to
enforce it to get proper lockdep checking.

> Is there a better solution than removing the __acquire() and
> __release() annotations from the above three functions?

The kernel-doc comment for ww_acquire_done() says:

	/**
	 * ww_acquire_done - marks the end of the acquire phase
	 * @ctx: the acquire context
	 *
>>	 * Marks the end of the acquire phase, any further w/w mutex lock calls using
>>	 * this context are forbidden.
>>	 *
>>	 * Calling this function is optional, it is just useful to document w/w mutex
>>	 * code and clearly designated the acquire phase from actually using the locked
>>	 * data structures.
	 */
	static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
		__releases(ctx) __acquires_shared(ctx) __no_context_analysis
	{
	#ifdef DEBUG_WW_MUTEXES
		lockdep_assert_held(ctx);

		DEBUG_LOCKS_WARN_ON(ctx->done_acquire);
		ctx->done_acquire = 1;
	#endif
	}

It states it's optional, but it's unclear if that's true with
DEBUG_WW_MUTEXES builds. I'd vote for enforcing use of
ww_acquire_done(). If there's old code that's not using it, it should be
added there to get proper lockdep checking.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-mm
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:06:50 +0000
Message-ID: <aWFt6hcLaCjQQu2c () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 12:16PM -0800, Bart Van Assche wrote:
> On 12/19/25 8:40 AM, Marco Elver wrote:
> > Add support for Clang's context analysis for ww_mutex.
> > 
> > The programming model for ww_mutex is subtly more complex than other
> > locking primitives when using ww_acquire_ctx. Encoding the respective
> > pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> > using Clang's context analysis makes incorrect use of the API harder.
> 
> That's a very short description. It should have been explained in the
> patch description how the ww_acquire_ctx changes affect callers of the
> ww_acquire_{init,done,fini}() functions.

How so? The API is the same (now statically enforced), and there's no
functional change at runtime. Or did I miss something?

> >   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
> >   				   struct ww_class *ww_class)
> > +	__acquires(ctx) __no_context_analysis
> > [ ... ]
> >   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> > +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
> >   {
> > [ ... ]
> >   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> > +	__releases_shared(ctx) __no_context_analysis
> 
> The above changes make it mandatory to call ww_acquire_done() before
> calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
> there is an example where there is no ww_acquire_done() call between
> ww_acquire_init() and ww_acquire_fini() (see also line 202).

It might be worth updating the example with what the kernel-doc
documentation recommends (below).

> The
> function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
> ww_acquire_done() at all. Does this mean that the above annotations are
> wrong?

If there's 1 out of N ww_mutex users that missed ww_acquire_done()
there's a good chance that 1 case is wrong.

But generally, depends if we want to enforce ww_acquire_done() or not
which itself is no-op in non-lockdep builds, however, with
DEBUG_WW_MUTEXES it's no longer no-op so it might be a good idea to
enforce it to get proper lockdep checking.

> Is there a better solution than removing the __acquire() and
> __release() annotations from the above three functions?

The kernel-doc comment for ww_acquire_done() says:

	/**
	 * ww_acquire_done - marks the end of the acquire phase
	 * @ctx: the acquire context
	 *
>>	 * Marks the end of the acquire phase, any further w/w mutex lock calls using
>>	 * this context are forbidden.
>>	 *
>>	 * Calling this function is optional, it is just useful to document w/w mutex
>>	 * code and clearly designated the acquire phase from actually using the locked
>>	 * data structures.
	 */
	static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
		__releases(ctx) __acquires_shared(ctx) __no_context_analysis
	{
	#ifdef DEBUG_WW_MUTEXES
		lockdep_assert_held(ctx);

		DEBUG_LOCKS_WARN_ON(ctx->done_acquire);
		ctx->done_acquire = 1;
	#endif
	}

It states it's optional, but it's unclear if that's true with
DEBUG_WW_MUTEXES builds. I'd vote for enforcing use of
ww_acquire_done(). If there's old code that's not using it, it should be
added there to get proper lockdep checking.

================================================================================

From: Marco Elver <elver () google ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:06:50 +0000
Message-ID: <aWFt6hcLaCjQQu2c () elver ! google ! com>
--------------------
On Fri, Jan 09, 2026 at 12:16PM -0800, Bart Van Assche wrote:
> On 12/19/25 8:40 AM, Marco Elver wrote:
> > Add support for Clang's context analysis for ww_mutex.
> > 
> > The programming model for ww_mutex is subtly more complex than other
> > locking primitives when using ww_acquire_ctx. Encoding the respective
> > pre-conditions for ww_mutex lock/unlock based on ww_acquire_ctx state
> > using Clang's context analysis makes incorrect use of the API harder.
> 
> That's a very short description. It should have been explained in the
> patch description how the ww_acquire_ctx changes affect callers of the
> ww_acquire_{init,done,fini}() functions.

How so? The API is the same (now statically enforced), and there's no
functional change at runtime. Or did I miss something?

> >   static inline void ww_acquire_init(struct ww_acquire_ctx *ctx,
> >   				   struct ww_class *ww_class)
> > +	__acquires(ctx) __no_context_analysis
> > [ ... ]
> >   static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
> > +	__releases(ctx) __acquires_shared(ctx) __no_context_analysis
> >   {
> > [ ... ]
> >   static inline void ww_acquire_fini(struct ww_acquire_ctx *ctx)
> > +	__releases_shared(ctx) __no_context_analysis
> 
> The above changes make it mandatory to call ww_acquire_done() before
> calling ww_acquire_fini(). In Documentation/locking/ww-mutex-design.rst
> there is an example where there is no ww_acquire_done() call between
> ww_acquire_init() and ww_acquire_fini() (see also line 202).

It might be worth updating the example with what the kernel-doc
documentation recommends (below).

> The
> function dma_resv_lockdep() in drivers/dma-buf/dma-resv.c doesn't call
> ww_acquire_done() at all. Does this mean that the above annotations are
> wrong?

If there's 1 out of N ww_mutex users that missed ww_acquire_done()
there's a good chance that 1 case is wrong.

But generally, depends if we want to enforce ww_acquire_done() or not
which itself is no-op in non-lockdep builds, however, with
DEBUG_WW_MUTEXES it's no longer no-op so it might be a good idea to
enforce it to get proper lockdep checking.

> Is there a better solution than removing the __acquire() and
> __release() annotations from the above three functions?

The kernel-doc comment for ww_acquire_done() says:

	/**
	 * ww_acquire_done - marks the end of the acquire phase
	 * @ctx: the acquire context
	 *
>>	 * Marks the end of the acquire phase, any further w/w mutex lock calls using
>>	 * this context are forbidden.
>>	 *
>>	 * Calling this function is optional, it is just useful to document w/w mutex
>>	 * code and clearly designated the acquire phase from actually using the locked
>>	 * data structures.
	 */
	static inline void ww_acquire_done(struct ww_acquire_ctx *ctx)
		__releases(ctx) __acquires_shared(ctx) __no_context_analysis
	{
	#ifdef DEBUG_WW_MUTEXES
		lockdep_assert_held(ctx);

		DEBUG_LOCKS_WARN_ON(ctx->done_acquire);
		ctx->done_acquire = 1;
	#endif
	}

It states it's optional, but it's unclear if that's true with
DEBUG_WW_MUTEXES builds. I'd vote for enforcing use of
ww_acquire_done(). If there's old code that's not using it, it should be
added there to get proper lockdep checking.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-mm
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:26:23 +0000
Message-ID: <8143ab09-fd9b-4615-8afb-7ee10e073c51 () acm ! org>
--------------------
(+Maarten)

On 1/9/26 2:06 PM, Marco Elver wrote:
> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
> there's a good chance that 1 case is wrong.

$ git grep -w ww_acquire_done '**c'|wc -l
11
$ git grep -w ww_acquire_fini '**c'|wc -l
33

The above statistics show that there are more cases where
ww_acquire_done() is not called rather than cases where
ww_acquire_done() is called.

Maarten, since you introduced the ww_mutex code, do you perhaps prefer
that calling ww_acquire_done() is optional or rather that all users that
do not call ww_acquire_done() are modified such that they call
ww_acquire_done()? The full email conversation is available here:
https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-sparse
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:26:23 +0000
Message-ID: <8143ab09-fd9b-4615-8afb-7ee10e073c51 () acm ! org>
--------------------
(+Maarten)

On 1/9/26 2:06 PM, Marco Elver wrote:
> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
> there's a good chance that 1 case is wrong.

$ git grep -w ww_acquire_done '**c'|wc -l
11
$ git grep -w ww_acquire_fini '**c'|wc -l
33

The above statistics show that there are more cases where
ww_acquire_done() is not called rather than cases where
ww_acquire_done() is called.

Maarten, since you introduced the ww_mutex code, do you perhaps prefer
that calling ww_acquire_done() is optional or rather that all users that
do not call ww_acquire_done() are modified such that they call
ww_acquire_done()? The full email conversation is available here:
https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-doc
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:26:23 +0000
Message-ID: <8143ab09-fd9b-4615-8afb-7ee10e073c51 () acm ! org>
--------------------
(+Maarten)

On 1/9/26 2:06 PM, Marco Elver wrote:
> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
> there's a good chance that 1 case is wrong.

$ git grep -w ww_acquire_done '**c'|wc -l
11
$ git grep -w ww_acquire_fini '**c'|wc -l
33

The above statistics show that there are more cases where
ww_acquire_done() is not called rather than cases where
ww_acquire_done() is called.

Maarten, since you introduced the ww_mutex code, do you perhaps prefer
that calling ww_acquire_done() is optional or rather that all users that
do not call ww_acquire_done() are modified such that they call
ww_acquire_done()? The full email conversation is available here:
https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-crypto-vger
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:26:23 +0000
Message-ID: <8143ab09-fd9b-4615-8afb-7ee10e073c51 () acm ! org>
--------------------
(+Maarten)

On 1/9/26 2:06 PM, Marco Elver wrote:
> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
> there's a good chance that 1 case is wrong.

$ git grep -w ww_acquire_done '**c'|wc -l
11
$ git grep -w ww_acquire_fini '**c'|wc -l
33

The above statistics show that there are more cases where
ww_acquire_done() is not called rather than cases where
ww_acquire_done() is called.

Maarten, since you introduced the ww_mutex code, do you perhaps prefer
that calling ww_acquire_done() is optional or rather that all users that
do not call ww_acquire_done() are modified such that they call
ww_acquire_done()? The full email conversation is available here:
https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-kbuild
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:26:23 +0000
Message-ID: <8143ab09-fd9b-4615-8afb-7ee10e073c51 () acm ! org>
--------------------
(+Maarten)

On 1/9/26 2:06 PM, Marco Elver wrote:
> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
> there's a good chance that 1 case is wrong.

$ git grep -w ww_acquire_done '**c'|wc -l
11
$ git grep -w ww_acquire_fini '**c'|wc -l
33

The above statistics show that there are more cases where
ww_acquire_done() is not called rather than cases where
ww_acquire_done() is called.

Maarten, since you introduced the ww_mutex code, do you perhaps prefer
that calling ww_acquire_done() is optional or rather that all users that
do not call ww_acquire_done() are modified such that they call
ww_acquire_done()? The full email conversation is available here:
https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-wireless
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:26:23 +0000
Message-ID: <8143ab09-fd9b-4615-8afb-7ee10e073c51 () acm ! org>
--------------------
(+Maarten)

On 1/9/26 2:06 PM, Marco Elver wrote:
> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
> there's a good chance that 1 case is wrong.

$ git grep -w ww_acquire_done '**c'|wc -l
11
$ git grep -w ww_acquire_fini '**c'|wc -l
33

The above statistics show that there are more cases where
ww_acquire_done() is not called rather than cases where
ww_acquire_done() is called.

Maarten, since you introduced the ww_mutex code, do you perhaps prefer
that calling ww_acquire_done() is optional or rather that all users that
do not call ww_acquire_done() are modified such that they call
ww_acquire_done()? The full email conversation is available here:
https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/

Thanks,

Bart.

================================================================================

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-kernel
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Fri, 09 Jan 2026 21:26:23 +0000
Message-ID: <8143ab09-fd9b-4615-8afb-7ee10e073c51 () acm ! org>
--------------------
(+Maarten)

On 1/9/26 2:06 PM, Marco Elver wrote:
> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
> there's a good chance that 1 case is wrong.

$ git grep -w ww_acquire_done '**c'|wc -l
11
$ git grep -w ww_acquire_fini '**c'|wc -l
33

The above statistics show that there are more cases where
ww_acquire_done() is not called rather than cases where
ww_acquire_done() is called.

Maarten, since you introduced the ww_mutex code, do you perhaps prefer
that calling ww_acquire_done() is optional or rather that all users that
do not call ww_acquire_done() are modified such that they call
ww_acquire_done()? The full email conversation is available here:
https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/

Thanks,

Bart.

================================================================================

From: Maarten Lankhorst <maarten.lankhorst () linux ! intel ! com>
To: linux-wireless
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Mon, 12 Jan 2026 10:32:25 +0000
Message-ID: <1502e5eb-0ac7-4581-85ce-2f0c390bd7db () linux ! intel ! com>
--------------------
Hey,

The acquire_done() call was always optional. It's meant to indicate that after this point,
ww_acquire_lock may no longer be called and backoff can no longer occur.

It's allowed to call ww_acquire_fini() without ww_acquire_done()

Think of this case:
ww_acquire_init()

ww_acquire_lock_interruptible() -> -ERESTARTSYS

ww_acquire_fini()

Here it wouldn't make sense to call ww_acquire_done().

It's mostly to facilitate this case:

ww_acquire_init()

ww_acquire_lock() a bunch.

/* Got all locks, do the work as no more backoff occurs */
ww_acquire_done()

...

unlock_all()
ww_acquire_fini()

If you call ww_acquire_lock after done, a warning should occur as this should no longer happen.

Kind regards,
~Maarten Lankhorst

Den 2026-01-09 kl. 22:26, skrev Bart Van Assche:
> (+Maarten)
> 
> On 1/9/26 2:06 PM, Marco Elver wrote:
>> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
>> there's a good chance that 1 case is wrong.
> 
> $ git grep -w ww_acquire_done '**c'|wc -l
> 11
> $ git grep -w ww_acquire_fini '**c'|wc -l
> 33
> 
> The above statistics show that there are more cases where
> ww_acquire_done() is not called rather than cases where
> ww_acquire_done() is called.
> 
> Maarten, since you introduced the ww_mutex code, do you perhaps prefer
> that calling ww_acquire_done() is optional or rather that all users that
> do not call ww_acquire_done() are modified such that they call
> ww_acquire_done()? The full email conversation is available here:
> https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/
> 
> Thanks,
> 
> Bart.


================================================================================

From: Maarten Lankhorst <maarten.lankhorst () linux ! intel ! com>
To: linux-kernel
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Mon, 12 Jan 2026 10:32:25 +0000
Message-ID: <1502e5eb-0ac7-4581-85ce-2f0c390bd7db () linux ! intel ! com>
--------------------
Hey,

The acquire_done() call was always optional. It's meant to indicate that after this point,
ww_acquire_lock may no longer be called and backoff can no longer occur.

It's allowed to call ww_acquire_fini() without ww_acquire_done()

Think of this case:
ww_acquire_init()

ww_acquire_lock_interruptible() -> -ERESTARTSYS

ww_acquire_fini()

Here it wouldn't make sense to call ww_acquire_done().

It's mostly to facilitate this case:

ww_acquire_init()

ww_acquire_lock() a bunch.

/* Got all locks, do the work as no more backoff occurs */
ww_acquire_done()

...

unlock_all()
ww_acquire_fini()

If you call ww_acquire_lock after done, a warning should occur as this should no longer happen.

Kind regards,
~Maarten Lankhorst

Den 2026-01-09 kl. 22:26, skrev Bart Van Assche:
> (+Maarten)
> 
> On 1/9/26 2:06 PM, Marco Elver wrote:
>> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
>> there's a good chance that 1 case is wrong.
> 
> $ git grep -w ww_acquire_done '**c'|wc -l
> 11
> $ git grep -w ww_acquire_fini '**c'|wc -l
> 33
> 
> The above statistics show that there are more cases where
> ww_acquire_done() is not called rather than cases where
> ww_acquire_done() is called.
> 
> Maarten, since you introduced the ww_mutex code, do you perhaps prefer
> that calling ww_acquire_done() is optional or rather that all users that
> do not call ww_acquire_done() are modified such that they call
> ww_acquire_done()? The full email conversation is available here:
> https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/
> 
> Thanks,
> 
> Bart.


================================================================================

From: Maarten Lankhorst <maarten.lankhorst () linux ! intel ! com>
To: linux-sparse
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Mon, 12 Jan 2026 10:32:25 +0000
Message-ID: <1502e5eb-0ac7-4581-85ce-2f0c390bd7db () linux ! intel ! com>
--------------------
Hey,

The acquire_done() call was always optional. It's meant to indicate that after this point,
ww_acquire_lock may no longer be called and backoff can no longer occur.

It's allowed to call ww_acquire_fini() without ww_acquire_done()

Think of this case:
ww_acquire_init()

ww_acquire_lock_interruptible() -> -ERESTARTSYS

ww_acquire_fini()

Here it wouldn't make sense to call ww_acquire_done().

It's mostly to facilitate this case:

ww_acquire_init()

ww_acquire_lock() a bunch.

/* Got all locks, do the work as no more backoff occurs */
ww_acquire_done()

...

unlock_all()
ww_acquire_fini()

If you call ww_acquire_lock after done, a warning should occur as this should no longer happen.

Kind regards,
~Maarten Lankhorst

Den 2026-01-09 kl. 22:26, skrev Bart Van Assche:
> (+Maarten)
> 
> On 1/9/26 2:06 PM, Marco Elver wrote:
>> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
>> there's a good chance that 1 case is wrong.
> 
> $ git grep -w ww_acquire_done '**c'|wc -l
> 11
> $ git grep -w ww_acquire_fini '**c'|wc -l
> 33
> 
> The above statistics show that there are more cases where
> ww_acquire_done() is not called rather than cases where
> ww_acquire_done() is called.
> 
> Maarten, since you introduced the ww_mutex code, do you perhaps prefer
> that calling ww_acquire_done() is optional or rather that all users that
> do not call ww_acquire_done() are modified such that they call
> ww_acquire_done()? The full email conversation is available here:
> https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/
> 
> Thanks,
> 
> Bart.


================================================================================

From: Maarten Lankhorst <maarten.lankhorst () linux ! intel ! com>
To: linux-mm
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Mon, 12 Jan 2026 10:32:25 +0000
Message-ID: <1502e5eb-0ac7-4581-85ce-2f0c390bd7db () linux ! intel ! com>
--------------------
Hey,

The acquire_done() call was always optional. It's meant to indicate that after this point,
ww_acquire_lock may no longer be called and backoff can no longer occur.

It's allowed to call ww_acquire_fini() without ww_acquire_done()

Think of this case:
ww_acquire_init()

ww_acquire_lock_interruptible() -> -ERESTARTSYS

ww_acquire_fini()

Here it wouldn't make sense to call ww_acquire_done().

It's mostly to facilitate this case:

ww_acquire_init()

ww_acquire_lock() a bunch.

/* Got all locks, do the work as no more backoff occurs */
ww_acquire_done()

...

unlock_all()
ww_acquire_fini()

If you call ww_acquire_lock after done, a warning should occur as this should no longer happen.

Kind regards,
~Maarten Lankhorst

Den 2026-01-09 kl. 22:26, skrev Bart Van Assche:
> (+Maarten)
> 
> On 1/9/26 2:06 PM, Marco Elver wrote:
>> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
>> there's a good chance that 1 case is wrong.
> 
> $ git grep -w ww_acquire_done '**c'|wc -l
> 11
> $ git grep -w ww_acquire_fini '**c'|wc -l
> 33
> 
> The above statistics show that there are more cases where
> ww_acquire_done() is not called rather than cases where
> ww_acquire_done() is called.
> 
> Maarten, since you introduced the ww_mutex code, do you perhaps prefer
> that calling ww_acquire_done() is optional or rather that all users that
> do not call ww_acquire_done() are modified such that they call
> ww_acquire_done()? The full email conversation is available here:
> https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/
> 
> Thanks,
> 
> Bart.


================================================================================

From: Maarten Lankhorst <maarten.lankhorst () linux ! intel ! com>
To: linux-doc
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Mon, 12 Jan 2026 10:32:25 +0000
Message-ID: <1502e5eb-0ac7-4581-85ce-2f0c390bd7db () linux ! intel ! com>
--------------------
Hey,

The acquire_done() call was always optional. It's meant to indicate that after this point,
ww_acquire_lock may no longer be called and backoff can no longer occur.

It's allowed to call ww_acquire_fini() without ww_acquire_done()

Think of this case:
ww_acquire_init()

ww_acquire_lock_interruptible() -> -ERESTARTSYS

ww_acquire_fini()

Here it wouldn't make sense to call ww_acquire_done().

It's mostly to facilitate this case:

ww_acquire_init()

ww_acquire_lock() a bunch.

/* Got all locks, do the work as no more backoff occurs */
ww_acquire_done()

...

unlock_all()
ww_acquire_fini()

If you call ww_acquire_lock after done, a warning should occur as this should no longer happen.

Kind regards,
~Maarten Lankhorst

Den 2026-01-09 kl. 22:26, skrev Bart Van Assche:
> (+Maarten)
> 
> On 1/9/26 2:06 PM, Marco Elver wrote:
>> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
>> there's a good chance that 1 case is wrong.
> 
> $ git grep -w ww_acquire_done '**c'|wc -l
> 11
> $ git grep -w ww_acquire_fini '**c'|wc -l
> 33
> 
> The above statistics show that there are more cases where
> ww_acquire_done() is not called rather than cases where
> ww_acquire_done() is called.
> 
> Maarten, since you introduced the ww_mutex code, do you perhaps prefer
> that calling ww_acquire_done() is optional or rather that all users that
> do not call ww_acquire_done() are modified such that they call
> ww_acquire_done()? The full email conversation is available here:
> https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/
> 
> Thanks,
> 
> Bart.


================================================================================

From: Maarten Lankhorst <maarten.lankhorst () linux ! intel ! com>
To: linux-crypto-vger
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Mon, 12 Jan 2026 10:32:25 +0000
Message-ID: <1502e5eb-0ac7-4581-85ce-2f0c390bd7db () linux ! intel ! com>
--------------------
Hey,

The acquire_done() call was always optional. It's meant to indicate that after this point,
ww_acquire_lock may no longer be called and backoff can no longer occur.

It's allowed to call ww_acquire_fini() without ww_acquire_done()

Think of this case:
ww_acquire_init()

ww_acquire_lock_interruptible() -> -ERESTARTSYS

ww_acquire_fini()

Here it wouldn't make sense to call ww_acquire_done().

It's mostly to facilitate this case:

ww_acquire_init()

ww_acquire_lock() a bunch.

/* Got all locks, do the work as no more backoff occurs */
ww_acquire_done()

...

unlock_all()
ww_acquire_fini()

If you call ww_acquire_lock after done, a warning should occur as this should no longer happen.

Kind regards,
~Maarten Lankhorst

Den 2026-01-09 kl. 22:26, skrev Bart Van Assche:
> (+Maarten)
> 
> On 1/9/26 2:06 PM, Marco Elver wrote:
>> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
>> there's a good chance that 1 case is wrong.
> 
> $ git grep -w ww_acquire_done '**c'|wc -l
> 11
> $ git grep -w ww_acquire_fini '**c'|wc -l
> 33
> 
> The above statistics show that there are more cases where
> ww_acquire_done() is not called rather than cases where
> ww_acquire_done() is called.
> 
> Maarten, since you introduced the ww_mutex code, do you perhaps prefer
> that calling ww_acquire_done() is optional or rather that all users that
> do not call ww_acquire_done() are modified such that they call
> ww_acquire_done()? The full email conversation is available here:
> https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/
> 
> Thanks,
> 
> Bart.


================================================================================

From: Maarten Lankhorst <maarten.lankhorst () linux ! intel ! com>
To: linux-kbuild
Subject: Re: [PATCH v5 20/36] locking/ww_mutex: Support Clang's context analysis
Date: Mon, 12 Jan 2026 10:32:25 +0000
Message-ID: <1502e5eb-0ac7-4581-85ce-2f0c390bd7db () linux ! intel ! com>
--------------------
Hey,

The acquire_done() call was always optional. It's meant to indicate that after this point,
ww_acquire_lock may no longer be called and backoff can no longer occur.

It's allowed to call ww_acquire_fini() without ww_acquire_done()

Think of this case:
ww_acquire_init()

ww_acquire_lock_interruptible() -> -ERESTARTSYS

ww_acquire_fini()

Here it wouldn't make sense to call ww_acquire_done().

It's mostly to facilitate this case:

ww_acquire_init()

ww_acquire_lock() a bunch.

/* Got all locks, do the work as no more backoff occurs */
ww_acquire_done()

...

unlock_all()
ww_acquire_fini()

If you call ww_acquire_lock after done, a warning should occur as this should no longer happen.

Kind regards,
~Maarten Lankhorst

Den 2026-01-09 kl. 22:26, skrev Bart Van Assche:
> (+Maarten)
> 
> On 1/9/26 2:06 PM, Marco Elver wrote:
>> If there's 1 out of N ww_mutex users that missed ww_acquire_done()
>> there's a good chance that 1 case is wrong.
> 
> $ git grep -w ww_acquire_done '**c'|wc -l
> 11
> $ git grep -w ww_acquire_fini '**c'|wc -l
> 33
> 
> The above statistics show that there are more cases where
> ww_acquire_done() is not called rather than cases where
> ww_acquire_done() is called.
> 
> Maarten, since you introduced the ww_mutex code, do you perhaps prefer
> that calling ww_acquire_done() is optional or rather that all users that
> do not call ww_acquire_done() are modified such that they call
> ww_acquire_done()? The full email conversation is available here:
> https://lore.kernel.org/all/20251219154418.3592607-1-elver@google.com/
> 
> Thanks,
> 
> Bart.


================================================================================


################################################################################

=== Thread: [PATCH v5 36/36] sched: Enable context analysis for core.c and fair.c ===

From: Bart Van Assche <bvanassche () acm ! org>
To: linux-sparse
Subject: Re: [PATCH v5 36/36] sched: Enable context analysis for core.c and fair.c
Date: Mon, 12 Jan 2026 22:04:59 +0000
Message-ID: <3de714fc-7a18-4bcc-9ab5-c3831efbdb84 () acm ! org>
--------------------
On 12/19/25 8:40 AM, Marco Elver wrote:
> diff --git a/include/linux/sched/signal.h b/include/linux/sched/signal.h
> index a63f65aa5bdd..a22248aebcf9 100644
> --- a/include/linux/sched/signal.h
> +++ b/include/linux/sched/signal.h
> @@ -738,10 +738,12 @@ static inline int thread_group_empty(struct task_struct *p)
>   		(thread_group_leader(p) && !thread_group_empty(p))
>   
>   extern struct sighand_struct *lock_task_sighand(struct task_struct *task,
> -						unsigned long *flags);
> +						unsigned long *flags)
> +	__acquires(&task->sighand->siglock);

I think the above annotation is wrong and should be changed into
__cond_acquires(nonnull, &task->sighand->siglock). My understanding of
the code in kernel/signal.c is that lock_task_sighand() only returns
with sighand->siglock acquired if it returns a non-NULL pointer.

Bart.

================================================================================


################################################################################

=== Thread: [PATCH] compiler-context-analysis: Support immediate acquisition
 after initialization ===

From: Marco Elver <elver@google.com>
To: Unknown
Subject: [PATCH] compiler-context-analysis: Support immediate acquisition
 after initialization
Date: Sat, 10 Jan 2026 00:47:35 +0100
Message-ID: 
--------------------
When a lock is initialized (e.g. mutex_init()), we assume/assert that
the context lock is held to allow initialization of guarded members
within the same scope.

However, this previously prevented actually acquiring the lock within
that same scope, as the analyzer would report a double-lock warning:

  mutex_init(&mtx);
  ...
  mutex_lock(&mtx); // acquiring mutex 'mtx' that is already held

To fix (without new init+lock APIs), we can tell the analysis to treat
the "held" context lock resulting from initialization as reentrant,
allowing subsequent acquisitions to succeed.

To do so *only* within the initialization scope, we can cast the lock
pointer to any reentrant type for the init assume/assert. Introduce a
generic reentrant context lock type `struct __ctx_lock_init` and add
`__inits_ctx_lock()` that casts the lock pointer to this type before
assuming/asserting it.

This ensures that the initial "held" state is reentrant, allowing
patterns like:

  mutex_init(&lock);
  ...
  mutex_lock(&lock);

to compile without false positives, and avoids having to make all
context lock types reentrant outside an initialization scope.

The caveat here is missing real double-lock bugs right after init scope.
However, this is a classic trade-off of avoiding false positives against
(unlikely) false negatives.

Link: https://lore.kernel.org/all/57062131-e79e-42c2-aa0b-8f931cb8cac2@acm.org/
Reported-by: Bart Van Assche <bvanassche@acm.org>
Signed-off-by: Marco Elver <elver@google.com>
---
 include/linux/compiler-context-analysis.h | 12 ++++++++++++
 include/linux/local_lock_internal.h       |  6 +++---
 include/linux/mutex.h                     |  2 +-
 include/linux/rwlock.h                    |  4 ++--
 include/linux/rwlock_rt.h                 |  2 +-
 include/linux/rwsem.h                     |  4 ++--
 include/linux/seqlock.h                   |  2 +-
 include/linux/spinlock.h                  |  8 ++++----
 include/linux/spinlock_rt.h               |  2 +-
 include/linux/ww_mutex.h                  |  2 +-
 lib/test_context-analysis.c               |  3 +++
 11 files changed, 31 insertions(+), 16 deletions(-)

diff --git a/include/linux/compiler-context-analysis.h b/include/linux/compiler-context-analysis.h
index db7e0d48d8f2..e056cd6e8aaa 100644
--- a/include/linux/compiler-context-analysis.h
+++ b/include/linux/compiler-context-analysis.h
@@ -43,6 +43,14 @@
 # define __assumes_ctx_lock(...)		__attribute__((assert_capability(__VA_ARGS__)))
 # define __assumes_shared_ctx_lock(...)	__attribute__((assert_shared_capability(__VA_ARGS__)))
 
+/*
+ * Generic reentrant context lock type that we cast to when initializing context
+ * locks with __assumes_ctx_lock(), so that we can support guarded member
+ * initialization, but also immediate use after initialization.
+ */
+struct __ctx_lock_type(init_generic) __reentrant_ctx_lock __ctx_lock_init;
+# define __inits_ctx_lock(var) __assumes_ctx_lock((const struct __ctx_lock_init *)(var))
+
 /**
  * __guarded_by - struct member and globals attribute, declares variable
  *                only accessible within active context
@@ -120,6 +128,8 @@
 		__attribute__((overloadable)) __assumes_ctx_lock(var) { }				\
 	static __always_inline void __assume_shared_ctx_lock(const struct name *var)			\
 		__attribute__((overloadable)) __assumes_shared_ctx_lock(var) { }			\
+	static __always_inline void __init_ctx_lock(const struct name *var)				\
+		__attribute__((overloadable)) __inits_ctx_lock(var) { }					\
 	struct name
 
 /**
@@ -162,6 +172,7 @@
 # define __releases_shared_ctx_lock(...)
 # define __assumes_ctx_lock(...)
 # define __assumes_shared_ctx_lock(...)
+# define __inits_ctx_lock(var)
 # define __returns_ctx_lock(var)
 # define __guarded_by(...)
 # define __pt_guarded_by(...)
@@ -176,6 +187,7 @@
 # define __release_shared_ctx_lock(var)		do { } while (0)
 # define __assume_ctx_lock(var)			do { (void)(var); } while (0)
 # define __assume_shared_ctx_lock(var)			do { (void)(var); } while (0)
+# define __init_ctx_lock(var)			do { (void)(var); } while (0)
 # define context_lock_struct(name, ...)		struct __VA_ARGS__ name
 # define disable_context_analysis()
 # define enable_context_analysis()
diff --git a/include/linux/local_lock_internal.h b/include/linux/local_lock_internal.h
index e8c4803d8db4..36b8628d09fd 100644
--- a/include/linux/local_lock_internal.h
+++ b/include/linux/local_lock_internal.h
@@ -86,13 +86,13 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_PERCPU);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_trylock_init(lock)				\
 do {								\
 	__local_lock_init((local_lock_t *)lock);		\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __spinlock_nested_bh_init(lock)				\
@@ -104,7 +104,7 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_NORMAL);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_lock_acquire(lock)					\
diff --git a/include/linux/mutex.h b/include/linux/mutex.h
index 89977c215cbd..5d2ef75c4fdb 100644
--- a/include/linux/mutex.h
+++ b/include/linux/mutex.h
@@ -62,7 +62,7 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__mutex_init((mutex), #mutex, &__key);				\
-	__assume_ctx_lock(mutex);					\
+	__init_ctx_lock(mutex);						\
 } while (0)
 
 /**
diff --git a/include/linux/rwlock.h b/include/linux/rwlock.h
index 65a5b55e1bcd..7e171634d2c4 100644
--- a/include/linux/rwlock.h
+++ b/include/linux/rwlock.h
@@ -22,11 +22,11 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__rwlock_init((lock), #lock, &__key);			\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 #else
 # define rwlock_init(lock)					\
-	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #ifdef CONFIG_DEBUG_SPINLOCK
diff --git a/include/linux/rwlock_rt.h b/include/linux/rwlock_rt.h
index 37b387dcab21..1e087a6ce2cf 100644
--- a/include/linux/rwlock_rt.h
+++ b/include/linux/rwlock_rt.h
@@ -22,7 +22,7 @@ do {							\
 							\
 	init_rwbase_rt(&(rwl)->rwbase);			\
 	__rt_rwlock_init(rwl, #rwl, &__key);		\
-	__assume_ctx_lock(rwl);				\
+	__init_ctx_lock(rwl);				\
 } while (0)
 
 extern void rt_read_lock(rwlock_t *rwlock)	__acquires_shared(rwlock);
diff --git a/include/linux/rwsem.h b/include/linux/rwsem.h
index 8da14a08a4e1..6ea7d2a23580 100644
--- a/include/linux/rwsem.h
+++ b/include/linux/rwsem.h
@@ -121,7 +121,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 /*
@@ -175,7 +175,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 static __always_inline int rwsem_is_locked(const struct rw_semaphore *sem)
diff --git a/include/linux/seqlock.h b/include/linux/seqlock.h
index 113320911a09..a0670adb4b6e 100644
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@ -816,7 +816,7 @@ static __always_inline void write_seqcount_latch_end(seqcount_latch_t *s)
 	do {								\
 		spin_lock_init(&(sl)->lock);				\
 		seqcount_spinlock_init(&(sl)->seqcount, &(sl)->lock);	\
-		__assume_ctx_lock(sl);					\
+		__init_ctx_lock(sl);					\
 	} while (0)
 
 /**
diff --git a/include/linux/spinlock.h b/include/linux/spinlock.h
index 396b8c5d6c1b..e50372a5f7d1 100644
--- a/include/linux/spinlock.h
+++ b/include/linux/spinlock.h
@@ -106,12 +106,12 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__raw_spin_lock_init((lock), #lock, &__key, LD_WAIT_SPIN);	\
-	__assume_ctx_lock(lock);					\
+	__init_ctx_lock(lock);						\
 } while (0)
 
 #else
 # define raw_spin_lock_init(lock)				\
-	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #define raw_spin_is_locked(lock)	arch_spin_is_locked(&(lock)->raw_lock)
@@ -324,7 +324,7 @@ do {								\
 								\
 	__raw_spin_lock_init(spinlock_check(lock),		\
 			     #lock, &__key, LD_WAIT_CONFIG);	\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #else
@@ -333,7 +333,7 @@ do {								\
 do {						\
 	spinlock_check(_lock);			\
 	*(_lock) = __SPIN_LOCK_UNLOCKED(_lock);	\
-	__assume_ctx_lock(_lock);		\
+	__init_ctx_lock(_lock);			\
 } while (0)
 
 #endif
diff --git a/include/linux/spinlock_rt.h b/include/linux/spinlock_rt.h
index 0a585768358f..154d7290bd99 100644
--- a/include/linux/spinlock_rt.h
+++ b/include/linux/spinlock_rt.h
@@ -20,7 +20,7 @@ static inline void __rt_spin_lock_init(spinlock_t *lock, const char *name,
 do {								\
 	rt_mutex_base_init(&(slock)->lock);			\
 	__rt_spin_lock_init(slock, name, key, percpu);		\
-	__assume_ctx_lock(slock);				\
+	__init_ctx_lock(slock);					\
 } while (0)
 
 #define _spin_lock_init(slock, percpu)				\
diff --git a/include/linux/ww_mutex.h b/include/linux/ww_mutex.h
index 58e959ee10e9..ecb5564ee70d 100644
--- a/include/linux/ww_mutex.h
+++ b/include/linux/ww_mutex.h
@@ -107,7 +107,7 @@ context_lock_struct(ww_acquire_ctx) {
  */
 static inline void ww_mutex_init(struct ww_mutex *lock,
 				 struct ww_class *ww_class)
-	__assumes_ctx_lock(lock)
+	__inits_ctx_lock(lock)
 {
 	ww_mutex_base_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 	lock->ctx = NULL;
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 1c5a381461fc..2f733b5cc650 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -165,6 +165,9 @@ static void __used test_mutex_init(struct test_mutex_data *d)
 {
 	mutex_init(&d->mtx);
 	d->counter = 0;
+
+	mutex_lock(&d->mtx);
+	mutex_unlock(&d->mtx);
 }
 
 static void __used test_mutex_lock(struct test_mutex_data *d)
-- 
2.52.0.457.g6b5491de43-goog

================================================================================

From: Marco Elver <elver@google.com>
To: Unknown
Subject: [PATCH] compiler-context-analysis: Support immediate acquisition
 after initialization
Date: Sat, 10 Jan 2026 00:47:35 +0100
Message-ID: 
--------------------
When a lock is initialized (e.g. mutex_init()), we assume/assert that
the context lock is held to allow initialization of guarded members
within the same scope.

However, this previously prevented actually acquiring the lock within
that same scope, as the analyzer would report a double-lock warning:

  mutex_init(&mtx);
  ...
  mutex_lock(&mtx); // acquiring mutex 'mtx' that is already held

To fix (without new init+lock APIs), we can tell the analysis to treat
the "held" context lock resulting from initialization as reentrant,
allowing subsequent acquisitions to succeed.

To do so *only* within the initialization scope, we can cast the lock
pointer to any reentrant type for the init assume/assert. Introduce a
generic reentrant context lock type `struct __ctx_lock_init` and add
`__inits_ctx_lock()` that casts the lock pointer to this type before
assuming/asserting it.

This ensures that the initial "held" state is reentrant, allowing
patterns like:

  mutex_init(&lock);
  ...
  mutex_lock(&lock);

to compile without false positives, and avoids having to make all
context lock types reentrant outside an initialization scope.

The caveat here is missing real double-lock bugs right after init scope.
However, this is a classic trade-off of avoiding false positives against
(unlikely) false negatives.

Link: https://lore.kernel.org/all/57062131-e79e-42c2-aa0b-8f931cb8cac2@acm.org/
Reported-by: Bart Van Assche <bvanassche@acm.org>
Signed-off-by: Marco Elver <elver@google.com>
---
 include/linux/compiler-context-analysis.h | 12 ++++++++++++
 include/linux/local_lock_internal.h       |  6 +++---
 include/linux/mutex.h                     |  2 +-
 include/linux/rwlock.h                    |  4 ++--
 include/linux/rwlock_rt.h                 |  2 +-
 include/linux/rwsem.h                     |  4 ++--
 include/linux/seqlock.h                   |  2 +-
 include/linux/spinlock.h                  |  8 ++++----
 include/linux/spinlock_rt.h               |  2 +-
 include/linux/ww_mutex.h                  |  2 +-
 lib/test_context-analysis.c               |  3 +++
 11 files changed, 31 insertions(+), 16 deletions(-)

diff --git a/include/linux/compiler-context-analysis.h b/include/linux/compiler-context-analysis.h
index db7e0d48d8f2..e056cd6e8aaa 100644
--- a/include/linux/compiler-context-analysis.h
+++ b/include/linux/compiler-context-analysis.h
@@ -43,6 +43,14 @@
 # define __assumes_ctx_lock(...)		__attribute__((assert_capability(__VA_ARGS__)))
 # define __assumes_shared_ctx_lock(...)	__attribute__((assert_shared_capability(__VA_ARGS__)))
 
+/*
+ * Generic reentrant context lock type that we cast to when initializing context
+ * locks with __assumes_ctx_lock(), so that we can support guarded member
+ * initialization, but also immediate use after initialization.
+ */
+struct __ctx_lock_type(init_generic) __reentrant_ctx_lock __ctx_lock_init;
+# define __inits_ctx_lock(var) __assumes_ctx_lock((const struct __ctx_lock_init *)(var))
+
 /**
  * __guarded_by - struct member and globals attribute, declares variable
  *                only accessible within active context
@@ -120,6 +128,8 @@
 		__attribute__((overloadable)) __assumes_ctx_lock(var) { }				\
 	static __always_inline void __assume_shared_ctx_lock(const struct name *var)			\
 		__attribute__((overloadable)) __assumes_shared_ctx_lock(var) { }			\
+	static __always_inline void __init_ctx_lock(const struct name *var)				\
+		__attribute__((overloadable)) __inits_ctx_lock(var) { }					\
 	struct name
 
 /**
@@ -162,6 +172,7 @@
 # define __releases_shared_ctx_lock(...)
 # define __assumes_ctx_lock(...)
 # define __assumes_shared_ctx_lock(...)
+# define __inits_ctx_lock(var)
 # define __returns_ctx_lock(var)
 # define __guarded_by(...)
 # define __pt_guarded_by(...)
@@ -176,6 +187,7 @@
 # define __release_shared_ctx_lock(var)		do { } while (0)
 # define __assume_ctx_lock(var)			do { (void)(var); } while (0)
 # define __assume_shared_ctx_lock(var)			do { (void)(var); } while (0)
+# define __init_ctx_lock(var)			do { (void)(var); } while (0)
 # define context_lock_struct(name, ...)		struct __VA_ARGS__ name
 # define disable_context_analysis()
 # define enable_context_analysis()
diff --git a/include/linux/local_lock_internal.h b/include/linux/local_lock_internal.h
index e8c4803d8db4..36b8628d09fd 100644
--- a/include/linux/local_lock_internal.h
+++ b/include/linux/local_lock_internal.h
@@ -86,13 +86,13 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_PERCPU);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_trylock_init(lock)				\
 do {								\
 	__local_lock_init((local_lock_t *)lock);		\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __spinlock_nested_bh_init(lock)				\
@@ -104,7 +104,7 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_NORMAL);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_lock_acquire(lock)					\
diff --git a/include/linux/mutex.h b/include/linux/mutex.h
index 89977c215cbd..5d2ef75c4fdb 100644
--- a/include/linux/mutex.h
+++ b/include/linux/mutex.h
@@ -62,7 +62,7 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__mutex_init((mutex), #mutex, &__key);				\
-	__assume_ctx_lock(mutex);					\
+	__init_ctx_lock(mutex);						\
 } while (0)
 
 /**
diff --git a/include/linux/rwlock.h b/include/linux/rwlock.h
index 65a5b55e1bcd..7e171634d2c4 100644
--- a/include/linux/rwlock.h
+++ b/include/linux/rwlock.h
@@ -22,11 +22,11 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__rwlock_init((lock), #lock, &__key);			\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 #else
 # define rwlock_init(lock)					\
-	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #ifdef CONFIG_DEBUG_SPINLOCK
diff --git a/include/linux/rwlock_rt.h b/include/linux/rwlock_rt.h
index 37b387dcab21..1e087a6ce2cf 100644
--- a/include/linux/rwlock_rt.h
+++ b/include/linux/rwlock_rt.h
@@ -22,7 +22,7 @@ do {							\
 							\
 	init_rwbase_rt(&(rwl)->rwbase);			\
 	__rt_rwlock_init(rwl, #rwl, &__key);		\
-	__assume_ctx_lock(rwl);				\
+	__init_ctx_lock(rwl);				\
 } while (0)
 
 extern void rt_read_lock(rwlock_t *rwlock)	__acquires_shared(rwlock);
diff --git a/include/linux/rwsem.h b/include/linux/rwsem.h
index 8da14a08a4e1..6ea7d2a23580 100644
--- a/include/linux/rwsem.h
+++ b/include/linux/rwsem.h
@@ -121,7 +121,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 /*
@@ -175,7 +175,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 static __always_inline int rwsem_is_locked(const struct rw_semaphore *sem)
diff --git a/include/linux/seqlock.h b/include/linux/seqlock.h
index 113320911a09..a0670adb4b6e 100644
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@ -816,7 +816,7 @@ static __always_inline void write_seqcount_latch_end(seqcount_latch_t *s)
 	do {								\
 		spin_lock_init(&(sl)->lock);				\
 		seqcount_spinlock_init(&(sl)->seqcount, &(sl)->lock);	\
-		__assume_ctx_lock(sl);					\
+		__init_ctx_lock(sl);					\
 	} while (0)
 
 /**
diff --git a/include/linux/spinlock.h b/include/linux/spinlock.h
index 396b8c5d6c1b..e50372a5f7d1 100644
--- a/include/linux/spinlock.h
+++ b/include/linux/spinlock.h
@@ -106,12 +106,12 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__raw_spin_lock_init((lock), #lock, &__key, LD_WAIT_SPIN);	\
-	__assume_ctx_lock(lock);					\
+	__init_ctx_lock(lock);						\
 } while (0)
 
 #else
 # define raw_spin_lock_init(lock)				\
-	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #define raw_spin_is_locked(lock)	arch_spin_is_locked(&(lock)->raw_lock)
@@ -324,7 +324,7 @@ do {								\
 								\
 	__raw_spin_lock_init(spinlock_check(lock),		\
 			     #lock, &__key, LD_WAIT_CONFIG);	\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #else
@@ -333,7 +333,7 @@ do {								\
 do {						\
 	spinlock_check(_lock);			\
 	*(_lock) = __SPIN_LOCK_UNLOCKED(_lock);	\
-	__assume_ctx_lock(_lock);		\
+	__init_ctx_lock(_lock);			\
 } while (0)
 
 #endif
diff --git a/include/linux/spinlock_rt.h b/include/linux/spinlock_rt.h
index 0a585768358f..154d7290bd99 100644
--- a/include/linux/spinlock_rt.h
+++ b/include/linux/spinlock_rt.h
@@ -20,7 +20,7 @@ static inline void __rt_spin_lock_init(spinlock_t *lock, const char *name,
 do {								\
 	rt_mutex_base_init(&(slock)->lock);			\
 	__rt_spin_lock_init(slock, name, key, percpu);		\
-	__assume_ctx_lock(slock);				\
+	__init_ctx_lock(slock);					\
 } while (0)
 
 #define _spin_lock_init(slock, percpu)				\
diff --git a/include/linux/ww_mutex.h b/include/linux/ww_mutex.h
index 58e959ee10e9..ecb5564ee70d 100644
--- a/include/linux/ww_mutex.h
+++ b/include/linux/ww_mutex.h
@@ -107,7 +107,7 @@ context_lock_struct(ww_acquire_ctx) {
  */
 static inline void ww_mutex_init(struct ww_mutex *lock,
 				 struct ww_class *ww_class)
-	__assumes_ctx_lock(lock)
+	__inits_ctx_lock(lock)
 {
 	ww_mutex_base_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 	lock->ctx = NULL;
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 1c5a381461fc..2f733b5cc650 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -165,6 +165,9 @@ static void __used test_mutex_init(struct test_mutex_data *d)
 {
 	mutex_init(&d->mtx);
 	d->counter = 0;
+
+	mutex_lock(&d->mtx);
+	mutex_unlock(&d->mtx);
 }
 
 static void __used test_mutex_lock(struct test_mutex_data *d)
-- 
2.52.0.457.g6b5491de43-goog

================================================================================

From: Marco Elver <elver@google.com>
To: Unknown
Subject: [PATCH] compiler-context-analysis: Support immediate acquisition
 after initialization
Date: Sat, 10 Jan 2026 00:47:35 +0100
Message-ID: 
--------------------
When a lock is initialized (e.g. mutex_init()), we assume/assert that
the context lock is held to allow initialization of guarded members
within the same scope.

However, this previously prevented actually acquiring the lock within
that same scope, as the analyzer would report a double-lock warning:

  mutex_init(&mtx);
  ...
  mutex_lock(&mtx); // acquiring mutex 'mtx' that is already held

To fix (without new init+lock APIs), we can tell the analysis to treat
the "held" context lock resulting from initialization as reentrant,
allowing subsequent acquisitions to succeed.

To do so *only* within the initialization scope, we can cast the lock
pointer to any reentrant type for the init assume/assert. Introduce a
generic reentrant context lock type `struct __ctx_lock_init` and add
`__inits_ctx_lock()` that casts the lock pointer to this type before
assuming/asserting it.

This ensures that the initial "held" state is reentrant, allowing
patterns like:

  mutex_init(&lock);
  ...
  mutex_lock(&lock);

to compile without false positives, and avoids having to make all
context lock types reentrant outside an initialization scope.

The caveat here is missing real double-lock bugs right after init scope.
However, this is a classic trade-off of avoiding false positives against
(unlikely) false negatives.

Link: https://lore.kernel.org/all/57062131-e79e-42c2-aa0b-8f931cb8cac2@acm.org/
Reported-by: Bart Van Assche <bvanassche@acm.org>
Signed-off-by: Marco Elver <elver@google.com>
---
 include/linux/compiler-context-analysis.h | 12 ++++++++++++
 include/linux/local_lock_internal.h       |  6 +++---
 include/linux/mutex.h                     |  2 +-
 include/linux/rwlock.h                    |  4 ++--
 include/linux/rwlock_rt.h                 |  2 +-
 include/linux/rwsem.h                     |  4 ++--
 include/linux/seqlock.h                   |  2 +-
 include/linux/spinlock.h                  |  8 ++++----
 include/linux/spinlock_rt.h               |  2 +-
 include/linux/ww_mutex.h                  |  2 +-
 lib/test_context-analysis.c               |  3 +++
 11 files changed, 31 insertions(+), 16 deletions(-)

diff --git a/include/linux/compiler-context-analysis.h b/include/linux/compiler-context-analysis.h
index db7e0d48d8f2..e056cd6e8aaa 100644
--- a/include/linux/compiler-context-analysis.h
+++ b/include/linux/compiler-context-analysis.h
@@ -43,6 +43,14 @@
 # define __assumes_ctx_lock(...)		__attribute__((assert_capability(__VA_ARGS__)))
 # define __assumes_shared_ctx_lock(...)	__attribute__((assert_shared_capability(__VA_ARGS__)))
 
+/*
+ * Generic reentrant context lock type that we cast to when initializing context
+ * locks with __assumes_ctx_lock(), so that we can support guarded member
+ * initialization, but also immediate use after initialization.
+ */
+struct __ctx_lock_type(init_generic) __reentrant_ctx_lock __ctx_lock_init;
+# define __inits_ctx_lock(var) __assumes_ctx_lock((const struct __ctx_lock_init *)(var))
+
 /**
  * __guarded_by - struct member and globals attribute, declares variable
  *                only accessible within active context
@@ -120,6 +128,8 @@
 		__attribute__((overloadable)) __assumes_ctx_lock(var) { }				\
 	static __always_inline void __assume_shared_ctx_lock(const struct name *var)			\
 		__attribute__((overloadable)) __assumes_shared_ctx_lock(var) { }			\
+	static __always_inline void __init_ctx_lock(const struct name *var)				\
+		__attribute__((overloadable)) __inits_ctx_lock(var) { }					\
 	struct name
 
 /**
@@ -162,6 +172,7 @@
 # define __releases_shared_ctx_lock(...)
 # define __assumes_ctx_lock(...)
 # define __assumes_shared_ctx_lock(...)
+# define __inits_ctx_lock(var)
 # define __returns_ctx_lock(var)
 # define __guarded_by(...)
 # define __pt_guarded_by(...)
@@ -176,6 +187,7 @@
 # define __release_shared_ctx_lock(var)		do { } while (0)
 # define __assume_ctx_lock(var)			do { (void)(var); } while (0)
 # define __assume_shared_ctx_lock(var)			do { (void)(var); } while (0)
+# define __init_ctx_lock(var)			do { (void)(var); } while (0)
 # define context_lock_struct(name, ...)		struct __VA_ARGS__ name
 # define disable_context_analysis()
 # define enable_context_analysis()
diff --git a/include/linux/local_lock_internal.h b/include/linux/local_lock_internal.h
index e8c4803d8db4..36b8628d09fd 100644
--- a/include/linux/local_lock_internal.h
+++ b/include/linux/local_lock_internal.h
@@ -86,13 +86,13 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_PERCPU);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_trylock_init(lock)				\
 do {								\
 	__local_lock_init((local_lock_t *)lock);		\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __spinlock_nested_bh_init(lock)				\
@@ -104,7 +104,7 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_NORMAL);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_lock_acquire(lock)					\
diff --git a/include/linux/mutex.h b/include/linux/mutex.h
index 89977c215cbd..5d2ef75c4fdb 100644
--- a/include/linux/mutex.h
+++ b/include/linux/mutex.h
@@ -62,7 +62,7 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__mutex_init((mutex), #mutex, &__key);				\
-	__assume_ctx_lock(mutex);					\
+	__init_ctx_lock(mutex);						\
 } while (0)
 
 /**
diff --git a/include/linux/rwlock.h b/include/linux/rwlock.h
index 65a5b55e1bcd..7e171634d2c4 100644
--- a/include/linux/rwlock.h
+++ b/include/linux/rwlock.h
@@ -22,11 +22,11 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__rwlock_init((lock), #lock, &__key);			\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 #else
 # define rwlock_init(lock)					\
-	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #ifdef CONFIG_DEBUG_SPINLOCK
diff --git a/include/linux/rwlock_rt.h b/include/linux/rwlock_rt.h
index 37b387dcab21..1e087a6ce2cf 100644
--- a/include/linux/rwlock_rt.h
+++ b/include/linux/rwlock_rt.h
@@ -22,7 +22,7 @@ do {							\
 							\
 	init_rwbase_rt(&(rwl)->rwbase);			\
 	__rt_rwlock_init(rwl, #rwl, &__key);		\
-	__assume_ctx_lock(rwl);				\
+	__init_ctx_lock(rwl);				\
 } while (0)
 
 extern void rt_read_lock(rwlock_t *rwlock)	__acquires_shared(rwlock);
diff --git a/include/linux/rwsem.h b/include/linux/rwsem.h
index 8da14a08a4e1..6ea7d2a23580 100644
--- a/include/linux/rwsem.h
+++ b/include/linux/rwsem.h
@@ -121,7 +121,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 /*
@@ -175,7 +175,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 static __always_inline int rwsem_is_locked(const struct rw_semaphore *sem)
diff --git a/include/linux/seqlock.h b/include/linux/seqlock.h
index 113320911a09..a0670adb4b6e 100644
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@ -816,7 +816,7 @@ static __always_inline void write_seqcount_latch_end(seqcount_latch_t *s)
 	do {								\
 		spin_lock_init(&(sl)->lock);				\
 		seqcount_spinlock_init(&(sl)->seqcount, &(sl)->lock);	\
-		__assume_ctx_lock(sl);					\
+		__init_ctx_lock(sl);					\
 	} while (0)
 
 /**
diff --git a/include/linux/spinlock.h b/include/linux/spinlock.h
index 396b8c5d6c1b..e50372a5f7d1 100644
--- a/include/linux/spinlock.h
+++ b/include/linux/spinlock.h
@@ -106,12 +106,12 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__raw_spin_lock_init((lock), #lock, &__key, LD_WAIT_SPIN);	\
-	__assume_ctx_lock(lock);					\
+	__init_ctx_lock(lock);						\
 } while (0)
 
 #else
 # define raw_spin_lock_init(lock)				\
-	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #define raw_spin_is_locked(lock)	arch_spin_is_locked(&(lock)->raw_lock)
@@ -324,7 +324,7 @@ do {								\
 								\
 	__raw_spin_lock_init(spinlock_check(lock),		\
 			     #lock, &__key, LD_WAIT_CONFIG);	\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #else
@@ -333,7 +333,7 @@ do {								\
 do {						\
 	spinlock_check(_lock);			\
 	*(_lock) = __SPIN_LOCK_UNLOCKED(_lock);	\
-	__assume_ctx_lock(_lock);		\
+	__init_ctx_lock(_lock);			\
 } while (0)
 
 #endif
diff --git a/include/linux/spinlock_rt.h b/include/linux/spinlock_rt.h
index 0a585768358f..154d7290bd99 100644
--- a/include/linux/spinlock_rt.h
+++ b/include/linux/spinlock_rt.h
@@ -20,7 +20,7 @@ static inline void __rt_spin_lock_init(spinlock_t *lock, const char *name,
 do {								\
 	rt_mutex_base_init(&(slock)->lock);			\
 	__rt_spin_lock_init(slock, name, key, percpu);		\
-	__assume_ctx_lock(slock);				\
+	__init_ctx_lock(slock);					\
 } while (0)
 
 #define _spin_lock_init(slock, percpu)				\
diff --git a/include/linux/ww_mutex.h b/include/linux/ww_mutex.h
index 58e959ee10e9..ecb5564ee70d 100644
--- a/include/linux/ww_mutex.h
+++ b/include/linux/ww_mutex.h
@@ -107,7 +107,7 @@ context_lock_struct(ww_acquire_ctx) {
  */
 static inline void ww_mutex_init(struct ww_mutex *lock,
 				 struct ww_class *ww_class)
-	__assumes_ctx_lock(lock)
+	__inits_ctx_lock(lock)
 {
 	ww_mutex_base_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 	lock->ctx = NULL;
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 1c5a381461fc..2f733b5cc650 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -165,6 +165,9 @@ static void __used test_mutex_init(struct test_mutex_data *d)
 {
 	mutex_init(&d->mtx);
 	d->counter = 0;
+
+	mutex_lock(&d->mtx);
+	mutex_unlock(&d->mtx);
 }
 
 static void __used test_mutex_lock(struct test_mutex_data *d)
-- 
2.52.0.457.g6b5491de43-goog

================================================================================

From: Marco Elver <elver@google.com>
To: Unknown
Subject: [PATCH] compiler-context-analysis: Support immediate acquisition
 after initialization
Date: Sat, 10 Jan 2026 00:47:35 +0100
Message-ID: 
--------------------
When a lock is initialized (e.g. mutex_init()), we assume/assert that
the context lock is held to allow initialization of guarded members
within the same scope.

However, this previously prevented actually acquiring the lock within
that same scope, as the analyzer would report a double-lock warning:

  mutex_init(&mtx);
  ...
  mutex_lock(&mtx); // acquiring mutex 'mtx' that is already held

To fix (without new init+lock APIs), we can tell the analysis to treat
the "held" context lock resulting from initialization as reentrant,
allowing subsequent acquisitions to succeed.

To do so *only* within the initialization scope, we can cast the lock
pointer to any reentrant type for the init assume/assert. Introduce a
generic reentrant context lock type `struct __ctx_lock_init` and add
`__inits_ctx_lock()` that casts the lock pointer to this type before
assuming/asserting it.

This ensures that the initial "held" state is reentrant, allowing
patterns like:

  mutex_init(&lock);
  ...
  mutex_lock(&lock);

to compile without false positives, and avoids having to make all
context lock types reentrant outside an initialization scope.

The caveat here is missing real double-lock bugs right after init scope.
However, this is a classic trade-off of avoiding false positives against
(unlikely) false negatives.

Link: https://lore.kernel.org/all/57062131-e79e-42c2-aa0b-8f931cb8cac2@acm.org/
Reported-by: Bart Van Assche <bvanassche@acm.org>
Signed-off-by: Marco Elver <elver@google.com>
---
 include/linux/compiler-context-analysis.h | 12 ++++++++++++
 include/linux/local_lock_internal.h       |  6 +++---
 include/linux/mutex.h                     |  2 +-
 include/linux/rwlock.h                    |  4 ++--
 include/linux/rwlock_rt.h                 |  2 +-
 include/linux/rwsem.h                     |  4 ++--
 include/linux/seqlock.h                   |  2 +-
 include/linux/spinlock.h                  |  8 ++++----
 include/linux/spinlock_rt.h               |  2 +-
 include/linux/ww_mutex.h                  |  2 +-
 lib/test_context-analysis.c               |  3 +++
 11 files changed, 31 insertions(+), 16 deletions(-)

diff --git a/include/linux/compiler-context-analysis.h b/include/linux/compiler-context-analysis.h
index db7e0d48d8f2..e056cd6e8aaa 100644
--- a/include/linux/compiler-context-analysis.h
+++ b/include/linux/compiler-context-analysis.h
@@ -43,6 +43,14 @@
 # define __assumes_ctx_lock(...)		__attribute__((assert_capability(__VA_ARGS__)))
 # define __assumes_shared_ctx_lock(...)	__attribute__((assert_shared_capability(__VA_ARGS__)))
 
+/*
+ * Generic reentrant context lock type that we cast to when initializing context
+ * locks with __assumes_ctx_lock(), so that we can support guarded member
+ * initialization, but also immediate use after initialization.
+ */
+struct __ctx_lock_type(init_generic) __reentrant_ctx_lock __ctx_lock_init;
+# define __inits_ctx_lock(var) __assumes_ctx_lock((const struct __ctx_lock_init *)(var))
+
 /**
  * __guarded_by - struct member and globals attribute, declares variable
  *                only accessible within active context
@@ -120,6 +128,8 @@
 		__attribute__((overloadable)) __assumes_ctx_lock(var) { }				\
 	static __always_inline void __assume_shared_ctx_lock(const struct name *var)			\
 		__attribute__((overloadable)) __assumes_shared_ctx_lock(var) { }			\
+	static __always_inline void __init_ctx_lock(const struct name *var)				\
+		__attribute__((overloadable)) __inits_ctx_lock(var) { }					\
 	struct name
 
 /**
@@ -162,6 +172,7 @@
 # define __releases_shared_ctx_lock(...)
 # define __assumes_ctx_lock(...)
 # define __assumes_shared_ctx_lock(...)
+# define __inits_ctx_lock(var)
 # define __returns_ctx_lock(var)
 # define __guarded_by(...)
 # define __pt_guarded_by(...)
@@ -176,6 +187,7 @@
 # define __release_shared_ctx_lock(var)		do { } while (0)
 # define __assume_ctx_lock(var)			do { (void)(var); } while (0)
 # define __assume_shared_ctx_lock(var)			do { (void)(var); } while (0)
+# define __init_ctx_lock(var)			do { (void)(var); } while (0)
 # define context_lock_struct(name, ...)		struct __VA_ARGS__ name
 # define disable_context_analysis()
 # define enable_context_analysis()
diff --git a/include/linux/local_lock_internal.h b/include/linux/local_lock_internal.h
index e8c4803d8db4..36b8628d09fd 100644
--- a/include/linux/local_lock_internal.h
+++ b/include/linux/local_lock_internal.h
@@ -86,13 +86,13 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_PERCPU);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_trylock_init(lock)				\
 do {								\
 	__local_lock_init((local_lock_t *)lock);		\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __spinlock_nested_bh_init(lock)				\
@@ -104,7 +104,7 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_NORMAL);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_lock_acquire(lock)					\
diff --git a/include/linux/mutex.h b/include/linux/mutex.h
index 89977c215cbd..5d2ef75c4fdb 100644
--- a/include/linux/mutex.h
+++ b/include/linux/mutex.h
@@ -62,7 +62,7 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__mutex_init((mutex), #mutex, &__key);				\
-	__assume_ctx_lock(mutex);					\
+	__init_ctx_lock(mutex);						\
 } while (0)
 
 /**
diff --git a/include/linux/rwlock.h b/include/linux/rwlock.h
index 65a5b55e1bcd..7e171634d2c4 100644
--- a/include/linux/rwlock.h
+++ b/include/linux/rwlock.h
@@ -22,11 +22,11 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__rwlock_init((lock), #lock, &__key);			\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 #else
 # define rwlock_init(lock)					\
-	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #ifdef CONFIG_DEBUG_SPINLOCK
diff --git a/include/linux/rwlock_rt.h b/include/linux/rwlock_rt.h
index 37b387dcab21..1e087a6ce2cf 100644
--- a/include/linux/rwlock_rt.h
+++ b/include/linux/rwlock_rt.h
@@ -22,7 +22,7 @@ do {							\
 							\
 	init_rwbase_rt(&(rwl)->rwbase);			\
 	__rt_rwlock_init(rwl, #rwl, &__key);		\
-	__assume_ctx_lock(rwl);				\
+	__init_ctx_lock(rwl);				\
 } while (0)
 
 extern void rt_read_lock(rwlock_t *rwlock)	__acquires_shared(rwlock);
diff --git a/include/linux/rwsem.h b/include/linux/rwsem.h
index 8da14a08a4e1..6ea7d2a23580 100644
--- a/include/linux/rwsem.h
+++ b/include/linux/rwsem.h
@@ -121,7 +121,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 /*
@@ -175,7 +175,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 static __always_inline int rwsem_is_locked(const struct rw_semaphore *sem)
diff --git a/include/linux/seqlock.h b/include/linux/seqlock.h
index 113320911a09..a0670adb4b6e 100644
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@ -816,7 +816,7 @@ static __always_inline void write_seqcount_latch_end(seqcount_latch_t *s)
 	do {								\
 		spin_lock_init(&(sl)->lock);				\
 		seqcount_spinlock_init(&(sl)->seqcount, &(sl)->lock);	\
-		__assume_ctx_lock(sl);					\
+		__init_ctx_lock(sl);					\
 	} while (0)
 
 /**
diff --git a/include/linux/spinlock.h b/include/linux/spinlock.h
index 396b8c5d6c1b..e50372a5f7d1 100644
--- a/include/linux/spinlock.h
+++ b/include/linux/spinlock.h
@@ -106,12 +106,12 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__raw_spin_lock_init((lock), #lock, &__key, LD_WAIT_SPIN);	\
-	__assume_ctx_lock(lock);					\
+	__init_ctx_lock(lock);						\
 } while (0)
 
 #else
 # define raw_spin_lock_init(lock)				\
-	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #define raw_spin_is_locked(lock)	arch_spin_is_locked(&(lock)->raw_lock)
@@ -324,7 +324,7 @@ do {								\
 								\
 	__raw_spin_lock_init(spinlock_check(lock),		\
 			     #lock, &__key, LD_WAIT_CONFIG);	\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #else
@@ -333,7 +333,7 @@ do {								\
 do {						\
 	spinlock_check(_lock);			\
 	*(_lock) = __SPIN_LOCK_UNLOCKED(_lock);	\
-	__assume_ctx_lock(_lock);		\
+	__init_ctx_lock(_lock);			\
 } while (0)
 
 #endif
diff --git a/include/linux/spinlock_rt.h b/include/linux/spinlock_rt.h
index 0a585768358f..154d7290bd99 100644
--- a/include/linux/spinlock_rt.h
+++ b/include/linux/spinlock_rt.h
@@ -20,7 +20,7 @@ static inline void __rt_spin_lock_init(spinlock_t *lock, const char *name,
 do {								\
 	rt_mutex_base_init(&(slock)->lock);			\
 	__rt_spin_lock_init(slock, name, key, percpu);		\
-	__assume_ctx_lock(slock);				\
+	__init_ctx_lock(slock);					\
 } while (0)
 
 #define _spin_lock_init(slock, percpu)				\
diff --git a/include/linux/ww_mutex.h b/include/linux/ww_mutex.h
index 58e959ee10e9..ecb5564ee70d 100644
--- a/include/linux/ww_mutex.h
+++ b/include/linux/ww_mutex.h
@@ -107,7 +107,7 @@ context_lock_struct(ww_acquire_ctx) {
  */
 static inline void ww_mutex_init(struct ww_mutex *lock,
 				 struct ww_class *ww_class)
-	__assumes_ctx_lock(lock)
+	__inits_ctx_lock(lock)
 {
 	ww_mutex_base_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 	lock->ctx = NULL;
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 1c5a381461fc..2f733b5cc650 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -165,6 +165,9 @@ static void __used test_mutex_init(struct test_mutex_data *d)
 {
 	mutex_init(&d->mtx);
 	d->counter = 0;
+
+	mutex_lock(&d->mtx);
+	mutex_unlock(&d->mtx);
 }
 
 static void __used test_mutex_lock(struct test_mutex_data *d)
-- 
2.52.0.457.g6b5491de43-goog

================================================================================

From: Marco Elver <elver@google.com>
To: Unknown
Subject: [PATCH] compiler-context-analysis: Support immediate acquisition
 after initialization
Date: Sat, 10 Jan 2026 00:47:35 +0100
Message-ID: 
--------------------
When a lock is initialized (e.g. mutex_init()), we assume/assert that
the context lock is held to allow initialization of guarded members
within the same scope.

However, this previously prevented actually acquiring the lock within
that same scope, as the analyzer would report a double-lock warning:

  mutex_init(&mtx);
  ...
  mutex_lock(&mtx); // acquiring mutex 'mtx' that is already held

To fix (without new init+lock APIs), we can tell the analysis to treat
the "held" context lock resulting from initialization as reentrant,
allowing subsequent acquisitions to succeed.

To do so *only* within the initialization scope, we can cast the lock
pointer to any reentrant type for the init assume/assert. Introduce a
generic reentrant context lock type `struct __ctx_lock_init` and add
`__inits_ctx_lock()` that casts the lock pointer to this type before
assuming/asserting it.

This ensures that the initial "held" state is reentrant, allowing
patterns like:

  mutex_init(&lock);
  ...
  mutex_lock(&lock);

to compile without false positives, and avoids having to make all
context lock types reentrant outside an initialization scope.

The caveat here is missing real double-lock bugs right after init scope.
However, this is a classic trade-off of avoiding false positives against
(unlikely) false negatives.

Link: https://lore.kernel.org/all/57062131-e79e-42c2-aa0b-8f931cb8cac2@acm.org/
Reported-by: Bart Van Assche <bvanassche@acm.org>
Signed-off-by: Marco Elver <elver@google.com>
---
 include/linux/compiler-context-analysis.h | 12 ++++++++++++
 include/linux/local_lock_internal.h       |  6 +++---
 include/linux/mutex.h                     |  2 +-
 include/linux/rwlock.h                    |  4 ++--
 include/linux/rwlock_rt.h                 |  2 +-
 include/linux/rwsem.h                     |  4 ++--
 include/linux/seqlock.h                   |  2 +-
 include/linux/spinlock.h                  |  8 ++++----
 include/linux/spinlock_rt.h               |  2 +-
 include/linux/ww_mutex.h                  |  2 +-
 lib/test_context-analysis.c               |  3 +++
 11 files changed, 31 insertions(+), 16 deletions(-)

diff --git a/include/linux/compiler-context-analysis.h b/include/linux/compiler-context-analysis.h
index db7e0d48d8f2..e056cd6e8aaa 100644
--- a/include/linux/compiler-context-analysis.h
+++ b/include/linux/compiler-context-analysis.h
@@ -43,6 +43,14 @@
 # define __assumes_ctx_lock(...)		__attribute__((assert_capability(__VA_ARGS__)))
 # define __assumes_shared_ctx_lock(...)	__attribute__((assert_shared_capability(__VA_ARGS__)))
 
+/*
+ * Generic reentrant context lock type that we cast to when initializing context
+ * locks with __assumes_ctx_lock(), so that we can support guarded member
+ * initialization, but also immediate use after initialization.
+ */
+struct __ctx_lock_type(init_generic) __reentrant_ctx_lock __ctx_lock_init;
+# define __inits_ctx_lock(var) __assumes_ctx_lock((const struct __ctx_lock_init *)(var))
+
 /**
  * __guarded_by - struct member and globals attribute, declares variable
  *                only accessible within active context
@@ -120,6 +128,8 @@
 		__attribute__((overloadable)) __assumes_ctx_lock(var) { }				\
 	static __always_inline void __assume_shared_ctx_lock(const struct name *var)			\
 		__attribute__((overloadable)) __assumes_shared_ctx_lock(var) { }			\
+	static __always_inline void __init_ctx_lock(const struct name *var)				\
+		__attribute__((overloadable)) __inits_ctx_lock(var) { }					\
 	struct name
 
 /**
@@ -162,6 +172,7 @@
 # define __releases_shared_ctx_lock(...)
 # define __assumes_ctx_lock(...)
 # define __assumes_shared_ctx_lock(...)
+# define __inits_ctx_lock(var)
 # define __returns_ctx_lock(var)
 # define __guarded_by(...)
 # define __pt_guarded_by(...)
@@ -176,6 +187,7 @@
 # define __release_shared_ctx_lock(var)		do { } while (0)
 # define __assume_ctx_lock(var)			do { (void)(var); } while (0)
 # define __assume_shared_ctx_lock(var)			do { (void)(var); } while (0)
+# define __init_ctx_lock(var)			do { (void)(var); } while (0)
 # define context_lock_struct(name, ...)		struct __VA_ARGS__ name
 # define disable_context_analysis()
 # define enable_context_analysis()
diff --git a/include/linux/local_lock_internal.h b/include/linux/local_lock_internal.h
index e8c4803d8db4..36b8628d09fd 100644
--- a/include/linux/local_lock_internal.h
+++ b/include/linux/local_lock_internal.h
@@ -86,13 +86,13 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_PERCPU);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_trylock_init(lock)				\
 do {								\
 	__local_lock_init((local_lock_t *)lock);		\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __spinlock_nested_bh_init(lock)				\
@@ -104,7 +104,7 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_NORMAL);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_lock_acquire(lock)					\
diff --git a/include/linux/mutex.h b/include/linux/mutex.h
index 89977c215cbd..5d2ef75c4fdb 100644
--- a/include/linux/mutex.h
+++ b/include/linux/mutex.h
@@ -62,7 +62,7 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__mutex_init((mutex), #mutex, &__key);				\
-	__assume_ctx_lock(mutex);					\
+	__init_ctx_lock(mutex);						\
 } while (0)
 
 /**
diff --git a/include/linux/rwlock.h b/include/linux/rwlock.h
index 65a5b55e1bcd..7e171634d2c4 100644
--- a/include/linux/rwlock.h
+++ b/include/linux/rwlock.h
@@ -22,11 +22,11 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__rwlock_init((lock), #lock, &__key);			\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 #else
 # define rwlock_init(lock)					\
-	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #ifdef CONFIG_DEBUG_SPINLOCK
diff --git a/include/linux/rwlock_rt.h b/include/linux/rwlock_rt.h
index 37b387dcab21..1e087a6ce2cf 100644
--- a/include/linux/rwlock_rt.h
+++ b/include/linux/rwlock_rt.h
@@ -22,7 +22,7 @@ do {							\
 							\
 	init_rwbase_rt(&(rwl)->rwbase);			\
 	__rt_rwlock_init(rwl, #rwl, &__key);		\
-	__assume_ctx_lock(rwl);				\
+	__init_ctx_lock(rwl);				\
 } while (0)
 
 extern void rt_read_lock(rwlock_t *rwlock)	__acquires_shared(rwlock);
diff --git a/include/linux/rwsem.h b/include/linux/rwsem.h
index 8da14a08a4e1..6ea7d2a23580 100644
--- a/include/linux/rwsem.h
+++ b/include/linux/rwsem.h
@@ -121,7 +121,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 /*
@@ -175,7 +175,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 static __always_inline int rwsem_is_locked(const struct rw_semaphore *sem)
diff --git a/include/linux/seqlock.h b/include/linux/seqlock.h
index 113320911a09..a0670adb4b6e 100644
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@ -816,7 +816,7 @@ static __always_inline void write_seqcount_latch_end(seqcount_latch_t *s)
 	do {								\
 		spin_lock_init(&(sl)->lock);				\
 		seqcount_spinlock_init(&(sl)->seqcount, &(sl)->lock);	\
-		__assume_ctx_lock(sl);					\
+		__init_ctx_lock(sl);					\
 	} while (0)
 
 /**
diff --git a/include/linux/spinlock.h b/include/linux/spinlock.h
index 396b8c5d6c1b..e50372a5f7d1 100644
--- a/include/linux/spinlock.h
+++ b/include/linux/spinlock.h
@@ -106,12 +106,12 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__raw_spin_lock_init((lock), #lock, &__key, LD_WAIT_SPIN);	\
-	__assume_ctx_lock(lock);					\
+	__init_ctx_lock(lock);						\
 } while (0)
 
 #else
 # define raw_spin_lock_init(lock)				\
-	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #define raw_spin_is_locked(lock)	arch_spin_is_locked(&(lock)->raw_lock)
@@ -324,7 +324,7 @@ do {								\
 								\
 	__raw_spin_lock_init(spinlock_check(lock),		\
 			     #lock, &__key, LD_WAIT_CONFIG);	\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #else
@@ -333,7 +333,7 @@ do {								\
 do {						\
 	spinlock_check(_lock);			\
 	*(_lock) = __SPIN_LOCK_UNLOCKED(_lock);	\
-	__assume_ctx_lock(_lock);		\
+	__init_ctx_lock(_lock);			\
 } while (0)
 
 #endif
diff --git a/include/linux/spinlock_rt.h b/include/linux/spinlock_rt.h
index 0a585768358f..154d7290bd99 100644
--- a/include/linux/spinlock_rt.h
+++ b/include/linux/spinlock_rt.h
@@ -20,7 +20,7 @@ static inline void __rt_spin_lock_init(spinlock_t *lock, const char *name,
 do {								\
 	rt_mutex_base_init(&(slock)->lock);			\
 	__rt_spin_lock_init(slock, name, key, percpu);		\
-	__assume_ctx_lock(slock);				\
+	__init_ctx_lock(slock);					\
 } while (0)
 
 #define _spin_lock_init(slock, percpu)				\
diff --git a/include/linux/ww_mutex.h b/include/linux/ww_mutex.h
index 58e959ee10e9..ecb5564ee70d 100644
--- a/include/linux/ww_mutex.h
+++ b/include/linux/ww_mutex.h
@@ -107,7 +107,7 @@ context_lock_struct(ww_acquire_ctx) {
  */
 static inline void ww_mutex_init(struct ww_mutex *lock,
 				 struct ww_class *ww_class)
-	__assumes_ctx_lock(lock)
+	__inits_ctx_lock(lock)
 {
 	ww_mutex_base_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 	lock->ctx = NULL;
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 1c5a381461fc..2f733b5cc650 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -165,6 +165,9 @@ static void __used test_mutex_init(struct test_mutex_data *d)
 {
 	mutex_init(&d->mtx);
 	d->counter = 0;
+
+	mutex_lock(&d->mtx);
+	mutex_unlock(&d->mtx);
 }
 
 static void __used test_mutex_lock(struct test_mutex_data *d)
-- 
2.52.0.457.g6b5491de43-goog

================================================================================

From: Marco Elver <elver@google.com>
To: Unknown
Subject: [PATCH] compiler-context-analysis: Support immediate acquisition
 after initialization
Date: Sat, 10 Jan 2026 00:47:35 +0100
Message-ID: 
--------------------
When a lock is initialized (e.g. mutex_init()), we assume/assert that
the context lock is held to allow initialization of guarded members
within the same scope.

However, this previously prevented actually acquiring the lock within
that same scope, as the analyzer would report a double-lock warning:

  mutex_init(&mtx);
  ...
  mutex_lock(&mtx); // acquiring mutex 'mtx' that is already held

To fix (without new init+lock APIs), we can tell the analysis to treat
the "held" context lock resulting from initialization as reentrant,
allowing subsequent acquisitions to succeed.

To do so *only* within the initialization scope, we can cast the lock
pointer to any reentrant type for the init assume/assert. Introduce a
generic reentrant context lock type `struct __ctx_lock_init` and add
`__inits_ctx_lock()` that casts the lock pointer to this type before
assuming/asserting it.

This ensures that the initial "held" state is reentrant, allowing
patterns like:

  mutex_init(&lock);
  ...
  mutex_lock(&lock);

to compile without false positives, and avoids having to make all
context lock types reentrant outside an initialization scope.

The caveat here is missing real double-lock bugs right after init scope.
However, this is a classic trade-off of avoiding false positives against
(unlikely) false negatives.

Link: https://lore.kernel.org/all/57062131-e79e-42c2-aa0b-8f931cb8cac2@acm.org/
Reported-by: Bart Van Assche <bvanassche@acm.org>
Signed-off-by: Marco Elver <elver@google.com>
---
 include/linux/compiler-context-analysis.h | 12 ++++++++++++
 include/linux/local_lock_internal.h       |  6 +++---
 include/linux/mutex.h                     |  2 +-
 include/linux/rwlock.h                    |  4 ++--
 include/linux/rwlock_rt.h                 |  2 +-
 include/linux/rwsem.h                     |  4 ++--
 include/linux/seqlock.h                   |  2 +-
 include/linux/spinlock.h                  |  8 ++++----
 include/linux/spinlock_rt.h               |  2 +-
 include/linux/ww_mutex.h                  |  2 +-
 lib/test_context-analysis.c               |  3 +++
 11 files changed, 31 insertions(+), 16 deletions(-)

diff --git a/include/linux/compiler-context-analysis.h b/include/linux/compiler-context-analysis.h
index db7e0d48d8f2..e056cd6e8aaa 100644
--- a/include/linux/compiler-context-analysis.h
+++ b/include/linux/compiler-context-analysis.h
@@ -43,6 +43,14 @@
 # define __assumes_ctx_lock(...)		__attribute__((assert_capability(__VA_ARGS__)))
 # define __assumes_shared_ctx_lock(...)	__attribute__((assert_shared_capability(__VA_ARGS__)))
 
+/*
+ * Generic reentrant context lock type that we cast to when initializing context
+ * locks with __assumes_ctx_lock(), so that we can support guarded member
+ * initialization, but also immediate use after initialization.
+ */
+struct __ctx_lock_type(init_generic) __reentrant_ctx_lock __ctx_lock_init;
+# define __inits_ctx_lock(var) __assumes_ctx_lock((const struct __ctx_lock_init *)(var))
+
 /**
  * __guarded_by - struct member and globals attribute, declares variable
  *                only accessible within active context
@@ -120,6 +128,8 @@
 		__attribute__((overloadable)) __assumes_ctx_lock(var) { }				\
 	static __always_inline void __assume_shared_ctx_lock(const struct name *var)			\
 		__attribute__((overloadable)) __assumes_shared_ctx_lock(var) { }			\
+	static __always_inline void __init_ctx_lock(const struct name *var)				\
+		__attribute__((overloadable)) __inits_ctx_lock(var) { }					\
 	struct name
 
 /**
@@ -162,6 +172,7 @@
 # define __releases_shared_ctx_lock(...)
 # define __assumes_ctx_lock(...)
 # define __assumes_shared_ctx_lock(...)
+# define __inits_ctx_lock(var)
 # define __returns_ctx_lock(var)
 # define __guarded_by(...)
 # define __pt_guarded_by(...)
@@ -176,6 +187,7 @@
 # define __release_shared_ctx_lock(var)		do { } while (0)
 # define __assume_ctx_lock(var)			do { (void)(var); } while (0)
 # define __assume_shared_ctx_lock(var)			do { (void)(var); } while (0)
+# define __init_ctx_lock(var)			do { (void)(var); } while (0)
 # define context_lock_struct(name, ...)		struct __VA_ARGS__ name
 # define disable_context_analysis()
 # define enable_context_analysis()
diff --git a/include/linux/local_lock_internal.h b/include/linux/local_lock_internal.h
index e8c4803d8db4..36b8628d09fd 100644
--- a/include/linux/local_lock_internal.h
+++ b/include/linux/local_lock_internal.h
@@ -86,13 +86,13 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_PERCPU);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_trylock_init(lock)				\
 do {								\
 	__local_lock_init((local_lock_t *)lock);		\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __spinlock_nested_bh_init(lock)				\
@@ -104,7 +104,7 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_NORMAL);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_lock_acquire(lock)					\
diff --git a/include/linux/mutex.h b/include/linux/mutex.h
index 89977c215cbd..5d2ef75c4fdb 100644
--- a/include/linux/mutex.h
+++ b/include/linux/mutex.h
@@ -62,7 +62,7 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__mutex_init((mutex), #mutex, &__key);				\
-	__assume_ctx_lock(mutex);					\
+	__init_ctx_lock(mutex);						\
 } while (0)
 
 /**
diff --git a/include/linux/rwlock.h b/include/linux/rwlock.h
index 65a5b55e1bcd..7e171634d2c4 100644
--- a/include/linux/rwlock.h
+++ b/include/linux/rwlock.h
@@ -22,11 +22,11 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__rwlock_init((lock), #lock, &__key);			\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 #else
 # define rwlock_init(lock)					\
-	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #ifdef CONFIG_DEBUG_SPINLOCK
diff --git a/include/linux/rwlock_rt.h b/include/linux/rwlock_rt.h
index 37b387dcab21..1e087a6ce2cf 100644
--- a/include/linux/rwlock_rt.h
+++ b/include/linux/rwlock_rt.h
@@ -22,7 +22,7 @@ do {							\
 							\
 	init_rwbase_rt(&(rwl)->rwbase);			\
 	__rt_rwlock_init(rwl, #rwl, &__key);		\
-	__assume_ctx_lock(rwl);				\
+	__init_ctx_lock(rwl);				\
 } while (0)
 
 extern void rt_read_lock(rwlock_t *rwlock)	__acquires_shared(rwlock);
diff --git a/include/linux/rwsem.h b/include/linux/rwsem.h
index 8da14a08a4e1..6ea7d2a23580 100644
--- a/include/linux/rwsem.h
+++ b/include/linux/rwsem.h
@@ -121,7 +121,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 /*
@@ -175,7 +175,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 static __always_inline int rwsem_is_locked(const struct rw_semaphore *sem)
diff --git a/include/linux/seqlock.h b/include/linux/seqlock.h
index 113320911a09..a0670adb4b6e 100644
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@ -816,7 +816,7 @@ static __always_inline void write_seqcount_latch_end(seqcount_latch_t *s)
 	do {								\
 		spin_lock_init(&(sl)->lock);				\
 		seqcount_spinlock_init(&(sl)->seqcount, &(sl)->lock);	\
-		__assume_ctx_lock(sl);					\
+		__init_ctx_lock(sl);					\
 	} while (0)
 
 /**
diff --git a/include/linux/spinlock.h b/include/linux/spinlock.h
index 396b8c5d6c1b..e50372a5f7d1 100644
--- a/include/linux/spinlock.h
+++ b/include/linux/spinlock.h
@@ -106,12 +106,12 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__raw_spin_lock_init((lock), #lock, &__key, LD_WAIT_SPIN);	\
-	__assume_ctx_lock(lock);					\
+	__init_ctx_lock(lock);						\
 } while (0)
 
 #else
 # define raw_spin_lock_init(lock)				\
-	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #define raw_spin_is_locked(lock)	arch_spin_is_locked(&(lock)->raw_lock)
@@ -324,7 +324,7 @@ do {								\
 								\
 	__raw_spin_lock_init(spinlock_check(lock),		\
 			     #lock, &__key, LD_WAIT_CONFIG);	\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #else
@@ -333,7 +333,7 @@ do {								\
 do {						\
 	spinlock_check(_lock);			\
 	*(_lock) = __SPIN_LOCK_UNLOCKED(_lock);	\
-	__assume_ctx_lock(_lock);		\
+	__init_ctx_lock(_lock);			\
 } while (0)
 
 #endif
diff --git a/include/linux/spinlock_rt.h b/include/linux/spinlock_rt.h
index 0a585768358f..154d7290bd99 100644
--- a/include/linux/spinlock_rt.h
+++ b/include/linux/spinlock_rt.h
@@ -20,7 +20,7 @@ static inline void __rt_spin_lock_init(spinlock_t *lock, const char *name,
 do {								\
 	rt_mutex_base_init(&(slock)->lock);			\
 	__rt_spin_lock_init(slock, name, key, percpu);		\
-	__assume_ctx_lock(slock);				\
+	__init_ctx_lock(slock);					\
 } while (0)
 
 #define _spin_lock_init(slock, percpu)				\
diff --git a/include/linux/ww_mutex.h b/include/linux/ww_mutex.h
index 58e959ee10e9..ecb5564ee70d 100644
--- a/include/linux/ww_mutex.h
+++ b/include/linux/ww_mutex.h
@@ -107,7 +107,7 @@ context_lock_struct(ww_acquire_ctx) {
  */
 static inline void ww_mutex_init(struct ww_mutex *lock,
 				 struct ww_class *ww_class)
-	__assumes_ctx_lock(lock)
+	__inits_ctx_lock(lock)
 {
 	ww_mutex_base_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 	lock->ctx = NULL;
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 1c5a381461fc..2f733b5cc650 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -165,6 +165,9 @@ static void __used test_mutex_init(struct test_mutex_data *d)
 {
 	mutex_init(&d->mtx);
 	d->counter = 0;
+
+	mutex_lock(&d->mtx);
+	mutex_unlock(&d->mtx);
 }
 
 static void __used test_mutex_lock(struct test_mutex_data *d)
-- 
2.52.0.457.g6b5491de43-goog

================================================================================

From: Marco Elver <elver@google.com>
To: Unknown
Subject: [PATCH] compiler-context-analysis: Support immediate acquisition
 after initialization
Date: Sat, 10 Jan 2026 00:47:35 +0100
Message-ID: 
--------------------
When a lock is initialized (e.g. mutex_init()), we assume/assert that
the context lock is held to allow initialization of guarded members
within the same scope.

However, this previously prevented actually acquiring the lock within
that same scope, as the analyzer would report a double-lock warning:

  mutex_init(&mtx);
  ...
  mutex_lock(&mtx); // acquiring mutex 'mtx' that is already held

To fix (without new init+lock APIs), we can tell the analysis to treat
the "held" context lock resulting from initialization as reentrant,
allowing subsequent acquisitions to succeed.

To do so *only* within the initialization scope, we can cast the lock
pointer to any reentrant type for the init assume/assert. Introduce a
generic reentrant context lock type `struct __ctx_lock_init` and add
`__inits_ctx_lock()` that casts the lock pointer to this type before
assuming/asserting it.

This ensures that the initial "held" state is reentrant, allowing
patterns like:

  mutex_init(&lock);
  ...
  mutex_lock(&lock);

to compile without false positives, and avoids having to make all
context lock types reentrant outside an initialization scope.

The caveat here is missing real double-lock bugs right after init scope.
However, this is a classic trade-off of avoiding false positives against
(unlikely) false negatives.

Link: https://lore.kernel.org/all/57062131-e79e-42c2-aa0b-8f931cb8cac2@acm.org/
Reported-by: Bart Van Assche <bvanassche@acm.org>
Signed-off-by: Marco Elver <elver@google.com>
---
 include/linux/compiler-context-analysis.h | 12 ++++++++++++
 include/linux/local_lock_internal.h       |  6 +++---
 include/linux/mutex.h                     |  2 +-
 include/linux/rwlock.h                    |  4 ++--
 include/linux/rwlock_rt.h                 |  2 +-
 include/linux/rwsem.h                     |  4 ++--
 include/linux/seqlock.h                   |  2 +-
 include/linux/spinlock.h                  |  8 ++++----
 include/linux/spinlock_rt.h               |  2 +-
 include/linux/ww_mutex.h                  |  2 +-
 lib/test_context-analysis.c               |  3 +++
 11 files changed, 31 insertions(+), 16 deletions(-)

diff --git a/include/linux/compiler-context-analysis.h b/include/linux/compiler-context-analysis.h
index db7e0d48d8f2..e056cd6e8aaa 100644
--- a/include/linux/compiler-context-analysis.h
+++ b/include/linux/compiler-context-analysis.h
@@ -43,6 +43,14 @@
 # define __assumes_ctx_lock(...)		__attribute__((assert_capability(__VA_ARGS__)))
 # define __assumes_shared_ctx_lock(...)	__attribute__((assert_shared_capability(__VA_ARGS__)))
 
+/*
+ * Generic reentrant context lock type that we cast to when initializing context
+ * locks with __assumes_ctx_lock(), so that we can support guarded member
+ * initialization, but also immediate use after initialization.
+ */
+struct __ctx_lock_type(init_generic) __reentrant_ctx_lock __ctx_lock_init;
+# define __inits_ctx_lock(var) __assumes_ctx_lock((const struct __ctx_lock_init *)(var))
+
 /**
  * __guarded_by - struct member and globals attribute, declares variable
  *                only accessible within active context
@@ -120,6 +128,8 @@
 		__attribute__((overloadable)) __assumes_ctx_lock(var) { }				\
 	static __always_inline void __assume_shared_ctx_lock(const struct name *var)			\
 		__attribute__((overloadable)) __assumes_shared_ctx_lock(var) { }			\
+	static __always_inline void __init_ctx_lock(const struct name *var)				\
+		__attribute__((overloadable)) __inits_ctx_lock(var) { }					\
 	struct name
 
 /**
@@ -162,6 +172,7 @@
 # define __releases_shared_ctx_lock(...)
 # define __assumes_ctx_lock(...)
 # define __assumes_shared_ctx_lock(...)
+# define __inits_ctx_lock(var)
 # define __returns_ctx_lock(var)
 # define __guarded_by(...)
 # define __pt_guarded_by(...)
@@ -176,6 +187,7 @@
 # define __release_shared_ctx_lock(var)		do { } while (0)
 # define __assume_ctx_lock(var)			do { (void)(var); } while (0)
 # define __assume_shared_ctx_lock(var)			do { (void)(var); } while (0)
+# define __init_ctx_lock(var)			do { (void)(var); } while (0)
 # define context_lock_struct(name, ...)		struct __VA_ARGS__ name
 # define disable_context_analysis()
 # define enable_context_analysis()
diff --git a/include/linux/local_lock_internal.h b/include/linux/local_lock_internal.h
index e8c4803d8db4..36b8628d09fd 100644
--- a/include/linux/local_lock_internal.h
+++ b/include/linux/local_lock_internal.h
@@ -86,13 +86,13 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_PERCPU);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_trylock_init(lock)				\
 do {								\
 	__local_lock_init((local_lock_t *)lock);		\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __spinlock_nested_bh_init(lock)				\
@@ -104,7 +104,7 @@ do {								\
 			      0, LD_WAIT_CONFIG, LD_WAIT_INV,	\
 			      LD_LOCK_NORMAL);			\
 	local_lock_debug_init(lock);				\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #define __local_lock_acquire(lock)					\
diff --git a/include/linux/mutex.h b/include/linux/mutex.h
index 89977c215cbd..5d2ef75c4fdb 100644
--- a/include/linux/mutex.h
+++ b/include/linux/mutex.h
@@ -62,7 +62,7 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__mutex_init((mutex), #mutex, &__key);				\
-	__assume_ctx_lock(mutex);					\
+	__init_ctx_lock(mutex);						\
 } while (0)
 
 /**
diff --git a/include/linux/rwlock.h b/include/linux/rwlock.h
index 65a5b55e1bcd..7e171634d2c4 100644
--- a/include/linux/rwlock.h
+++ b/include/linux/rwlock.h
@@ -22,11 +22,11 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__rwlock_init((lock), #lock, &__key);			\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 #else
 # define rwlock_init(lock)					\
-	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RW_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #ifdef CONFIG_DEBUG_SPINLOCK
diff --git a/include/linux/rwlock_rt.h b/include/linux/rwlock_rt.h
index 37b387dcab21..1e087a6ce2cf 100644
--- a/include/linux/rwlock_rt.h
+++ b/include/linux/rwlock_rt.h
@@ -22,7 +22,7 @@ do {							\
 							\
 	init_rwbase_rt(&(rwl)->rwbase);			\
 	__rt_rwlock_init(rwl, #rwl, &__key);		\
-	__assume_ctx_lock(rwl);				\
+	__init_ctx_lock(rwl);				\
 } while (0)
 
 extern void rt_read_lock(rwlock_t *rwlock)	__acquires_shared(rwlock);
diff --git a/include/linux/rwsem.h b/include/linux/rwsem.h
index 8da14a08a4e1..6ea7d2a23580 100644
--- a/include/linux/rwsem.h
+++ b/include/linux/rwsem.h
@@ -121,7 +121,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 /*
@@ -175,7 +175,7 @@ do {								\
 	static struct lock_class_key __key;			\
 								\
 	__init_rwsem((sem), #sem, &__key);			\
-	__assume_ctx_lock(sem);					\
+	__init_ctx_lock(sem);					\
 } while (0)
 
 static __always_inline int rwsem_is_locked(const struct rw_semaphore *sem)
diff --git a/include/linux/seqlock.h b/include/linux/seqlock.h
index 113320911a09..a0670adb4b6e 100644
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@ -816,7 +816,7 @@ static __always_inline void write_seqcount_latch_end(seqcount_latch_t *s)
 	do {								\
 		spin_lock_init(&(sl)->lock);				\
 		seqcount_spinlock_init(&(sl)->seqcount, &(sl)->lock);	\
-		__assume_ctx_lock(sl);					\
+		__init_ctx_lock(sl);					\
 	} while (0)
 
 /**
diff --git a/include/linux/spinlock.h b/include/linux/spinlock.h
index 396b8c5d6c1b..e50372a5f7d1 100644
--- a/include/linux/spinlock.h
+++ b/include/linux/spinlock.h
@@ -106,12 +106,12 @@ do {									\
 	static struct lock_class_key __key;				\
 									\
 	__raw_spin_lock_init((lock), #lock, &__key, LD_WAIT_SPIN);	\
-	__assume_ctx_lock(lock);					\
+	__init_ctx_lock(lock);						\
 } while (0)
 
 #else
 # define raw_spin_lock_init(lock)				\
-	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __assume_ctx_lock(lock); } while (0)
+	do { *(lock) = __RAW_SPIN_LOCK_UNLOCKED(lock); __init_ctx_lock(lock); } while (0)
 #endif
 
 #define raw_spin_is_locked(lock)	arch_spin_is_locked(&(lock)->raw_lock)
@@ -324,7 +324,7 @@ do {								\
 								\
 	__raw_spin_lock_init(spinlock_check(lock),		\
 			     #lock, &__key, LD_WAIT_CONFIG);	\
-	__assume_ctx_lock(lock);				\
+	__init_ctx_lock(lock);					\
 } while (0)
 
 #else
@@ -333,7 +333,7 @@ do {								\
 do {						\
 	spinlock_check(_lock);			\
 	*(_lock) = __SPIN_LOCK_UNLOCKED(_lock);	\
-	__assume_ctx_lock(_lock);		\
+	__init_ctx_lock(_lock);			\
 } while (0)
 
 #endif
diff --git a/include/linux/spinlock_rt.h b/include/linux/spinlock_rt.h
index 0a585768358f..154d7290bd99 100644
--- a/include/linux/spinlock_rt.h
+++ b/include/linux/spinlock_rt.h
@@ -20,7 +20,7 @@ static inline void __rt_spin_lock_init(spinlock_t *lock, const char *name,
 do {								\
 	rt_mutex_base_init(&(slock)->lock);			\
 	__rt_spin_lock_init(slock, name, key, percpu);		\
-	__assume_ctx_lock(slock);				\
+	__init_ctx_lock(slock);					\
 } while (0)
 
 #define _spin_lock_init(slock, percpu)				\
diff --git a/include/linux/ww_mutex.h b/include/linux/ww_mutex.h
index 58e959ee10e9..ecb5564ee70d 100644
--- a/include/linux/ww_mutex.h
+++ b/include/linux/ww_mutex.h
@@ -107,7 +107,7 @@ context_lock_struct(ww_acquire_ctx) {
  */
 static inline void ww_mutex_init(struct ww_mutex *lock,
 				 struct ww_class *ww_class)
-	__assumes_ctx_lock(lock)
+	__inits_ctx_lock(lock)
 {
 	ww_mutex_base_init(&lock->base, ww_class->mutex_name, &ww_class->mutex_key);
 	lock->ctx = NULL;
diff --git a/lib/test_context-analysis.c b/lib/test_context-analysis.c
index 1c5a381461fc..2f733b5cc650 100644
--- a/lib/test_context-analysis.c
+++ b/lib/test_context-analysis.c
@@ -165,6 +165,9 @@ static void __used test_mutex_init(struct test_mutex_data *d)
 {
 	mutex_init(&d->mtx);
 	d->counter = 0;
+
+	mutex_lock(&d->mtx);
+	mutex_unlock(&d->mtx);
 }
 
 static void __used test_mutex_lock(struct test_mutex_data *d)
-- 
2.52.0.457.g6b5491de43-goog

================================================================================


################################################################################

=== Thread: [PATCH] compiler: Use __typeof_unqual__() for __unqual_scalar_typeof() ===

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-kernel
Subject: [PATCH] compiler: Use __typeof_unqual__() for __unqual_scalar_typeof()
Date: Fri, 16 Jan 2026 18:18:16 +0000
Message-ID: <87ecnp2zh3.ffs () tglx>
--------------------
From: Peter Zijlstra <peterz@infradead.org>

The recent changes to get_unaligned() resulted in a new sparse warning:

   net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
   net/rds/ib_cm.c:96:35: sparse:     expected void *
   net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
 
The updated get_unaligned_t() uses __unqual_scalar_typeof() to get an
unqualified type. This works correctly for the compilers, but fails for
sparse when the data type is __be64 (or any other __beNN variant).

On sparse runs (C=[12]) __beNN types are annotated with
__attribute__((bitwise)).

That annotation allows sparse to detect incompatible operations on __beNN
variables, but it also prevents sparse from evaluating the _Generic() in
__unqual_scalar_typeof() and map __beNN to a unqualified scalar type, so it
ends up with the default, i.e. the original qualified type of a 'const
__beNN' pointer. That then ends up as the first pointer argument to
builtin_memcpy(), which obviously causes the above sparse warnings.

The sparse git tree supports typeof_unqual() now, which allows to use it
instead of the _Generic() based __unqual_scalar_typeof(). With that sparse
correctly evaluates the unqualified type and keeps the __beNN logic intact.

The downside is that this requires a top of tree sparse build and an old
sparse version will emit a metric ton of incomprehensible error messages
before it dies with a segfault.

Therefore implement a sanity check which validates that the checker is
available and capable of handling typeof_unqual(). Emit a warning if not so
the user can take informed action.

[ tglx: Move the evaluation of USE_TYPEOF_UNQUAL to compiler_types.h so it is
  	set before use and implement the sanity checker ]

Reported-by: kernel test robot <lkp@intel.com>
Signed-off-by: Peter Zijlstra <peterz@infradead.org>
Signed-off-by: Thomas Gleixner <tglx@kernel.org>
Closes: https://lore.kernel.org/oe-kbuild-all/202601150001.sKSN644a-lkp@intel.com/
---
 Makefile                       |    8 ++++++++
 include/linux/compiler.h       |   10 ----------
 include/linux/compiler_types.h |   11 +++++++++++
 scripts/checker-valid.sh       |   19 +++++++++++++++++++
 4 files changed, 38 insertions(+), 10 deletions(-)

--- a/Makefile
+++ b/Makefile
@@ -1178,6 +1178,14 @@ ifdef CONFIG_CC_IS_CLANG
 KBUILD_USERLDFLAGS += --ld-path=$(LD)
 endif
 
+# Validate the checker is available and functional
+ifneq ($(KBUILD_CHECKSRC), 0)
+  ifneq ($(shell $(srctree)/scripts/checker-valid.sh $(CHECK)), 1)
+    $(warning C=$(KBUILD_CHECKSRC) specified, but $(CHECK) is not available or not up to date)
+    KBUILD_CHECKSRC = 0
+  endif
+endif
+
 # make the checker run with the right architecture
 CHECKFLAGS += --arch=$(ARCH)
 
--- a/include/linux/compiler.h
+++ b/include/linux/compiler.h
@@ -231,16 +231,6 @@ void ftrace_likely_update(struct ftrace_
 				"must be non-C-string (not NUL-terminated)")
 
 /*
- * Use __typeof_unqual__() when available.
- *
- * XXX: Remove test for __CHECKER__ once
- * sparse learns about __typeof_unqual__().
- */
-#if CC_HAS_TYPEOF_UNQUAL && !defined(__CHECKER__)
-# define USE_TYPEOF_UNQUAL 1
-#endif
-
-/*
  * Define TYPEOF_UNQUAL() to use __typeof_unqual__() as typeof
  * operator when available, to return an unqualified type of the exp.
  */
--- a/include/linux/compiler_types.h
+++ b/include/linux/compiler_types.h
@@ -562,6 +562,13 @@ struct ftrace_likely_data {
 #define asm_inline asm
 #endif
 
+/*
+ * Use __typeof_unqual__() when available.
+ */
+#if CC_HAS_TYPEOF_UNQUAL || defined(__CHECKER__)
+# define USE_TYPEOF_UNQUAL 1
+#endif
+
 /* Are two types/vars the same type (ignoring qualifiers)? */
 #define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))
 
@@ -569,6 +576,7 @@ struct ftrace_likely_data {
  * __unqual_scalar_typeof(x) - Declare an unqualified scalar type, leaving
  *			       non-scalar types unchanged.
  */
+#ifndef USE_TYPEOF_UNQUAL
 /*
  * Prefer C11 _Generic for better compile-times and simpler code. Note: 'char'
  * is not type-compatible with 'signed char', and we define a separate case.
@@ -586,6 +594,9 @@ struct ftrace_likely_data {
 			 __scalar_type_to_expr_cases(long),		\
 			 __scalar_type_to_expr_cases(long long),	\
 			 default: (x)))
+#else
+#define __unqual_scalar_typeof(x) __typeof_unqual__(x)
+#endif
 
 /* Is this type a native word size -- useful for atomic operations */
 #define __native_word(t) \
--- /dev/null
+++ b/scripts/checker-valid.sh
@@ -0,0 +1,19 @@
+#!/bin/sh -eu
+# SPDX-License-Identifier: GPL-2.0
+
+[ ! -x "$(command -v "$1")" ] && exit 1
+
+tmp_file=$(mktemp)
+trap "rm -f $tmp_file" EXIT
+
+cat << EOF >$tmp_file
+static inline int u(const int *q)
+{
+	__typeof_unqual__(*q) v = *q;
+	return v;
+}
+EOF
+
+# sparse happily exits with 0 on error so validate
+# there is none on stderr. Use awk as grep is a pain with sh -e
+$1 $tmp_file 2>&1 | awk -v c=1 '/error/{c=0}END{print c}'

================================================================================

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-sparse
Subject: [PATCH] compiler: Use __typeof_unqual__() for __unqual_scalar_typeof()
Date: Fri, 16 Jan 2026 18:18:16 +0000
Message-ID: <87ecnp2zh3.ffs () tglx>
--------------------
From: Peter Zijlstra <peterz@infradead.org>

The recent changes to get_unaligned() resulted in a new sparse warning:

   net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
   net/rds/ib_cm.c:96:35: sparse:     expected void *
   net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
 
The updated get_unaligned_t() uses __unqual_scalar_typeof() to get an
unqualified type. This works correctly for the compilers, but fails for
sparse when the data type is __be64 (or any other __beNN variant).

On sparse runs (C=[12]) __beNN types are annotated with
__attribute__((bitwise)).

That annotation allows sparse to detect incompatible operations on __beNN
variables, but it also prevents sparse from evaluating the _Generic() in
__unqual_scalar_typeof() and map __beNN to a unqualified scalar type, so it
ends up with the default, i.e. the original qualified type of a 'const
__beNN' pointer. That then ends up as the first pointer argument to
builtin_memcpy(), which obviously causes the above sparse warnings.

The sparse git tree supports typeof_unqual() now, which allows to use it
instead of the _Generic() based __unqual_scalar_typeof(). With that sparse
correctly evaluates the unqualified type and keeps the __beNN logic intact.

The downside is that this requires a top of tree sparse build and an old
sparse version will emit a metric ton of incomprehensible error messages
before it dies with a segfault.

Therefore implement a sanity check which validates that the checker is
available and capable of handling typeof_unqual(). Emit a warning if not so
the user can take informed action.

[ tglx: Move the evaluation of USE_TYPEOF_UNQUAL to compiler_types.h so it is
  	set before use and implement the sanity checker ]

Reported-by: kernel test robot <lkp@intel.com>
Signed-off-by: Peter Zijlstra <peterz@infradead.org>
Signed-off-by: Thomas Gleixner <tglx@kernel.org>
Closes: https://lore.kernel.org/oe-kbuild-all/202601150001.sKSN644a-lkp@intel.com/
---
 Makefile                       |    8 ++++++++
 include/linux/compiler.h       |   10 ----------
 include/linux/compiler_types.h |   11 +++++++++++
 scripts/checker-valid.sh       |   19 +++++++++++++++++++
 4 files changed, 38 insertions(+), 10 deletions(-)

--- a/Makefile
+++ b/Makefile
@@ -1178,6 +1178,14 @@ ifdef CONFIG_CC_IS_CLANG
 KBUILD_USERLDFLAGS += --ld-path=$(LD)
 endif
 
+# Validate the checker is available and functional
+ifneq ($(KBUILD_CHECKSRC), 0)
+  ifneq ($(shell $(srctree)/scripts/checker-valid.sh $(CHECK)), 1)
+    $(warning C=$(KBUILD_CHECKSRC) specified, but $(CHECK) is not available or not up to date)
+    KBUILD_CHECKSRC = 0
+  endif
+endif
+
 # make the checker run with the right architecture
 CHECKFLAGS += --arch=$(ARCH)
 
--- a/include/linux/compiler.h
+++ b/include/linux/compiler.h
@@ -231,16 +231,6 @@ void ftrace_likely_update(struct ftrace_
 				"must be non-C-string (not NUL-terminated)")
 
 /*
- * Use __typeof_unqual__() when available.
- *
- * XXX: Remove test for __CHECKER__ once
- * sparse learns about __typeof_unqual__().
- */
-#if CC_HAS_TYPEOF_UNQUAL && !defined(__CHECKER__)
-# define USE_TYPEOF_UNQUAL 1
-#endif
-
-/*
  * Define TYPEOF_UNQUAL() to use __typeof_unqual__() as typeof
  * operator when available, to return an unqualified type of the exp.
  */
--- a/include/linux/compiler_types.h
+++ b/include/linux/compiler_types.h
@@ -562,6 +562,13 @@ struct ftrace_likely_data {
 #define asm_inline asm
 #endif
 
+/*
+ * Use __typeof_unqual__() when available.
+ */
+#if CC_HAS_TYPEOF_UNQUAL || defined(__CHECKER__)
+# define USE_TYPEOF_UNQUAL 1
+#endif
+
 /* Are two types/vars the same type (ignoring qualifiers)? */
 #define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))
 
@@ -569,6 +576,7 @@ struct ftrace_likely_data {
  * __unqual_scalar_typeof(x) - Declare an unqualified scalar type, leaving
  *			       non-scalar types unchanged.
  */
+#ifndef USE_TYPEOF_UNQUAL
 /*
  * Prefer C11 _Generic for better compile-times and simpler code. Note: 'char'
  * is not type-compatible with 'signed char', and we define a separate case.
@@ -586,6 +594,9 @@ struct ftrace_likely_data {
 			 __scalar_type_to_expr_cases(long),		\
 			 __scalar_type_to_expr_cases(long long),	\
 			 default: (x)))
+#else
+#define __unqual_scalar_typeof(x) __typeof_unqual__(x)
+#endif
 
 /* Is this type a native word size -- useful for atomic operations */
 #define __native_word(t) \
--- /dev/null
+++ b/scripts/checker-valid.sh
@@ -0,0 +1,19 @@
+#!/bin/sh -eu
+# SPDX-License-Identifier: GPL-2.0
+
+[ ! -x "$(command -v "$1")" ] && exit 1
+
+tmp_file=$(mktemp)
+trap "rm -f $tmp_file" EXIT
+
+cat << EOF >$tmp_file
+static inline int u(const int *q)
+{
+	__typeof_unqual__(*q) v = *q;
+	return v;
+}
+EOF
+
+# sparse happily exits with 0 on error so validate
+# there is none on stderr. Use awk as grep is a pain with sh -e
+$1 $tmp_file 2>&1 | awk -v c=1 '/error/{c=0}END{print c}'

================================================================================

From: Ian Rogers <irogers () google ! com>
To: linux-kernel
Subject: Re: [PATCH] compiler: Use __typeof_unqual__() for __unqual_scalar_typeof()
Date: Sat, 17 Jan 2026 05:25:19 +0000
Message-ID: <CAP-5=fUDQ6NTLWVfA2B+3022D6fZjvAksKH5EJ9Agnd1Qzvobw () mail ! gmail ! com>
--------------------
On Fri, Jan 16, 2026 at 10:18=E2=80=AFAM Thomas Gleixner <tglx@kernel.org> =
wrote:
>
> From: Peter Zijlstra <peterz@infradead.org>
>
> The recent changes to get_unaligned() resulted in a new sparse warning:
>
>    net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (d=
ifferent modifiers) @@     expected void * @@     got restricted __be64 con=
st * @@
>    net/rds/ib_cm.c:96:35: sparse:     expected void *
>    net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
>
> The updated get_unaligned_t() uses __unqual_scalar_typeof() to get an
> unqualified type. This works correctly for the compilers, but fails for
> sparse when the data type is __be64 (or any other __beNN variant).
>
> On sparse runs (C=3D[12]) __beNN types are annotated with
> __attribute__((bitwise)).
>
> That annotation allows sparse to detect incompatible operations on __beNN
> variables, but it also prevents sparse from evaluating the _Generic() in
> __unqual_scalar_typeof() and map __beNN to a unqualified scalar type, so =
it
> ends up with the default, i.e. the original qualified type of a 'const
> __beNN' pointer. That then ends up as the first pointer argument to
> builtin_memcpy(), which obviously causes the above sparse warnings.
>
> The sparse git tree supports typeof_unqual() now, which allows to use it
> instead of the _Generic() based __unqual_scalar_typeof(). With that spars=
e
> correctly evaluates the unqualified type and keeps the __beNN logic intac=
t.

Wow, that's painful. Congratulations on finding the root case.

Acked-by: Ian Rogers <irogers@google.com>

Thanks,
Ian

> The downside is that this requires a top of tree sparse build and an old
> sparse version will emit a metric ton of incomprehensible error messages
> before it dies with a segfault.
>
> Therefore implement a sanity check which validates that the checker is
> available and capable of handling typeof_unqual(). Emit a warning if not =
so
> the user can take informed action.
>
> [ tglx: Move the evaluation of USE_TYPEOF_UNQUAL to compiler_types.h so i=
t is
>         set before use and implement the sanity checker ]
>
> Reported-by: kernel test robot <lkp@intel.com>
> Signed-off-by: Peter Zijlstra <peterz@infradead.org>
> Signed-off-by: Thomas Gleixner <tglx@kernel.org>
> Closes: https://lore.kernel.org/oe-kbuild-all/202601150001.sKSN644a-lkp@i=
ntel.com/
> ---
>  Makefile                       |    8 ++++++++
>  include/linux/compiler.h       |   10 ----------
>  include/linux/compiler_types.h |   11 +++++++++++
>  scripts/checker-valid.sh       |   19 +++++++++++++++++++
>  4 files changed, 38 insertions(+), 10 deletions(-)
>
> --- a/Makefile
> +++ b/Makefile
> @@ -1178,6 +1178,14 @@ ifdef CONFIG_CC_IS_CLANG
>  KBUILD_USERLDFLAGS +=3D --ld-path=3D$(LD)
>  endif
>
> +# Validate the checker is available and functional
> +ifneq ($(KBUILD_CHECKSRC), 0)
> +  ifneq ($(shell $(srctree)/scripts/checker-valid.sh $(CHECK)), 1)
> +    $(warning C=3D$(KBUILD_CHECKSRC) specified, but $(CHECK) is not avai=
lable or not up to date)
> +    KBUILD_CHECKSRC =3D 0
> +  endif
> +endif
> +
>  # make the checker run with the right architecture
>  CHECKFLAGS +=3D --arch=3D$(ARCH)
>
> --- a/include/linux/compiler.h
> +++ b/include/linux/compiler.h
> @@ -231,16 +231,6 @@ void ftrace_likely_update(struct ftrace_
>                                 "must be non-C-string (not NUL-terminated=
)")
>
>  /*
> - * Use __typeof_unqual__() when available.
> - *
> - * XXX: Remove test for __CHECKER__ once
> - * sparse learns about __typeof_unqual__().
> - */
> -#if CC_HAS_TYPEOF_UNQUAL && !defined(__CHECKER__)
> -# define USE_TYPEOF_UNQUAL 1
> -#endif
> -
> -/*
>   * Define TYPEOF_UNQUAL() to use __typeof_unqual__() as typeof
>   * operator when available, to return an unqualified type of the exp.
>   */
> --- a/include/linux/compiler_types.h
> +++ b/include/linux/compiler_types.h
> @@ -562,6 +562,13 @@ struct ftrace_likely_data {
>  #define asm_inline asm
>  #endif
>
> +/*
> + * Use __typeof_unqual__() when available.
> + */
> +#if CC_HAS_TYPEOF_UNQUAL || defined(__CHECKER__)
> +# define USE_TYPEOF_UNQUAL 1
> +#endif
> +
>  /* Are two types/vars the same type (ignoring qualifiers)? */
>  #define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof=
(b))
>
> @@ -569,6 +576,7 @@ struct ftrace_likely_data {
>   * __unqual_scalar_typeof(x) - Declare an unqualified scalar type, leavi=
ng
>   *                            non-scalar types unchanged.
>   */
> +#ifndef USE_TYPEOF_UNQUAL
>  /*
>   * Prefer C11 _Generic for better compile-times and simpler code. Note: =
'char'
>   * is not type-compatible with 'signed char', and we define a separate c=
ase.
> @@ -586,6 +594,9 @@ struct ftrace_likely_data {
>                          __scalar_type_to_expr_cases(long),             \
>                          __scalar_type_to_expr_cases(long long),        \
>                          default: (x)))
> +#else
> +#define __unqual_scalar_typeof(x) __typeof_unqual__(x)
> +#endif
>
>  /* Is this type a native word size -- useful for atomic operations */
>  #define __native_word(t) \
> --- /dev/null
> +++ b/scripts/checker-valid.sh
> @@ -0,0 +1,19 @@
> +#!/bin/sh -eu
> +# SPDX-License-Identifier: GPL-2.0
> +
> +[ ! -x "$(command -v "$1")" ] && exit 1
> +
> +tmp_file=3D$(mktemp)
> +trap "rm -f $tmp_file" EXIT
> +
> +cat << EOF >$tmp_file
> +static inline int u(const int *q)
> +{
> +       __typeof_unqual__(*q) v =3D *q;
> +       return v;
> +}
> +EOF
> +
> +# sparse happily exits with 0 on error so validate
> +# there is none on stderr. Use awk as grep is a pain with sh -e
> +$1 $tmp_file 2>&1 | awk -v c=3D1 '/error/{c=3D0}END{print c}'

================================================================================

From: Ian Rogers <irogers () google ! com>
To: linux-sparse
Subject: Re: [PATCH] compiler: Use __typeof_unqual__() for __unqual_scalar_typeof()
Date: Sat, 17 Jan 2026 05:25:19 +0000
Message-ID: <CAP-5=fUDQ6NTLWVfA2B+3022D6fZjvAksKH5EJ9Agnd1Qzvobw () mail ! gmail ! com>
--------------------
On Fri, Jan 16, 2026 at 10:18=E2=80=AFAM Thomas Gleixner <tglx@kernel.org> =
wrote:
>
> From: Peter Zijlstra <peterz@infradead.org>
>
> The recent changes to get_unaligned() resulted in a new sparse warning:
>
>    net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (d=
ifferent modifiers) @@     expected void * @@     got restricted __be64 con=
st * @@
>    net/rds/ib_cm.c:96:35: sparse:     expected void *
>    net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
>
> The updated get_unaligned_t() uses __unqual_scalar_typeof() to get an
> unqualified type. This works correctly for the compilers, but fails for
> sparse when the data type is __be64 (or any other __beNN variant).
>
> On sparse runs (C=3D[12]) __beNN types are annotated with
> __attribute__((bitwise)).
>
> That annotation allows sparse to detect incompatible operations on __beNN
> variables, but it also prevents sparse from evaluating the _Generic() in
> __unqual_scalar_typeof() and map __beNN to a unqualified scalar type, so =
it
> ends up with the default, i.e. the original qualified type of a 'const
> __beNN' pointer. That then ends up as the first pointer argument to
> builtin_memcpy(), which obviously causes the above sparse warnings.
>
> The sparse git tree supports typeof_unqual() now, which allows to use it
> instead of the _Generic() based __unqual_scalar_typeof(). With that spars=
e
> correctly evaluates the unqualified type and keeps the __beNN logic intac=
t.

Wow, that's painful. Congratulations on finding the root case.

Acked-by: Ian Rogers <irogers@google.com>

Thanks,
Ian

> The downside is that this requires a top of tree sparse build and an old
> sparse version will emit a metric ton of incomprehensible error messages
> before it dies with a segfault.
>
> Therefore implement a sanity check which validates that the checker is
> available and capable of handling typeof_unqual(). Emit a warning if not =
so
> the user can take informed action.
>
> [ tglx: Move the evaluation of USE_TYPEOF_UNQUAL to compiler_types.h so i=
t is
>         set before use and implement the sanity checker ]
>
> Reported-by: kernel test robot <lkp@intel.com>
> Signed-off-by: Peter Zijlstra <peterz@infradead.org>
> Signed-off-by: Thomas Gleixner <tglx@kernel.org>
> Closes: https://lore.kernel.org/oe-kbuild-all/202601150001.sKSN644a-lkp@i=
ntel.com/
> ---
>  Makefile                       |    8 ++++++++
>  include/linux/compiler.h       |   10 ----------
>  include/linux/compiler_types.h |   11 +++++++++++
>  scripts/checker-valid.sh       |   19 +++++++++++++++++++
>  4 files changed, 38 insertions(+), 10 deletions(-)
>
> --- a/Makefile
> +++ b/Makefile
> @@ -1178,6 +1178,14 @@ ifdef CONFIG_CC_IS_CLANG
>  KBUILD_USERLDFLAGS +=3D --ld-path=3D$(LD)
>  endif
>
> +# Validate the checker is available and functional
> +ifneq ($(KBUILD_CHECKSRC), 0)
> +  ifneq ($(shell $(srctree)/scripts/checker-valid.sh $(CHECK)), 1)
> +    $(warning C=3D$(KBUILD_CHECKSRC) specified, but $(CHECK) is not avai=
lable or not up to date)
> +    KBUILD_CHECKSRC =3D 0
> +  endif
> +endif
> +
>  # make the checker run with the right architecture
>  CHECKFLAGS +=3D --arch=3D$(ARCH)
>
> --- a/include/linux/compiler.h
> +++ b/include/linux/compiler.h
> @@ -231,16 +231,6 @@ void ftrace_likely_update(struct ftrace_
>                                 "must be non-C-string (not NUL-terminated=
)")
>
>  /*
> - * Use __typeof_unqual__() when available.
> - *
> - * XXX: Remove test for __CHECKER__ once
> - * sparse learns about __typeof_unqual__().
> - */
> -#if CC_HAS_TYPEOF_UNQUAL && !defined(__CHECKER__)
> -# define USE_TYPEOF_UNQUAL 1
> -#endif
> -
> -/*
>   * Define TYPEOF_UNQUAL() to use __typeof_unqual__() as typeof
>   * operator when available, to return an unqualified type of the exp.
>   */
> --- a/include/linux/compiler_types.h
> +++ b/include/linux/compiler_types.h
> @@ -562,6 +562,13 @@ struct ftrace_likely_data {
>  #define asm_inline asm
>  #endif
>
> +/*
> + * Use __typeof_unqual__() when available.
> + */
> +#if CC_HAS_TYPEOF_UNQUAL || defined(__CHECKER__)
> +# define USE_TYPEOF_UNQUAL 1
> +#endif
> +
>  /* Are two types/vars the same type (ignoring qualifiers)? */
>  #define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof=
(b))
>
> @@ -569,6 +576,7 @@ struct ftrace_likely_data {
>   * __unqual_scalar_typeof(x) - Declare an unqualified scalar type, leavi=
ng
>   *                            non-scalar types unchanged.
>   */
> +#ifndef USE_TYPEOF_UNQUAL
>  /*
>   * Prefer C11 _Generic for better compile-times and simpler code. Note: =
'char'
>   * is not type-compatible with 'signed char', and we define a separate c=
ase.
> @@ -586,6 +594,9 @@ struct ftrace_likely_data {
>                          __scalar_type_to_expr_cases(long),             \
>                          __scalar_type_to_expr_cases(long long),        \
>                          default: (x)))
> +#else
> +#define __unqual_scalar_typeof(x) __typeof_unqual__(x)
> +#endif
>
>  /* Is this type a native word size -- useful for atomic operations */
>  #define __native_word(t) \
> --- /dev/null
> +++ b/scripts/checker-valid.sh
> @@ -0,0 +1,19 @@
> +#!/bin/sh -eu
> +# SPDX-License-Identifier: GPL-2.0
> +
> +[ ! -x "$(command -v "$1")" ] && exit 1
> +
> +tmp_file=3D$(mktemp)
> +trap "rm -f $tmp_file" EXIT
> +
> +cat << EOF >$tmp_file
> +static inline int u(const int *q)
> +{
> +       __typeof_unqual__(*q) v =3D *q;
> +       return v;
> +}
> +EOF
> +
> +# sparse happily exits with 0 on error so validate
> +# there is none on stderr. Use awk as grep is a pain with sh -e
> +$1 $tmp_file 2>&1 | awk -v c=3D1 '/error/{c=3D0}END{print c}'

================================================================================


################################################################################

=== Thread: [PATCH] fix ===

From: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
To: Unknown
Subject: [PATCH] fix
Date: Tue, 27 Jan 2026 10:10:55 +0000
Message-ID: 
--------------------
Signed-off-by: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
---
 tools/include/linux/compiler_types.h | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/tools/include/linux/compiler_types.h b/tools/include/linux/compiler_types.h
index 949b2cdd3412..ca60d491d4e8 100644
--- a/tools/include/linux/compiler_types.h
+++ b/tools/include/linux/compiler_types.h
@@ -60,4 +60,6 @@
 			__scalar_type_to_expr_cases(long long),	\
 			default: (x)))

+#define __no_context_analysis
+
 #endif /* __LINUX_COMPILER_TYPES_H */
--
2.52.0

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
To: Unknown
Subject: [PATCH] fix
Date: Tue, 27 Jan 2026 10:10:55 +0000
Message-ID: 
--------------------
Signed-off-by: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
---
 tools/include/linux/compiler_types.h | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/tools/include/linux/compiler_types.h b/tools/include/linux/compiler_types.h
index 949b2cdd3412..ca60d491d4e8 100644
--- a/tools/include/linux/compiler_types.h
+++ b/tools/include/linux/compiler_types.h
@@ -60,4 +60,6 @@
 			__scalar_type_to_expr_cases(long long),	\
 			default: (x)))

+#define __no_context_analysis
+
 #endif /* __LINUX_COMPILER_TYPES_H */
--
2.52.0

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
To: Unknown
Subject: [PATCH] fix
Date: Tue, 27 Jan 2026 10:10:55 +0000
Message-ID: 
--------------------
Signed-off-by: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
---
 tools/include/linux/compiler_types.h | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/tools/include/linux/compiler_types.h b/tools/include/linux/compiler_types.h
index 949b2cdd3412..ca60d491d4e8 100644
--- a/tools/include/linux/compiler_types.h
+++ b/tools/include/linux/compiler_types.h
@@ -60,4 +60,6 @@
 			__scalar_type_to_expr_cases(long long),	\
 			default: (x)))

+#define __no_context_analysis
+
 #endif /* __LINUX_COMPILER_TYPES_H */
--
2.52.0

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
To: Unknown
Subject: [PATCH] fix
Date: Tue, 27 Jan 2026 10:10:55 +0000
Message-ID: 
--------------------
Signed-off-by: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
---
 tools/include/linux/compiler_types.h | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/tools/include/linux/compiler_types.h b/tools/include/linux/compiler_types.h
index 949b2cdd3412..ca60d491d4e8 100644
--- a/tools/include/linux/compiler_types.h
+++ b/tools/include/linux/compiler_types.h
@@ -60,4 +60,6 @@
 			__scalar_type_to_expr_cases(long long),	\
 			default: (x)))

+#define __no_context_analysis
+
 #endif /* __LINUX_COMPILER_TYPES_H */
--
2.52.0

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
To: Unknown
Subject: [PATCH] fix
Date: Tue, 27 Jan 2026 10:10:55 +0000
Message-ID: 
--------------------
Signed-off-by: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
---
 tools/include/linux/compiler_types.h | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/tools/include/linux/compiler_types.h b/tools/include/linux/compiler_types.h
index 949b2cdd3412..ca60d491d4e8 100644
--- a/tools/include/linux/compiler_types.h
+++ b/tools/include/linux/compiler_types.h
@@ -60,4 +60,6 @@
 			__scalar_type_to_expr_cases(long long),	\
 			default: (x)))

+#define __no_context_analysis
+
 #endif /* __LINUX_COMPILER_TYPES_H */
--
2.52.0

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
To: Unknown
Subject: [PATCH] fix
Date: Tue, 27 Jan 2026 10:10:55 +0000
Message-ID: 
--------------------
Signed-off-by: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
---
 tools/include/linux/compiler_types.h | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/tools/include/linux/compiler_types.h b/tools/include/linux/compiler_types.h
index 949b2cdd3412..ca60d491d4e8 100644
--- a/tools/include/linux/compiler_types.h
+++ b/tools/include/linux/compiler_types.h
@@ -60,4 +60,6 @@
 			__scalar_type_to_expr_cases(long long),	\
 			default: (x)))

+#define __no_context_analysis
+
 #endif /* __LINUX_COMPILER_TYPES_H */
--
2.52.0

================================================================================

From: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
To: Unknown
Subject: [PATCH] fix
Date: Tue, 27 Jan 2026 10:10:55 +0000
Message-ID: 
--------------------
Signed-off-by: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
---
 tools/include/linux/compiler_types.h | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/tools/include/linux/compiler_types.h b/tools/include/linux/compiler_types.h
index 949b2cdd3412..ca60d491d4e8 100644
--- a/tools/include/linux/compiler_types.h
+++ b/tools/include/linux/compiler_types.h
@@ -60,4 +60,6 @@
 			__scalar_type_to_expr_cases(long long),	\
 			default: (x)))

+#define __no_context_analysis
+
 #endif /* __LINUX_COMPILER_TYPES_H */
--
2.52.0

================================================================================


################################################################################

=== Thread: [PATCH] sparse/dissect: change do_symbol(sym) to use sym->definition ===

From: Oleg Nesterov <oleg () redhat ! com>
To: linux-sparse
Subject: [PATCH] sparse/dissect: change do_symbol(sym) to use sym->definition
Date: Sun, 11 Jan 2026 17:28:26 +0000
Message-ID: <aWPduv1ewBCFVn5w () redhat ! com>
--------------------
Test-case:

	$ cat TEST.c
	static inline void i_func(void) { FUNC(); }
	static inline void i_func(void);
	void func(void) { i_func(); }

	$ ./test-dissect TEST.c

	   3:6                    def   f func                             void ( ... )
	   2:20                   def   f i_func                           void ( ... )
	   3:19  func             --r   f i_func                           void ( ... )

dissect reports the wrong position for the definition of i_func()
and doesn't inspect its body.

This is because the 2nd external_declaration() binds another SYM_NODE
to the same ident and lookup_symbol() called during parsing returns
the most recent one, which is then used by do_symbol().

With this patch:

	$ ./test-dissect TEST.c

	   3:6                    def   f func                             void ( ... )
	   1:20                   def   f i_func                           void ( ... )
	   1:35  i_func           --r   f FUNC                             bad type
	   3:19  func             --r   f i_func                           void ( ... )

Signed-off-by: Oleg Nesterov <oleg@redhat.com>
---
 dissect.c | 7 ++++++-
 1 file changed, 6 insertions(+), 1 deletion(-)

diff --git a/dissect.c b/dissect.c
index a0fda09c..f20522f0 100644
--- a/dissect.c
+++ b/dissect.c
@@ -630,12 +630,17 @@ static inline bool is_typedef(struct symbol *sym)
 	return (sym->namespace == NS_TYPEDEF);
 }
 
-static struct symbol *do_symbol(struct symbol *sym)
+static struct symbol *do_symbol(struct symbol *__sym)
 {
+	struct symbol *sym = __sym->definition ?: __sym;
 	struct symbol *type = base_type(sym);
 	struct symbol *dctx = dissect_ctx;
 	struct statement *stmt;
 
+	if (sym->inspected)
+		return type;
+	sym->inspected = 1;
+
 	reporter->r_symdef(sym);
 
 	switch (type->type) {
-- 
2.52.0



================================================================================


################################################################################

=== Thread: [PATCH] sparse/pre-process: don't update next->pos in collect_arg() ===

From: Oleg Nesterov <oleg () redhat ! com>
To: linux-sparse
Subject: [PATCH] sparse/pre-process: don't update next->pos in collect_arg()
Date: Sun, 18 Jan 2026 14:55:19 +0000
Message-ID: <aWz0V_zQ47afKFJy () redhat ! com>
--------------------
I don't quite understand why the expand() -> collect_arg() path
updates ->pos for each token in the input *list, but this breaks
dissect and thus semind.

Change collect_arg() to update next->pos only if "preprocess_only"
is true, the "if (preprocess_only)" block in sparse_tokenstream()
relies on the current behaviour.

Test-case:

	$ cat -n PP_POS.c
	     1	#define READ_ONCE(x) x
	     2	#define WRITE_ONCE(x, y) x = y
	     3
	     4	int R, W;
	     5
	     6	void func(void)
	     7	{
	     8	  WRITE_ONCE(
	     9	     W,
	    10	     READ_ONCE(R)
	    11	  );
	    12	}

	$ ./test-dissect PP_POS.c
	   4:5                    def   v R                                int
	   4:8                    def   v W                                int
	   6:6                    def   f func                             void ( ... )
	   8:3   func             -w-   v W                                int
	   8:3   func             -r-   v R                                int

The reported positions of the usage of R and W are wrong, and thus
./semind doesn't work:

	$ ./semind add PP_POS.c
	$ ./semind search -l PP_POS.c:10:16

With this patch:

	$ ./test-dissect PP_POS.c
	   4:5                    def   v R                                int
	   4:8                    def   v W                                int
	   6:6                    def   f func                             void ( ... )
	   9:6   func             -w-   v W                                int
	  10:16  func             -r-   v R                                int

	$ ./semind add PP_POS.c
	$ ./semind search -l PP_POS.c:10:16
	(def) PP_POS.c	4	5		int R, W;
	(-r-) PP_POS.c	10	16	func	READ_ONCE(R)

See also the changes in validation/parsing/attr-cleanup.c and
validation/sizeof-void.c, the updated positions look more correct.

Suggested-by: Chris Li <sparse@chrisli.org>
Signed-off-by: Oleg Nesterov <oleg@redhat.com>
---
 pre-process.c                     | 9 ++++++---
 validation/parsing/attr-cleanup.c | 2 +-
 validation/sizeof-void.c          | 2 +-
 3 files changed, 8 insertions(+), 5 deletions(-)

diff --git a/pre-process.c b/pre-process.c
index 3fb25082..5ab4810d 100644
--- a/pre-process.c
+++ b/pre-process.c
@@ -294,9 +294,12 @@ static struct token *collect_arg(struct token *prev, int vararg, struct position
 		} else if (match_op(next, ',') && !nesting && !vararg) {
 			break;
 		}
-		next->pos.stream = pos->stream;
-		next->pos.line = pos->line;
-		next->pos.pos = pos->pos;
+		/* See "if (preprocess_only)" in sparse_tokenstream() */
+		if (preprocess_only) {
+			next->pos.stream = pos->stream;
+			next->pos.line = pos->line;
+			next->pos.pos = pos->pos;
+		}
 		next->pos.newline = 0;
 		p = &next->next;
 	}
diff --git a/validation/parsing/attr-cleanup.c b/validation/parsing/attr-cleanup.c
index ac64649c..fa3cb1ca 100644
--- a/validation/parsing/attr-cleanup.c
+++ b/validation/parsing/attr-cleanup.c
@@ -24,7 +24,7 @@ int test(int n)
  * check-command: sparse -Wunknown-attribute $file
  *
  * check-error-start
-parsing/attr-cleanup.c:10:17: error: argument is not an identifier
+parsing/attr-cleanup.c:10:27: error: argument is not an identifier
 parsing/attr-cleanup.c:11:39: error: an argument is expected for attribute 'cleanup'
 parsing/attr-cleanup.c:12:40: error: an argument is expected for attribute 'cleanup'
 parsing/attr-cleanup.c:13:43: error: Expected ) after attribute's argument'
diff --git a/validation/sizeof-void.c b/validation/sizeof-void.c
index 0fd917a2..6792ff02 100644
--- a/validation/sizeof-void.c
+++ b/validation/sizeof-void.c
@@ -36,7 +36,7 @@ sizeof-void.c:16:14: warning: expression using sizeof(void)
 sizeof-void.c:17:14: warning: expression using sizeof(void)
 sizeof-void.c:18:14: warning: expression using sizeof(void)
 sizeof-void.c:19:14: warning: expression using sizeof(void)
-sizeof-void.c:20:14: warning: expression using sizeof(void)
+sizeof-void.c:20:27: warning: expression using sizeof(void)
 sizeof-void.c:21:14: warning: expression using sizeof(void)
 sizeof-void.c:22:14: warning: expression using sizeof(void)
 sizeof-void.c:23:14: warning: expression using sizeof(void)
-- 
2.52.0



================================================================================


################################################################################

=== Thread: [PATCH] sparse/pre-process: introduce "dissect_mode" option to fix dissect/semind ===

From: Oleg Nesterov <oleg () redhat ! com>
To: linux-sparse
Subject: [PATCH] sparse/pre-process: introduce "dissect_mode" option to fix dissect/semind
Date: Wed, 17 Dec 2025 15:17:44 +0000
Message-ID: <aULJmGi8yib_XH0P () redhat ! com>
--------------------
I don't quite understand why does expand() -> collect_arg() path
update ->pos for each token in the input *list, but this breaks
dissect and thus semind.

Test-case:

	$ cat -n PP_POS.c
	     1	#define READ_ONCE(x) x
	     2	#define WRITE_ONCE(x, y) x = y
	     3
	     4	int R, W;
	     5
	     6	void func(void)
	     7	{
	     8	  WRITE_ONCE(
	     9	     W,
	    10	     READ_ONCE(R)
	    11	  );
	    12	}

	$ ./test-dissect PP_POS.c
	   4:5                    def   v R                                int
	   4:8                    def   v W                                int
	   6:6                    def   f func                             void ( ... )
	   8:3   func             -w-   v W                                int
	   8:3   func             -r-   v R                                int

The reported positions of the usage of R and W are wrong,
and thus ./semind doesn't work:

	$ ./semind add PP_POS.c
	$ ./semind search -l PP_POS.c:10:16

With this patch:

	$ ./test-dissect PP_POS.c
	   4:5                    def   v R                                int
	   4:8                    def   v W                                int
	   6:6                    def   f func                             void ( ... )
	   9:6   func             -w-   v W                                int
	  10:16  func             -r-   v R                                int

	$ ./semind add PP_POS.c
	$ ./semind search -l PP_POS.c:10:16
	(def) PP_POS.c	4	5		int R, W;
	(-r-) PP_POS.c	10	16	func	READ_ONCE(R)

Signed-off-by: Oleg Nesterov <oleg@redhat.com>
---
 dissect.c     | 1 +
 options.c     | 1 +
 options.h     | 1 +
 pre-process.c | 8 +++++---
 4 files changed, 8 insertions(+), 3 deletions(-)

diff --git a/dissect.c b/dissect.c
index a6003afa..5fed8e22 100644
--- a/dissect.c
+++ b/dissect.c
@@ -714,6 +714,7 @@ end:
 
 void dissect(struct reporter *rep, struct string_list *filelist)
 {
+	dissect_mode = 1;
 	reporter = rep;
 
 	DO_LIST(filelist, file, do_file(file));
diff --git a/options.c b/options.c
index 6ee4d878..0f207e80 100644
--- a/options.c
+++ b/options.c
@@ -71,6 +71,7 @@ int dump_macro_defs = 0;
 int dump_macros_only = 0;
 
 int dissect_show_all_symbols = 0;
+int dissect_mode = 0;
 
 unsigned long fdump_ir;
 int fhosted = 1;
diff --git a/options.h b/options.h
index c2a9551a..b559254d 100644
--- a/options.h
+++ b/options.h
@@ -71,6 +71,7 @@ extern int dump_macro_defs;
 extern int dump_macros_only;
 
 extern int dissect_show_all_symbols;
+extern int dissect_mode;
 
 extern unsigned long fdump_ir;
 extern int fhosted;
diff --git a/pre-process.c b/pre-process.c
index 3fb25082..64445881 100644
--- a/pre-process.c
+++ b/pre-process.c
@@ -294,9 +294,11 @@ static struct token *collect_arg(struct token *prev, int vararg, struct position
 		} else if (match_op(next, ',') && !nesting && !vararg) {
 			break;
 		}
-		next->pos.stream = pos->stream;
-		next->pos.line = pos->line;
-		next->pos.pos = pos->pos;
+		if (!dissect_mode) {
+			next->pos.stream = pos->stream;
+			next->pos.line = pos->line;
+			next->pos.pos = pos->pos;
+		}
 		next->pos.newline = 0;
 		p = &next->next;
 	}
-- 
2.52.0



================================================================================

From: Chris Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse/pre-process: introduce "dissect_mode" option to fix dissect/semind
Date: Fri, 16 Jan 2026 23:29:41 +0000
Message-ID: <CACePvbW2OybP7P-Vk+pa23SqA0+R0i8=20TiQMq99PvNAYJ8GA () mail ! gmail ! com>
--------------------
Hi Oleg,

Slowly catching up my back log from the holidays.

On Wed, Dec 17, 2025 at 7:26=E2=80=AFAM Oleg Nesterov <oleg@redhat.com> wro=
te:
>
> I don't quite understand why does expand() -> collect_arg() path
> update ->pos for each token in the input *list, but this breaks
> dissect and thus semind.

That is a good question, I don't understand why it did that either. I
did some digging, inside macro argument list expansion, the "#include
" is not allowed. It is not possible to switch streams here. The
"pos.pos" is for human consumption anyway, it has no effect on the IR
generation. The only visible effect as far as I can tell is related to
the preprocessor "-E" in lib.c:

        if (preprocess_only) {
                while (!eof_token(token)) {
                        int prec =3D 1;
                        struct token *next =3D token->next;
                        const char *separator =3D "";
                        if (next->pos.whitespace)
                                separator =3D " ";
                        if (next->pos.newline) {
                                separator =3D "\n\t\t\t\t\t";
                                prec =3D next->pos.pos; <--- use pos as
indentation level.
                                if (prec > 4)
                                        prec =3D 4;
                        }
                        printf("%s%.*s", show_token(token), prec, separator=
);
                        token =3D next;

The "-E" output has some indentation enhancement to turn space into
tab level indentation. This "pos" assignment tries to align the
indentation context of the input arguments to the same level of the
expanding macro name.

> Test-case:
>
>         $ cat -n PP_POS.c
>              1  #define READ_ONCE(x) x
>              2  #define WRITE_ONCE(x, y) x =3D y
>              3
>              4  int R, W;
>              5
>              6  void func(void)
>              7  {
>              8    WRITE_ONCE(
>              9       W,

With your patch, when doing "-E", the W will get indentation deeper
than WRITE_ONCE.

>             10       READ_ONCE(R)
>             11    );
>             12  }
>
>         $ ./test-dissect PP_POS.c
>            4:5                    def   v R                              =
  int
>            4:8                    def   v W                              =
  int
>            6:6                    def   f func                           =
  void ( ... )
>            8:3   func             -w-   v W                              =
  int
>            8:3   func             -r-   v R                              =
  int
>
> The reported positions of the usage of R and W are wrong,
> and thus ./semind doesn't work:

It seems to me this enhancement can be used on other macro related
expansions as well.

>
>         $ ./semind add PP_POS.c
>         $ ./semind search -l PP_POS.c:10:16
>
> With this patch:
>
>         $ ./test-dissect PP_POS.c
>            4:5                    def   v R                              =
  int
>            4:8                    def   v W                              =
  int
>            6:6                    def   f func                           =
  void ( ... )
>            9:6   func             -w-   v W                              =
  int
>           10:16  func             -r-   v R                              =
  int
>
>         $ ./semind add PP_POS.c
>         $ ./semind search -l PP_POS.c:10:16
>         (def) PP_POS.c  4       5               int R, W;
>         (-r-) PP_POS.c  10      16      func    READ_ONCE(R)
>
> Signed-off-by: Oleg Nesterov <oleg@redhat.com>
> ---
>  dissect.c     | 1 +
>  options.c     | 1 +
>  options.h     | 1 +
>  pre-process.c | 8 +++++---
>  4 files changed, 8 insertions(+), 3 deletions(-)
>
> diff --git a/dissect.c b/dissect.c
> index a6003afa..5fed8e22 100644
> --- a/dissect.c
> +++ b/dissect.c
> @@ -714,6 +714,7 @@ end:
>
>  void dissect(struct reporter *rep, struct string_list *filelist)
>  {
> +       dissect_mode =3D 1;

I don't think we need dissect_mode. I am leaning towards enabling it
all the time, maybe except for the preprocessor only mode.

>         reporter =3D rep;
>
>         DO_LIST(filelist, file, do_file(file));
> diff --git a/options.c b/options.c
> index 6ee4d878..0f207e80 100644
> --- a/options.c
> +++ b/options.c
> @@ -71,6 +71,7 @@ int dump_macro_defs =3D 0;
>  int dump_macros_only =3D 0;
>
>  int dissect_show_all_symbols =3D 0;
> +int dissect_mode =3D 0;
>
>  unsigned long fdump_ir;
>  int fhosted =3D 1;
> diff --git a/options.h b/options.h
> index c2a9551a..b559254d 100644
> --- a/options.h
> +++ b/options.h
> @@ -71,6 +71,7 @@ extern int dump_macro_defs;
>  extern int dump_macros_only;
>
>  extern int dissect_show_all_symbols;
> +extern int dissect_mode;
>
>  extern unsigned long fdump_ir;
>  extern int fhosted;
> diff --git a/pre-process.c b/pre-process.c
> index 3fb25082..64445881 100644
> --- a/pre-process.c
> +++ b/pre-process.c
> @@ -294,9 +294,11 @@ static struct token *collect_arg(struct token *prev,=
 int vararg, struct position
>                 } else if (match_op(next, ',') && !nesting && !vararg) {
>                         break;
>                 }
> -               next->pos.stream =3D pos->stream;
> -               next->pos.line =3D pos->line;
> -               next->pos.pos =3D pos->pos;
> +               if (!dissect_mode) {
> +                       next->pos.stream =3D pos->stream;
> +                       next->pos.line =3D pos->line;
> +                       next->pos.pos =3D pos->pos;
> +               }

Maybe change it to "if (preprocess_only)", and fix all the validation
error output of the checker. What do you say?

Overall I feel that without this position overwrite is better to
locate the real location of the argument of the macro. If anyone knows
another reason we should do the position overwrite, please let me
know.

Alternatively we can also fix the preprocessor "-E" indentation
output. Might not be worth the complexity.

Chris

>                 next->pos.newline =3D 0;
>                 p =3D &next->next;
>         }
> --
> 2.52.0
>
>

================================================================================

From: Oleg Nesterov <oleg () redhat ! com>
To: linux-sparse
Subject: Re: [PATCH] sparse/pre-process: introduce "dissect_mode" option to fix dissect/semind
Date: Sat, 17 Jan 2026 14:19:45 +0000
Message-ID: <aWuagcDh53AQxEmw () redhat ! com>
--------------------
Hi Chris,

On 01/16, Chris Li wrote:
>
> On Wed, Dec 17, 2025 at 7:26AM Oleg Nesterov <oleg@redhat.com> wrote:
> >
> > I don't quite understand why does expand() -> collect_arg() path
> > update ->pos for each token in the input *list, but this breaks
> > dissect and thus semind.
>
> That is a good question, I don't understand why it did that either. I
> did some digging, inside macro argument list expansion, the "#include
> " is not allowed. It is not possible to switch streams here. The
> "pos.pos" is for human consumption anyway, it has no effect on the IR
> generation. The only visible effect as far as I can tell is related to
> the preprocessor "-E" in lib.c:
>
>         if (preprocess_only) {
>                 while (!eof_token(token)) {
>                         int prec = 1;
>                         struct token *next = token->next;
>                         const char *separator = "";
>                         if (next->pos.whitespace)
>                                 separator = " ";
>                         if (next->pos.newline) {
>                                 separator = "\n\t\t\t\t\t";
>                                 prec = next->pos.pos; <--- use pos as
> indentation level.
>                                 if (prec > 4)
>                                         prec = 4;
>                         }
>                         printf("%s%.*s", show_token(token), prec, separator);
>                         token = next;
>
> The "-E" output has some indentation enhancement to turn space into
> tab level indentation. This "pos" assignment tries to align the
> indentation context of the input arguments to the same level of the
> expanding macro name.

Yes, exactly! Initially I tried to simply remove these next->pos.* updates
in collect_arg(), but this causes a lot of failures in validation/preprocessor
(due to extra indentations) and I failed to find a simple fix for the
"if (preprocess_only)" code above. Plus I wasn't comfortable because
I don't understand the intent...

> >  void dissect(struct reporter *rep, struct string_list *filelist)
> >  {
> > +       dissect_mode = 1;
>
> I don't think we need dissect_mode. I am leaning towards enabling it
> all the time, maybe except for the preprocessor only mode.

...

> > +               if (!dissect_mode) {
> > +                       next->pos.stream = pos->stream;
> > +                       next->pos.line = pos->line;
> > +                       next->pos.pos = pos->pos;
> > +               }
>
> Maybe change it to "if (preprocess_only)", and fix all the validation
> error output of the checker. What do you say?

Agreed! This was my plan B ;)

With this change

	-               if (!dissect_mode) {
	+               if (preprocess_only) {

make check reports 2 failures

	-parsing/attr-cleanup.c:10:17: error: argument is not an identifier
	+parsing/attr-cleanup.c:10:27: error: argument is not an identifier

	-sizeof-void.c:20:14: warning: expression using sizeof(void)
	+sizeof-void.c:20:27: warning: expression using sizeof(void)

but the new positions look more correct.

However. I didn't dare to send this patch because other warnings from
sizeof-void.c still blame the column 14, this looks inconsistent...
But perhaps we don't really care?

So. I am going to update the changelog and send the trivial V2 below.

Will you agree?

Oleg.
---

diff --git a/pre-process.c b/pre-process.c
index 3fb25082..a4bb6cb6 100644
--- a/pre-process.c
+++ b/pre-process.c
@@ -294,9 +294,11 @@ static struct token *collect_arg(struct token *prev, int vararg, struct position
 		} else if (match_op(next, ',') && !nesting && !vararg) {
 			break;
 		}
-		next->pos.stream = pos->stream;
-		next->pos.line = pos->line;
-		next->pos.pos = pos->pos;
+		if (preprocess_only) {
+			next->pos.stream = pos->stream;
+			next->pos.line = pos->line;
+			next->pos.pos = pos->pos;
+		}
 		next->pos.newline = 0;
 		p = &next->next;
 	}
diff --git a/validation/parsing/attr-cleanup.c b/validation/parsing/attr-cleanup.c
index ac64649c..fa3cb1ca 100644
--- a/validation/parsing/attr-cleanup.c
+++ b/validation/parsing/attr-cleanup.c
@@ -24,7 +24,7 @@ int test(int n)
  * check-command: sparse -Wunknown-attribute $file
  *
  * check-error-start
-parsing/attr-cleanup.c:10:17: error: argument is not an identifier
+parsing/attr-cleanup.c:10:27: error: argument is not an identifier
 parsing/attr-cleanup.c:11:39: error: an argument is expected for attribute 'cleanup'
 parsing/attr-cleanup.c:12:40: error: an argument is expected for attribute 'cleanup'
 parsing/attr-cleanup.c:13:43: error: Expected ) after attribute's argument'
diff --git a/validation/sizeof-void.c b/validation/sizeof-void.c
index 0fd917a2..6792ff02 100644
--- a/validation/sizeof-void.c
+++ b/validation/sizeof-void.c
@@ -36,7 +36,7 @@ sizeof-void.c:16:14: warning: expression using sizeof(void)
 sizeof-void.c:17:14: warning: expression using sizeof(void)
 sizeof-void.c:18:14: warning: expression using sizeof(void)
 sizeof-void.c:19:14: warning: expression using sizeof(void)
-sizeof-void.c:20:14: warning: expression using sizeof(void)
+sizeof-void.c:20:27: warning: expression using sizeof(void)
 sizeof-void.c:21:14: warning: expression using sizeof(void)
 sizeof-void.c:22:14: warning: expression using sizeof(void)
 sizeof-void.c:23:14: warning: expression using sizeof(void)


================================================================================

From: Oleg Nesterov <oleg () redhat ! com>
To: linux-sparse
Subject: Re: [PATCH] sparse/pre-process: introduce "dissect_mode" option to fix dissect/semind
Date: Sat, 17 Jan 2026 16:32:03 +0000
Message-ID: <aWu5g1VkGe0ktRaW () redhat ! com>
--------------------
On 01/17, Oleg Nesterov wrote:
>
> Agreed! This was my plan B ;)
>
> With this change
>
> 	-               if (!dissect_mode) {
> 	+               if (preprocess_only) {
>
> make check reports 2 failures
>
> 	-parsing/attr-cleanup.c:10:17: error: argument is not an identifier
> 	+parsing/attr-cleanup.c:10:27: error: argument is not an identifier
>
> 	-sizeof-void.c:20:14: warning: expression using sizeof(void)
> 	+sizeof-void.c:20:27: warning: expression using sizeof(void)
>
> but the new positions look more correct.
>
> However. I didn't dare to send this patch because other warnings from
> sizeof-void.c still blame the column 14, this looks inconsistent...
> But perhaps we don't really care?

On a 2nd thought...

Unlike other warnings, this one (sizeof-void.c:20:27) refers to the
inner "sizeof *ptr", so I think that this patch fixes the reported
position. So yes, I think we don't care even if the new column == 27
differs from other warnings.

What do you think?

Oleg.


> So. I am going to update the changelog and send the trivial V2 below.
>
> Will you agree?
>
> Oleg.
> ---
>
> diff --git a/pre-process.c b/pre-process.c
> index 3fb25082..a4bb6cb6 100644
> --- a/pre-process.c
> +++ b/pre-process.c
> @@ -294,9 +294,11 @@ static struct token *collect_arg(struct token *prev, int vararg, struct position
>  		} else if (match_op(next, ',') && !nesting && !vararg) {
>  			break;
>  		}
> -		next->pos.stream = pos->stream;
> -		next->pos.line = pos->line;
> -		next->pos.pos = pos->pos;
> +		if (preprocess_only) {
> +			next->pos.stream = pos->stream;
> +			next->pos.line = pos->line;
> +			next->pos.pos = pos->pos;
> +		}
>  		next->pos.newline = 0;
>  		p = &next->next;
>  	}
> diff --git a/validation/parsing/attr-cleanup.c b/validation/parsing/attr-cleanup.c
> index ac64649c..fa3cb1ca 100644
> --- a/validation/parsing/attr-cleanup.c
> +++ b/validation/parsing/attr-cleanup.c
> @@ -24,7 +24,7 @@ int test(int n)
>   * check-command: sparse -Wunknown-attribute $file
>   *
>   * check-error-start
> -parsing/attr-cleanup.c:10:17: error: argument is not an identifier
> +parsing/attr-cleanup.c:10:27: error: argument is not an identifier
>  parsing/attr-cleanup.c:11:39: error: an argument is expected for attribute 'cleanup'
>  parsing/attr-cleanup.c:12:40: error: an argument is expected for attribute 'cleanup'
>  parsing/attr-cleanup.c:13:43: error: Expected ) after attribute's argument'
> diff --git a/validation/sizeof-void.c b/validation/sizeof-void.c
> index 0fd917a2..6792ff02 100644
> --- a/validation/sizeof-void.c
> +++ b/validation/sizeof-void.c
> @@ -36,7 +36,7 @@ sizeof-void.c:16:14: warning: expression using sizeof(void)
>  sizeof-void.c:17:14: warning: expression using sizeof(void)
>  sizeof-void.c:18:14: warning: expression using sizeof(void)
>  sizeof-void.c:19:14: warning: expression using sizeof(void)
> -sizeof-void.c:20:14: warning: expression using sizeof(void)
> +sizeof-void.c:20:27: warning: expression using sizeof(void)
>  sizeof-void.c:21:14: warning: expression using sizeof(void)
>  sizeof-void.c:22:14: warning: expression using sizeof(void)
>  sizeof-void.c:23:14: warning: expression using sizeof(void)


================================================================================

From: Chris Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse/pre-process: introduce "dissect_mode" option to fix dissect/semind
Date: Mon, 19 Jan 2026 00:21:54 +0000
Message-ID: <CACePvbWe8FoUjKvtaAyBtVdurMOE=c9zDuX_eNfGqouaQ0kDFg () mail ! gmail ! com>
--------------------
On Sat, Jan 17, 2026 at 6:19=E2=80=AFAM Oleg Nesterov <oleg@redhat.com> wro=
te:
>
> Hi Chris,
>
> On 01/16, Chris Li wrote:
> >
> > On Wed, Dec 17, 2025 at 7:26=E2=80=AFAM Oleg Nesterov <oleg@redhat.com>=
 wrote:
> > >
> > > I don't quite understand why does expand() -> collect_arg() path
> > > update ->pos for each token in the input *list, but this breaks
> > > dissect and thus semind.
> >
> > That is a good question, I don't understand why it did that either. I
> > did some digging, inside macro argument list expansion, the "#include
> > " is not allowed. It is not possible to switch streams here. The
> > "pos.pos" is for human consumption anyway, it has no effect on the IR
> > generation. The only visible effect as far as I can tell is related to
> > the preprocessor "-E" in lib.c:
> >
> >         if (preprocess_only) {
> >                 while (!eof_token(token)) {
> >                         int prec =3D 1;
> >                         struct token *next =3D token->next;
> >                         const char *separator =3D "";
> >                         if (next->pos.whitespace)
> >                                 separator =3D " ";
> >                         if (next->pos.newline) {
> >                                 separator =3D "\n\t\t\t\t\t";
> >                                 prec =3D next->pos.pos; <--- use pos as
> > indentation level.
> >                                 if (prec > 4)
> >                                         prec =3D 4;
> >                         }
> >                         printf("%s%.*s", show_token(token), prec, separ=
ator);
> >                         token =3D next;
> >
> > The "-E" output has some indentation enhancement to turn space into
> > tab level indentation. This "pos" assignment tries to align the
> > indentation context of the input arguments to the same level of the
> > expanding macro name.
>
> Yes, exactly! Initially I tried to simply remove these next->pos.* update=
s
> in collect_arg(), but this causes a lot of failures in validation/preproc=
essor
> (due to extra indentations) and I failed to find a simple fix for the
> "if (preprocess_only)" code above. Plus I wasn't comfortable because
> I don't understand the intent...

As far as I can tell, the new position report is more useful to the
reader. I haven't heard any objections yet. Let's put it on the
sparse-dev for a bit then merge into sparse. In the worst case there
is some burning reason to use the old behavior, we can always change
the behavior back. It is only  software and it is easy to fix.

>
> > >  void dissect(struct reporter *rep, struct string_list *filelist)
> > >  {
> > > +       dissect_mode =3D 1;
> >
> > I don't think we need dissect_mode. I am leaning towards enabling it
> > all the time, maybe except for the preprocessor only mode.
>
> ...
>
> > > +               if (!dissect_mode) {
> > > +                       next->pos.stream =3D pos->stream;
> > > +                       next->pos.line =3D pos->line;
> > > +                       next->pos.pos =3D pos->pos;
> > > +               }
> >
> > Maybe change it to "if (preprocess_only)", and fix all the validation
> > error output of the checker. What do you say?
>
> Agreed! This was my plan B ;)
>
> With this change
>
>         -               if (!dissect_mode) {
>         +               if (preprocess_only) {
>
> make check reports 2 failures
>
>         -parsing/attr-cleanup.c:10:17: error: argument is not an identifi=
er
>         +parsing/attr-cleanup.c:10:27: error: argument is not an identifi=
er
>
>         -sizeof-void.c:20:14: warning: expression using sizeof(void)
>         +sizeof-void.c:20:27: warning: expression using sizeof(void)
>
> but the new positions look more correct.
>
> However. I didn't dare to send this patch because other warnings from
> sizeof-void.c still blame the column 14, this looks inconsistent...
> But perhaps we don't really care?

Well, we care in the sense that we don't want unnecessary check
failures. But we can update the expected output of the validation
check to silence the error.

>
> So. I am going to update the changelog and send the trivial V2 below.
>
> Will you agree?

Agree. As far as I can tell. The new position is more desirable. Let's
switch to the new position.

Chris

>
> Oleg.
> ---
>
> diff --git a/pre-process.c b/pre-process.c
> index 3fb25082..a4bb6cb6 100644
> --- a/pre-process.c
> +++ b/pre-process.c
> @@ -294,9 +294,11 @@ static struct token *collect_arg(struct token *prev,=
 int vararg, struct position
>                 } else if (match_op(next, ',') && !nesting && !vararg) {
>                         break;
>                 }
> -               next->pos.stream =3D pos->stream;
> -               next->pos.line =3D pos->line;
> -               next->pos.pos =3D pos->pos;
> +               if (preprocess_only) {
> +                       next->pos.stream =3D pos->stream;
> +                       next->pos.line =3D pos->line;
> +                       next->pos.pos =3D pos->pos;
> +               }
>                 next->pos.newline =3D 0;
>                 p =3D &next->next;
>         }
> diff --git a/validation/parsing/attr-cleanup.c b/validation/parsing/attr-=
cleanup.c
> index ac64649c..fa3cb1ca 100644
> --- a/validation/parsing/attr-cleanup.c
> +++ b/validation/parsing/attr-cleanup.c
> @@ -24,7 +24,7 @@ int test(int n)
>   * check-command: sparse -Wunknown-attribute $file
>   *
>   * check-error-start
> -parsing/attr-cleanup.c:10:17: error: argument is not an identifier
> +parsing/attr-cleanup.c:10:27: error: argument is not an identifier
>  parsing/attr-cleanup.c:11:39: error: an argument is expected for attribu=
te 'cleanup'
>  parsing/attr-cleanup.c:12:40: error: an argument is expected for attribu=
te 'cleanup'
>  parsing/attr-cleanup.c:13:43: error: Expected ) after attribute's argume=
nt'
> diff --git a/validation/sizeof-void.c b/validation/sizeof-void.c
> index 0fd917a2..6792ff02 100644
> --- a/validation/sizeof-void.c
> +++ b/validation/sizeof-void.c
> @@ -36,7 +36,7 @@ sizeof-void.c:16:14: warning: expression using sizeof(v=
oid)
>  sizeof-void.c:17:14: warning: expression using sizeof(void)
>  sizeof-void.c:18:14: warning: expression using sizeof(void)
>  sizeof-void.c:19:14: warning: expression using sizeof(void)
> -sizeof-void.c:20:14: warning: expression using sizeof(void)
> +sizeof-void.c:20:27: warning: expression using sizeof(void)
>  sizeof-void.c:21:14: warning: expression using sizeof(void)
>  sizeof-void.c:22:14: warning: expression using sizeof(void)
>  sizeof-void.c:23:14: warning: expression using sizeof(void)
>

================================================================================

From: Chris Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse/pre-process: introduce "dissect_mode" option to fix dissect/semind
Date: Mon, 19 Jan 2026 00:23:37 +0000
Message-ID: <CACePvbXb+EJ9tdq=E8pw3uC-fjYp4CgQ27GqLwEgirWJiMVU6g () mail ! gmail ! com>
--------------------
On Sat, Jan 17, 2026 at 8:32=E2=80=AFAM Oleg Nesterov <oleg@redhat.com> wro=
te:
>
> On 01/17, Oleg Nesterov wrote:
> >
> > Agreed! This was my plan B ;)
> >
> > With this change
> >
> >       -               if (!dissect_mode) {
> >       +               if (preprocess_only) {
> >
> > make check reports 2 failures
> >
> >       -parsing/attr-cleanup.c:10:17: error: argument is not an identifi=
er
> >       +parsing/attr-cleanup.c:10:27: error: argument is not an identifi=
er
> >
> >       -sizeof-void.c:20:14: warning: expression using sizeof(void)
> >       +sizeof-void.c:20:27: warning: expression using sizeof(void)
> >
> > but the new positions look more correct.
> >
> > However. I didn't dare to send this patch because other warnings from
> > sizeof-void.c still blame the column 14, this looks inconsistent...
> > But perhaps we don't really care?
>
> On a 2nd thought...
>
> Unlike other warnings, this one (sizeof-void.c:20:27) refers to the
> inner "sizeof *ptr", so I think that this patch fixes the reported
> position. So yes, I think we don't care even if the new column =3D=3D 27
> differs from other warnings.
>
> What do you think?

I would just update the checker to have the new expected value
matching what new pos so validation can pass without errors.

Chris

================================================================================

From: Oleg Nesterov <oleg () redhat ! com>
To: linux-sparse
Subject: Re: [PATCH] sparse/pre-process: introduce "dissect_mode" option to fix dissect/semind
Date: Mon, 19 Jan 2026 12:32:56 +0000
Message-ID: <aW4keHjmqTS_S9ie () redhat ! com>
--------------------
On 01/18, Chris Li wrote:
>
> On Sat, Jan 17, 2026 at 8:32AM Oleg Nesterov <oleg@redhat.com> wrote:
> >
> > On a 2nd thought...
> >
> > Unlike other warnings, this one (sizeof-void.c:20:27) refers to the
> > inner "sizeof *ptr", so I think that this patch fixes the reported
> > position. So yes, I think we don't care even if the new column == 27
> > differs from other warnings.
> >
> > What do you think?
>
> I would just update the checker to have the new expected value
> matching what new pos so validation can pass without errors.

Yes, this is what I did. See

	[PATCH] sparse/pre-process: don't update next->pos in collect_arg()
	https://lore.kernel.org/all/aWz0V_zQ47afKFJy@redhat.com/

I was confused and tried to confuse you... let me explain. With this patch
./sparse -Wpointer-arith validation/sizeof-void.c outputs

	validation/sizeof-void.c:16:14: warning: expression using sizeof(void)
	validation/sizeof-void.c:17:14: warning: expression using sizeof(void)
	validation/sizeof-void.c:18:14: warning: expression using sizeof(void)
	validation/sizeof-void.c:19:14: warning: expression using sizeof(void)
	validation/sizeof-void.c:20:27: warning: expression using sizeof(void) // changed
	validation/sizeof-void.c:21:14: warning: expression using sizeof(void)
	validation/sizeof-void.c:22:14: warning: expression using sizeof(void)
	validation/sizeof-void.c:23:14: warning: expression using sizeof(void)

and somehow I wrongly came to conlusion that my patch is incomplete or
inconsistent because it only corrects the warning's position for the
line 20.

Now that I actually looked at validation/sizeof-void.c, I see that the
code at line 20

	s += is_constexpr(sizeof *ptr);

differs in that it is the inner "sizeof *ptr" which triggers the warning,
so I think the patch is fine.

Thank you,

Oleg.


================================================================================


################################################################################

=== Thread: [PATCH] sparse/semind: change r_member() to use r_symbol() when mem->kind == 'e' ===

From: Oleg Nesterov <oleg () redhat ! com>
To: linux-sparse
Subject: [PATCH] sparse/semind: change r_member() to use r_symbol() when mem->kind == 'e'
Date: Sun, 11 Jan 2026 17:28:14 +0000
Message-ID: <aWPdrkv4DTnGRHPf () redhat ! com>
--------------------
dissect() tries to provide as much info as possible, but from the
semind's perspective it doesn't make sense to store the enumerators
as members; this just complicates the searching.

Signed-off-by: Oleg Nesterov <oleg@redhat.com>
---
 semind.c | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/semind.c b/semind.c
index e9708444..92b8f243 100644
--- a/semind.c
+++ b/semind.c
@@ -746,6 +746,9 @@ static void r_member(unsigned mode, struct position *pos, struct symbol *sym, st
 	struct ident *ctx = &null;
 	struct index_record rec;
 
+	if (mem && mem->kind == 'e')
+		return r_symbol(mode, pos, mem);
+
 	update_stream();
 
 	if (semind_streams[pos->stream].id == -1)
-- 
2.52.0



================================================================================


################################################################################

=== Thread: [PATCH] sparse: add the new m_pos member into struct expression{EXPR_DEREF} ===

From: Chris Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse: add the new m_pos member into struct expression{EXPR_DEREF}
Date: Fri, 16 Jan 2026 22:55:34 +0000
Message-ID: <CACePvbWfwsu_gEUqfg47joLpD=UmO5Rj7hyoJFgiLzv5LyRFCw () mail ! gmail ! com>
--------------------
Hi Oleg,

Applied to sparse-dev.

Chris



Chris

On Tue, Dec 16, 2025 at 5:40=E2=80=AFAM Oleg Nesterov <oleg@redhat.com> wro=
te:
>
> Test-case:
>
>         $ cat -n MEMPOS.c
>              1  struct T {
>              2   int mem;
>              3  } X;
>              4
>              5  void func(struct T *x)
>              6  {
>              7   x -> mem =3D 1;
>              8   X .  mem =3D 2;
>              9  }
>
>         $ ./test-dissect MEMPOS.c | grep -F T.mem
>            2:6                    def   m T.mem                          =
  int
>            7:4   func             -w-   m T.mem                          =
  int
>            8:4   func             -w-   m T.mem                          =
  int
>
> Note that the reported position of .mem usage is wrong. This is because
> do_expression(EXPR_DEREF) uses &expr->pos which is position of TOKEN_SPEC=
IAL,
> not the position of the next token (mem).
>
> This also breaks "semind search -l" (search by location)
>
>         $ ./semind add MEMPOS.c
>         $ ./semind search -l MEMPOS.c:7:7
>
> reports nothing.
>
> With this patch:
>
>         $ ./test-dissect MEMPOS.c | grep -F T.mem
>            2:6                    def   m T.mem                          =
  int
>            7:7   func             -w-   m T.mem                          =
  int
>            8:7   func             -w-   m T.mem                          =
  int
>
>         $ ./semind add MEMPOS.c
>         $ ./semind search -l MEMPOS.c:7:7
>         (def) MEMPOS.c  2       6                int mem;
>         (-w-) MEMPOS.c  7       7       func     x -> mem =3D 1;
>         (-w-) MEMPOS.c  8       7       func     X .  mem =3D 2;
>
> Signed-off-by: Oleg Nesterov <oleg@redhat.com>
> ---
>  dissect.c    | 2 +-
>  expression.c | 1 +
>  expression.h | 1 +
>  3 files changed, 3 insertions(+), 1 deletion(-)
>
> diff --git a/dissect.c b/dissect.c
> index 9419c593..a6003afa 100644
> --- a/dissect.c
> +++ b/dissect.c
> @@ -454,7 +454,7 @@ again:
>                         p_mode =3D U_R_VAL;
>                 p_type =3D do_expression(p_mode, expr->deref);
>
> -               ret =3D report_member(mode, &expr->pos, p_type,
> +               ret =3D report_member(mode, &expr->m_pos, p_type,
>                         lookup_member(p_type, expr->member, NULL));
>         }
>
> diff --git a/expression.c b/expression.c
> index 727e7056..b23107da 100644
> --- a/expression.c
> +++ b/expression.c
> @@ -605,6 +605,7 @@ static struct token *postfix_expression(struct token =
*token, struct expression *
>                                 break;
>                         }
>                         deref->member =3D token->ident;
> +                       deref->m_pos =3D token->pos;
>                         token =3D token->next;
>                         expr =3D deref;
>                         continue;
> diff --git a/expression.h b/expression.h
> index 8bf40d32..ce8a29ce 100644
> --- a/expression.h
> +++ b/expression.h
> @@ -202,6 +202,7 @@ struct expression {
>                 struct /* deref_arg */ {
>                         struct expression *deref;
>                         struct ident *member;
> +                       struct position m_pos;
>                 };
>                 // EXPR_SLICE
>                 struct /* slice */ {
> --
> 2.52.0
>
>

================================================================================


################################################################################

=== Thread: [PATCH] sparse: update MAINTAINERS info. ===

From: Chris Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse: update MAINTAINERS info.
Date: Fri, 16 Jan 2026 23:31:30 +0000
Message-ID: <CACePvbVNiWKOHxT0GAtFUp7QcP7t43RZnZR75yM_SR28a6TNvA () mail ! gmail ! com>
--------------------
Acked-by: Chris LI <sparse@chrisli.org>

Chris

On Wed, Dec 17, 2025 at 10:09=E2=80=AFPM Randy Dunlap <rdunlap@infradead.or=
g> wrote:
>
> Chris Li is back as sparse maintainer.
>
> See https://git.kernel.org/pub/scm/devel/sparse/sparse.git/commit/?id=3D6=
7f0a03cee4637e495151c48a02be642a158cbbb
>
> Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
> ---
> Cc: Chris Li <sparse@chrisli.org>
> Cc: Andrew Morton <akpm@linux-foundation.org>
> Cc: linux-sparse@vger.kernel.org
> ---
>  MAINTAINERS |    2 +-
>  1 file changed, 1 insertion(+), 1 deletion(-)
>
> --- linux-next-20251217.orig/MAINTAINERS
> +++ linux-next-20251217/MAINTAINERS
> @@ -24595,7 +24595,7 @@ F:      drivers/tty/vcc.c
>  F:     include/linux/sunserialcore.h
>
>  SPARSE CHECKER
> -M:     "Luc Van Oostenryck" <luc.vanoostenryck@gmail.com>
> +M:     Chris Li <sparse@chrisli.org>
>  L:     linux-sparse@vger.kernel.org
>  S:     Maintained
>  W:     https://sparse.docs.kernel.org/

================================================================================


################################################################################

=== Thread: [PATCHv2 1/2] RISC-V: Stop warning about Zabha and Zacas ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: [PATCHv2 1/2] RISC-V: Stop warning about Zabha and Zacas
Date: Wed, 07 Jan 2026 21:30:10 +0000
Message-ID: <20260107213011.204578-1-ben.dooks () codethink ! co ! uk>
--------------------
The zabha (atomic byte and halfword) and zacas (atomic compare/swap)
are now being used by the kernel, so parse these and stop the warnings
when running make C=1 on current kernels.

WARNING: invalid argument to '-march': '_zacas_zabha'

Tested-by: Paul Walmsley <pjw@kernel.org>
Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
---
 target-riscv.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/target-riscv.c b/target-riscv.c
index d30be04b..80c25285 100644
--- a/target-riscv.c
+++ b/target-riscv.c
@@ -22,6 +22,8 @@
 #define RISCV_ZICBOM	(1 << 12)
 #define RISCV_ZIHINTPAUSE	(1 << 13)
 #define RISCV_VECTOR	(1 << 14)
+#define RISCV_ATOMIC_CAS (1 << 15)
+#define RISCV_ATOMIC_BH	 (1 << 16)
 
 static unsigned int riscv_flags;
 
@@ -43,6 +45,8 @@ static void parse_march_riscv(const char *arg)
 		{ "d",		RISCV_DOUBLE|RISCV_FDIV|RISCV_ZICSR },
 		{ "c",		RISCV_COMP },
 		{ "v",		RISCV_VECTOR|RISCV_FPU|RISCV_ZICSR },
+		{ "_zacas",	RISCV_ATOMIC_CAS },
+		{ "_zabha",	RISCV_ATOMIC_BH },
 		{ "_zicsr",	RISCV_ZICSR },
 		{ "_zifencei",	RISCV_ZIFENCEI },
 		{ "_zicbom",	RISCV_ZICBOM },
-- 
2.37.2.352.g3c44437643


================================================================================


################################################################################

=== Thread: [PATCHv2 2/2] RISC-V: restart extension search on match ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: [PATCHv2 2/2] RISC-V: restart extension search on match
Date: Wed, 07 Jan 2026 21:30:11 +0000
Message-ID: <20260107213011.204578-2-ben.dooks () codethink ! co ! uk>
--------------------
If we are passed multiple extensions in -march, don't assume these will
be in any sort of order. If we do match, then restart the loop by setting
the search back to 0, and retrying.

This sorts out issues with the current kernel build where there are now
lots of extensions for the rv64i and even adding zacas doesn't silence the
warnings generated.

Tested-by: Paul Walmsley <pjw@kernel.org>
Signed-off-by: Ben Dooks <ben.dooks@codethink.co.uk>
---
v2:
  - fixed accidental whitespace change.
---
 target-riscv.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/target-riscv.c b/target-riscv.c
index 80c25285..cd6104b2 100644
--- a/target-riscv.c
+++ b/target-riscv.c
@@ -80,6 +80,7 @@ ext:
 		if (!strncmp(arg, pat, len)) {
 			riscv_flags |= extensions[i].flags;
 			arg += len;
+			i = 0;
 		}
 	}
 	if (arg[0])
-- 
2.37.2.352.g3c44437643


================================================================================


################################################################################

=== Thread: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif ===

From: Ian Rogers <irogers () google ! com>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Wed, 14 Jan 2026 17:51:14 +0000
Message-ID: <CAP-5=fUyAtf9PQqYvagByK+-=-mN-T1zuLmxuvsPFVVHT3qLXA () mail ! gmail ! com>
--------------------
On Wed, Jan 14, 2026 at 8:37=E2=80=AFAM kernel test robot <lkp@intel.com> w=
rote:
>
> tree:   https://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git timer=
s/vdso
> head:   759a1f97373f25770cf438d9fb5f2bddf4d77a54
> commit: e04a494143bab7ea804fe1ebe286701ee8288e4a [12/14] vdso: Switch get=
/put_unaligned() from packed struct to memcpy()
> config: x86_64-randconfig-122-20260114 (https://download.01.org/0day-ci/a=
rchive/20260115/202601150001.sKSN644a-lkp@intel.com/config)
> compiler: clang version 20.1.8 (https://github.com/llvm/llvm-project 87f0=
227cb60147a26a1eeb4fb06e3b505e9c7261)
> rustc: rustc 1.88.0 (6b00bc388 2025-06-23)
> reproduce (this is a W=3D1 build): (https://download.01.org/0day-ci/archi=
ve/20260115/202601150001.sKSN644a-lkp@intel.com/reproduce)
>
> If you fix the issue in a separate patch/commit (i.e. not just a new vers=
ion of
> the same patch/commit), kindly add following tags
> | Reported-by: kernel test robot <lkp@intel.com>
> | Closes: https://lore.kernel.org/oe-kbuild-all/202601150001.sKSN644a-lkp=
@intel.com/
>
> sparse warnings: (new ones prefixed by >>)
> >> net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (d=
ifferent modifiers) @@     expected void * @@     got restricted __be64 con=
st * @@
>    net/rds/ib_cm.c:96:35: sparse:     expected void *
>    net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
>    net/rds/ib_cm.c:103:27: sparse: sparse: incorrect type in argument 1 (=
different modifiers) @@     expected void * @@     got restricted __be64 co=
nst * @@
>    net/rds/ib_cm.c:103:27: sparse:     expected void *
>    net/rds/ib_cm.c:103:27: sparse:     got restricted __be64 const *
>
> vim +96 net/rds/ib_cm.c
>
> ec16227e14141e Andy Grover                  2009-02-24   69
> ec16227e14141e Andy Grover                  2009-02-24   70  /*
> ec16227e14141e Andy Grover                  2009-02-24   71   * Connectio=
n established.
> ec16227e14141e Andy Grover                  2009-02-24   72   * We get he=
re for both outgoing and incoming connection.
> ec16227e14141e Andy Grover                  2009-02-24   73   */
> ec16227e14141e Andy Grover                  2009-02-24   74  void rds_ib_=
cm_connect_complete(struct rds_connection *conn, struct rdma_cm_event *even=
t)
> ec16227e14141e Andy Grover                  2009-02-24   75  {
> ec16227e14141e Andy Grover                  2009-02-24   76     struct rd=
s_ib_connection *ic =3D conn->c_transport_data;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   77     const uni=
on rds_ib_conn_priv *dp =3D NULL;

Here dp is a pointer to a constant value.

> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   78     __be64 ac=
k_seq =3D 0;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   79     __be32 cr=
edit =3D 0;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   80     u8 major =
=3D 0;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   81     u8 minor =
=3D 0;
> ec16227e14141e Andy Grover                  2009-02-24   82     int err;
> ec16227e14141e Andy Grover                  2009-02-24   83
> ec16227e14141e Andy Grover                  2009-02-24   84     dp =3D ev=
ent->param.conn.private_data;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   85     if (conn-=
>c_isv6) {
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   86             i=
f (event->param.conn.private_data_len >=3D
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   87              =
   sizeof(struct rds6_ib_connect_private)) {
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   88              =
       major =3D dp->ricp_v6.dp_protocol_major;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   89              =
       minor =3D dp->ricp_v6.dp_protocol_minor;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   90              =
       credit =3D dp->ricp_v6.dp_credit;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   91              =
       /* dp structure start is not guaranteed to be 8 bytes
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   92              =
        * aligned.  Since dp_ack_seq is 64-bit extended load
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   93              =
        * operations can be used so go through get_unaligned
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   94              =
        * to avoid unaligned errors.
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   95              =
        */
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  @96              =
       ack_seq =3D get_unaligned(&dp->ricp_v6.dp_ack_seq);

This is a warned about get_unaligned reported here.

In my patch:

+/**
+ * __get_unaligned_t - read an unaligned value from memory.
+ * @type:      the type to load from the pointer.
+ * @ptr:       the pointer to load from.
+ *
+ * Use memcpy to affect an unaligned type sized load avoiding
undefined behavior
+ * from approaches like type punning that require -fno-strict-aliasing in =
order
+ * to be correct. As type may be const, use __unqual_scalar_typeof to map =
to a
+ * non-const type - you can't memcpy into a const type. The
+ * __get_unaligned_ctrl_type gives __unqual_scalar_typeof its required
+ * expression rather than type, a pointer is used to avoid warnings
about mixing
+ * the use of 0 and NULL. The void* cast silences ubsan warnings.
+ */
+#define __get_unaligned_t(type, ptr) ({
         \
+       type *__get_unaligned_ctrl_type __always_unused =3D NULL;         \
+       __unqual_scalar_typeof(*__get_unaligned_ctrl_type)
__get_unaligned_val; \
+       __builtin_memcpy(&__get_unaligned_val, (void *)(ptr),           \
+                        sizeof(__get_unaligned_val));                  \
+       __get_unaligned_val;                                            \
 })

in "__builtin_memcpy(&__get_unaligned_val, (void *)(ptr)" there is a
void* cast and I believe this is what sparse is now warning about - I
don't believe the warning was present at the time of the original
series.

I believe, although it is a distant memory, I tried making the cast a
"(const void*)" cast rather than a "void*" cast but this caused
different warnings/issues. My patch is going through a compiler
warning, sparse, etc. wac-a-mole and the comment notes the cast is
present to avoid warnings with ubsan (undefined behavior sanitizer).

I think there are 2 options:
1) ignore the new sparse warning as tech debt for later clean up,
2) modify the cast to be "const void*" instead of "void *" and play
more wac-a-mole.

My preference would be 1 as I have a suspicion I played 2 and thought
the non-const cast was best (hence it being in the patch) given other
issues.

Thanks,
Ian


> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   97             }
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   98     } else if=
 (event->param.conn.private_data_len >=3D
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   99              =
  sizeof(struct rds_ib_connect_private)) {
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  100             m=
ajor =3D dp->ricp_v4.dp_protocol_major;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  101             m=
inor =3D dp->ricp_v4.dp_protocol_minor;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  102             c=
redit =3D dp->ricp_v4.dp_credit;
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  103             a=
ck_seq =3D get_unaligned(&dp->ricp_v4.dp_ack_seq);
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  104     }
> ec16227e14141e Andy Grover                  2009-02-24  105
> 02a6a2592e41d2 Andy Grover                  2009-07-17  106     /* make s=
ure it isn't empty data */
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  107     if (major=
) {
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  108             r=
ds_ib_set_protocol(conn, RDS_PROTOCOL(major, minor));
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  109             r=
ds_ib_set_flow_control(conn, be32_to_cpu(credit));
> 02a6a2592e41d2 Andy Grover                  2009-07-17  110     }
> ec16227e14141e Andy Grover                  2009-02-24  111
> cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  112     if (conn-=
>c_version < RDS_PROTOCOL_VERSION) {
> cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  113             i=
f (conn->c_version !=3D RDS_PROTOCOL_COMPAT_VERSION) {
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  114              =
       pr_notice("RDS/IB: Connection <%pI6c,%pI6c> version %u.%u no longer =
supported\n",
> ff3f19a2f608ee Santosh Shilimkar            2016-03-14  115              =
                 &conn->c_laddr, &conn->c_faddr,
> f147dd9ecabf23 Andy Grover                  2010-01-13  116              =
                 RDS_PROTOCOL_MAJOR(conn->c_version),
> f147dd9ecabf23 Andy Grover                  2010-01-13  117              =
                 RDS_PROTOCOL_MINOR(conn->c_version));
> f147dd9ecabf23 Andy Grover                  2010-01-13  118              =
       rds_conn_destroy(conn);
> f147dd9ecabf23 Andy Grover                  2010-01-13  119              =
       return;
> cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  120             }
> cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  121     }
> cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  122
> fd261ce6a30e01 Santosh Shilimkar            2018-10-13  123     pr_notice=
("RDS/IB: %s conn connected <%pI6c,%pI6c,%d> version %u.%u%s\n",
> 581d53c91cbf7b Santosh Shilimkar            2016-07-09  124              =
 ic->i_active_side ? "Active" : "Passive",
> fd261ce6a30e01 Santosh Shilimkar            2018-10-13  125              =
 &conn->c_laddr, &conn->c_faddr, conn->c_tos,
> ec16227e14141e Andy Grover                  2009-02-24  126              =
 RDS_PROTOCOL_MAJOR(conn->c_version),
> ec16227e14141e Andy Grover                  2009-02-24  127              =
 RDS_PROTOCOL_MINOR(conn->c_version),
> ec16227e14141e Andy Grover                  2009-02-24  128              =
 ic->i_flowctl ? ", flow control" : "");
> ec16227e14141e Andy Grover                  2009-02-24  129
> e0e6d062822529 Zhu Yanjun                   2019-08-23  130     /* receiv=
e sl from the peer */
> e0e6d062822529 Zhu Yanjun                   2019-08-23  131     ic->i_sl =
=3D ic->i_cm_id->route.path_rec->sl;
> e0e6d062822529 Zhu Yanjun                   2019-08-23  132
> cf657269d311d5 Santosh Shilimkar            2016-09-29  133     atomic_se=
t(&ic->i_cq_quiesce, 0);
> cf657269d311d5 Santosh Shilimkar            2016-09-29  134
> 581d53c91cbf7b Santosh Shilimkar            2016-07-09  135     /* Init r=
ings and fill recv. this needs to wait until protocol
> 581d53c91cbf7b Santosh Shilimkar            2016-07-09  136      * negoti=
ation is complete, since ring layout is different
> 581d53c91cbf7b Santosh Shilimkar            2016-07-09  137      * from 3=
.1 to 4.1.
> e11d912a7dd4df Andy Grover                  2009-07-17  138      */
> e11d912a7dd4df Andy Grover                  2009-07-17  139     rds_ib_se=
nd_init_ring(ic);
> e11d912a7dd4df Andy Grover                  2009-07-17  140     rds_ib_re=
cv_init_ring(ic);
> e11d912a7dd4df Andy Grover                  2009-07-17  141     /* Post r=
eceive buffers - as a side effect, this will update
> e11d912a7dd4df Andy Grover                  2009-07-17  142      * the po=
sted credit count. */
> 73ce4317bf9832 santosh.shilimkar@oracle.com 2015-08-22  143     rds_ib_re=
cv_refill(conn, 1, GFP_KERNEL);
> e11d912a7dd4df Andy Grover                  2009-07-17  144
> 3e0249f9c05cb7 Zach Brown                   2010-05-18  145     /* update=
 ib_device with this local ipaddr */
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  146     err =3D r=
ds_ib_update_ipaddr(ic->rds_ibdev, &conn->c_laddr);
> ec16227e14141e Andy Grover                  2009-02-24  147     if (err)
> 3e0249f9c05cb7 Zach Brown                   2010-05-18  148             p=
rintk(KERN_ERR "rds_ib_update_ipaddr failed (%d)\n",
> 3e0249f9c05cb7 Zach Brown                   2010-05-18  149              =
       err);
> ec16227e14141e Andy Grover                  2009-02-24  150
> ec16227e14141e Andy Grover                  2009-02-24  151     /* If the=
 peer gave us the last packet it saw, process this as if
> ec16227e14141e Andy Grover                  2009-02-24  152      * we had=
 received a regular ACK. */
> c0adf54a10903b shamir rabinovitch           2015-04-30  153     if (dp) {
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  154             i=
f (ack_seq)
> eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  155              =
       rds_send_drop_acked(conn, be64_to_cpu(ack_seq),
> c0adf54a10903b shamir rabinovitch           2015-04-30  156              =
                           NULL);
> c0adf54a10903b shamir rabinovitch           2015-04-30  157     }
> ec16227e14141e Andy Grover                  2009-02-24  158
> cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  159     conn->c_p=
roposed_version =3D conn->c_version;
> ec16227e14141e Andy Grover                  2009-02-24  160     rds_conne=
ct_complete(conn);
> ec16227e14141e Andy Grover                  2009-02-24  161  }
> ec16227e14141e Andy Grover                  2009-02-24  162
>
> :::::: The code at line 96 was first introduced by commit
> :::::: eee2fa6ab3225192d6d894c54a6fb02ac9efdff6 rds: Changing IP address =
internal representation to struct in6_addr
>
> :::::: TO: Ka-Cheong Poon <ka-cheong.poon@oracle.com>
> :::::: CC: David S. Miller <davem@davemloft.net>
>
> --
> 0-DAY CI Kernel Test Service
> https://github.com/intel/lkp-tests/wiki

================================================================================

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Wed, 14 Jan 2026 20:04:22 +0000
Message-ID: <874ioohsft.ffs () tglx>
--------------------
On Wed, Jan 14 2026 at 09:51, Ian Rogers wrote:
> On Wed, Jan 14, 2026 at 8:37=E2=80=AFAM kernel test robot <lkp@intel.com>=
 wrote:
> I think there are 2 options:
> 1) ignore the new sparse warning as tech debt for later clean up,
> 2) modify the cast to be "const void*" instead of "void *" and play
> more wac-a-mole.

Option #3:

You might have tried the 'const void*' cast and figured out that sparse
is still unhappy. I actually did, but I didn't try to figure out why as
that's really not my duty.

> My preference would be 1 as I have a suspicion I played 2 and thought
> the non-const cast was best (hence it being in the patch) given other
> issues.

Preferences based on suspicions are not really usefull. Please go and
figure out what's going on and either fix it in the kernel code or tell
the sparse folks what they are missing.

Leaving it unresolved and handwaved away is not an option.

Thanks,

        tglx

================================================================================

From: Ian Rogers <irogers () google ! com>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Wed, 14 Jan 2026 21:03:31 +0000
Message-ID: <CAP-5=fVGnY37bCOUHx_tCgQ=K55CcSOzs98Hg2Mh7KF4Mbya+g () mail ! gmail ! com>
--------------------
On Wed, Jan 14, 2026 at 12:04=E2=80=AFPM Thomas Gleixner <tglx@kernel.org> =
wrote:
>
> On Wed, Jan 14 2026 at 09:51, Ian Rogers wrote:
> > On Wed, Jan 14, 2026 at 8:37=E2=80=AFAM kernel test robot <lkp@intel.co=
m> wrote:
> > I think there are 2 options:
> > 1) ignore the new sparse warning as tech debt for later clean up,
> > 2) modify the cast to be "const void*" instead of "void *" and play
> > more wac-a-mole.
>
> Option #3:
>
> You might have tried the 'const void*' cast and figured out that sparse
> is still unhappy. I actually did, but I didn't try to figure out why as
> that's really not my duty.
>
> > My preference would be 1 as I have a suspicion I played 2 and thought
> > the non-const cast was best (hence it being in the patch) given other
> > issues.
>
> Preferences based on suspicions are not really usefull. Please go and
> figure out what's going on and either fix it in the kernel code or tell
> the sparse folks what they are missing.
>
> Leaving it unresolved and handwaved away is not an option.

I'd like to call this option, play a bunch of wac-a-mole but then
still don't really progress. I had tried out I believe all the options
6 months ago where the builds were clean. There's always 1 more tool
that's going to raise its head and complain about types, my motivation
remains clang and gcc for user space copies of this code so we don't
need to propagate -fno-strict-aliasing into places like perf. Tbh, I'm
not going to be able to look at this for a while so I'd suggest just
dropping the patches.

Thanks,
Ian

> Thanks,
>
>         tglx

================================================================================

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Wed, 14 Jan 2026 21:27:06 +0000
Message-ID: <871pjrj36d.ffs () tglx>
--------------------
On Wed, Jan 14 2026 at 13:03, Ian Rogers wrote:
> On Wed, Jan 14, 2026 at 12:04=E2=80=AFPM Thomas Gleixner <tglx@kernel.org=
> wrote:
>> > My preference would be 1 as I have a suspicion I played 2 and thought
>> > the non-const cast was best (hence it being in the patch) given other
>> > issues.
>>
>> Preferences based on suspicions are not really usefull. Please go and
>> figure out what's going on and either fix it in the kernel code or tell
>> the sparse folks what they are missing.
>>
>> Leaving it unresolved and handwaved away is not an option.
>
> I'd like to call this option, play a bunch of wac-a-mole but then

I'm not familiar enough with internet slang, but to my limited knowledge
it's spelled 'Whack-a-mole'. That aside:

     "Whack-a-mole" without a real conclusive explanation is really a
      lame excuse, actually it's beyond lame.

> still don't really progress. I had tried out I believe all the options
> 6 months ago where the builds were clean. There's always 1 more tool
> that's going to raise its head and complain about types, my motivation
> remains clang and gcc for user space copies of this code so we don't
> need to propagate -fno-strict-aliasing into places like perf.

So because your motivation ends there and other tools which raise their
ugly heads are not relevant to you ...

> Tbh, I'm not going to be able to look at this for a while so I'd
> suggest just dropping the patches.

... everything stays with the status quo, i.e. unresolved.

That makes a lot of sense - NOT!

Thanks for wasting my time to deal with your patches and welcome to my
extremly short ignore list!

Your's grumpy

       Thomas




================================================================================

From: Ian Rogers <irogers () google ! com>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Wed, 14 Jan 2026 21:42:06 +0000
Message-ID: <CAP-5=fWgReuXY5im5-qCMBmryZHkRcZCLTkU6YzOSGJwufnYJg () mail ! gmail ! com>
--------------------
On Wed, Jan 14, 2026 at 1:27=E2=80=AFPM Thomas Gleixner <tglx@kernel.org> w=
rote:
>
> On Wed, Jan 14 2026 at 13:03, Ian Rogers wrote:
> > On Wed, Jan 14, 2026 at 12:04=E2=80=AFPM Thomas Gleixner <tglx@kernel.o=
rg> wrote:
> >> > My preference would be 1 as I have a suspicion I played 2 and though=
t
> >> > the non-const cast was best (hence it being in the patch) given othe=
r
> >> > issues.
> >>
> >> Preferences based on suspicions are not really usefull. Please go and
> >> figure out what's going on and either fix it in the kernel code or tel=
l
> >> the sparse folks what they are missing.
> >>
> >> Leaving it unresolved and handwaved away is not an option.
> >
> > I'd like to call this option, play a bunch of wac-a-mole but then
>
> I'm not familiar enough with internet slang, but to my limited knowledge
> it's spelled 'Whack-a-mole'. That aside:
>
>      "Whack-a-mole" without a real conclusive explanation is really a
>       lame excuse, actually it's beyond lame.
>
> > still don't really progress. I had tried out I believe all the options
> > 6 months ago where the builds were clean. There's always 1 more tool
> > that's going to raise its head and complain about types, my motivation
> > remains clang and gcc for user space copies of this code so we don't
> > need to propagate -fno-strict-aliasing into places like perf.
>
> So because your motivation ends there and other tools which raise their
> ugly heads are not relevant to you ...
>
> > Tbh, I'm not going to be able to look at this for a while so I'd
> > suggest just dropping the patches.
>
> ... everything stays with the status quo, i.e. unresolved.
>
> That makes a lot of sense - NOT!
>
> Thanks for wasting my time to deal with your patches and welcome to my
> extremly short ignore list!

The patches have been through 5 versions with considerable hurdles
jumped, testing my ending, both kernel building and user space tool
building and running with sanitizers, etc. My work commitments mean I
can't just leap up and say I'm going to explore the ramifications of
moving the (void*) to (const void*) in all these combinations again,
but as a a const lover (even having published papers on it [1]) I
doubt the choice of using "void*" rather than "const void*" is likely
no accident. Even if I come up with a new series, waiting months for
any kind of review, merging, feedback, .. I'm just left in limbo and I
lose the context that I've built up and we end up here. In perf
changes we often end up with good patches vs perfect patches and I
don't believe with these patches we'll ever get perfect, hence saying
we should move forward even with the sparse regression that may only
be fixable with #ifdef DOING_A_SPARSE_BUILD... Given the bar seems to
be perfect, I'm recommending just dropping the patches.

Sorry to be on your ignore list,
Ian

[1] https://research.manchester.ac.uk/en/publications/constraint-based-opti=
mization-of-stationary-fields/

> Your's grumpy
>
>        Thomas
>
>
>

================================================================================

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-sparse
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 19:28:51 +0000
Message-ID: <87v7h23cb0.ffs () tglx>
--------------------
On Thu, Jan 15 2026 at 00:36, kernel test robot wrote:

Cc+ sparse folks.

> sparse warnings: (new ones prefixed by >>)
>>> net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
>    net/rds/ib_cm.c:96:35: sparse:     expected void *
>    net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
>    net/rds/ib_cm.c:103:27: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
>    net/rds/ib_cm.c:103:27: sparse:     expected void *
>    net/rds/ib_cm.c:103:27: sparse:     got restricted __be64 const *

After staring a while at it, it turns out that get_unaligned_t(), which
uses __unqual_scalar_typeof() to get an unqualified type makes sparse
unhappy when the data type is __be64 (or any other __beNN variant).

__beNN is annotated with __attribute__((bitwise)) when sparse is invoked
(#ifdef CHECKER). That allows sparse to detect incompatible math
operations with __beNN variables.

That annotation also causes the type comparison in the sparse _Generic()
evaluation to fail so that it ends up with the default, i.e. the
original qualified type of a 'const __beNN' pointer. That then ends up as
the first pointer argument to builtin_memcpy(), which obviously causes
the above sparse warnings.

The easiest solution would be to force cast the pointer to void * when
CHECKER is defined, but that reduces coverage.

I've come up with the below, but it's clearly a hack... __CAST_SPARSE()
is required as sparse otherwise complains about storing __u64 in __be64.

Thanks,

        tglx
---
 include/linux/compiler_types.h |   10 ++++++++++
 include/vdso/unaligned.h       |   16 +++++++++++-----
 2 files changed, 21 insertions(+), 5 deletions(-)

--- a/include/linux/compiler_types.h
+++ b/include/linux/compiler_types.h
@@ -577,6 +577,15 @@ struct ftrace_likely_data {
 		unsigned type:	(unsigned type)0,			\
 		signed type:	(signed type)0
 
+#ifdef __CHECKER__
+#define __be_types_expr_cases()						\
+	__be16: (__u16)0,						\
+	__be32: (__u32)0,						\
+	__be64: (__u64)0,
+#else
+#define __be_types_expr_cases()
+#endif
+
 #define __unqual_scalar_typeof(x) typeof(				\
 		_Generic((x),						\
 			 char:	(char)0,				\
@@ -585,6 +594,7 @@ struct ftrace_likely_data {
 			 __scalar_type_to_expr_cases(int),		\
 			 __scalar_type_to_expr_cases(long),		\
 			 __scalar_type_to_expr_cases(long long),	\
+			 __be_types_expr_cases()			\
 			 default: (x)))
 
 /* Is this type a native word size -- useful for atomic operations */
--- a/include/vdso/unaligned.h
+++ b/include/vdso/unaligned.h
@@ -4,6 +4,12 @@
 
 #include <linux/compiler_types.h>
 
+#ifdef __CHECKER__
+#define __CAST_SPARSE(type) (type __force)
+#else
+#define __CAST_SPARSE(type)
+#endif
+
 /**
  * __get_unaligned_t - read an unaligned value from memory.
  * @type:	the type to load from the pointer.
@@ -17,12 +23,12 @@
  * expression rather than type, a pointer is used to avoid warnings about mixing
  * the use of 0 and NULL. The void* cast silences ubsan warnings.
  */
-#define __get_unaligned_t(type, ptr) ({					\
-	type *__get_unaligned_ctrl_type __always_unused = NULL;		\
+#define __get_unaligned_t(type, ptr) ({						\
+	type *__get_unaligned_ctrl_type __always_unused = NULL;			\
 	__unqual_scalar_typeof(*__get_unaligned_ctrl_type) __get_unaligned_val; \
-	__builtin_memcpy(&__get_unaligned_val, (void *)(ptr),		\
-			 sizeof(__get_unaligned_val));			\
-	__get_unaligned_val;						\
+	__builtin_memcpy(&__get_unaligned_val, (void *)(ptr),			\
+			 sizeof(__get_unaligned_val));				\
+	__CAST_SPARSE(type) __get_unaligned_val;				\
 })
 
 /**




    

      

================================================================================

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 19:28:51 +0000
Message-ID: <87v7h23cb0.ffs () tglx>
--------------------
On Thu, Jan 15 2026 at 00:36, kernel test robot wrote:

Cc+ sparse folks.

> sparse warnings: (new ones prefixed by >>)
>>> net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
>    net/rds/ib_cm.c:96:35: sparse:     expected void *
>    net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
>    net/rds/ib_cm.c:103:27: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
>    net/rds/ib_cm.c:103:27: sparse:     expected void *
>    net/rds/ib_cm.c:103:27: sparse:     got restricted __be64 const *

After staring a while at it, it turns out that get_unaligned_t(), which
uses __unqual_scalar_typeof() to get an unqualified type makes sparse
unhappy when the data type is __be64 (or any other __beNN variant).

__beNN is annotated with __attribute__((bitwise)) when sparse is invoked
(#ifdef CHECKER). That allows sparse to detect incompatible math
operations with __beNN variables.

That annotation also causes the type comparison in the sparse _Generic()
evaluation to fail so that it ends up with the default, i.e. the
original qualified type of a 'const __beNN' pointer. That then ends up as
the first pointer argument to builtin_memcpy(), which obviously causes
the above sparse warnings.

The easiest solution would be to force cast the pointer to void * when
CHECKER is defined, but that reduces coverage.

I've come up with the below, but it's clearly a hack... __CAST_SPARSE()
is required as sparse otherwise complains about storing __u64 in __be64.

Thanks,

        tglx
---
 include/linux/compiler_types.h |   10 ++++++++++
 include/vdso/unaligned.h       |   16 +++++++++++-----
 2 files changed, 21 insertions(+), 5 deletions(-)

--- a/include/linux/compiler_types.h
+++ b/include/linux/compiler_types.h
@@ -577,6 +577,15 @@ struct ftrace_likely_data {
 		unsigned type:	(unsigned type)0,			\
 		signed type:	(signed type)0
 
+#ifdef __CHECKER__
+#define __be_types_expr_cases()						\
+	__be16: (__u16)0,						\
+	__be32: (__u32)0,						\
+	__be64: (__u64)0,
+#else
+#define __be_types_expr_cases()
+#endif
+
 #define __unqual_scalar_typeof(x) typeof(				\
 		_Generic((x),						\
 			 char:	(char)0,				\
@@ -585,6 +594,7 @@ struct ftrace_likely_data {
 			 __scalar_type_to_expr_cases(int),		\
 			 __scalar_type_to_expr_cases(long),		\
 			 __scalar_type_to_expr_cases(long long),	\
+			 __be_types_expr_cases()			\
 			 default: (x)))
 
 /* Is this type a native word size -- useful for atomic operations */
--- a/include/vdso/unaligned.h
+++ b/include/vdso/unaligned.h
@@ -4,6 +4,12 @@
 
 #include <linux/compiler_types.h>
 
+#ifdef __CHECKER__
+#define __CAST_SPARSE(type) (type __force)
+#else
+#define __CAST_SPARSE(type)
+#endif
+
 /**
  * __get_unaligned_t - read an unaligned value from memory.
  * @type:	the type to load from the pointer.
@@ -17,12 +23,12 @@
  * expression rather than type, a pointer is used to avoid warnings about mixing
  * the use of 0 and NULL. The void* cast silences ubsan warnings.
  */
-#define __get_unaligned_t(type, ptr) ({					\
-	type *__get_unaligned_ctrl_type __always_unused = NULL;		\
+#define __get_unaligned_t(type, ptr) ({						\
+	type *__get_unaligned_ctrl_type __always_unused = NULL;			\
 	__unqual_scalar_typeof(*__get_unaligned_ctrl_type) __get_unaligned_val; \
-	__builtin_memcpy(&__get_unaligned_val, (void *)(ptr),		\
-			 sizeof(__get_unaligned_val));			\
-	__get_unaligned_val;						\
+	__builtin_memcpy(&__get_unaligned_val, (void *)(ptr),			\
+			 sizeof(__get_unaligned_val));				\
+	__CAST_SPARSE(type) __get_unaligned_val;				\
 })
 
 /**




    

      

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 21:11:20 +0000
Message-ID: <20260115211120.GD831050 () noisy ! programming ! kicks-ass ! net>
--------------------
On Thu, Jan 15, 2026 at 08:28:51PM +0100, Thomas Gleixner wrote:
> On Thu, Jan 15 2026 at 00:36, kernel test robot wrote:
> 
> Cc+ sparse folks.
> 
> > sparse warnings: (new ones prefixed by >>)
> >>> net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
> >    net/rds/ib_cm.c:96:35: sparse:     expected void *
> >    net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
> >    net/rds/ib_cm.c:103:27: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
> >    net/rds/ib_cm.c:103:27: sparse:     expected void *
> >    net/rds/ib_cm.c:103:27: sparse:     got restricted __be64 const *
> 
> After staring a while at it, it turns out that get_unaligned_t(), which
> uses __unqual_scalar_typeof() to get an unqualified type makes sparse
> unhappy when the data type is __be64 (or any other __beNN variant).
> 
> __beNN is annotated with __attribute__((bitwise)) when sparse is invoked
> (#ifdef CHECKER). That allows sparse to detect incompatible math
> operations with __beNN variables.
> 

Per:

  https://git.kernel.org/pub/scm/devel/sparse/sparse-dev.git/commit/?id=dc9efe442b8949234a6599fdc94dc7221dd040e1

it seems Sparse now knows about __typeof_unqual__; and it looks like the
implementation does what you want here (although I've not tested it).

Something like so perhaps, which then mandates the very latest Sparse.

---
diff --git a/include/linux/compiler.h b/include/linux/compiler.h
index 04487c9bd751..7e0583ceb49f 100644
--- a/include/linux/compiler.h
+++ b/include/linux/compiler.h
@@ -232,11 +232,8 @@ void ftrace_likely_update(struct ftrace_likely_data *f, int val,
 
 /*
  * Use __typeof_unqual__() when available.
- *
- * XXX: Remove test for __CHECKER__ once
- * sparse learns about __typeof_unqual__().
  */
-#if CC_HAS_TYPEOF_UNQUAL && !defined(__CHECKER__)
+#if CC_HAS_TYPEOF_UNQUAL || defined(__CHECKER__)
 # define USE_TYPEOF_UNQUAL 1
 #endif
 
diff --git a/include/linux/compiler_types.h b/include/linux/compiler_types.h
index d3318a3c2577..a37d832d99a8 100644
--- a/include/linux/compiler_types.h
+++ b/include/linux/compiler_types.h
@@ -569,6 +569,7 @@ struct ftrace_likely_data {
  * __unqual_scalar_typeof(x) - Declare an unqualified scalar type, leaving
  *			       non-scalar types unchanged.
  */
+#ifndef USE_TYPEOF_UNQUAL
 /*
  * Prefer C11 _Generic for better compile-times and simpler code. Note: 'char'
  * is not type-compatible with 'signed char', and we define a separate case.
@@ -586,6 +587,9 @@ struct ftrace_likely_data {
 			 __scalar_type_to_expr_cases(long),		\
 			 __scalar_type_to_expr_cases(long long),	\
 			 default: (x)))
+#else
+#define __unqual_scalar_typeof(x) __typeof_unqual__(x)
+#endif
 
 /* Is this type a native word size -- useful for atomic operations */
 #define __native_word(t) \

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-sparse
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 21:11:20 +0000
Message-ID: <20260115211120.GD831050 () noisy ! programming ! kicks-ass ! net>
--------------------
On Thu, Jan 15, 2026 at 08:28:51PM +0100, Thomas Gleixner wrote:
> On Thu, Jan 15 2026 at 00:36, kernel test robot wrote:
> 
> Cc+ sparse folks.
> 
> > sparse warnings: (new ones prefixed by >>)
> >>> net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
> >    net/rds/ib_cm.c:96:35: sparse:     expected void *
> >    net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
> >    net/rds/ib_cm.c:103:27: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
> >    net/rds/ib_cm.c:103:27: sparse:     expected void *
> >    net/rds/ib_cm.c:103:27: sparse:     got restricted __be64 const *
> 
> After staring a while at it, it turns out that get_unaligned_t(), which
> uses __unqual_scalar_typeof() to get an unqualified type makes sparse
> unhappy when the data type is __be64 (or any other __beNN variant).
> 
> __beNN is annotated with __attribute__((bitwise)) when sparse is invoked
> (#ifdef CHECKER). That allows sparse to detect incompatible math
> operations with __beNN variables.
> 

Per:

  https://git.kernel.org/pub/scm/devel/sparse/sparse-dev.git/commit/?id=dc9efe442b8949234a6599fdc94dc7221dd040e1

it seems Sparse now knows about __typeof_unqual__; and it looks like the
implementation does what you want here (although I've not tested it).

Something like so perhaps, which then mandates the very latest Sparse.

---
diff --git a/include/linux/compiler.h b/include/linux/compiler.h
index 04487c9bd751..7e0583ceb49f 100644
--- a/include/linux/compiler.h
+++ b/include/linux/compiler.h
@@ -232,11 +232,8 @@ void ftrace_likely_update(struct ftrace_likely_data *f, int val,
 
 /*
  * Use __typeof_unqual__() when available.
- *
- * XXX: Remove test for __CHECKER__ once
- * sparse learns about __typeof_unqual__().
  */
-#if CC_HAS_TYPEOF_UNQUAL && !defined(__CHECKER__)
+#if CC_HAS_TYPEOF_UNQUAL || defined(__CHECKER__)
 # define USE_TYPEOF_UNQUAL 1
 #endif
 
diff --git a/include/linux/compiler_types.h b/include/linux/compiler_types.h
index d3318a3c2577..a37d832d99a8 100644
--- a/include/linux/compiler_types.h
+++ b/include/linux/compiler_types.h
@@ -569,6 +569,7 @@ struct ftrace_likely_data {
  * __unqual_scalar_typeof(x) - Declare an unqualified scalar type, leaving
  *			       non-scalar types unchanged.
  */
+#ifndef USE_TYPEOF_UNQUAL
 /*
  * Prefer C11 _Generic for better compile-times and simpler code. Note: 'char'
  * is not type-compatible with 'signed char', and we define a separate case.
@@ -586,6 +587,9 @@ struct ftrace_likely_data {
 			 __scalar_type_to_expr_cases(long),		\
 			 __scalar_type_to_expr_cases(long long),	\
 			 default: (x)))
+#else
+#define __unqual_scalar_typeof(x) __typeof_unqual__(x)
+#endif
 
 /* Is this type a native word size -- useful for atomic operations */
 #define __native_word(t) \

================================================================================

From: Linus Torvalds <torvalds () linux-foundation ! org>
To: linux-sparse
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 21:19:14 +0000
Message-ID: <CAHk-=wg9pxiKm3kcZ0XQrFvz6fFek_A1WGqRh9yeghx3pE2d3w () mail ! gmail ! com>
--------------------
On Thu, 15 Jan 2026 at 13:13, Peter Zijlstra <peterz@infradead.org> wrote:
>
> Something like so perhaps, which then mandates the very latest Sparse.

Ack. We want that compiler_tpes.h change for the real compilers that
support __typeof_unqual__ anyway.

Eventually we can just force that everywhere, but as Al pointed out in
another thread, we're not quite there yet (ie we'd need clang-19.0.1
and gcc-8.4 to be able to just switch entirely over to
__typeof_unqual__).

For sparse users, I think we should have the policy that we just don't
support older versions at all, since it just gets too painful.

                 Linus

================================================================================

From: Linus Torvalds <torvalds () linux-foundation ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 21:19:14 +0000
Message-ID: <CAHk-=wg9pxiKm3kcZ0XQrFvz6fFek_A1WGqRh9yeghx3pE2d3w () mail ! gmail ! com>
--------------------
On Thu, 15 Jan 2026 at 13:13, Peter Zijlstra <peterz@infradead.org> wrote:
>
> Something like so perhaps, which then mandates the very latest Sparse.

Ack. We want that compiler_tpes.h change for the real compilers that
support __typeof_unqual__ anyway.

Eventually we can just force that everywhere, but as Al pointed out in
another thread, we're not quite there yet (ie we'd need clang-19.0.1
and gcc-8.4 to be able to just switch entirely over to
__typeof_unqual__).

For sparse users, I think we should have the policy that we just don't
support older versions at all, since it just gets too painful.

                 Linus

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-sparse
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 21:30:54 +0000
Message-ID: <20260115213054.GF831050 () noisy ! programming ! kicks-ass ! net>
--------------------
On Thu, Jan 15, 2026 at 01:19:14PM -0800, Linus Torvalds wrote:

> Eventually we can just force that everywhere, but as Al pointed out in
> another thread, we're not quite there yet (ie we'd need clang-19.0.1
> and gcc-8.4 to be able to just switch entirely over to
> __typeof_unqual__).

GCC-14 :-/ The GCC-8.4 one was the function return value trick.

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 21:30:54 +0000
Message-ID: <20260115213054.GF831050 () noisy ! programming ! kicks-ass ! net>
--------------------
On Thu, Jan 15, 2026 at 01:19:14PM -0800, Linus Torvalds wrote:

> Eventually we can just force that everywhere, but as Al pointed out in
> another thread, we're not quite there yet (ie we'd need clang-19.0.1
> and gcc-8.4 to be able to just switch entirely over to
> __typeof_unqual__).

GCC-14 :-/ The GCC-8.4 one was the function return value trick.

================================================================================

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 23:01:19 +0000
Message-ID: <87ms2e32gw.ffs () tglx>
--------------------
On Thu, Jan 15 2026 at 22:11, Peter Zijlstra wrote:

> On Thu, Jan 15, 2026 at 08:28:51PM +0100, Thomas Gleixner wrote:
>> On Thu, Jan 15 2026 at 00:36, kernel test robot wrote:
>> 
>> Cc+ sparse folks.
>> 
>> > sparse warnings: (new ones prefixed by >>)
>> >>> net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
>> >    net/rds/ib_cm.c:96:35: sparse:     expected void *
>> >    net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
>> >    net/rds/ib_cm.c:103:27: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
>> >    net/rds/ib_cm.c:103:27: sparse:     expected void *
>> >    net/rds/ib_cm.c:103:27: sparse:     got restricted __be64 const *
>> 
>> After staring a while at it, it turns out that get_unaligned_t(), which
>> uses __unqual_scalar_typeof() to get an unqualified type makes sparse
>> unhappy when the data type is __be64 (or any other __beNN variant).
>> 
>> __beNN is annotated with __attribute__((bitwise)) when sparse is invoked
>> (#ifdef CHECKER). That allows sparse to detect incompatible math
>> operations with __beNN variables.
>> 
>
> Per:
>
>   https://git.kernel.org/pub/scm/devel/sparse/sparse-dev.git/commit/?id=dc9efe442b8949234a6599fdc94dc7221dd040e1
>
> it seems Sparse now knows about __typeof_unqual__; and it looks like the
> implementation does what you want here (although I've not tested it).
>
> Something like so perhaps, which then mandates the very latest Sparse.

I tried that before and sparse is still upset:

  net/rds/ib_cm.c:96:35: warning: incorrect type in argument 1 (different modifiers)
  net/rds/ib_cm.c:96:35:    expected void *
  net/rds/ib_cm.c:96:35:    got restricted __be64 const *
  net/rds/ib_cm.c:103:27: warning: incorrect type in argument 1 (different modifiers)
  net/rds/ib_cm.c:103:27:    expected void *
  net/rds/ib_cm.c:103:27:    got restricted __be64 const *

This time I looked deeper and it seems that USE_TYPEOF_UNQUAL is not
set.

If I force it to be set and use a proper compiler and top of tree
sparse, everything seems to be happy.

Figuring that out is something for tomorrow...

Thanks,

        tglx


================================================================================

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-sparse
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 23:01:19 +0000
Message-ID: <87ms2e32gw.ffs () tglx>
--------------------
On Thu, Jan 15 2026 at 22:11, Peter Zijlstra wrote:

> On Thu, Jan 15, 2026 at 08:28:51PM +0100, Thomas Gleixner wrote:
>> On Thu, Jan 15 2026 at 00:36, kernel test robot wrote:
>> 
>> Cc+ sparse folks.
>> 
>> > sparse warnings: (new ones prefixed by >>)
>> >>> net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
>> >    net/rds/ib_cm.c:96:35: sparse:     expected void *
>> >    net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
>> >    net/rds/ib_cm.c:103:27: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
>> >    net/rds/ib_cm.c:103:27: sparse:     expected void *
>> >    net/rds/ib_cm.c:103:27: sparse:     got restricted __be64 const *
>> 
>> After staring a while at it, it turns out that get_unaligned_t(), which
>> uses __unqual_scalar_typeof() to get an unqualified type makes sparse
>> unhappy when the data type is __be64 (or any other __beNN variant).
>> 
>> __beNN is annotated with __attribute__((bitwise)) when sparse is invoked
>> (#ifdef CHECKER). That allows sparse to detect incompatible math
>> operations with __beNN variables.
>> 
>
> Per:
>
>   https://git.kernel.org/pub/scm/devel/sparse/sparse-dev.git/commit/?id=dc9efe442b8949234a6599fdc94dc7221dd040e1
>
> it seems Sparse now knows about __typeof_unqual__; and it looks like the
> implementation does what you want here (although I've not tested it).
>
> Something like so perhaps, which then mandates the very latest Sparse.

I tried that before and sparse is still upset:

  net/rds/ib_cm.c:96:35: warning: incorrect type in argument 1 (different modifiers)
  net/rds/ib_cm.c:96:35:    expected void *
  net/rds/ib_cm.c:96:35:    got restricted __be64 const *
  net/rds/ib_cm.c:103:27: warning: incorrect type in argument 1 (different modifiers)
  net/rds/ib_cm.c:103:27:    expected void *
  net/rds/ib_cm.c:103:27:    got restricted __be64 const *

This time I looked deeper and it seems that USE_TYPEOF_UNQUAL is not
set.

If I force it to be set and use a proper compiler and top of tree
sparse, everything seems to be happy.

Figuring that out is something for tomorrow...

Thanks,

        tglx


================================================================================

From: Linus Torvalds <torvalds () linux-foundation ! org>
To: linux-sparse
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 23:03:52 +0000
Message-ID: <CAHk-=wgXxY4NTZW8rcrXqx3h=j+t2445VWccbpywXYdoL_V0qA () mail ! gmail ! com>
--------------------
On Thu, 15 Jan 2026 at 13:31, Peter Zijlstra <peterz@infradead.org> wrote:
>
> GCC-14 :-/ The GCC-8.4 one was the function return value trick.

Right you are. And yeah, us moving on to gcc-14 as a minimum version
is not imminent.

Still, while we can't force it, lots of distros are on gcc-15, so
while we'd have the _Generic() macro as a fallback for older versions,
at least most developers would hopefully get the nice clean modern
__typeof_unqual__ thing...

           Linus

================================================================================

From: Linus Torvalds <torvalds () linux-foundation ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Thu, 15 Jan 2026 23:03:52 +0000
Message-ID: <CAHk-=wgXxY4NTZW8rcrXqx3h=j+t2445VWccbpywXYdoL_V0qA () mail ! gmail ! com>
--------------------
On Thu, 15 Jan 2026 at 13:31, Peter Zijlstra <peterz@infradead.org> wrote:
>
> GCC-14 :-/ The GCC-8.4 one was the function return value trick.

Right you are. And yeah, us moving on to gcc-14 as a minimum version
is not imminent.

Still, while we can't force it, lots of distros are on gcc-15, so
while we'd have the _Generic() macro as a fallback for older versions,
at least most developers would hopefully get the nice clean modern
__typeof_unqual__ thing...

           Linus

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-sparse
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Fri, 16 Jan 2026 08:28:12 +0000
Message-ID: <20260116082812.GH830755 () noisy ! programming ! kicks-ass ! net>
--------------------
On Thu, Jan 15, 2026 at 03:03:52PM -0800, Linus Torvalds wrote:
> On Thu, 15 Jan 2026 at 13:31, Peter Zijlstra <peterz@infradead.org> wrote:
> >
> > GCC-14 :-/ The GCC-8.4 one was the function return value trick.
> 
> Right you are. And yeah, us moving on to gcc-14 as a minimum version
> is not imminent.
> 
> Still, while we can't force it, lots of distros are on gcc-15, so
> while we'd have the _Generic() macro as a fallback for older versions,
> at least most developers would hopefully get the nice clean modern
> __typeof_unqual__ thing...

Absolutely. I'll try and make it happen if tglx doesn't.

================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Fri, 16 Jan 2026 08:28:12 +0000
Message-ID: <20260116082812.GH830755 () noisy ! programming ! kicks-ass ! net>
--------------------
On Thu, Jan 15, 2026 at 03:03:52PM -0800, Linus Torvalds wrote:
> On Thu, 15 Jan 2026 at 13:31, Peter Zijlstra <peterz@infradead.org> wrote:
> >
> > GCC-14 :-/ The GCC-8.4 one was the function return value trick.
> 
> Right you are. And yeah, us moving on to gcc-14 as a minimum version
> is not imminent.
> 
> Still, while we can't force it, lots of distros are on gcc-15, so
> while we'd have the _Generic() macro as a fallback for older versions,
> at least most developers would hopefully get the nice clean modern
> __typeof_unqual__ thing...

Absolutely. I'll try and make it happen if tglx doesn't.

================================================================================

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-sparse
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Fri, 16 Jan 2026 11:25:53 +0000
Message-ID: <87jyxh3ike.ffs () tglx>
--------------------
On Fri, Jan 16 2026 at 00:01, Thomas Gleixner wrote:
> This time I looked deeper and it seems that USE_TYPEOF_UNQUAL is not
> set.
>
> If I force it to be set and use a proper compiler and top of tree
> sparse, everything seems to be happy.
>
> Figuring that out is something for tomorrow...

USE_TYPEOF_UNQUAL is set _after_ the __unqual_scalar muck is
processed...

Updated fix below.

Thanks,

        tglx
---
 include/linux/compiler.h       |   10 ----------
 include/linux/compiler_types.h |   11 +++++++++++
 2 files changed, 11 insertions(+), 10 deletions(-)

--- a/include/linux/compiler.h
+++ b/include/linux/compiler.h
@@ -231,16 +231,6 @@ void ftrace_likely_update(struct ftrace_
 				"must be non-C-string (not NUL-terminated)")
 
 /*
- * Use __typeof_unqual__() when available.
- *
- * XXX: Remove test for __CHECKER__ once
- * sparse learns about __typeof_unqual__().
- */
-#if CC_HAS_TYPEOF_UNQUAL && !defined(__CHECKER__)
-# define USE_TYPEOF_UNQUAL 1
-#endif
-
-/*
  * Define TYPEOF_UNQUAL() to use __typeof_unqual__() as typeof
  * operator when available, to return an unqualified type of the exp.
  */
--- a/include/linux/compiler_types.h
+++ b/include/linux/compiler_types.h
@@ -562,6 +562,13 @@ struct ftrace_likely_data {
 #define asm_inline asm
 #endif
 
+/*
+ * Use __typeof_unqual__() when available.
+ */
+#if CC_HAS_TYPEOF_UNQUAL || defined(__CHECKER__)
+# define USE_TYPEOF_UNQUAL 1
+#endif
+
 /* Are two types/vars the same type (ignoring qualifiers)? */
 #define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))
 
@@ -569,6 +576,7 @@ struct ftrace_likely_data {
  * __unqual_scalar_typeof(x) - Declare an unqualified scalar type, leaving
  *			       non-scalar types unchanged.
  */
+#ifndef USE_TYPEOF_UNQUAL
 /*
  * Prefer C11 _Generic for better compile-times and simpler code. Note: 'char'
  * is not type-compatible with 'signed char', and we define a separate case.
@@ -586,6 +594,9 @@ struct ftrace_likely_data {
 			 __scalar_type_to_expr_cases(long),		\
 			 __scalar_type_to_expr_cases(long long),	\
 			 default: (x)))
+#else
+#define __unqual_scalar_typeof(x) __typeof_unqual__(x)
+#endif
 
 /* Is this type a native word size -- useful for atomic operations */
 #define __native_word(t) \

================================================================================

From: Thomas Gleixner <tglx () kernel ! org>
To: linux-kernel
Subject: Re: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (dif
Date: Fri, 16 Jan 2026 11:25:53 +0000
Message-ID: <87jyxh3ike.ffs () tglx>
--------------------
On Fri, Jan 16 2026 at 00:01, Thomas Gleixner wrote:
> This time I looked deeper and it seems that USE_TYPEOF_UNQUAL is not
> set.
>
> If I force it to be set and use a proper compiler and top of tree
> sparse, everything seems to be happy.
>
> Figuring that out is something for tomorrow...

USE_TYPEOF_UNQUAL is set _after_ the __unqual_scalar muck is
processed...

Updated fix below.

Thanks,

        tglx
---
 include/linux/compiler.h       |   10 ----------
 include/linux/compiler_types.h |   11 +++++++++++
 2 files changed, 11 insertions(+), 10 deletions(-)

--- a/include/linux/compiler.h
+++ b/include/linux/compiler.h
@@ -231,16 +231,6 @@ void ftrace_likely_update(struct ftrace_
 				"must be non-C-string (not NUL-terminated)")
 
 /*
- * Use __typeof_unqual__() when available.
- *
- * XXX: Remove test for __CHECKER__ once
- * sparse learns about __typeof_unqual__().
- */
-#if CC_HAS_TYPEOF_UNQUAL && !defined(__CHECKER__)
-# define USE_TYPEOF_UNQUAL 1
-#endif
-
-/*
  * Define TYPEOF_UNQUAL() to use __typeof_unqual__() as typeof
  * operator when available, to return an unqualified type of the exp.
  */
--- a/include/linux/compiler_types.h
+++ b/include/linux/compiler_types.h
@@ -562,6 +562,13 @@ struct ftrace_likely_data {
 #define asm_inline asm
 #endif
 
+/*
+ * Use __typeof_unqual__() when available.
+ */
+#if CC_HAS_TYPEOF_UNQUAL || defined(__CHECKER__)
+# define USE_TYPEOF_UNQUAL 1
+#endif
+
 /* Are two types/vars the same type (ignoring qualifiers)? */
 #define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))
 
@@ -569,6 +576,7 @@ struct ftrace_likely_data {
  * __unqual_scalar_typeof(x) - Declare an unqualified scalar type, leaving
  *			       non-scalar types unchanged.
  */
+#ifndef USE_TYPEOF_UNQUAL
 /*
  * Prefer C11 _Generic for better compile-times and simpler code. Note: 'char'
  * is not type-compatible with 'signed char', and we define a separate case.
@@ -586,6 +594,9 @@ struct ftrace_likely_data {
 			 __scalar_type_to_expr_cases(long),		\
 			 __scalar_type_to_expr_cases(long long),	\
 			 default: (x)))
+#else
+#define __unqual_scalar_typeof(x) __typeof_unqual__(x)
+#endif
 
 /* Is this type a native word size -- useful for atomic operations */
 #define __native_word(t) \

================================================================================


################################################################################

=== Thread: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (differe ===

From: kernel test robot <lkp () intel ! com>
To: linux-kernel
Subject: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (differe
Date: Wed, 14 Jan 2026 07:13:03 +0000
Message-ID: <202601141546.GCQHsj5y-lkp () intel ! com>
--------------------
tree:   https://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git timers/vdso
head:   576d8a7a985dde4f51a4561dddc0d8734494d3de
commit: e04a494143bab7ea804fe1ebe286701ee8288e4a [12/14] vdso: Switch get/put_unaligned() from packed struct to memcpy()
config: x86_64-randconfig-122-20260114 (https://download.01.org/0day-ci/archive/20260114/202601141546.GCQHsj5y-lkp@intel.com/config)
compiler: clang version 20.1.8 (https://github.com/llvm/llvm-project 87f0227cb60147a26a1eeb4fb06e3b505e9c7261)
rustc: rustc 1.88.0 (6b00bc388 2025-06-23)
reproduce (this is a W=1 build): (https://download.01.org/0day-ci/archive/20260114/202601141546.GCQHsj5y-lkp@intel.com/reproduce)

If you fix the issue in a separate patch/commit (i.e. not just a new version of
the same patch/commit), kindly add following tags
| Reported-by: kernel test robot <lkp@intel.com>
| Closes: https://lore.kernel.org/oe-kbuild-all/202601141546.GCQHsj5y-lkp@intel.com/

sparse warnings: (new ones prefixed by >>)
>> net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
   net/rds/ib_cm.c:96:35: sparse:     expected void *
   net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
   net/rds/ib_cm.c:103:27: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
   net/rds/ib_cm.c:103:27: sparse:     expected void *
   net/rds/ib_cm.c:103:27: sparse:     got restricted __be64 const *

vim +96 net/rds/ib_cm.c

ec16227e14141e4 Andy Grover                  2009-02-24   69  
ec16227e14141e4 Andy Grover                  2009-02-24   70  /*
ec16227e14141e4 Andy Grover                  2009-02-24   71   * Connection established.
ec16227e14141e4 Andy Grover                  2009-02-24   72   * We get here for both outgoing and incoming connection.
ec16227e14141e4 Andy Grover                  2009-02-24   73   */
ec16227e14141e4 Andy Grover                  2009-02-24   74  void rds_ib_cm_connect_complete(struct rds_connection *conn, struct rdma_cm_event *event)
ec16227e14141e4 Andy Grover                  2009-02-24   75  {
ec16227e14141e4 Andy Grover                  2009-02-24   76  	struct rds_ib_connection *ic = conn->c_transport_data;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   77  	const union rds_ib_conn_priv *dp = NULL;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   78  	__be64 ack_seq = 0;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   79  	__be32 credit = 0;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   80  	u8 major = 0;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   81  	u8 minor = 0;
ec16227e14141e4 Andy Grover                  2009-02-24   82  	int err;
ec16227e14141e4 Andy Grover                  2009-02-24   83  
ec16227e14141e4 Andy Grover                  2009-02-24   84  	dp = event->param.conn.private_data;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   85  	if (conn->c_isv6) {
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   86  		if (event->param.conn.private_data_len >=
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   87  		    sizeof(struct rds6_ib_connect_private)) {
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   88  			major = dp->ricp_v6.dp_protocol_major;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   89  			minor = dp->ricp_v6.dp_protocol_minor;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   90  			credit = dp->ricp_v6.dp_credit;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   91  			/* dp structure start is not guaranteed to be 8 bytes
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   92  			 * aligned.  Since dp_ack_seq is 64-bit extended load
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   93  			 * operations can be used so go through get_unaligned
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   94  			 * to avoid unaligned errors.
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   95  			 */
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  @96  			ack_seq = get_unaligned(&dp->ricp_v6.dp_ack_seq);
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   97  		}
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   98  	} else if (event->param.conn.private_data_len >=
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23   99  		   sizeof(struct rds_ib_connect_private)) {
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  100  		major = dp->ricp_v4.dp_protocol_major;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  101  		minor = dp->ricp_v4.dp_protocol_minor;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  102  		credit = dp->ricp_v4.dp_credit;
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  103  		ack_seq = get_unaligned(&dp->ricp_v4.dp_ack_seq);
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  104  	}
ec16227e14141e4 Andy Grover                  2009-02-24  105  
02a6a2592e41d27 Andy Grover                  2009-07-17  106  	/* make sure it isn't empty data */
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  107  	if (major) {
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  108  		rds_ib_set_protocol(conn, RDS_PROTOCOL(major, minor));
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  109  		rds_ib_set_flow_control(conn, be32_to_cpu(credit));
02a6a2592e41d27 Andy Grover                  2009-07-17  110  	}
ec16227e14141e4 Andy Grover                  2009-02-24  111  
cdc306a5c9cd360 Santosh Shilimkar            2018-10-13  112  	if (conn->c_version < RDS_PROTOCOL_VERSION) {
cdc306a5c9cd360 Santosh Shilimkar            2018-10-13  113  		if (conn->c_version != RDS_PROTOCOL_COMPAT_VERSION) {
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  114  			pr_notice("RDS/IB: Connection <%pI6c,%pI6c> version %u.%u no longer supported\n",
ff3f19a2f608ee4 Santosh Shilimkar            2016-03-14  115  				  &conn->c_laddr, &conn->c_faddr,
f147dd9ecabf23f Andy Grover                  2010-01-13  116  				  RDS_PROTOCOL_MAJOR(conn->c_version),
f147dd9ecabf23f Andy Grover                  2010-01-13  117  				  RDS_PROTOCOL_MINOR(conn->c_version));
f147dd9ecabf23f Andy Grover                  2010-01-13  118  			rds_conn_destroy(conn);
f147dd9ecabf23f Andy Grover                  2010-01-13  119  			return;
cdc306a5c9cd360 Santosh Shilimkar            2018-10-13  120  		}
cdc306a5c9cd360 Santosh Shilimkar            2018-10-13  121  	}
cdc306a5c9cd360 Santosh Shilimkar            2018-10-13  122  
fd261ce6a30e01a Santosh Shilimkar            2018-10-13  123  	pr_notice("RDS/IB: %s conn connected <%pI6c,%pI6c,%d> version %u.%u%s\n",
581d53c91cbf7b3 Santosh Shilimkar            2016-07-09  124  		  ic->i_active_side ? "Active" : "Passive",
fd261ce6a30e01a Santosh Shilimkar            2018-10-13  125  		  &conn->c_laddr, &conn->c_faddr, conn->c_tos,
ec16227e14141e4 Andy Grover                  2009-02-24  126  		  RDS_PROTOCOL_MAJOR(conn->c_version),
ec16227e14141e4 Andy Grover                  2009-02-24  127  		  RDS_PROTOCOL_MINOR(conn->c_version),
ec16227e14141e4 Andy Grover                  2009-02-24  128  		  ic->i_flowctl ? ", flow control" : "");
ec16227e14141e4 Andy Grover                  2009-02-24  129  
e0e6d062822529d Zhu Yanjun                   2019-08-23  130  	/* receive sl from the peer */
e0e6d062822529d Zhu Yanjun                   2019-08-23  131  	ic->i_sl = ic->i_cm_id->route.path_rec->sl;
e0e6d062822529d Zhu Yanjun                   2019-08-23  132  
cf657269d311d57 Santosh Shilimkar            2016-09-29  133  	atomic_set(&ic->i_cq_quiesce, 0);
cf657269d311d57 Santosh Shilimkar            2016-09-29  134  
581d53c91cbf7b3 Santosh Shilimkar            2016-07-09  135  	/* Init rings and fill recv. this needs to wait until protocol
581d53c91cbf7b3 Santosh Shilimkar            2016-07-09  136  	 * negotiation is complete, since ring layout is different
581d53c91cbf7b3 Santosh Shilimkar            2016-07-09  137  	 * from 3.1 to 4.1.
e11d912a7dd4dfe Andy Grover                  2009-07-17  138  	 */
e11d912a7dd4dfe Andy Grover                  2009-07-17  139  	rds_ib_send_init_ring(ic);
e11d912a7dd4dfe Andy Grover                  2009-07-17  140  	rds_ib_recv_init_ring(ic);
e11d912a7dd4dfe Andy Grover                  2009-07-17  141  	/* Post receive buffers - as a side effect, this will update
e11d912a7dd4dfe Andy Grover                  2009-07-17  142  	 * the posted credit count. */
73ce4317bf98328 santosh.shilimkar@oracle.com 2015-08-22  143  	rds_ib_recv_refill(conn, 1, GFP_KERNEL);
e11d912a7dd4dfe Andy Grover                  2009-07-17  144  
3e0249f9c05cb77 Zach Brown                   2010-05-18  145  	/* update ib_device with this local ipaddr */
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  146  	err = rds_ib_update_ipaddr(ic->rds_ibdev, &conn->c_laddr);
ec16227e14141e4 Andy Grover                  2009-02-24  147  	if (err)
3e0249f9c05cb77 Zach Brown                   2010-05-18  148  		printk(KERN_ERR "rds_ib_update_ipaddr failed (%d)\n",
3e0249f9c05cb77 Zach Brown                   2010-05-18  149  			err);
ec16227e14141e4 Andy Grover                  2009-02-24  150  
ec16227e14141e4 Andy Grover                  2009-02-24  151  	/* If the peer gave us the last packet it saw, process this as if
ec16227e14141e4 Andy Grover                  2009-02-24  152  	 * we had received a regular ACK. */
c0adf54a10903b5 shamir rabinovitch           2015-04-30  153  	if (dp) {
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  154  		if (ack_seq)
eee2fa6ab322519 Ka-Cheong Poon               2018-07-23  155  			rds_send_drop_acked(conn, be64_to_cpu(ack_seq),
c0adf54a10903b5 shamir rabinovitch           2015-04-30  156  					    NULL);
c0adf54a10903b5 shamir rabinovitch           2015-04-30  157  	}
ec16227e14141e4 Andy Grover                  2009-02-24  158  
cdc306a5c9cd360 Santosh Shilimkar            2018-10-13  159  	conn->c_proposed_version = conn->c_version;
ec16227e14141e4 Andy Grover                  2009-02-24  160  	rds_connect_complete(conn);
ec16227e14141e4 Andy Grover                  2009-02-24  161  }
ec16227e14141e4 Andy Grover                  2009-02-24  162  

:::::: The code at line 96 was first introduced by commit
:::::: eee2fa6ab3225192d6d894c54a6fb02ac9efdff6 rds: Changing IP address internal representation to struct in6_addr

:::::: TO: Ka-Cheong Poon <ka-cheong.poon@oracle.com>
:::::: CC: David S. Miller <davem@davemloft.net>

-- 
0-DAY CI Kernel Test Service
https://github.com/intel/lkp-tests/wiki

================================================================================

From: kernel test robot <lkp () intel ! com>
To: linux-kernel
Subject: [tip:timers/vdso 12/14] net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (differe
Date: Wed, 14 Jan 2026 16:36:01 +0000
Message-ID: <202601150001.sKSN644a-lkp () intel ! com>
--------------------
tree:   https://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git timers/vdso
head:   759a1f97373f25770cf438d9fb5f2bddf4d77a54
commit: e04a494143bab7ea804fe1ebe286701ee8288e4a [12/14] vdso: Switch get/put_unaligned() from packed struct to memcpy()
config: x86_64-randconfig-122-20260114 (https://download.01.org/0day-ci/archive/20260115/202601150001.sKSN644a-lkp@intel.com/config)
compiler: clang version 20.1.8 (https://github.com/llvm/llvm-project 87f0227cb60147a26a1eeb4fb06e3b505e9c7261)
rustc: rustc 1.88.0 (6b00bc388 2025-06-23)
reproduce (this is a W=1 build): (https://download.01.org/0day-ci/archive/20260115/202601150001.sKSN644a-lkp@intel.com/reproduce)

If you fix the issue in a separate patch/commit (i.e. not just a new version of
the same patch/commit), kindly add following tags
| Reported-by: kernel test robot <lkp@intel.com>
| Closes: https://lore.kernel.org/oe-kbuild-all/202601150001.sKSN644a-lkp@intel.com/

sparse warnings: (new ones prefixed by >>)
>> net/rds/ib_cm.c:96:35: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
   net/rds/ib_cm.c:96:35: sparse:     expected void *
   net/rds/ib_cm.c:96:35: sparse:     got restricted __be64 const *
   net/rds/ib_cm.c:103:27: sparse: sparse: incorrect type in argument 1 (different modifiers) @@     expected void * @@     got restricted __be64 const * @@
   net/rds/ib_cm.c:103:27: sparse:     expected void *
   net/rds/ib_cm.c:103:27: sparse:     got restricted __be64 const *

vim +96 net/rds/ib_cm.c

ec16227e14141e Andy Grover                  2009-02-24   69  
ec16227e14141e Andy Grover                  2009-02-24   70  /*
ec16227e14141e Andy Grover                  2009-02-24   71   * Connection established.
ec16227e14141e Andy Grover                  2009-02-24   72   * We get here for both outgoing and incoming connection.
ec16227e14141e Andy Grover                  2009-02-24   73   */
ec16227e14141e Andy Grover                  2009-02-24   74  void rds_ib_cm_connect_complete(struct rds_connection *conn, struct rdma_cm_event *event)
ec16227e14141e Andy Grover                  2009-02-24   75  {
ec16227e14141e Andy Grover                  2009-02-24   76  	struct rds_ib_connection *ic = conn->c_transport_data;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   77  	const union rds_ib_conn_priv *dp = NULL;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   78  	__be64 ack_seq = 0;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   79  	__be32 credit = 0;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   80  	u8 major = 0;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   81  	u8 minor = 0;
ec16227e14141e Andy Grover                  2009-02-24   82  	int err;
ec16227e14141e Andy Grover                  2009-02-24   83  
ec16227e14141e Andy Grover                  2009-02-24   84  	dp = event->param.conn.private_data;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   85  	if (conn->c_isv6) {
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   86  		if (event->param.conn.private_data_len >=
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   87  		    sizeof(struct rds6_ib_connect_private)) {
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   88  			major = dp->ricp_v6.dp_protocol_major;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   89  			minor = dp->ricp_v6.dp_protocol_minor;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   90  			credit = dp->ricp_v6.dp_credit;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   91  			/* dp structure start is not guaranteed to be 8 bytes
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   92  			 * aligned.  Since dp_ack_seq is 64-bit extended load
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   93  			 * operations can be used so go through get_unaligned
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   94  			 * to avoid unaligned errors.
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   95  			 */
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  @96  			ack_seq = get_unaligned(&dp->ricp_v6.dp_ack_seq);
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   97  		}
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   98  	} else if (event->param.conn.private_data_len >=
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23   99  		   sizeof(struct rds_ib_connect_private)) {
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  100  		major = dp->ricp_v4.dp_protocol_major;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  101  		minor = dp->ricp_v4.dp_protocol_minor;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  102  		credit = dp->ricp_v4.dp_credit;
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  103  		ack_seq = get_unaligned(&dp->ricp_v4.dp_ack_seq);
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  104  	}
ec16227e14141e Andy Grover                  2009-02-24  105  
02a6a2592e41d2 Andy Grover                  2009-07-17  106  	/* make sure it isn't empty data */
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  107  	if (major) {
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  108  		rds_ib_set_protocol(conn, RDS_PROTOCOL(major, minor));
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  109  		rds_ib_set_flow_control(conn, be32_to_cpu(credit));
02a6a2592e41d2 Andy Grover                  2009-07-17  110  	}
ec16227e14141e Andy Grover                  2009-02-24  111  
cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  112  	if (conn->c_version < RDS_PROTOCOL_VERSION) {
cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  113  		if (conn->c_version != RDS_PROTOCOL_COMPAT_VERSION) {
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  114  			pr_notice("RDS/IB: Connection <%pI6c,%pI6c> version %u.%u no longer supported\n",
ff3f19a2f608ee Santosh Shilimkar            2016-03-14  115  				  &conn->c_laddr, &conn->c_faddr,
f147dd9ecabf23 Andy Grover                  2010-01-13  116  				  RDS_PROTOCOL_MAJOR(conn->c_version),
f147dd9ecabf23 Andy Grover                  2010-01-13  117  				  RDS_PROTOCOL_MINOR(conn->c_version));
f147dd9ecabf23 Andy Grover                  2010-01-13  118  			rds_conn_destroy(conn);
f147dd9ecabf23 Andy Grover                  2010-01-13  119  			return;
cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  120  		}
cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  121  	}
cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  122  
fd261ce6a30e01 Santosh Shilimkar            2018-10-13  123  	pr_notice("RDS/IB: %s conn connected <%pI6c,%pI6c,%d> version %u.%u%s\n",
581d53c91cbf7b Santosh Shilimkar            2016-07-09  124  		  ic->i_active_side ? "Active" : "Passive",
fd261ce6a30e01 Santosh Shilimkar            2018-10-13  125  		  &conn->c_laddr, &conn->c_faddr, conn->c_tos,
ec16227e14141e Andy Grover                  2009-02-24  126  		  RDS_PROTOCOL_MAJOR(conn->c_version),
ec16227e14141e Andy Grover                  2009-02-24  127  		  RDS_PROTOCOL_MINOR(conn->c_version),
ec16227e14141e Andy Grover                  2009-02-24  128  		  ic->i_flowctl ? ", flow control" : "");
ec16227e14141e Andy Grover                  2009-02-24  129  
e0e6d062822529 Zhu Yanjun                   2019-08-23  130  	/* receive sl from the peer */
e0e6d062822529 Zhu Yanjun                   2019-08-23  131  	ic->i_sl = ic->i_cm_id->route.path_rec->sl;
e0e6d062822529 Zhu Yanjun                   2019-08-23  132  
cf657269d311d5 Santosh Shilimkar            2016-09-29  133  	atomic_set(&ic->i_cq_quiesce, 0);
cf657269d311d5 Santosh Shilimkar            2016-09-29  134  
581d53c91cbf7b Santosh Shilimkar            2016-07-09  135  	/* Init rings and fill recv. this needs to wait until protocol
581d53c91cbf7b Santosh Shilimkar            2016-07-09  136  	 * negotiation is complete, since ring layout is different
581d53c91cbf7b Santosh Shilimkar            2016-07-09  137  	 * from 3.1 to 4.1.
e11d912a7dd4df Andy Grover                  2009-07-17  138  	 */
e11d912a7dd4df Andy Grover                  2009-07-17  139  	rds_ib_send_init_ring(ic);
e11d912a7dd4df Andy Grover                  2009-07-17  140  	rds_ib_recv_init_ring(ic);
e11d912a7dd4df Andy Grover                  2009-07-17  141  	/* Post receive buffers - as a side effect, this will update
e11d912a7dd4df Andy Grover                  2009-07-17  142  	 * the posted credit count. */
73ce4317bf9832 santosh.shilimkar@oracle.com 2015-08-22  143  	rds_ib_recv_refill(conn, 1, GFP_KERNEL);
e11d912a7dd4df Andy Grover                  2009-07-17  144  
3e0249f9c05cb7 Zach Brown                   2010-05-18  145  	/* update ib_device with this local ipaddr */
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  146  	err = rds_ib_update_ipaddr(ic->rds_ibdev, &conn->c_laddr);
ec16227e14141e Andy Grover                  2009-02-24  147  	if (err)
3e0249f9c05cb7 Zach Brown                   2010-05-18  148  		printk(KERN_ERR "rds_ib_update_ipaddr failed (%d)\n",
3e0249f9c05cb7 Zach Brown                   2010-05-18  149  			err);
ec16227e14141e Andy Grover                  2009-02-24  150  
ec16227e14141e Andy Grover                  2009-02-24  151  	/* If the peer gave us the last packet it saw, process this as if
ec16227e14141e Andy Grover                  2009-02-24  152  	 * we had received a regular ACK. */
c0adf54a10903b shamir rabinovitch           2015-04-30  153  	if (dp) {
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  154  		if (ack_seq)
eee2fa6ab32251 Ka-Cheong Poon               2018-07-23  155  			rds_send_drop_acked(conn, be64_to_cpu(ack_seq),
c0adf54a10903b shamir rabinovitch           2015-04-30  156  					    NULL);
c0adf54a10903b shamir rabinovitch           2015-04-30  157  	}
ec16227e14141e Andy Grover                  2009-02-24  158  
cdc306a5c9cd36 Santosh Shilimkar            2018-10-13  159  	conn->c_proposed_version = conn->c_version;
ec16227e14141e Andy Grover                  2009-02-24  160  	rds_connect_complete(conn);
ec16227e14141e Andy Grover                  2009-02-24  161  }
ec16227e14141e Andy Grover                  2009-02-24  162  

:::::: The code at line 96 was first introduced by commit
:::::: eee2fa6ab3225192d6d894c54a6fb02ac9efdff6 rds: Changing IP address internal representation to struct in6_addr

:::::: TO: Ka-Cheong Poon <ka-cheong.poon@oracle.com>
:::::: CC: David S. Miller <davem@davemloft.net>

-- 
0-DAY CI Kernel Test Service
https://github.com/intel/lkp-tests/wiki

================================================================================


################################################################################

=== Thread: add variadic format checking ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: add variadic format checking
Date: Fri, 16 Jan 2026 17:58:05 +0000
Message-ID: <20260116175809.6849-1-ben.dooks () codethink ! co ! uk>
--------------------
Third version with a few minor fixes, the only issues seem to be
with the complexities of the linux-kernel which has some printk
fun locally defined.


This series (which was initially sent back in 2020) adds the
ability to deal with __attribute__((format) and checking the
arguments to formatted variadic functions.

I have been considering adding a -Wformat-linux to this as
the kernel now has a number of extra formatting options and
checking the type of these would be useful. An even nicer
extension would be some way of informing the compiler/sparse
of these at compile time (but would need to get agreement on
how to do this with the compilers too)



================================================================================


################################################################################

=== Thread: issue with _Static_assert and __builtin()s ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: issue with _Static_assert and __builtin()s
Date: Wed, 07 Jan 2026 19:41:45 +0000
Message-ID: <2943a1fd-1168-4043-bede-8f39cad4444b () codethink ! co ! uk>
--------------------
This is a multi-part message in MIME format.
--------------g2cVKzvqn4i6DYTqoYhBm6vd
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 7bit

So I am looking at why the Linux kernel's check for nul characters
in strings is causing errors out of sparse.

EG:
drivers/md/dm.c:3813:1: error: bad constant expression
drivers/md/dm.c:3814:1: error: bad constant expression
drivers/md/dm.c:3816:1: error: bad constant expression
drivers/md/dm.c:3817:1: error: bad constant expression

I've tracked it down to the sizeof(str) - 1 == __builtin_strlen(str)
failing to be a good constant expression...

This is an example of the assert which isn't working:

_Static_assert(sizeof("moo") - 1 == __builtin_strlen("moo"), "nul!");

This does at least get past w/o warnings
_Static_assert(__builtin_types_compatible_p(int, int), "doh!");

I've had a go at updating builtin.c to deal with __builtin_strlen()
for a string constant (attached) but that's just changing the
output to "error: bad integer constant expression" so not sure
what I've missed here.


-- 
Ben Dooks				http://www.codethink.co.uk/
Senior Engineer				Codethink - Providing Genius

https://www.codethink.co.uk/privacy.html

--------------g2cVKzvqn4i6DYTqoYhBm6vd
Content-Type: text/x-patch; charset=UTF-8; name="initial-strlen.patch"
Content-Disposition: attachment; filename="initial-strlen.patch"
Content-Transfer-Encoding: base64
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--------------g2cVKzvqn4i6DYTqoYhBm6vd--

================================================================================

From: Dan Carpenter <dan.carpenter () linaro ! org>
To: linux-sparse
Subject: Re: issue with _Static_assert and __builtin()s
Date: Thu, 08 Jan 2026 05:41:26 +0000
Message-ID: <aV9DhtIM7Z5ZmJRz () stanley ! mountain>
--------------------
On Wed, Jan 07, 2026 at 07:41:45PM +0000, Ben Dooks wrote:
> So I am looking at why the Linux kernel's check for nul characters
> in strings is causing errors out of sparse.
> 
> EG:
> drivers/md/dm.c:3813:1: error: bad constant expression
> drivers/md/dm.c:3814:1: error: bad constant expression
> drivers/md/dm.c:3816:1: error: bad constant expression
> drivers/md/dm.c:3817:1: error: bad constant expression
> 
> I've tracked it down to the sizeof(str) - 1 == __builtin_strlen(str)
> failing to be a good constant expression...
> 
> This is an example of the assert which isn't working:
> 
> _Static_assert(sizeof("moo") - 1 == __builtin_strlen("moo"), "nul!");
> 
> This does at least get past w/o warnings
> _Static_assert(__builtin_types_compatible_p(int, int), "doh!");
> 
> I've had a go at updating builtin.c to deal with __builtin_strlen()
> for a string constant (attached) but that's just changing the
> output to "error: bad integer constant expression" so not sure
> what I've missed here.
> 

Al has a fix for that.
https://git.kernel.org/pub/scm/linux/kernel/git/viro/sparse.git/commit/?id=2634e39bf02697a18fece057208150362c985992

regards,
dan carpenter



================================================================================

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: Re: issue with _Static_assert and __builtin()s
Date: Thu, 08 Jan 2026 09:38:25 +0000
Message-ID: <13cb6e5b-94f0-487d-a8fb-9e5ab8a3e45c () codethink ! co ! uk>
--------------------
On 08/01/2026 05:41, Dan Carpenter wrote:
> On Wed, Jan 07, 2026 at 07:41:45PM +0000, Ben Dooks wrote:
>> So I am looking at why the Linux kernel's check for nul characters
>> in strings is causing errors out of sparse.
>>
>> EG:
>> drivers/md/dm.c:3813:1: error: bad constant expression
>> drivers/md/dm.c:3814:1: error: bad constant expression
>> drivers/md/dm.c:3816:1: error: bad constant expression
>> drivers/md/dm.c:3817:1: error: bad constant expression
>>
>> I've tracked it down to the sizeof(str) - 1 == __builtin_strlen(str)
>> failing to be a good constant expression...
>>
>> This is an example of the assert which isn't working:
>>
>> _Static_assert(sizeof("moo") - 1 == __builtin_strlen("moo"), "nul!");
>>
>> This does at least get past w/o warnings
>> _Static_assert(__builtin_types_compatible_p(int, int), "doh!");
>>
>> I've had a go at updating builtin.c to deal with __builtin_strlen()
>> for a string constant (attached) but that's just changing the
>> output to "error: bad integer constant expression" so not sure
>> what I've missed here.
>>
> 
> Al has a fix for that.
> https://git.kernel.org/pub/scm/linux/kernel/git/viro/sparse.git/commit/?id=2634e39bf02697a18fece057208150362c985992

Ah thanks, that'll save me a few hours of prodding my code to try
getting it working.

-- 
Ben Dooks				http://www.codethink.co.uk/
Senior Engineer				Codethink - Providing Genius

https://www.codethink.co.uk/privacy.html

================================================================================


################################################################################

=== Thread: req: option to show area warning is from ===

From: Ben Dooks <ben.dooks () codethink ! co ! uk>
To: linux-sparse
Subject: req: option to show area warning is from
Date: Wed, 07 Jan 2026 14:58:44 +0000
Message-ID: <944a3c73-f971-441c-8ba6-344f1ac099f3 () codethink ! co ! uk>
--------------------
SSB0aGluayBpdCB3b3VsZCBiZSB1c2VmdWwgdG8gaGF2ZSBhbiBvcHRpb24gdG8gc2hvdyBh
IG1vcmUgZGV0YWlsZWQNCnZpZXcgb2Ygd2hpY2ggcGFydCBvZiB0aGUgc291cmNlIGdlbmVy
YXRlZCBhIHdhcm5pbmcuIFdvdWxkIHRoaXMgYmUNCnBvc3NpYmxlIGFuZCBpZiBzbyBpcyB0
aGVyZSBhbnlvbmUgaW50ZXJlc3RlZCBpbiBkb2luZyBpdD8NCg0KSSdtIGxvb2tpbmcgYXQg
dGhlIGZvbGxvd2luZyB3YXJuaW5nOg0KLi9pbmNsdWRlL3RyYWNlL2V2ZW50cy94ZHAuaDoz
MDQ6MTogd2FybmluZzogVXNpbmcgcGxhaW4gaW50ZWdlciBhcyBOVUxMIA0KcG9pbnRlcg0K
DQpBbmQgdGhlIGtlcm5lbCBzb3VyY2UgZnJvbSB0aGUgcHJlLXByb2Nlc3NlZCBmaWxlIGxv
b2tzIGxpa2UgdGhpczoNCg0KPiBzdGF0aWMgX19hdHRyaWJ1dGVfXygobm9faW5zdHJ1bWVu
dF9mdW5jdGlvbikpIHZvaWQgZG9fcGVyZl90cmFjZV9tZW1fZGlzY29ubmVjdCh2b2lkICpf
X2RhdGEsIGNvbnN0IHN0cnVjdCB4ZHBfbWVtX2FsbG9jYXRvciAqeGEpIHsgc3RydWN0IHRy
YWNlX2V2ZW50X2NhbGwgKmV2ZW50X2NhbGwgPSBfX2RhdGE7IHN0cnVjdCB0cmFjZV9ldmVu
dF9kYXRhX29mZnNldHNfbWVtX2Rpc2Nvbm5lY3QgX19hdHRyaWJ1dGVfXygoX191bnVzZWRf
XykpIF9fZGF0YV9vZmZzZXRzOyBzdHJ1Y3QgdHJhY2VfZXZlbnRfcmF3X21lbV9kaXNjb25u
ZWN0ICplbnRyeTsgc3RydWN0IHB0X3JlZ3MgKl9fcmVnczsgdTY0IF9fY291bnQgPSAxOyBz
dHJ1Y3QgdGFza19zdHJ1Y3QgKl9fdGFzayA9ICgodm9pZCAqKTApOyBzdHJ1Y3QgaGxpc3Rf
aGVhZCAqaGVhZDsgaW50IF9fZW50cnlfc2l6ZTsgaW50IF9fZGF0YV9zaXplOyBpbnQgcmN0
eDsgX19kYXRhX3NpemUgPSB0cmFjZV9ldmVudF9nZXRfb2Zmc2V0c19tZW1fZGlzY29ubmVj
dCgmX19kYXRhX29mZnNldHMsIHhhKTsgaGVhZCA9ICh7IGRvIHsgY29uc3Qgdm9pZCBfX3Nl
Z19ncyAqX192cHBfdmVyaWZ5ID0gKHR5cGVvZigoZXZlbnRfY2FsbC0+cGVyZl9ldmVudHMp
ICsgMCkpKCh2b2lkICopMCk7ICh2b2lkKV9fdnBwX3ZlcmlmeTsgfSB3aGlsZSAoMCk7ICh7
IHVuc2lnbmVkIGxvbmcgdGNwX3B0cl9fID0gKHsgKiggdHlwZW9mKHRoaXNfY3B1X29mZikg
KikoJih0aGlzX2NwdV9vZmYpKTsgfSk7IHRjcF9wdHJfXyArPSAoIHVuc2lnbmVkIGxvbmcp
KGV2ZW50X2NhbGwtPnBlcmZfZXZlbnRzKTsgKF9fdHlwZW9mX3VucXVhbF9fKCooZXZlbnRf
Y2FsbC0+cGVyZl9ldmVudHMpKSAqKXRjcF9wdHJfXzsgfSk7IH0pOyBpZiAoIWJwZl9wcm9n
X2FycmF5X3ZhbGlkKGV2ZW50X2NhbGwpICYmIF9fYnVpbHRpbl9jb25zdGFudF9wKCFfX3Rh
c2spICYmICFfX3Rhc2sgJiYgaGxpc3RfZW1wdHkoaGVhZCkpIHJldHVybjsgX19lbnRyeV9z
aXplID0gKCgoKF9fZGF0YV9zaXplICsgc2l6ZW9mKCplbnRyeSkgKyBzaXplb2YodTMyKSkp
ICsgKChfX3R5cGVvZl9fKChfX2RhdGFfc2l6ZSArIHNpemVvZigqZW50cnkpICsgc2l6ZW9m
KHUzMikpKSkoKHNpemVvZih1NjQpKSkgLSAxKSkgJiB+KChfX3R5cGVvZl9fKChfX2RhdGFf
c2l6ZSArIHNpemVvZigqZW50cnkpICsgc2l6ZW9mKHUzMikpKSkoKHNpemVvZih1NjQpKSkg
LSAxKSk7IF9fZW50cnlfc2l6ZSAtPSBzaXplb2YodTMyKTsgZW50cnkgPSBwZXJmX3RyYWNl
X2J1Zl9hbGxvYyhfX2VudHJ5X3NpemUsICZfX3JlZ3MsICZyY3R4KTsgaWYgKCFlbnRyeSkg
cmV0dXJuOyBwZXJmX2ZldGNoX2NhbGxlcl9yZWdzKF9fcmVncyk7IHsgZW50cnktPnhhID0g
eGE7IGVudHJ5LT5tZW1faWQgPSB4YS0+bWVtLmlkOyBlbnRyeS0+bWVtX3R5cGUgPSB4YS0+
bWVtLnR5cGU7IGVudHJ5LT5hbGxvY2F0b3IgPSB4YS0+YWxsb2NhdG9yOzsgfSBwZXJmX3Ry
YWNlX3J1bl9icGZfc3VibWl0KGVudHJ5LCBfX2VudHJ5X3NpemUsIHJjdHgsIGV2ZW50X2Nh
bGwsIF9fY291bnQsIF9fcmVncywgaGVhZCwgX190YXNrKTsgfSBzdGF0aWMgX19hdHRyaWJ1
dGVfXygobm9faW5zdHJ1bWVudF9mdW5jdGlvbikpIHZvaWQgcGVyZl90cmFjZV9tZW1fZGlz
Y29ubmVjdCh2b2lkICpfX2RhdGEsIGNvbnN0IHN0cnVjdCB4ZHBfbWVtX2FsbG9jYXRvciAq
eGEpIHsgdTY0IF9fY291bnQgX19hdHRyaWJ1dGVfXygodW51c2VkKSk7IHN0cnVjdCB0YXNr
X3N0cnVjdCAqX190YXNrIF9fYXR0cmlidXRlX18oKHVudXNlZCkpOyBkb19wZXJmX3RyYWNl
X21lbV9kaXNjb25uZWN0KF9fZGF0YSwgeGEpOyB9OyBzdGF0aWMgaW5saW5lIF9fYXR0cmli
dXRlX18oKF9fZ251X2lubGluZV9fKSkgX19hdHRyaWJ1dGVfXygoX191bnVzZWRfXykpIF9f
YXR0cmlidXRlX18oKG5vX2luc3RydW1lbnRfZnVuY3Rpb24pKSB2b2lkIHBlcmZfdGVzdF9w
cm9iZV9tZW1fZGlzY29ubmVjdCh2b2lkKSB7IGNoZWNrX3RyYWNlX2NhbGxiYWNrX3R5cGVf
bWVtX2Rpc2Nvbm5lY3QocGVyZl90cmFjZV9tZW1fZGlzY29ubmVjdCk7IH07DQoNCg0KVGhp
cyBpcyBvYnZpb3VzbHkgYSBsb3QgdG8gZ28gdGhyb3VnaCBhbmQgdmVyeSBkaWZmaWN1bHQg
dG8gcmVhZC4NCg0KSXQgd291bGQgYmUgZ3JlYXQgaWYgd2UgY291bGQgZ2V0IGEgZHVtcCBv
ZiB3aGF0IHdhcyBnb2luZyBvbi4NCg0KLS0gDQpCZW4gRG9va3MJCQkJaHR0cDovL3d3dy5j
b2RldGhpbmsuY28udWsvDQpTZW5pb3IgRW5naW5lZXIJCQkJQ29kZXRoaW5rIC0gUHJvdmlk
aW5nIEdlbml1cw0KDQpodHRwczovL3d3dy5jb2RldGhpbmsuY28udWsvcHJpdmFjeS5odG1s
DQoNCg==

================================================================================

From: Dan Carpenter <dan.carpenter () linaro ! org>
To: linux-sparse
Subject: Re: req: option to show area warning is from
Date: Wed, 07 Jan 2026 19:40:32 +0000
Message-ID: <aV62sDxNla12F1V4 () stanley ! mountain>
--------------------
On Wed, Jan 07, 2026 at 02:58:44PM +0000, Ben Dooks wrote:
> I think it would be useful to have an option to show a more detailed
> view of which part of the source generated a warning. Would this be
> possible and if so is there anyone interested in doing it?
>=20
> I'm looking at the following warning:
> ./include/trace/events/xdp.h:304:1: warning: Using plain integer as NULL
> pointer
>=20
> And the kernel source from the pre-processed file looks like this:
>=20
> > static __attribute__((no_instrument_function)) void do_perf_trace_mem_d=
isconnect(void *__data, const struct xdp_mem_allocator *xa) { struct trace_=
event_call *event_call =3D __data; struct trace_event_data_offsets_mem_disc=
onnect __attribute__((__unused__)) __data_offsets; struct trace_event_raw_m=
em_disconnect *entry; struct pt_regs *__regs; u64 __count =3D 1; struct tas=
k_struct *__task =3D ((void *)0); struct hlist_head *head; int __entry_size=
; int __data_size; int rctx; __data_size =3D trace_event_get_offsets_mem_di=
sconnect(&__data_offsets, xa); head =3D ({ do { const void __seg_gs *__vpp_=
verify =3D (typeof((event_call->perf_events) + 0))((void *)0); (void)__vpp_=
verify; } while (0); ({ unsigned long tcp_ptr__ =3D ({ *( typeof(this_cpu_o=
ff) *)(&(this_cpu_off)); }); tcp_ptr__ +=3D ( unsigned long)(event_call->pe=
rf_events); (__typeof_unqual__(*(event_call->perf_events)) *)tcp_ptr__; });=
 }); if (!bpf_prog_array_valid(event_call) && __builtin_constant_p(!__task)=
 && !__task && hlist_empty(head)) return; __entry_size =3D ((((__data_size =
+ sizeof(*entry) + sizeof(u32))) + ((__typeof__((__data_size + sizeof(*entr=
y) + sizeof(u32))))((sizeof(u64))) - 1)) & ~((__typeof__((__data_size + siz=
eof(*entry) + sizeof(u32))))((sizeof(u64))) - 1)); __entry_size -=3D sizeof=
(u32); entry =3D perf_trace_buf_alloc(__entry_size, &__regs, &rctx); if (!e=
ntry) return; perf_fetch_caller_regs(__regs); { entry->xa =3D xa; entry->me=
m_id =3D xa->mem.id; entry->mem_type =3D xa->mem.type; entry->allocator =3D=
 xa->allocator;; } perf_trace_run_bpf_submit(entry, __entry_size, rctx, eve=
nt_call, __count, __regs, head, __task); } static __attribute__((no_instrum=
ent_function)) void perf_trace_mem_disconnect(void *__data, const struct xd=
p_mem_allocator *xa) { u64 __count __attribute__((unused)); struct task_str=
uct *__task __attribute__((unused)); do_perf_trace_mem_disconnect(__data, x=
a); }; static inline __attribute__((__gnu_inline__)) __attribute__((__unuse=
d__)) __attribute__((no_instrument_function)) void perf_test_probe_mem_disc=
onnect(void) { check_trace_callback_type_mem_disconnect(perf_trace_mem_disc=
onnect); };
>=20
>=20
> This is obviously a lot to go through and very difficult to read.
>=20
> It would be great if we could get a dump of what was going on.

Yeah, I spend a lot of time adding newlines to pre-processed code.  Is
there a good script to re-indent .i files?

regards,
dan carpenter

================================================================================


################################################################################

