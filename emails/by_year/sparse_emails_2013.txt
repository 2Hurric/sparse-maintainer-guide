--- Emails for Year 2013 ---

=== Thread: [No Subject] ===

From: e639 () humv ! es
To: linux-sparse
Subject: 
Date: Tue, 26 Mar 2013 07:27:54 +0000
Message-ID: <54770.82.128.15.135.1364282874.squirrel () correo ! humv ! es>
--------------------



-- 
Ich bin Barrister Werner Erich Zeller, ich brauche eure aufrichtige
Partnerschaft intransferring die Summe von 15.000.000,00 EUR auf Ihr
Bankkonto in dieser Woche für den Nutzen der beiden von uns 50% each.It
ist 100% legal, legitim und sicher! für Details, schreiben Sie mir auf
dieser meiner privaten E-Mail statt: Dies ist dringende und ernste Sie
müssen bereit sein und bereit, bevor Sie mich kontaktieren.

bitte! Rufen Sie +44 702 409 0820 (Büro)
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "AFG GTBANK LOAN" <turnos-escuelas () ifir-conicet ! gov ! ar>
To: linux-sparse
Subject: 
Date: Mon, 17 Jun 2013 19:28:00 +0000
Message-ID: <bf2bd1c7747c2b14e57da8b2a5c50f0c.squirrel () ifir-conicet ! gov ! ar>
--------------------



Loan Syndicacion

Am AFG Guaranty Trust Bank, zu strukturieren wir Kreditlinien treffen Sie
unsere
Kunden spezifischen geschäftlichen Anforderungen und einen deutlichen
Mehrwert für unsere
Kunden Unternehmen.
eine Division der AFG Finance und Private Bank plc.

Wenn Sie erwägen, eine große Akquisition oder ein Großprojekt sind, können
Sie
brauchen eine erhebliche Menge an Kredit. AFG Guaranty Trust Bank setzen
können
zusammen das Syndikat, das die gesamte Kredit schnürt für
Sie.


Als Bank mit internationaler Reichweite, sind wir gekommen, um Darlehen zu
identifizieren
Syndizierungen als Teil unseres Kerngeschäfts und durch spitzte diese Zeile
aggressiv sind wir an einem Punkt, wo wir kommen, um als erkannt haben
Hauptakteur in diesem Bereich.


öffnen Sie ein Girokonto heute mit einem Minimum Bankguthaben von 500 £ und
Getup zu £ 10.000 als Darlehen und auch den Hauch einer Chance und gewann
die Sterne
Preis von £ 500.000 in die sparen und gewinnen promo in may.aply jetzt.


mit dem Folowing Informationen über Rechtsanwalt steven lee das Konto
Offizier.


FULL NAME;


Wohnadresse;


E-MAIL-ADRESSE;

Telefonnummer;

Nächsten KINS;

MUTTER MAIDEN NAME;


Familienstand;


BÜROADRESSE;

ALTERNATIVE Telefonnummer;

TO @ yahoo.com bar.stevenlee
NOTE; ALLE Darlehen sind für 10JAHRE RATE VALID
ANGEBOT ENDET BALD SO JETZT HURRY

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?= ===

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: dccp
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 13:07:55 +0000
Message-ID: <237646137.26165.1361452075452.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe dccp" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-netdev
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 15:48:21 +0000
Message-ID: <659677805.29418.1361461701943.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe netdev" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-btrace
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:39 +0000
Message-ID: <729710404.30030.1361462439162.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-btrace" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-msdos
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:39 +0000
Message-ID: <729710404.30030.1361462439162.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-msdos" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-raid
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:39 +0000
Message-ID: <729710404.30030.1361462439162.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-raid" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-sparse
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:39 +0000
Message-ID: <729710404.30030.1361462439162.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-ext4
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:39 +0000
Message-ID: <729710404.30030.1361462439162.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-ide
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:39 +0000
Message-ID: <729710404.30030.1361462439162.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-ide" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-fsdevel
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:39 +0000
Message-ID: <729710404.30030.1361462439162.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-fsdevel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-m68k
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:39 +0000
Message-ID: <729710404.30030.1361462439162.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-m68k" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-ia64
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:39 +0000
Message-ID: <729710404.30030.1361462439162.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-ia64" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-fsdevel
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:43 +0000
Message-ID: <246010858.30034.1361462443488.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-fsdevel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-msdos
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:43 +0000
Message-ID: <246010858.30034.1361462443488.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-msdos" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-ext4
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:43 +0000
Message-ID: <246010858.30034.1361462443488.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-arch
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:43 +0000
Message-ID: <246010858.30034.1361462443488.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-arch" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-ide
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:43 +0000
Message-ID: <246010858.30034.1361462443488.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-ide" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-m68k
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:43 +0000
Message-ID: <246010858.30034.1361462443488.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-m68k" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Webmail Administrator <fauzi () matic ! gov ! my>
To: linux-scsi
Subject: =?utf-8?Q?Your_Mailbox_Has_Exceeded_It_Quota/Limit=C2=AE?=
Date: Thu, 21 Feb 2013 16:00:43 +0000
Message-ID: <246010858.30034.1361462443488.JavaMail.root () mail ! matic ! gov ! my>
--------------------


-- 
Your Mailbox Has Exceeded It Quota/Limit As Set By Your Administration, And You May Not Be Able To Send Or Receive New Mails Until You Re-Validate It. To Re-Validate, Please CLICK:  www.mailservices.at.tf
--
To unsubscribe from this list: send the line "unsubscribe linux-scsi" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: A sparse warning I dont understand in drivers/hwmon/max16065.c [was: smatch warning] ===

From: Guenter Roeck <linux () roeck-us ! net>
To: linux-sparse
Subject: Re: A sparse warning I dont understand in drivers/hwmon/max16065.c [was: smatch warning]
Date: Tue, 06 Aug 2013 14:53:37 +0000
Message-ID: <52010DF1.6050301 () roeck-us ! net>
--------------------
On 08/06/2013 12:31 AM, Dan Carpenter wrote:
> On Mon, Aug 05, 2013 at 03:00:32PM -0700, Guenter Roeck wrote:
>> Hi all,
>>
>> I get the following warning while scanning drivers/hwmon/max16065.c.
>>
>> drivers/hwmon/max16065.c:67:10: warning: Initializer entry defined twice
>> drivers/hwmon/max16065.c:68:10:   also defined here
>> drivers/hwmon/max16065.c:76:10: warning: Initializer entry defined twice
>> drivers/hwmon/max16065.c:77:10:   also defined here
>>
>> I must have looked at the code half a dozen times, but I just
>> don't see what might be wrong.
>>
>> Any idea, anyone ?
>
> This is actually a Sparse warning not a Smatch warning.  To get the
> Smatch warnings (there aren't any) do:

Thanks for the clarification. I updated the subject.

Guenter

> ~/path/to/smatch/smatch_scripts/kchecker --spammy drivers/hwmon/max16065.c
>
> This problem is here is a bug in Sparse handling arrays of _Bool.
> Let me add the Sparse people to the CC list and a small test case.
>
> static _Bool array_name[] = {
> 	[0] = 0,
> 	[1] = 0,
> 	[2] = 0,
> 	[3] = 0,
> };
>
> Sparse complains that element 1 was already initialized.
>
> regards,
> dan carpenter
>
>
>

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: ACHTUNG FRIEND! ===

From: "WERNER ERICH ZELLER" <e639 () humv ! es>
To: linux-sparse
Subject: ACHTUNG FRIEND!
Date: Thu, 21 Mar 2013 23:57:10 +0000
Message-ID: <55112.82.128.17.98.1363910230.squirrel () correo ! humv ! es>
--------------------



-- 
Eure Eminenz, das ist das dritte Mal, dass ich schreibe Ihnen bin, ich
bete nur du es dieses Mal! Ich bin Barrister Werner Erich Zeller des
Vereinigten Königreichs und ich schreibe auf Ihre 100% aufrichtiges
Interesse und Partnerschaft bei der Wiederherstellung der Höhe von  15
Mio. (EURO) Privatbank, die früher zu einem späten Kunde von mir, die,
ohne einem bestimmten Nest weitergegeben gehörten zu suchen Angehörigen
und Empfänger. Wie für die Rechtmäßigkeit und Echtheit, lassen Sie das zu
mir, ich werde es als Rechtsanwalt rechtlich 100% Griff! Wir stehen beide
zu 50% des  15 Mio. (EURO) jeweils als Partner profitieren. Schicken Sie
mir eine private E-Mail für die Details: wernererichzeller@yahoo.com und
Telefon: +447024090820

Bitte zurück zu mir sofort!
Werner Erich Zeller (Attorney)
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Build setting for sparse ===

From: Jean Sacren <sakiwit () gmail ! com>
To: linux-sparse
Subject: Build setting for sparse
Date: Sat, 03 Aug 2013 04:13:43 +0000
Message-ID: <20130803041343.GA3620 () mail ! gmail ! com>
--------------------
What are the simplest build settings to be put in local.mk so that all
the output files of sparse could be located in <DIRECTORY> other than
the source directory? Thanks in advance.

-- 
Jean Sacren
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Buy the most popular product ===

From: <NathanRijckmans () markdanton ! onmicrosoft ! com>
To: linux-sparse
Subject: Buy the most popular product
Date: Thu, 26 Sep 2013 22:28:48 +0000
Message-ID: <c3288cfc-15d7-415d-a39f-8231252330df () DBXPR04MB030 ! eurprd04 ! prod ! outlook ! com>
--------------------

		Dear Customer,

There is a lot of people in this world who spend so much time 
watching their health that they have not the time to enjoy it.

No doctor visits
Lowest price World Wide 
Discreet Packaging

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=de&url=www.google.com.kh&u=http://onlineshop56.yolasite.com/store&usg=ALkJrhiPIj0JIe5ltgZLyZ-4D3x8QMLv4g

Best Regards,
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Do not miss a chance! ===

From: <RichardTrapanese () rufyrily ! onmicrosoft ! com>
To: linux-sparse
Subject: Do not miss a chance!
Date: Tue, 17 Sep 2013 21:40:33 +0000
Message-ID: <4f9a6c1a-a2b2-4486-bb37-421294206e45 () AMSPR03MB100 ! eurprd03 ! prod ! outlook ! com>
--------------------

		Dear Customer,

There is a lot of people in this world who spend so much time 
watching their health that they have not the time to enjoy it.

No doctor visits
Lowest price World Wide 
Discreet Packaging

http://onlineshop2.yolasite.com/shop

Best Regards,
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Exclusive offer, feel it for real ===

From: <RonaldzBruns () wabipyge ! onmicrosoft ! com>
To: linux-scsi
Subject: Exclusive offer, feel it for real
Date: Thu, 12 Sep 2013 12:13:13 +0000
Message-ID: <662a4238-66b6-46c2-b40b-c45c58e2ecd5 () AMXPR05MB055 ! eurprd05 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Doubling your money before you have even started playing!

http://onlinecasino25.webnode.com/casino/casino4

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-scsi" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <RonaldzBruns () morriswatanabe ! onmicrosoft ! com>
To: linux-ext4
Subject: Exclusive offer, feel it for real
Date: Thu, 12 Sep 2013 12:13:13 +0000
Message-ID: <2ed8fa12-71df-467e-adb8-c33bc9eb66f5 () DBXPR01MB030 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Doubling your money before you have even started playing!

http://onlinecasino46.webnode.com/casino/casino1

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <ROBERTMELDRUM () markdanton ! onmicrosoft ! com>
To: linux-ide
Subject: Exclusive offer, feel it for real
Date: Thu, 12 Sep 2013 12:13:14 +0000
Message-ID: <64820813-1b67-45ac-8f60-d8601fb241d5 () AMXPR04MB230 ! eurprd04 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Make your first deposit and we will triple your bonus money up to Â£600.

http://onlinecasino25.webnode.com/casino/casino5

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-ide" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <RichardTrapanese () angelwill ! onmicrosoft ! com>
To: linux-raid
Subject: Exclusive offer, feel it for real
Date: Thu, 12 Sep 2013 12:13:14 +0000
Message-ID: <60daecc0-2b59-4cdc-b90e-3c8088c50e86 () DB3PR01MB041 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Doubling your money before you have even started playing!

http://onlinecasino36.webnode.com/casino/casino1

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-raid" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <RichardTrapanese () markdanton ! onmicrosoft ! com>
To: linux-sparse
Subject: Exclusive offer, feel it for real
Date: Thu, 12 Sep 2013 12:13:14 +0000
Message-ID: <e22ab2bd-2666-428f-a6a3-2163d194d97e () AMXPR04MB229 ! eurprd04 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Doubling your money before you have even started playing!

http://onlinecasino46.webnode.com/casino/casino2

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <ROBERTLBEMIS () angelwill ! onmicrosoft ! com>
To: linux-fsdevel
Subject: Exclusive offer, feel it for real
Date: Thu, 12 Sep 2013 12:13:21 +0000
Message-ID: <9ac629a6-a740-4b39-bf24-75621ca69ad3 () AMXPR01MB040 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Amazing Welcome Bonus offers including an incredible 100% match bonus of up to Â£200.

http://onlinecasino18.webnode.com/casino/casino5

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-fsdevel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <ROBERTMELDRUM () wabipyge ! onmicrosoft ! com>
To: linux-m68k
Subject: Exclusive offer, feel it for real
Date: Thu, 12 Sep 2013 12:13:22 +0000
Message-ID: <a9026bef-954f-40a9-bc4f-ff23fb6d1e9f () DBXPR05MB109 ! eurprd05 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Amazing Welcome Bonus offers including an incredible 100% match bonus of up to Â£200.

http://onlinecasino36.webnode.com/casino/casino5

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-m68k" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <DonnaVaught () robertwill ! onmicrosoft ! com>
To: dccp
Subject: Exclusive offer, feel it for real
Date: Mon, 16 Sep 2013 22:15:13 +0000
Message-ID: <beb2bba3-5770-445b-8aa5-524dc9ef27fc () AMXPR01MB008 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Amazing Welcome Bonus offers including an incredible 100% match bonus of up to Â£200.

http://onlinecasino46.webnode.com/casino/casino3

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe dccp" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <KeithASmith () angelwill ! onmicrosoft ! com>
To: linux-fsdevel
Subject: Exclusive offer, feel it for real
Date: Fri, 20 Sep 2013 17:16:50 +0000
Message-ID: <a3676cd0-9e78-41a2-817d-72c4ac22399e () AMSPR01MB065 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Doubling your money before you have even started playing!

http://fb.me/39Y8VgSsC

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-fsdevel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <johntaylor () morriswatanabe ! onmicrosoft ! com>
To: linux-msdos
Subject: Exclusive offer, feel it for real
Date: Fri, 20 Sep 2013 17:17:00 +0000
Message-ID: <e9292490-26f7-4a21-b0d4-be0f2a352eee () DB3PR01MB027 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Doubling your money before you have even started playing!

http://t.co/xoTAMo4mnL

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-msdos" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <KeithASmith () robertdanton ! onmicrosoft ! com>
To: linux-arch
Subject: Exclusive offer, feel it for real
Date: Fri, 20 Sep 2013 17:17:03 +0000
Message-ID: <ce7d0922-e014-4e64-9899-02866f8bad15 () DBXPR01MB048 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Doubling your money before you have even started playing!

http://t.co/HTmm1FkTRf

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-arch" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <KennethEEGGLESTON () robertdanton ! onmicrosoft ! com>
To: linux-scsi
Subject: Exclusive offer, feel it for real
Date: Fri, 20 Sep 2013 17:17:03 +0000
Message-ID: <1144511c-508c-4bdb-a110-7ced3c7968da () AMSPR01MB067 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Make your first deposit and we will triple your bonus money up to Â£600.

http://fb.me/W62qZEBP

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-scsi" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <KeithASmith () wabipyge ! onmicrosoft ! com>
To: linux-ide
Subject: Exclusive offer, feel it for real
Date: Fri, 20 Sep 2013 17:17:03 +0000
Message-ID: <594e1d0f-75d3-499d-9d9b-ef9091f4bbf6 () AMSPR05MB035 ! eurprd05 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Make a first deposit to receive your first casino bonus.

http://t.co/IF1X3v7GKu

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-ide" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <BarryFolmar () MichaelStrelnik ! onmicrosoft ! com>
To: linux-scsi
Subject: Exclusive offer, feel it for real
Date: Fri, 27 Sep 2013 23:34:17 +0000
Message-ID: <9874cab7-cd7e-4507-8149-4435529e1135 () DB3PR02MB011 ! eurprd02 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Sign up today to receive a welcome bonus of up to Â£200 to get you started on your streak!

http://fb.me/IojfxTNl

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-scsi" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <BarryFolmar () MichaelStrelnik ! onmicrosoft ! com>
To: linux-sparse
Subject: Exclusive offer, feel it for real
Date: Fri, 27 Sep 2013 23:34:17 +0000
Message-ID: <a2c51dc0-a07d-471e-88c9-a302ca388db6 () DB3PR02MB011 ! eurprd02 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Amazing Welcome Bonus offers including an incredible 100% match bonus of up to Â£200.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.ae&u=http://onlinecasino27.yolasite.com/casino1&usg=ALkJrhigo2DxeKnp8k6CY7J-q-rVMUPqBw

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <AndreSnodgrass () robertwill ! onmicrosoft ! com>
To: linux-m68k
Subject: Exclusive offer, feel it for real
Date: Fri, 27 Sep 2013 23:34:37 +0000
Message-ID: <f4e787f6-490f-4514-ba89-c4e1387cdcfc () DBXPR01MB014 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Make a first deposit to receive your first casino bonus.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.bs&u=http://onlinecasino27.yolasite.com/casino2&usg=ALkJrhhK-lSlaqpaRYJ582o05dhhglmEmw

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-m68k" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <BarrettDavis () morriswatanabe ! onmicrosoft ! com>
To: linux-netdev
Subject: Exclusive offer, feel it for real
Date: Sat, 28 Sep 2013 11:08:05 +0000
Message-ID: <6b9039e4-b266-4fdf-92fc-359d29459e24 () DB3PR01MB009 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Make your first deposit and we will triple your bonus money up to Â£600.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.com.bd&u=http://onlinecasino27.yolasite.com/casino1&usg=ALkJrhjsEp2wEy6D4p3zB8y4lFpDcS7xmg

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe netdev" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: I PREFERRED YOUR HELP ===

From: "Mr Jr. Laurent" <juniorlaur100 () gmail ! com>
To: linux-sparse
Subject: I PREFERRED YOUR HELP
Date: Thu, 28 Feb 2013 09:49:37 +0000
Message-ID: <1362044977.91345.YahooMailRC () web5718 ! biz ! mail ! ne1 ! yahoo ! com>
--------------------
---1667998798-954689149-1362044977=:91345
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

I PREFERRED YOU (GO THROUGH THE ATTACHMENT FOR THE MESSAGE)
---1667998798-954689149-1362044977=:91345
Content-Type: application/vnd.openxmlformats-officedocument.wordprocessingml.document; name="Laur.docx"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="Laur.docx"
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---1667998798-954689149-1362044977=:91345--
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Let the moment last as much as you want. ===

From: <KurtCarver () markdanton ! onmicrosoft ! com>
To: linux-sparse
Subject: Let the moment last as much as you want.
Date: Sun, 13 Oct 2013 09:19:29 +0000
Message-ID: <4fc87c5a-4edd-437f-916c-8bec8d1c63ce () DBXPR04MB047 ! eurprd04 ! prod ! outlook ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=de&url=www.google.dk&u=http://dl.dropboxusercontent.com/s/kk99xdcmjnl5ehv/beonline.html&usg=ALkJrhigo2DxeKnp8k6CY7J-q-rVMUPqBw

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: MY GOOD FRIEND! ===

From: Michele Roca <michele.rocca () cacciatoritrentini ! it>
To: linux-sparse
Subject: MY GOOD FRIEND!
Date: Wed, 27 Mar 2013 08:10:09 +0000
Message-ID: <858397a3c3e05f3d5407156d0b746379 () cacciatoritrentini ! it>
--------------------



I am Barrister Werner Erich Zeller; I need your sincere partnership in
transferring the sum of 15,000,000.00 EUR The details await you as you 
reply!

please! Call +44 702 409 0820 (office)

-- 
Ich bin Barrister Werner Erich Zeller, ich brauche eure aufrichtige
Partnerschaft intransferring die Summe von 15.000.000,00 EUR auf Ihr
Bankkonto in dieser Woche fÃ¼r den Nutzen der beiden von uns 50% each.It
ist 100% legal, legitim und sicher! fÃ¼r Details, schreiben Sie mir auf
dieser meiner privaten E-Mail statt: Dies ist dringende und ernste Sie
mÃ¼ssen bereit sein und bereit, bevor Sie mich kontaktieren.

bitte! Rufen Sie +44 702 409 0820 (BÃ¼ro)
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Quick Loans ===

From: Sec Capital Loan <alucero () ciudaddemendoza ! gov ! ar>
To: linux-sparse
Subject: Quick Loans
Date: Mon, 17 Jun 2013 10:58:05 +0000
Message-ID: <1488474810.142860.1371466685027.JavaMail.root () ciudaddemendoza ! gov ! ar>
--------------------
Do you need a personal or business loan without stress and quick approval? If yes, contact us today as we are currently offering loans at superb interest rate. Our loan is secured and safe,For more information and Application, Please reply to this Email.

Sincerely,
Vijay Nath
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Quick Loans(Apply Today) ===

From: "Sec Capital Loan" <info () secloans ! com>
To: linux-sparse
Subject: Quick Loans(Apply Today)
Date: Wed, 12 Jun 2013 04:16:49 +0000
Message-ID: <20130612040507.3E8D944DC8F () zimbra ! apolar ! imb ! br>
--------------------
Do you need a personal or business loan without stress and quick approval? If yes, contact us today as we are currently offering loans at superb interest rate. Our loan is secured and safe,For more information and Application, Please reply to this Email.

Sincerely,
Vijay Nath
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: RFC: [0/2] Moving attribute data out of ctype ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: RFC: [0/2] Moving attribute data out of ctype
Date: Wed, 27 Feb 2013 15:13:53 +0000
Message-ID: <CANeU7Q=UNu=Jy5dfSp+3CpAHSn3onnB_TVBSqZdA=OypGkY8+g () mail ! gmail ! com>
--------------------
Hi Al,

As we know "ctype" is a very common data struct, we don't want
to expand the size of ctype. It is running out of bits to proper
store fancy attribute data.

I want to store the attribute in a separate structure. The ctype
only keep a pointer to it. Most of the C code don't use attribute
at all. It will reuse the empty attribute pointer. I can grow that
attribute struct easier because only symbol that use the fancy
attribute will have the extra attribute structure allocated.

The first patch add the attribute structure, duplicating the attribute
in ctype. The second patch remove the reference of old attribute
member inside ctype.

What do you say about eventually move all the attribute bits
out of the modifiers into attribute struct? e.g. noreturn,pure etc.

Testing:
- make check passed.
- I run the patch against current Linux source tree. It produce the same
sparse checking output in all module configuration.

Thanks

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: RFC: [0/2] Moving attribute data out of ctype
Date: Wed, 27 Feb 2013 15:28:53 +0000
Message-ID: <CANeU7Q=bcQ_jC_kphn9E7-6N7U8ByQkiBwuxEZ-KFbSu291skQ () mail ! gmail ! com>
--------------------
BTW, I put up a review branch "rfc-attribute-struct" on

git://git.kernel.org/pub/scm/devel/sparse/chrisl/sparse.git

Chris

On Wed, Feb 27, 2013 at 7:13 AM, Christopher Li <sparse@chrisli.org> wrote:
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Response to your email. ===

From: guillermocha1 () aol ! com
To: linux-sparse
Subject: Response to your email.
Date: Wed, 03 Apr 2013 21:51:28 +0000
Message-ID: <20130403215202.56F061AC2B9E1 () mail ! factum ! hk>
--------------------
Mr name is Mr Guillermo Chavez and am writing you to kindly reply me once you get this message it is about one of my late friend who died in the ongoing war in SYRIA he was in the engineering oil legal dealer who was also my client and i his legal Lawyer to his business, i will explain further if you show your interest by responding to me through this my personal email (gchavez2013@aim.com)
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Sparse 0.5.0-rc1 ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Sparse 0.5.0-rc1
Date: Sat, 21 Dec 2013 17:45:31 +0000
Message-ID: <CANeU7QkDAONM63hx-fHWQzd9j4CVuEJqQn5A_dD1uYDHxUzS=w () mail ! gmail ! com>
--------------------
I am cutting a new release to mark the migration to MIT License
in the sparse project.

I want to thank Novafora and all sparse developers for making
this migration possible.  Special thanks to Dan Carpenter
and Franz Schrober for contacting each sparse developer to
get permission for the new license.

Please give it a good test. I plan to cut the finial release in
a week.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Sparse release 0.4.5-rc1 ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Sparse release 0.4.5-rc1
Date: Thu, 09 May 2013 13:31:58 +0000
Message-ID: <518BA54E.9030005 () chrisli ! org>
--------------------
I just push the tag for sparse 0.4.5-rc1

It is about time to cut a new release. There have been a lot of
small improvements. It produces less warning on the recent kernel
check.

Please give it a good test.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Sparse repository updated ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Sparse repository updated
Date: Wed, 27 Feb 2013 14:36:21 +0000
Message-ID: <CANeU7QmBEJX8Hka2nsDYLexMOdvpaMx2=9ARK49dr4__tLUtMQ () mail ! gmail ! com>
--------------------
For a while I lost my kernel.org access, I use github to host sparse repository
in github. I have recently regain the kernel.org access.

Both repository have been updated, the official repository is still at:
git://git.kernel.org/pub/scm/devel/sparse/sparse.git

My development tree:
git://git.kernel.org/pub/scm/devel/sparse/chrisl/sparse.git

Thanks

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Stop your worries and share again your special moments. ===

From: <RichardWhitt () angelwill ! onmicrosoft ! com>
To: linux-btrace
Subject: Stop your worries and share again your special moments.
Date: Thu, 19 Sep 2013 06:18:04 +0000
Message-ID: <c44b0a5a-30a7-47b2-a01e-e4414a1c7561 () AMSPR01MB150 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://onlinestore13.webnode.com/store

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-btrace" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <RichardDElias () angelwill ! onmicrosoft ! com>
To: linux-msdos
Subject: Stop your worries and share again your special moments.
Date: Thu, 19 Sep 2013 06:18:35 +0000
Message-ID: <7abd18bb-76e7-441a-b814-20459e16fd04 () DB3PR01MB140 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://onlinestore15.webnode.com/store

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-msdos" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <RichardWhitt () markdanton ! onmicrosoft ! com>
To: linux-ia64
Subject: Stop your worries and share again your special moments.
Date: Thu, 19 Sep 2013 06:20:44 +0000
Message-ID: <0d849cab-4bb2-42aa-9680-c64412e276ad () AMSPR04MB130 ! eurprd04 ! prod ! outlook ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://onlinestore18.yolasite.com/shop

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-ia64" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <DebraPENNEY () morriswatanabe ! onmicrosoft ! com>
To: dccp
Subject: Stop your worries and share again your special moments.
Date: Sat, 21 Sep 2013 13:50:31 +0000
Message-ID: <7e8c80b7-7bf0-48a5-844a-7f3ea09ad43d () AMSPR01MB019 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Why missing moments with your loved ones when you have the solution at one click distance?

Never miss a moment again

http://onlinestore13.yolasite.com/store

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe dccp" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <DebraPENNEY () rufyrily ! onmicrosoft ! com>
To: linux-sparse
Subject: Stop your worries and share again your special moments.
Date: Tue, 24 Sep 2013 22:59:08 +0000
Message-ID: <9775c5ad-00a1-4110-aff4-f6a106133563 () AMXPR03MB056 ! eurprd03 ! prod ! outlook ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.com.bh&u=http://onlineshop63.yolasite.com/shop&usg=ALkJrhiAlYaq_M5N1Kwb51HLkDjfWEwKig

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <DeepakRullay () rufyrily ! onmicrosoft ! com>
To: linux-ide
Subject: Stop your worries and share again your special moments.
Date: Tue, 24 Sep 2013 22:59:08 +0000
Message-ID: <af86c0e0-2ddf-407e-b12f-a2e17cfc51d9 () DBXPR03MB109 ! eurprd03 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Why missing moments with your loved ones when you have the solution at one click distance?

Never miss a moment again

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=de&url=www.google.co.zw&u=http://onlineshop67.yolasite.com/store&usg=ALkJrhgFCu9UFdrTRdMCMEiIo6cEQdlF8w

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-ide" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <DebraPENNEY () rufyrily ! onmicrosoft ! com>
To: linux-sparse
Subject: Stop your worries and share again your special moments.
Date: Tue, 24 Sep 2013 22:59:08 +0000
Message-ID: <9775c5ad-00a1-4110-aff4-f6a106133563 () AMXPR03MB056 ! eurprd03 ! prod ! outlook ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.com.bh&u=http://onlineshop63.yolasite.com/shop&usg=ALkJrhiAlYaq_M5N1Kwb51HLkDjfWEwKig

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <GiuseppeArena () morriswatanabe ! onmicrosoft ! com>
To: dccp
Subject: Stop your worries and share again your special moments.
Date: Tue, 01 Oct 2013 07:11:51 +0000
Message-ID: <ac77e9b1-951d-45db-a6e0-8ecc2b756935 () AMSPR01MB004 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Why missing moments with your loved ones when you have the solution at one click distance?

Never miss a moment again

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.fm&u=http://myshoponline1.yolasite.com/store&usg=ALkJrhiPIj0JIe5ltgZLyZ-4D3x8QMLv4g

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe dccp" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <BarrettDavis () robertwill ! onmicrosoft ! com>
To: linux-btrace
Subject: Stop your worries and share again your special moments.
Date: Wed, 02 Oct 2013 16:56:12 +0000
Message-ID: <52647b80-31a4-4f0f-9dba-002e1fce6d81 () DBXPR01MB046 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.co.cr&u=http://onlineshop67.yolasite.com/shop&usg=ALkJrhiAlYaq_M5N1Kwb51HLkDjfWEwKig

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-btrace" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <ChiMingPan () dantonweimer ! onmicrosoft ! com>
To: linux-raid
Subject: Stop your worries and share again your special moments.
Date: Thu, 03 Oct 2013 09:47:02 +0000
Message-ID: <8d0220df-e50a-4070-b7e9-4a639a252765 () DBXPR04MB109 ! eurprd04 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Why missing moments with your loved ones when you have the solution at one click distance?

Never miss a moment again

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.com.gh&u=http://onlineshop66.yolasite.com/store&usg=ALkJrhjsEp2wEy6D4p3zB8y4lFpDcS7xmg

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-raid" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <ChiMingPan () rufyrily ! onmicrosoft ! com>
To: linux-sparse
Subject: Stop your worries and share again your special moments.
Date: Thu, 03 Oct 2013 09:47:49 +0000
Message-ID: <d9f76936-ea4b-4899-9746-9eb23e7af848 () DB3PR03MB107 ! eurprd03 ! prod ! outlook ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=de&url=www.google.ba&u=http://onlineshop67.yolasite.com/store&usg=ALkJrhi5ttZIbmPMAR-MPDhk5psS3FlSAw

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <BarrettDavis () morriswatanabe ! onmicrosoft ! com>
To: linux-ext4
Subject: Stop your worries and share again your special moments.
Date: Thu, 03 Oct 2013 10:38:18 +0000
Message-ID: <0cc0ac7a-d601-4336-9407-1a11648fb609 () DB3PR01MB009 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=de&url=www.google.com.cu&u=http://myonlineshop2.yolasite.com/store&usg=ALkJrhh3JjaMUtGSx3BnIJjj9viGsGjNxw

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <DebraPENNEY () markdanton ! onmicrosoft ! com>
To: linux-ide
Subject: Stop your worries and share again your special moments.
Date: Thu, 03 Oct 2013 13:47:35 +0000
Message-ID: <962d0e2e-0822-4d7c-a9e5-d70d335ac420 () AMXPR04MB150 ! eurprd04 ! prod ! outlook ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.bi&u=http://myonlineshop2.yolasite.com/store&usg=ALkJrhiPIj0JIe5ltgZLyZ-4D3x8QMLv4g

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-ide" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <FrankJCullen () robertwill ! onmicrosoft ! com>
To: linux-sparc
Subject: Stop your worries and share again your special moments.
Date: Thu, 03 Oct 2013 15:21:15 +0000
Message-ID: <26573be5-ad29-4ece-b4fb-4b7fc500e176 () DB3PR01MB028 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Why missing moments with your loved ones when you have the solution at one click distance?

Never miss a moment again

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=de&url=www.google.bf&u=http://onlineshop67.yolasite.com/store&usg=ALkJrhgFCu9UFdrTRdMCMEiIo6cEQdlF8w

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe sparclinux" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <GiuseppeArena () robertdanton ! onmicrosoft ! com>
To: linux-sparc
Subject: Stop your worries and share again your special moments.
Date: Thu, 03 Oct 2013 20:38:43 +0000
Message-ID: <862ae889-4e5f-4016-ad05-d7b87aa4d8eb () DBXPR01MB030 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Why missing moments with your loved ones when you have the solution at one click distance?

Never miss a moment again

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.com.ag&u=http://myonlinestore1.yolasite.com/store&usg=ALkJrhiAlYaq_M5N1Kwb51HLkDjfWEwKig

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe sparclinux" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <johntaylor () dantonweimer ! onmicrosoft ! com>
To: linux-msdos
Subject: Stop your worries and share again your special moments.
Date: Sun, 13 Oct 2013 09:14:47 +0000
Message-ID: <061d2616-0ecb-40d1-a70a-884af4c815a2 () DBXPR04MB127 ! eurprd04 ! prod ! outlook ! com>
--------------------

		Dear Customer,

Sometimes things happen much quicker than you would love to.

Let the moment last as much as you want.

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=fr&url=www.google.com.au&u=http://dl.dropboxusercontent.com/s/3y8wf16zw44fg0o/buynow.html&usg=ALkJrhjuuBC9SIdn3nj6vfQ7-8vR_Bt35g

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-msdos" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <KurtCarver () markdanton ! onmicrosoft ! com>
To: linux-m68k
Subject: Stop your worries and share again your special moments.
Date: Sun, 13 Oct 2013 09:14:47 +0000
Message-ID: <17d52791-2771-414a-beff-e93f04f91e6d () DBXPR04MB047 ! eurprd04 ! prod ! outlook ! com>
--------------------

		Dear Customer 

Why missing moments with your loved ones when you have the solution at one click distance?

Never miss a moment again

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=de&url=www.google.ee&u=http://dl.dropboxusercontent.com/s/3y8wf16zw44fg0o/buynow.html&usg=ALkJrhgFCu9UFdrTRdMCMEiIo6cEQdlF8w

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-m68k" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <johntaylor () robertdanton ! onmicrosoft ! com>
To: linux-sparse
Subject: Stop your worries and share again your special moments.
Date: Sun, 13 Oct 2013 09:14:54 +0000
Message-ID: <7a94e973-a71e-40f6-a758-ac519712b4f3 () DBXPR01MB031 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Why missing moments with your loved ones when you have the solution at one click distance?

Never miss a moment again

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=de&url=www.google.com.af&u=http://dl.dropboxusercontent.com/s/vgox1rwyo5xvdtj/goodpriceonline.html&usg=ALkJrhgFCu9UFdrTRdMCMEiIo6cEQdlF8w

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: <KevinWKahl () morriswatanabe ! onmicrosoft ! com>
To: linux-ext4
Subject: Stop your worries and share again your special moments.
Date: Sun, 13 Oct 2013 09:29:17 +0000
Message-ID: <16f91b68-52f2-4b5e-8489-e80018720c3e () AMSPR01MB017 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Why missing moments with your loved ones when you have the solution at one click distance?

Never miss a moment again

http://translate.googleusercontent.com/translate_c?depth=1&hl=auto&sl=de&url=www.google.bi&u=http://dl.dropboxusercontent.com/s/vgox1rwyo5xvdtj/goodpriceonline.html&usg=ALkJrhigo2DxeKnp8k6CY7J-q-rVMUPqBw

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Suggestion for fixing the variable length array used in the kernel. ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Suggestion for fixing the variable length array used in the kernel.
Date: Thu, 07 Mar 2013 04:46:35 +0000
Message-ID: <CANeU7Qn-5b5U_64QzFt-beP-PyAJgzz=z1100F0v5WbWqZwZOQ () mail ! gmail ! com>
--------------------
Hi,

I am looking at the current sparse warning on the kernel source.
One category of those warning are produce by the variable length array.
We all know that the kernel stack has a limit so we don't want to allocate
too much stack to the variable size array.

Is there a recommended way to fix those warnings? Is it worth while to
fix it at all? I am looking forward to some kind of guideline how to handle
this.


Some of them has estimated size limited, like the one fournd in decode_rs.c

	/* Err+Eras Locator poly and syndrome poly The maximum value
	 * of nroots is 8. So the necessary stack size will be about
	 * 220 bytes max.
	 */
	uint16_t lambda[nroots + 1], syn[nroots];
	uint16_t b[nroots + 1], t[nroots + 1], omega[nroots + 1];
	uint16_t root[nroots], reg[nroots + 1], loc[nroots];

Some of them did not said the size estimation but you kind of know
they are not likely to blow up the stack:
In xen_flush_tlb_others

	struct {
		struct mmuext_op op;
#ifdef CONFIG_SMP
		DECLARE_BITMAP(mask, num_processors);
#else
		DECLARE_BITMAP(mask, NR_CPUS);
#endif
	} *args;

And also some of them are harder to tell from the context if
there will be a size limit:

int snd_pcm_hw_refine(struct snd_pcm_substream *substream,
		      struct snd_pcm_hw_params *params)
{
	unsigned int k;
	struct snd_pcm_hardware *hw;
	struct snd_interval *i = NULL;
	struct snd_mask *m = NULL;
	struct snd_pcm_hw_constraints *constrs = &substream->runtime->hw_constraints;
	unsigned int rstamps[constrs->rules_num]; <---------------------------------


Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Andrew Morton <akpm () linux-foundation ! org>
To: linux-kernel
Subject: Re: Suggestion for fixing the variable length array used in the kernel.
Date: Sat, 09 Mar 2013 00:29:22 +0000
Message-ID: <20130308162922.88ad40997d01099949008452 () linux-foundation ! org>
--------------------
On Wed, 6 Mar 2013 20:46:35 -0800 Christopher Li <sparse@chrisli.org> wrote:

> Hi,
> 
> I am looking at the current sparse warning on the kernel source.
> One category of those warning are produce by the variable length array.
> We all know that the kernel stack has a limit so we don't want to allocate
> too much stack to the variable size array.
> 
> Is there a recommended way to fix those warnings? Is it worth while to
> fix it at all? I am looking forward to some kind of guideline how to handle
> this.

Roughly how many instances of this are there kernel-wide?

I don't think it's good practice in the kernel - it's somewhat
dangerous and the effects of errors will be catastrophic.  And as
you've seen, those sites are difficult to review for safety.

We could just outright ban the thing and convert those sites to
kmalloc() or whatever.  If people howl about the performance impact
(unlikely) then perhaps we can put something together using
__builtin_alloca() which includes runtime checking for "excessive"
allocations.  If an excessive allocation is detected we'd warn and
return NULL.

Anyway, yes, variable-length arrays are problematic so for now, let's
leave the sparse warnings in place?

--
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
================================================================================

From: Andrew Morton <akpm () linux-foundation ! org>
To: linux-sparse
Subject: Re: Suggestion for fixing the variable length array used in the kernel.
Date: Sat, 09 Mar 2013 00:29:22 +0000
Message-ID: <20130308162922.88ad40997d01099949008452 () linux-foundation ! org>
--------------------
On Wed, 6 Mar 2013 20:46:35 -0800 Christopher Li <sparse@chrisli.org> wrote:

> Hi,
> 
> I am looking at the current sparse warning on the kernel source.
> One category of those warning are produce by the variable length array.
> We all know that the kernel stack has a limit so we don't want to allocate
> too much stack to the variable size array.
> 
> Is there a recommended way to fix those warnings? Is it worth while to
> fix it at all? I am looking forward to some kind of guideline how to handle
> this.

Roughly how many instances of this are there kernel-wide?

I don't think it's good practice in the kernel - it's somewhat
dangerous and the effects of errors will be catastrophic.  And as
you've seen, those sites are difficult to review for safety.

We could just outright ban the thing and convert those sites to
kmalloc() or whatever.  If people howl about the performance impact
(unlikely) then perhaps we can put something together using
__builtin_alloca() which includes runtime checking for "excessive"
allocations.  If an excessive allocation is detected we'd warn and
return NULL.

Anyway, yes, variable-length arrays are problematic so for now, let's
leave the sparse warnings in place?

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-sparse
Subject: Re: Suggestion for fixing the variable length array used in the kernel.
Date: Sat, 09 Mar 2013 05:39:00 +0000
Message-ID: <20130309053859.GY9138 () mwanda>
--------------------
On Fri, Mar 08, 2013 at 04:29:22PM -0800, Andrew Morton wrote:
> On Wed, 6 Mar 2013 20:46:35 -0800 Christopher Li <sparse@chrisli.org> wrote:
> 
> > Hi,
> > 
> > I am looking at the current sparse warning on the kernel source.
> > One category of those warning are produce by the variable length array.
> > We all know that the kernel stack has a limit so we don't want to allocate
> > too much stack to the variable size array.
> > 
> > Is there a recommended way to fix those warnings? Is it worth while to
> > fix it at all? I am looking forward to some kind of guideline how to handle
> > this.
> 
> Roughly how many instances of this are there kernel-wide?
> 

Around 150 on x86 allmodconfig.  They are pretty well audited.

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-kernel
Subject: Re: Suggestion for fixing the variable length array used in the kernel.
Date: Sat, 09 Mar 2013 05:39:00 +0000
Message-ID: <20130309053859.GY9138 () mwanda>
--------------------
On Fri, Mar 08, 2013 at 04:29:22PM -0800, Andrew Morton wrote:
> On Wed, 6 Mar 2013 20:46:35 -0800 Christopher Li <sparse@chrisli.org> wrote:
> 
> > Hi,
> > 
> > I am looking at the current sparse warning on the kernel source.
> > One category of those warning are produce by the variable length array.
> > We all know that the kernel stack has a limit so we don't want to allocate
> > too much stack to the variable size array.
> > 
> > Is there a recommended way to fix those warnings? Is it worth while to
> > fix it at all? I am looking forward to some kind of guideline how to handle
> > this.
> 
> Roughly how many instances of this are there kernel-wide?
> 

Around 150 on x86 allmodconfig.  They are pretty well audited.

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: Suggestion for fixing the variable length array used in the kernel.
Date: Sat, 09 Mar 2013 18:10:08 +0000
Message-ID: <CANeU7QnhB566ZJqjcaLkn7o701EeVbJcB=8VHW_33nwK=FZRhg () mail ! gmail ! com>
--------------------
--e89a8fb20660a3171b04d781d9d8
Content-Type: text/plain; charset=ISO-8859-1

On Fri, Mar 8, 2013 at 9:39 PM, Dan Carpenter <dan.carpenter@oracle.com> wrote:
> On Fri, Mar 08, 2013 at 04:29:22PM -0800, Andrew Morton wrote:
>> Roughly how many instances of this are there kernel-wide?
>>
>
> Around 150 on x86 allmodconfig.  They are pretty well audited.

I saw 207 on x86-64 allmodconfig. See the list that I attached.

Can you elaborate the well audited part? How it was audited?

I try to figure out if it is worth the trouble to fix it.


Chris

--e89a8fb20660a3171b04d781d9d8
Content-Type: application/octet-stream; name=var-array-error
Content-Disposition: attachment; filename=var-array-error
Content-Transfer-Encoding: base64
X-Attachment-Id: f_he335jfe0
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--e89a8fb20660a3171b04d781d9d8--
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-sparse
Subject: Re: Suggestion for fixing the variable length array used in the kernel.
Date: Sat, 09 Mar 2013 22:34:03 +0000
Message-ID: <20130309223403.GZ9138 () mwanda>
--------------------
On Sat, Mar 09, 2013 at 10:10:08AM -0800, Christopher Li wrote:
> On Fri, Mar 8, 2013 at 9:39 PM, Dan Carpenter <dan.carpenter@oracle.com> wrote:
> > On Fri, Mar 08, 2013 at 04:29:22PM -0800, Andrew Morton wrote:
> >> Roughly how many instances of this are there kernel-wide?
> >>
> >
> > Around 150 on x86 allmodconfig.  They are pretty well audited.
> 
> I saw 207 on x86-64 allmodconfig. See the list that I attached.
> 

Ah.  Sorry, I'm on my laptop and my sparse output was old.

> Can you elaborate the well audited part? How it was audited?
> 

The problems is if we go over the 8k stack.  So big arrays are bad.
Also if the dynamically sized array is inside a loop then normally
GCC frees it after each iteration, but on some arches it didn't free
it until after the last iteration.

Btw, I've Smatch has cross function analysis, and I'd like to use
it here to figure out if the max size for dynamically sized arrays.
I ran into a problem:

The code looks like this:
	char buf[a];
The size expression should be an EXPR_SYMBOL, but smatch gets:
	char buf[*a];
Where the size expression is an EXPR_PREOP.

In smatch, how I use sparse is that I call sparse_keep_tokens() and
then I parse the resulting symbol list myself.  The problem is in
examine_array_type() we call get_expression_value() which changes
the symbols from normal symbols to dereferences. The call tree is:
examine_array_type()
  -> get_expression_value()
     -> __get_expression_value()
        -> evaluate_expression()
	   -> evaluate_symbol_expression() <- change happens here.

I'm not sure what to do.

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: Suggestion for fixing the variable length array used in the kernel.
Date: Sat, 09 Mar 2013 23:00:54 +0000
Message-ID: <CANeU7Qk2axG8wUFt9JgHt3UpJZTiF50Ug9Udt3BAv99cBR9HPw () mail ! gmail ! com>
--------------------
On Sat, Mar 9, 2013 at 2:34 PM, Dan Carpenter <dan.carpenter@oracle.com> wrote:
> The problems is if we go over the 8k stack.  So big arrays are bad.
> Also if the dynamically sized array is inside a loop then normally
> GCC frees it after each iteration, but on some arches it didn't free
> it until after the last iteration.

So it seems that you agree those variable array usage should be
better change to use kmalloc or some thing.

> Btw, I've Smatch has cross function analysis, and I'd like to use
> it here to figure out if the max size for dynamically sized arrays.
> I ran into a problem:
>
> The code looks like this:
>         char buf[a];
> The size expression should be an EXPR_SYMBOL, but smatch gets:
>         char buf[*a];

Sparse currently does not deal with the dynamic array size right now.
It only want to get constant value from the array size.

The part that evaluate the array size is actually correct. Remember
the EXPR_SYMBOL
actually contain the *address* of symbol "a". So the proper
sizeof(buf) is actually
the content of "*a". That part is fine.
The more complicated case of dynamic array size is using the dynamic array in
a struct:

struct {
    char descriptor1[length+1];
    char descriptor2[length+1];
} *d;

Then the sizeof(*d) need to be ((*length) + 1 + (*length) + 1), assume
"length" is a
symbol address. The sizeof (struct foo) can be pretty complicate expression.

Some USB code use this kind of the dynamic array. However, it does not allocate
the struct in the stack, the struct is allocated via kmalloc using pointer.
Sparse still complain the variable length array though.

Let me see if I can make the sparse handle dynamic array better.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-kernel
Subject: Re: Suggestion for fixing the variable length array used in the kernel.
Date: Sat, 09 Mar 2013 23:00:54 +0000
Message-ID: <CANeU7Qk2axG8wUFt9JgHt3UpJZTiF50Ug9Udt3BAv99cBR9HPw () mail ! gmail ! com>
--------------------
On Sat, Mar 9, 2013 at 2:34 PM, Dan Carpenter <dan.carpenter@oracle.com> wrote:
> The problems is if we go over the 8k stack.  So big arrays are bad.
> Also if the dynamically sized array is inside a loop then normally
> GCC frees it after each iteration, but on some arches it didn't free
> it until after the last iteration.

So it seems that you agree those variable array usage should be
better change to use kmalloc or some thing.

> Btw, I've Smatch has cross function analysis, and I'd like to use
> it here to figure out if the max size for dynamically sized arrays.
> I ran into a problem:
>
> The code looks like this:
>         char buf[a];
> The size expression should be an EXPR_SYMBOL, but smatch gets:
>         char buf[*a];

Sparse currently does not deal with the dynamic array size right now.
It only want to get constant value from the array size.

The part that evaluate the array size is actually correct. Remember
the EXPR_SYMBOL
actually contain the *address* of symbol "a". So the proper
sizeof(buf) is actually
the content of "*a". That part is fine.
The more complicated case of dynamic array size is using the dynamic array in
a struct:

struct {
    char descriptor1[length+1];
    char descriptor2[length+1];
} *d;

Then the sizeof(*d) need to be ((*length) + 1 + (*length) + 1), assume
"length" is a
symbol address. The sizeof (struct foo) can be pretty complicate expression.

Some USB code use this kind of the dynamic array. However, it does not allocate
the struct in the stack, the struct is allocated via kmalloc using pointer.
Sparse still complain the variable length array though.

Let me see if I can make the sparse handle dynamic array better.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-sparse
Subject: Re: Suggestion for fixing the variable length array used in the kernel.
Date: Sun, 10 Mar 2013 11:38:42 +0000
Message-ID: <20130310113842.GA9138 () mwanda>
--------------------
On Sat, Mar 09, 2013 at 03:00:54PM -0800, Christopher Li wrote:
> On Sat, Mar 9, 2013 at 2:34 PM, Dan Carpenter <dan.carpenter@oracle.com> wrote:
> > The problems is if we go over the 8k stack.  So big arrays are bad.
> > Also if the dynamically sized array is inside a loop then normally
> > GCC frees it after each iteration, but on some arches it didn't free
> > it until after the last iteration.
> 
> So it seems that you agree those variable array usage should be
> better change to use kmalloc or some thing.
> 
> > Btw, I've Smatch has cross function analysis, and I'd like to use
> > it here to figure out if the max size for dynamically sized arrays.
> > I ran into a problem:
> >
> > The code looks like this:
> >         char buf[a];
> > The size expression should be an EXPR_SYMBOL, but smatch gets:
> >         char buf[*a];
> 
> Sparse currently does not deal with the dynamic array size right now.
> It only want to get constant value from the array size.
> 
> The part that evaluate the array size is actually correct. Remember
> the EXPR_SYMBOL
> actually contain the *address* of symbol "a". So the proper
> sizeof(buf) is actually
> the content of "*a". That part is fine.

It's evaluating it correctly, but Smatch normally expects
expressions which haven't been evaluated yet.

I can probably hack my own Sparse tree for what I need.  It's not a
big deal.

regards,
dan carpenter
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Twice the action, double the fun! ===

From: <johntaylor () robertdanton ! onmicrosoft ! com>
To: linux-sparse
Subject: Twice the action, double the fun!
Date: Fri, 20 Sep 2013 17:17:05 +0000
Message-ID: <64d5a277-cdbf-4c4b-8eaa-f831bd5ce9fe () DBXPR01MB031 ! eurprd01 ! prod ! exchangelabs ! com>
--------------------

		Dear Customer 

Doubling your money before you have even started playing!

http://fb.me/2MbRm4yRk

Best Regards, 
		
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Your  Attention Is Needed ===

From: "Mr. Raymond Khumalo" <asmaind () dnet ! net ! id>
To: linux-sparse
Subject: Your  Attention Is Needed
Date: Thu, 08 Aug 2013 16:51:23 +0000
Message-ID: <9f4bad57a739916d9819962269d252bf.squirrel () newwebmail ! dnet ! net ! id>
--------------------



I am.  Mr. Raymond Khumalo, Head

Accounts Management Section, of a

well-known
Bank here in South Africa. Can i

trust you on a transaction deal worth
US$10,000,000.if interested contact

me for details Email:
mrraymondkhumalo13@gmail.com

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: Your mailbox ===

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-arch
Subject: Your mailbox
Date: Tue, 11 Jun 2013 08:32:15 +0000
Message-ID: <20130611082032.5D2E444500F () zimbra ! apolar ! imb ! br>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-arch" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: dccp
Subject: Your mailbox
Date: Tue, 11 Jun 2013 08:32:15 +0000
Message-ID: <20130611082032.5D2E444500F () zimbra ! apolar ! imb ! br>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe dccp" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-m68k
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.28A7A28F9471 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-m68k" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-msdos
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.28A7A28F9471 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-msdos" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-fsdevel
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.28A7A28F9471 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-fsdevel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-arch
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.28A7A28F9471 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-arch" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-btrace
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.28A7A28F9471 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-btrace" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-ext4
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.28A7A28F9471 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-netdev
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.3767D28F94C2 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe netdev" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-sparc
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.3767D28F94C2 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe sparclinux" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-scsi
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.28A7A28F9471 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-scsi" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-ide
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.28A7A28F9471 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-ide" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "System Administrator" <sbirici () firat ! edu ! tr>
To: linux-ia64
Subject: Your mailbox
Date: Tue, 11 Jun 2013 09:54:43 +0000
Message-ID: <20130611094256.28A7A28F9471 () mail ! ekon ! go ! id>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-ia64" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: linux-raid
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <4b06779e-b3c7-426a-be3d-92cbd8fa7883 () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-raid" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: linux-arch
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <4b06779e-b3c7-426a-be3d-92cbd8fa7883 () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-arch" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: linux-ext4
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <4b06779e-b3c7-426a-be3d-92cbd8fa7883 () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: linux-ide
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <4b06779e-b3c7-426a-be3d-92cbd8fa7883 () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-ide" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: linux-netdev
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <6ad6329f-ed3a-494e-abe0-bae5b903e45a () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe netdev" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: linux-scsi
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <4b06779e-b3c7-426a-be3d-92cbd8fa7883 () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-scsi" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: dccp
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <4b06779e-b3c7-426a-be3d-92cbd8fa7883 () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe dccp" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: linux-msdos
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <4b06779e-b3c7-426a-be3d-92cbd8fa7883 () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-msdos" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: linux-fsdevel
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <4b06779e-b3c7-426a-be3d-92cbd8fa7883 () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-fsdevel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sec Capital Loan <ncatalbas () firat ! edu ! tr>
To: linux-btrace
Subject: Your mailbox
Date: Tue, 11 Jun 2013 15:30:21 +0000
Message-ID: <4b06779e-b3c7-426a-be3d-92cbd8fa7883 () FIRAT-CAS2 ! firat ! edu ! tr>
--------------------
ATTENTION;

Your mailbox has exceeded the storage limit which is 5GB as set by your administrator, you are currently running on 10.9GB,you may not be able to send or receive new mail until you re-validate your mailbox. To re-validate your mailbox  please send the following details below:

Name:
Username:
Password:
Retype Password:
Email Address:
Phone Number:

If you fail to re-validate your mailbox, your mailbox will be De-activated!!!

Thanks
System Administrator
--
To unsubscribe from this list: send the line "unsubscribe linux-btrace" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [BUG report]sparse warnings on DEFINE_PER_CPU() symbols non-static ===

From: Wanlong Gao <gaowanlong () cn ! fujitsu ! com>
To: linux-sparse
Subject: Re: [BUG report]sparse warnings on DEFINE_PER_CPU() symbols non-static
Date: Thu, 05 Dec 2013 00:18:56 +0000
Message-ID: <529FC670.2080308 () cn ! fujitsu ! com>
--------------------
On 12/04/2013 11:12 PM, Tejun Heo wrote:
> On Wed, Dec 04, 2013 at 11:26:44AM +0800, Wanlong Gao wrote:
>> Goes away but comes new error:
>>
>> /git/linux/fs/inode.c:74:8: error: symbol 'nr_inodes' redeclared with different type (originally declared at /git/linux/fs/inode.c:74) - different address spaces
>> /git/linux/fs/inode.c:75:8: error: symbol 'nr_unused' redeclared with different type (originally declared at /git/linux/fs/inode.c:75) - different address spaces
>> /git/linux/fs/inode.c:835:8: error: symbol 'last_ino' redeclared with different type (originally declared at /git/linux/fs/inode.c:835) - different address spaces
> 
> Oops, my bad.  How about the following?

It works, thank you.

Tested-by: Wanlong Gao <gaowanlong@cn.fujitsu.com>

> 
> diff --git a/include/linux/percpu-defs.h b/include/linux/percpu-defs.h
> index 57e890a..a5fc7d0 100644
> --- a/include/linux/percpu-defs.h
> +++ b/include/linux/percpu-defs.h
> @@ -69,6 +69,7 @@
>  	__PCPU_DUMMY_ATTRS char __pcpu_scope_##name;			\
>  	extern __PCPU_DUMMY_ATTRS char __pcpu_unique_##name;		\
>  	__PCPU_DUMMY_ATTRS char __pcpu_unique_##name;			\
> +	extern __PCPU_ATTRS(sec) __typeof__(type) name;			\
>  	__PCPU_ATTRS(sec) PER_CPU_DEF_ATTRIBUTES __weak			\
>  	__typeof__(type) name
>  #else
> 

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [GIT PULL] Sparse/LLVM updates ===

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [GIT PULL] Sparse/LLVM updates
Date: Wed, 10 Oct 2012 06:35:57 +0000
Message-ID: <CAOJsxLHYpiNPo7DUMrbfJGkw1ivB440ZMMAaYOmJT9uyTAbzTw () mail ! gmail ! com>
--------------------
Hi Chris,

On Tue, Oct 9, 2012 at 9:34 AM, Pekka Enberg <penberg@kernel.org> wrote:
> Hi Chris,
>
> Please pull the latest Sparse/LLVM tree from:
>
>   git@github.com:penberg/sparse-llvm.git llvm/core
>
> It contains few LLVM backend fixes from myself and Jonathan Neuschäfer.
>
>                         Pekka
>
> ------------------>

I have added one more LLVM backend fix from Jonathan to the branch:

The following changes since commit 063236fd3f46bc83b49172f5ecb597e0a91cede8:

  ptrlist.c: fix a typo in a comment (2012-06-26 00:54:24 -0700)

are available in the git repository at:
  git@github.com:penberg/sparse-llvm.git llvm/core

Jonathan Neuschäfer (3):
      sparse, llvm: 'Verify' the LLVM module before writing it
      sparse, llvm: convert the condition of branch/select to bool
      sparse, llvm: Fix type of loaded values

Pekka Enberg (2):
      sparse, llvm: Fix SIGSEGV for extern symbols
      sparse, llvm: Fix 'void' return type code generation

 sparse-llvm.c                         |   38 ++++++++++++++++++++++++++++----
 validation/backend/extern.c           |   11 +++++++++
 validation/backend/int-cond.c         |   30 ++++++++++++++++++++++++++
 validation/backend/load-type.c        |   12 ++++++++++
 validation/backend/void-return-type.c |   13 +++++++++++
 5 files changed, 99 insertions(+), 5 deletions(-)
 create mode 100644 validation/backend/extern.c
 create mode 100644 validation/backend/int-cond.c
 create mode 100644 validation/backend/load-type.c
 create mode 100644 validation/backend/void-return-type.c
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [GIT PULL] Sparse/LLVM updates
Date: Fri, 12 Oct 2012 02:34:04 +0000
Message-ID: <CANeU7Q=O_2UGjo0eUF=r4tqPFey0wpX3ww_g+6SiB_PeejAF-g () mail ! gmail ! com>
--------------------
The change looks good.

It is pull and updated on the github sparse repository.

Thanks

Chris

On Tue, Oct 9, 2012 at 11:35 PM, Pekka Enberg <penberg@kernel.org> wrote:
> Hi Chris,
>
> On Tue, Oct 9, 2012 at 9:34 AM, Pekka Enberg <penberg@kernel.org> wrote:
>> Hi Chris,
>>
>> Please pull the latest Sparse/LLVM tree from:
>>
>>   git@github.com:penberg/sparse-llvm.git llvm/core
>>
>> It contains few LLVM backend fixes from myself and Jonathan Neuschäfer.
>>
>>                         Pekka
>>
>> ------------------>
>
> I have added one more LLVM backend fix from Jonathan to the branch:
>
> The following changes since commit 063236fd3f46bc83b49172f5ecb597e0a91cede8:
>
>   ptrlist.c: fix a typo in a comment (2012-06-26 00:54:24 -0700)
>
> are available in the git repository at:
>   git@github.com:penberg/sparse-llvm.git llvm/core
>
> Jonathan Neuschäfer (3):
>       sparse, llvm: 'Verify' the LLVM module before writing it
>       sparse, llvm: convert the condition of branch/select to bool
>       sparse, llvm: Fix type of loaded values
>
> Pekka Enberg (2):
>       sparse, llvm: Fix SIGSEGV for extern symbols
>       sparse, llvm: Fix 'void' return type code generation
>
>  sparse-llvm.c                         |   38 ++++++++++++++++++++++++++++----
>  validation/backend/extern.c           |   11 +++++++++
>  validation/backend/int-cond.c         |   30 ++++++++++++++++++++++++++
>  validation/backend/load-type.c        |   12 ++++++++++
>  validation/backend/void-return-type.c |   13 +++++++++++
>  5 files changed, 99 insertions(+), 5 deletions(-)
>  create mode 100644 validation/backend/extern.c
>  create mode 100644 validation/backend/int-cond.c
>  create mode 100644 validation/backend/load-type.c
>  create mode 100644 validation/backend/void-return-type.c
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: [GIT PULL] Sparse/LLVM updates
Date: Tue, 09 Jul 2013 12:21:21 +0000
Message-ID: <CAOJsxLGSp7oPm8-qHEZvS4Oj=nfA2ZgnQAHwT762QxWSUj_JuQ () mail ! gmail ! com>
--------------------
Hi Chris,

Please consider pulling the latest Sparse/LLVM tree:

  git@github.com:penberg/sparse-llvm.git llvm/core

It has various LLVM backend fixes from Jonathan and Xi.

                        Pekka

------------------>

The following changes since commit 5449cfbfe55eea2a602a40122c122b5040d67243:

  Allow forced attribute in function argument (2013-04-26 08:27:41 -0700)

are available in the git repository at:

  git@github.com:penberg/sparse-llvm.git llvm/core

for you to fetch changes up to c0296d71405a97349d82e9909cad82a2af3271c2:

  Fix expression type for floating point negation ('!') (2013-05-27
14:15:56 +0300)

----------------------------------------------------------------
Jonathan Neuschäfer (4):
      sparse, llvm: Fix resulting type of store address calculations
      sparse, llvm: de-duplicate load/store address calculation code
      sparse, llvm: base load/store address type on insn_symbol_type()
      sparse, llvm: add a struct access test case

Pekka Enberg (1):
      sparse, llvm: Use LLVM_HOSTTRIPLE

Xi Wang (12):
      sparse, llvm: fix phi generation
      sparse, llvm: simplify function generation
      sparse, llvm: improve pointer arithmetic handling
      sparse, llvm: set target specification
      sparse, llvm: use LLVM_DEFAULT_TARGET_TRIPLE
      sparse, llvm: fix array size
      sparse, llvm: cache symbol_type() result
      sparse, llvm: fix struct name generation
      sparse, llvm: set more data attributes
      sparse, llvm: die if error
      Fix result type of relational and logical operators
      Fix expression type for floating point negation ('!')

 evaluate.c                         |  17 ++--
 lib.h                              |   2 +
 linearize.c                        |   4 +-
 sparse-llvm.c                      | 488
++++++++++++++++++++++++++++++++++++--------------------------------------------------------
 sparsei                            |  13 +++
 validation/backend/loop2.c         |  14 +++
 validation/backend/store-type.c    |  12 +++
 validation/backend/struct-access.c |  28 ++++++
 validation/backend/struct.c        |   6 ++
 validation/backend/sum.c           |  28 ++++++
 validation/cond_expr3.c            |  17 ++++
 11 files changed, 320 insertions(+), 309 deletions(-)
 create mode 100755 sparsei
 create mode 100644 validation/backend/loop2.c
 create mode 100644 validation/backend/store-type.c
 create mode 100644 validation/backend/struct-access.c
 create mode 100644 validation/backend/sum.c
 create mode 100644 validation/cond_expr3.c
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [GIT PULL] Sparse/LLVM updates
Date: Thu, 25 Jul 2013 16:43:22 +0000
Message-ID: <CANeU7Q=GuZZH8B_wpvUXG4o7TnyC_EZdevcWPq0TYJ2boiC=nw () mail ! gmail ! com>
--------------------
On Tue, Jul 9, 2013 at 5:21 AM, Pekka Enberg <penberg@kernel.org> wrote:
> Hi Chris,
>
> Please consider pulling the latest Sparse/LLVM tree:
>
>   git@github.com:penberg/sparse-llvm.git llvm/core
>
> It has various LLVM backend fixes from Jonathan and Xi.
>

I merge the branch and push at the chrisl repository. Please check if I make it
right. I will make it to the official repository soon.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 0/3] v0.4.5-rc1 ===

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: [PATCH 0/3] v0.4.5-rc1
Date: Thu, 16 May 2013 19:39:04 +0000
Message-ID: <519535D8.3090808 () ramsay1 ! demon ! co ! uk>
--------------------

Hi Christopher,

I recently updated my sparse repo(s) to give v0.4.5-rc1 a try.

I found two regressions. The first is addressed by the first
patch (char.c: Fix parsing of escapes). I have not fixed the
second regression yet. It Looks like this:

  $ cat -n test1.c
       1
       2  static unsigned int fred(int a, char *b) __attribute ((pure));
       3  static unsigned int __attribute ((pure)) fred(int a, char *b)
       4  {
       5          return (unsigned)(a + ((b) ? 1 : 0));
       6  }
       7
  $ ./sparse test1.c
  test1.c:3:42: error: symbol 'fred' redeclared with different type (originally de
  clared at test1.c:2) - different modifiers
  $

Essentially, the __attribute((pure)) placed before the function
prototype gets 'forgotten'; move the __attribute to match the
declaration, after the function prototype, and everything is fine.

The commit which introduced the regression was commit 8376ab09
("sparse: Fix __builtin_safe_p for pure and const functions",
22-08-2011). Since the pure attribute was simply ignored before
this patch, I guess you could argue that it is not responsible
for this failure to apply the attribute placed in this position.

The second patch just fixes some new build warnings.

The final patch was just lying around in my Linux repo! Several
of the patches I had on Linux are no longer required (e.g I also
have a patch to add --version).

For example, I had a patch to fix the problem which was addressed
by commit fbc8230fa8 ("Larger buffer size for token concatenation",
05-03-2013). However, I have added my patch below (it's an *old*
patch based on v0.4.3 which will most likely not apply anymore),
since commit fbc8230fa8 can not handle my test-case. (It *does*
fix the actual problem on the git source). If nothing else, it
demonstrates another solution to the problem. Just FYI, my test
looks like:

  $ cat -n too-long-test.c
       1  #include <assert.h>
       2
       3  #define some(x) x x x x x x x x x x
       4  #define more(x) some(x) some(x) some(x) some(x) some(x)
       5  #define time(x) more(x) more(x) more(x) more(x) more(x)
       6  #define now(x)  time(x) time(x) time(x) time(x) time(x)
       7
       8  int main(int argc, char **argv)
       9  {
      10          assert(now("is the winter of our discontent"));
      11  }
  $ cgcc -no-compile too-long-test.c
  too-long-test.c:10:9: warning: trying to concatenate 38750-character string (409
  5 bytes max)
  $

I have 3 sparse repos on Linux, cygwin and MinGW, each with some
local patches. In particular, I ported sparse to MinGW four years
ago, but have yet to "tidy-up" and post them here! :-D (I note that
someone asked about sparse on MinGW a few months ago on the list).

HTH

Ramsay Jones (3):
  char.c: Fix parsing of escapes
  Makefile: Fix some macro redefinition warnings
  symbol.c: Set correct size of array from parenthesized string
    initializer

 Makefile                      |  2 +-
 char.c                        |  9 ++++++---
 symbol.c                      | 10 ++++++++++
 validation/escapes.c          | 12 ++++++++++++
 validation/init-char-array1.c | 25 +++++++++++++++++++++++++
 5 files changed, 54 insertions(+), 4 deletions(-)
 create mode 100644 validation/init-char-array1.c

ATB,
Ramsay Jones

-- >8 --
From: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
Date: Fri, 22 Apr 2011 19:58:40 +0100
Subject: [PATCH] Fix token overflow

When compiling with optimisation enabled, the glibc headers
define some "mega" macros for some string handling routines.
This causes string overflow problems on git when compiling
several instances of expressions like:
    assert(strcmp(...));

Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
---
 pre-process.c | 51 ++++++++++++++++++++++++++++++++++++++++++++++++---
 1 file changed, 48 insertions(+), 3 deletions(-)

diff --git a/pre-process.c b/pre-process.c
index 656acaa..c05ca9f 100644
--- a/pre-process.c
+++ b/pre-process.c
@@ -340,15 +340,60 @@ static struct token *dup_list(struct token *list)
 	return res;
 }
 
+static int token_sequence_length(struct token *token)
+{
+	int length = 0, whitespace = 0;
+
+	if (!token)
+		return 0;
+	while (!eof_token(token)) {
+		const char *val = show_token(token);
+		int len = strlen(val);
+
+		if (whitespace)
+			length++;
+		length += len;
+		token = token->next;
+		whitespace = token->pos.whitespace;
+	}
+	return length;
+}
+
+static void token_sequence_to_string(struct string *s, struct token *token)
+{
+	char *ptr = s->data;
+	int whitespace = 0;
+
+	*ptr = 0;
+	if (!token)
+		return;
+	while (!eof_token(token)) {
+		const char *val = show_token(token);
+		int len = strlen(val);
+
+		if (ptr + whitespace + len >= s->data + s->length) {
+			sparse_error(token->pos, "too long token expansion");
+			break;
+		}
+
+		if (whitespace)
+			*ptr++ = ' ';
+		memcpy(ptr, val, len);
+		ptr += len;
+		token = token->next;
+		whitespace = token->pos.whitespace;
+	}
+	*ptr = 0;
+}
+
 static struct token *stringify(struct token *arg)
 {
-	const char *s = show_token_sequence(arg);
-	int size = strlen(s)+1;
+	int size = token_sequence_length(arg)+1;
 	struct token *token = __alloc_token(0);
 	struct string *string = __alloc_string(size);
 
-	memcpy(string->data, s, size);
 	string->length = size;
+	token_sequence_to_string(string, arg);
 	token->pos = arg->pos;
 	token_type(token) = TOKEN_STRING;
 	token->string = string;
-- 
1.8.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree ===

From: Zheng Liu <gnehzuil.liu () gmail ! com>
To: linux-ext4
Subject: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Wed, 23 Jan 2013 11:50:46 +0000
Message-ID: <1358942640-2262-4-git-send-email-wenqing.lz () taobao ! com>
--------------------
From: Zheng Liu <wenqing.lz@taobao.com>

es_pblk is used to record physical block that maps to the disk.
es_status is used to record the status of the extent.  Three status
are defined, which are written, unwritten and delayed.

Signed-off-by: Zheng Liu <wenqing.lz@taobao.com>
Cc: "Theodore Ts'o" <tytso@mit.edu>
---
 fs/ext4/extents_status.h | 16 ++++++++++++++--
 1 file changed, 14 insertions(+), 2 deletions(-)

diff --git a/fs/ext4/extents_status.h b/fs/ext4/extents_status.h
index 81e9339..2eb9cc3 100644
--- a/fs/ext4/extents_status.h
+++ b/fs/ext4/extents_status.h
@@ -20,10 +20,22 @@
 #define es_debug(fmt, ...)	no_printk(fmt, ##__VA_ARGS__)
 #endif
 
+enum {
+	EXTENT_STATUS_WRITTEN = 0,	/* written extent */
+	EXTENT_STATUS_UNWRITTEN = 1,	/* unwritten extent */
+	EXTENT_STATUS_DELAYED = 2,	/* delayed extent */
+};
+
+/*
+ * Here for save memory es_status is stashed into es_pblk because we only have
+ * 48 bits physical block and es_status only needs 2 bits.
+ */
 struct extent_status {
 	struct rb_node rb_node;
-	ext4_lblk_t es_lblk;	/* first logical block extent covers */
-	ext4_lblk_t es_len;	/* length of extent in block */
+	ext4_lblk_t es_lblk;		/* first logical block extent covers */
+	ext4_lblk_t es_len;		/* length of extent in block */
+	ext4_fsblk_t es_pblk : 62;	/* first physical block */
+	ext4_fsblk_t es_status : 2;	/* record the status of extent */
 };
 
 struct ext4_es_tree {
-- 
1.7.12.rc2.18.g61b472e

--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Theodore Ts'o <tytso () mit ! edu>
To: linux-ext4
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Tue, 29 Jan 2013 03:03:53 +0000
Message-ID: <20130129030353.GK7003 () thunk ! org>
--------------------
On Wed, Jan 23, 2013 at 08:03:53PM +0800, Zheng Liu wrote:
> +	ext4_fsblk_t es_pblk : 62;	/* first physical block */
> +	ext4_fsblk_t es_status : 2;	/* record the status of extent */

I'll accept this for now but note that ext4_fsblk_t is typedefed to be
an unsigned long long, and C99 only guarantees that bitfields can be
made from Bool, signed int, and unsigned int.  Gcc accepts unsigned
long long based bit fields as an extension, but it's not portable
code.  This is kernel code, though, and we have plenty more gcc
specific code....

						- Ted


--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Zheng Liu <gnehzuil.liu () gmail ! com>
To: linux-fsdevel
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Tue, 29 Jan 2013 05:34:15 +0000
Message-ID: <20130129053415.GA27002 () gmail ! com>
--------------------
On Mon, Jan 28, 2013 at 10:03:53PM -0500, Theodore Ts'o wrote:
> On Wed, Jan 23, 2013 at 08:03:53PM +0800, Zheng Liu wrote:
> > +	ext4_fsblk_t es_pblk : 62;	/* first physical block */
> > +	ext4_fsblk_t es_status : 2;	/* record the status of extent */
> 
> I'll accept this for now but note that ext4_fsblk_t is typedefed to be
> an unsigned long long, and C99 only guarantees that bitfields can be
> made from Bool, signed int, and unsigned int.  Gcc accepts unsigned
> long long based bit fields as an extension, but it's not portable
> code.  This is kernel code, though, and we have plenty more gcc
> specific code....

Thanks for pointing out.  When I tried to implement this code, there are
two choices.  One is like this that bit field is used.  IMHO it is clear
enough, although it is not portable.

Another choice is like this:

        struct extent_status {
                ...
                ext4_fsblk_t es_pblk;   /* first physical block */
        };

        #define EXTENT_STATUS_WRITTEN   (1ULL << 60)
        #define EXTENT_STATUS_UNWRITTEN (1ULL << 61)
        #define EXTENT_STATUS_DELAYED   (1ULL << 62)

When we want to set extent status, we will need to do like the following:

        es->es_pblk |= EXTENT_STATUS_WRITTEN;

This can make us avoid non-protable code.  I am happy to refine this
patch if you think the latter one is better.

Thanks,
                                                - Zheng
--
To unsubscribe from this list: send the line "unsubscribe linux-fsdevel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Theodore Ts'o <tytso () mit ! edu>
To: linux-ext4
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Tue, 29 Jan 2013 17:28:14 +0000
Message-ID: <20130129172814.GC4261 () thunk ! org>
--------------------
On Tue, Jan 29, 2013 at 01:34:15PM +0800, Zheng Liu wrote:
> 
> Another choice is like this:
> 
>         struct extent_status {
>                 ...
>                 ext4_fsblk_t es_pblk;   /* first physical block */
>         };
> 
>         #define EXTENT_STATUS_WRITTEN   (1ULL << 60)
>         #define EXTENT_STATUS_UNWRITTEN (1ULL << 61)
>         #define EXTENT_STATUS_DELAYED   (1ULL << 62)
> 
> When we want to set extent status, we will need to do like the following:
> 
>         es->es_pblk |= EXTENT_STATUS_WRITTEN;
> 
> This can make us avoid non-protable code.  I am happy to refine this
> patch if you think the latter one is better.

This is probably the way I would have done it myself, but the then you
need to make sure that all of the places where es_pblk is used you
have to mask off the high bits.

At this point, though, I don't think it's worth it to make the change
now, especially since we're almost at -rc6, I want to make sure this
gets into linux-next and so we get lots of testing.

As a matter of fact, I've already started testing the v3 vesion of the
extent status patches from January 23rd, with the v2 version of the
slab reclaim patch.  It's in the unstable portion of the ext4 git
tree, at:

      http://repo.or.cz/w/ext4-patch-queue.git /
      git://repo.or.cz/ext4-patch-queue.git

I'm waiting for your next version of your patch series before I move
it into the dev branch which will get fed into linux-next; my
understanding is you're just about ready to push it out, right?

If we want to move away from using bitfields, we can do that as a
separate patch that gets submitted later, since that's pretty easy to
audit and verify for correctness.  Also, I've since tested clang and
noted that it supports bitfields for unsigned long long.  There is
some differences between how gcc and clang handles sign extension for
unsigned long values, though:

#include <stdio.h>
struct s
{
        unsigned long long a:2;
        unsigned long long b:40;
        unsigned long long c:22;
};

int main()
{
        struct s t = {1, 2, 3};
        printf("0x%llx\n",(t.b-8));
}

Gcc 4.7.2 will print "0xfffffffffa", while clang 3.0-6 will print
"0xfffffffffffffffa" for the same program.

I don't think this is a huge issue for us, but it's worth keeping in
mind...

So let's go ahead and keep the bitfields at least for the initial
patch submission.

Thanks for all your on this patch series!

					- Ted



--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Zheng Liu <gnehzuil.liu () gmail ! com>
To: linux-fsdevel
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Wed, 30 Jan 2013 02:43:33 +0000
Message-ID: <20130130024332.GA12111 () gmail ! com>
--------------------
On Tue, Jan 29, 2013 at 12:28:14PM -0500, Theodore Ts'o wrote:
> On Tue, Jan 29, 2013 at 01:34:15PM +0800, Zheng Liu wrote:
> > 
> > Another choice is like this:
> > 
> >         struct extent_status {
> >                 ...
> >                 ext4_fsblk_t es_pblk;   /* first physical block */
> >         };
> > 
> >         #define EXTENT_STATUS_WRITTEN   (1ULL << 60)
> >         #define EXTENT_STATUS_UNWRITTEN (1ULL << 61)
> >         #define EXTENT_STATUS_DELAYED   (1ULL << 62)
> > 
> > When we want to set extent status, we will need to do like the following:
> > 
> >         es->es_pblk |= EXTENT_STATUS_WRITTEN;
> > 
> > This can make us avoid non-protable code.  I am happy to refine this
> > patch if you think the latter one is better.
> 
> This is probably the way I would have done it myself, but the then you
> need to make sure that all of the places where es_pblk is used you
> have to mask off the high bits.
> 
> At this point, though, I don't think it's worth it to make the change
> now, especially since we're almost at -rc6, I want to make sure this
> gets into linux-next and so we get lots of testing.
> 
> As a matter of fact, I've already started testing the v3 vesion of the
> extent status patches from January 23rd, with the v2 version of the
> slab reclaim patch.  It's in the unstable portion of the ext4 git
> tree, at:
> 
>       http://repo.or.cz/w/ext4-patch-queue.git /
>       git://repo.or.cz/ext4-patch-queue.git
> 
> I'm waiting for your next version of your patch series before I move
> it into the dev branch which will get fed into linux-next; my
> understanding is you're just about ready to push it out, right?

Yes, I am running xfstests to make sure that the patch series doesn't
break anything.  Later it will be sent out.

> 
> If we want to move away from using bitfields, we can do that as a
> separate patch that gets submitted later, since that's pretty easy to
> audit and verify for correctness.  Also, I've since tested clang and
> noted that it supports bitfields for unsigned long long.  There is
> some differences between how gcc and clang handles sign extension for
> unsigned long values, though:
> 
> #include <stdio.h>
> struct s
> {
>         unsigned long long a:2;
>         unsigned long long b:40;
>         unsigned long long c:22;
> };
> 
> int main()
> {
>         struct s t = {1, 2, 3};
>         printf("0x%llx\n",(t.b-8));
> }
> 
> Gcc 4.7.2 will print "0xfffffffffa", while clang 3.0-6 will print
> "0xfffffffffffffffa" for the same program.

Clang is first coming in my mind.  I know that some one try to use it
to build a linux kernel and get a lot of problems that are about gcc
extension.  But for us it seems that things are not too bad. ;)

> 
> I don't think this is a huge issue for us, but it's worth keeping in
> mind...
> 
> So let's go ahead and keep the bitfields at least for the initial
> patch submission.

Yes, just keep in mind and go ahead.

Thanks for teaching me a lot,
                                                - Zheng
--
To unsubscribe from this list: send the line "unsubscribe linux-fsdevel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Zheng Liu <gnehzuil.liu () gmail ! com>
To: linux-ext4
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Wed, 30 Jan 2013 02:43:33 +0000
Message-ID: <20130130024332.GA12111 () gmail ! com>
--------------------
On Tue, Jan 29, 2013 at 12:28:14PM -0500, Theodore Ts'o wrote:
> On Tue, Jan 29, 2013 at 01:34:15PM +0800, Zheng Liu wrote:
> > 
> > Another choice is like this:
> > 
> >         struct extent_status {
> >                 ...
> >                 ext4_fsblk_t es_pblk;   /* first physical block */
> >         };
> > 
> >         #define EXTENT_STATUS_WRITTEN   (1ULL << 60)
> >         #define EXTENT_STATUS_UNWRITTEN (1ULL << 61)
> >         #define EXTENT_STATUS_DELAYED   (1ULL << 62)
> > 
> > When we want to set extent status, we will need to do like the following:
> > 
> >         es->es_pblk |= EXTENT_STATUS_WRITTEN;
> > 
> > This can make us avoid non-protable code.  I am happy to refine this
> > patch if you think the latter one is better.
> 
> This is probably the way I would have done it myself, but the then you
> need to make sure that all of the places where es_pblk is used you
> have to mask off the high bits.
> 
> At this point, though, I don't think it's worth it to make the change
> now, especially since we're almost at -rc6, I want to make sure this
> gets into linux-next and so we get lots of testing.
> 
> As a matter of fact, I've already started testing the v3 vesion of the
> extent status patches from January 23rd, with the v2 version of the
> slab reclaim patch.  It's in the unstable portion of the ext4 git
> tree, at:
> 
>       http://repo.or.cz/w/ext4-patch-queue.git /
>       git://repo.or.cz/ext4-patch-queue.git
> 
> I'm waiting for your next version of your patch series before I move
> it into the dev branch which will get fed into linux-next; my
> understanding is you're just about ready to push it out, right?

Yes, I am running xfstests to make sure that the patch series doesn't
break anything.  Later it will be sent out.

> 
> If we want to move away from using bitfields, we can do that as a
> separate patch that gets submitted later, since that's pretty easy to
> audit and verify for correctness.  Also, I've since tested clang and
> noted that it supports bitfields for unsigned long long.  There is
> some differences between how gcc and clang handles sign extension for
> unsigned long values, though:
> 
> #include <stdio.h>
> struct s
> {
>         unsigned long long a:2;
>         unsigned long long b:40;
>         unsigned long long c:22;
> };
> 
> int main()
> {
>         struct s t = {1, 2, 3};
>         printf("0x%llx\n",(t.b-8));
> }
> 
> Gcc 4.7.2 will print "0xfffffffffa", while clang 3.0-6 will print
> "0xfffffffffffffffa" for the same program.

Clang is first coming in my mind.  I know that some one try to use it
to build a linux kernel and get a lot of problems that are about gcc
extension.  But for us it seems that things are not too bad. ;)

> 
> I don't think this is a huge issue for us, but it's worth keeping in
> mind...
> 
> So let's go ahead and keep the bitfields at least for the initial
> patch submission.

Yes, just keep in mind and go ahead.

Thanks for teaching me a lot,
                                                - Zheng
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Theodore Ts'o <tytso () mit ! edu>
To: linux-sparse
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Sun, 03 Feb 2013 03:03:43 +0000
Message-ID: <20130203030343.GB1359 () thunk ! org>
--------------------
On Wed, Jan 30, 2013 at 10:43:33AM +0800, Zheng Liu wrote:
> 
> Clang is first coming in my mind.  I know that some one try to use it
> to build a linux kernel and get a lot of problems that are about gcc
> extension.  But for us it seems that things are not too bad. ;)

Clang accepts bitfields with "unsigned long long", but I've discovered
something which does _not_ support unsigned long long --- the "sparse"
tool.  :-(

I discovered this when running "make C=1", i.e.:

  rm -f fs/ext4/extents_status.o
  make C=1 fs/ext4/extents_status.o

Here's a simple test case which demo's that sparse doesn't deal well
with unsigned long long.  If we change the last two fields in struct
extents_status to:

	unsigned long es_pblk : 30;	/* first physical block */
	unsigned long es_status : 2;	/* record the status of extent */

sparse doesn't complain.  But as shown below, sparse complains bitterly:

/tmp/foo.c:22:24: warning: invalid access past the end of 'es' (24 28)

I'm not sure Chris will consider this a bug, since bitfields
with "unsigned long long" isn't standards complaint, even if gcc and
clang supports it.   Chris, what do you think?

              	       		      	       - Ted
   	

#!/bin/sh
cat > /tmp/foo.c << EOF
#include <unistd.h>
#include <stdio.h>

struct rb_node {
	unsigned long  __rb_parent_color;
	struct rb_node *rb_right;
	struct rb_node *rb_left;
} __attribute__((aligned(sizeof(long))));

struct extent_status {
	struct rb_node rb_node;
	unsigned long es_lblk;		/* first logical block extent covers */
	unsigned long es_len;		/* length of extent in block */
	unsigned long long es_pblk : 62;	/* first physical block */
	unsigned long long es_status : 2;	/* record the status of extent */
};

int main(int argc, char **argv)
{
	struct extent_status es;

	es.es_status = 3;

	printf("%d\n", es.es_status);
	printf("size %u\n", sizeof(es));
}
EOF
sparse /tmp/foo.c
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Zheng Liu <gnehzuil.liu () gmail ! com>
To: linux-sparse
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Sun, 03 Feb 2013 05:21:13 +0000
Message-ID: <20130203052113.GA9823 () gmail ! com>
--------------------
On Sat, Feb 02, 2013 at 10:03:43PM -0500, Theodore Ts'o wrote:
> On Wed, Jan 30, 2013 at 10:43:33AM +0800, Zheng Liu wrote:
> > 
> > Clang is first coming in my mind.  I know that some one try to use it
> > to build a linux kernel and get a lot of problems that are about gcc
> > extension.  But for us it seems that things are not too bad. ;)
> 
> Clang accepts bitfields with "unsigned long long", but I've discovered
> something which does _not_ support unsigned long long --- the "sparse"
> tool.  :-(

Yes, this problem has been reported by Fengguang.  So I am plan to use
another method to define extent_status structure as last time we
discuessed.  What do you think?

Thanks,
                                                - Zheng

> 
> I discovered this when running "make C=1", i.e.:
> 
>   rm -f fs/ext4/extents_status.o
>   make C=1 fs/ext4/extents_status.o
> 
> Here's a simple test case which demo's that sparse doesn't deal well
> with unsigned long long.  If we change the last two fields in struct
> extents_status to:
> 
> 	unsigned long es_pblk : 30;	/* first physical block */
> 	unsigned long es_status : 2;	/* record the status of extent */
> 
> sparse doesn't complain.  But as shown below, sparse complains bitterly:
> 
> /tmp/foo.c:22:24: warning: invalid access past the end of 'es' (24 28)
> 
> I'm not sure Chris will consider this a bug, since bitfields
> with "unsigned long long" isn't standards complaint, even if gcc and
> clang supports it.   Chris, what do you think?
> 
>               	       		      	       - Ted
>    	
> 
> #!/bin/sh
> cat > /tmp/foo.c << EOF
> #include <unistd.h>
> #include <stdio.h>
> 
> struct rb_node {
> 	unsigned long  __rb_parent_color;
> 	struct rb_node *rb_right;
> 	struct rb_node *rb_left;
> } __attribute__((aligned(sizeof(long))));
> 
> struct extent_status {
> 	struct rb_node rb_node;
> 	unsigned long es_lblk;		/* first logical block extent covers */
> 	unsigned long es_len;		/* length of extent in block */
> 	unsigned long long es_pblk : 62;	/* first physical block */
> 	unsigned long long es_status : 2;	/* record the status of extent */
> };
> 
> int main(int argc, char **argv)
> {
> 	struct extent_status es;
> 
> 	es.es_status = 3;
> 
> 	printf("%d\n", es.es_status);
> 	printf("size %u\n", sizeof(es));
> }
> EOF
> sparse /tmp/foo.c
> --
> To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
> the body of a message to majordomo@vger.kernel.org
> More majordomo info at  http://vger.kernel.org/majordomo-info.html
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sam Ravnborg <sam () ravnborg ! org>
To: linux-sparse
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Sun, 03 Feb 2013 07:30:13 +0000
Message-ID: <20130203073013.GA25947 () merkur ! ravnborg ! org>
--------------------
On Sat, Feb 02, 2013 at 10:03:43PM -0500, Theodore Ts'o wrote:
> On Wed, Jan 30, 2013 at 10:43:33AM +0800, Zheng Liu wrote:
> > 
> > Clang is first coming in my mind.  I know that some one try to use it
> > to build a linux kernel and get a lot of problems that are about gcc
> > extension.  But for us it seems that things are not too bad. ;)
> 
> Clang accepts bitfields with "unsigned long long", but I've discovered
> something which does _not_ support unsigned long long --- the "sparse"
> tool.  :-(
> 
> I discovered this when running "make C=1", i.e.:
> 
>   rm -f fs/ext4/extents_status.o
>   make C=1 fs/ext4/extents_status.o

Small hint...
If you use:

    make C=2 fs/ext4/extents_status.o

Then kbuild will run sparse on all targets you specify,
even if they do not need to be rebuild.
In other words - you then do not need to delete the .o file first.

This works for all the usual ways you can specify a target so to
check all of ext4 you just issue:

    make C=2 fs/ext4/

	Sam
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Sam Ravnborg <sam () ravnborg ! org>
To: linux-ext4
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Sun, 03 Feb 2013 07:30:13 +0000
Message-ID: <20130203073013.GA25947 () merkur ! ravnborg ! org>
--------------------
On Sat, Feb 02, 2013 at 10:03:43PM -0500, Theodore Ts'o wrote:
> On Wed, Jan 30, 2013 at 10:43:33AM +0800, Zheng Liu wrote:
> > 
> > Clang is first coming in my mind.  I know that some one try to use it
> > to build a linux kernel and get a lot of problems that are about gcc
> > extension.  But for us it seems that things are not too bad. ;)
> 
> Clang accepts bitfields with "unsigned long long", but I've discovered
> something which does _not_ support unsigned long long --- the "sparse"
> tool.  :-(
> 
> I discovered this when running "make C=1", i.e.:
> 
>   rm -f fs/ext4/extents_status.o
>   make C=1 fs/ext4/extents_status.o

Small hint...
If you use:

    make C=2 fs/ext4/extents_status.o

Then kbuild will run sparse on all targets you specify,
even if they do not need to be rebuild.
In other words - you then do not need to delete the .o file first.

This works for all the usual ways you can specify a target so to
check all of ext4 you just issue:

    make C=2 fs/ext4/

	Sam
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-sparse
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Sun, 03 Feb 2013 08:19:43 +0000
Message-ID: <20130203081943.GF4937 () mwanda>
--------------------
On Sun, Feb 03, 2013 at 01:21:13PM +0800, Zheng Liu wrote:
> On Sat, Feb 02, 2013 at 10:03:43PM -0500, Theodore Ts'o wrote:
> > On Wed, Jan 30, 2013 at 10:43:33AM +0800, Zheng Liu wrote:
> > > 
> > > Clang is first coming in my mind.  I know that some one try to use it
> > > to build a linux kernel and get a lot of problems that are about gcc
> > > extension.  But for us it seems that things are not too bad. ;)
> > 
> > Clang accepts bitfields with "unsigned long long", but I've discovered
> > something which does _not_ support unsigned long long --- the "sparse"
> > tool.  :-(
> 
> Yes, this problem has been reported by Fengguang.  So I am plan to use
> another method to define extent_status structure as last time we
> discuessed.  What do you think?
> 

I don't get this warning on my version of Sparse.

Sparse used to assume -m32 all the time but now that's been changed.
Are you using the most recent version of Sparse?  Try passing -m64.

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-ext4
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Sun, 03 Feb 2013 08:19:43 +0000
Message-ID: <20130203081943.GF4937 () mwanda>
--------------------
On Sun, Feb 03, 2013 at 01:21:13PM +0800, Zheng Liu wrote:
> On Sat, Feb 02, 2013 at 10:03:43PM -0500, Theodore Ts'o wrote:
> > On Wed, Jan 30, 2013 at 10:43:33AM +0800, Zheng Liu wrote:
> > > 
> > > Clang is first coming in my mind.  I know that some one try to use it
> > > to build a linux kernel and get a lot of problems that are about gcc
> > > extension.  But for us it seems that things are not too bad. ;)
> > 
> > Clang accepts bitfields with "unsigned long long", but I've discovered
> > something which does _not_ support unsigned long long --- the "sparse"
> > tool.  :-(
> 
> Yes, this problem has been reported by Fengguang.  So I am plan to use
> another method to define extent_status structure as last time we
> discuessed.  What do you think?
> 

I don't get this warning on my version of Sparse.

Sparse used to assume -m32 all the time but now that's been changed.
Are you using the most recent version of Sparse?  Try passing -m64.

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Theodore Ts'o <tytso () mit ! edu>
To: linux-ext4
Subject: Re: [PATCH 03/10 v3] ext4: add physical block and status member into extent status tree
Date: Sun, 03 Feb 2013 14:57:42 +0000
Message-ID: <20130203145742.GA5424 () thunk ! org>
--------------------

--HcAYCG3uE/tztfnV
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline

On Sun, Feb 03, 2013 at 11:19:43AM +0300, Dan Carpenter wrote:
> 
> I don't get this warning on my version of Sparse.
> 
> Sparse used to assume -m32 all the time but now that's been changed.
> Are you using the most recent version of Sparse?  Try passing -m64.

Hmm, I got my version of sparse from

git://git.kernel.org/pub/scm/devel/sparse/sparse.git

... where the latest version is 0.4.4, dated November 21, 2011.  Is
there a different dit repository I should be using?

I see that it doesn't complain with -m64, but the test program should
be valid for x86 with 32 bits just as much as 64 bits.  Am I missing
something?

						- Ted


--HcAYCG3uE/tztfnV
Content-Type: text/plain; charset=us-ascii
Content-Disposition: attachment; filename=testcase

#!/bin/sh
cat > /tmp/testcase.c << EOF
#include <unistd.h>
#include <stdio.h>

struct rb_node {
	unsigned long  __rb_parent_color;
	struct rb_node *rb_right;
	struct rb_node *rb_left;
} __attribute__((aligned(sizeof(long))));

struct extent_status {
	struct rb_node rb_node;
	unsigned long es_lblk;		/* first logical block extent covers */
	unsigned long es_len;		/* length of extent in block */
	unsigned long long es_pblk : 62;	/* first physical block */
	unsigned long long es_status : 2;	/* record the status of extent */
};

int main(int argc, char **argv)
{
	struct extent_status es;

	es.es_status = 3;

	printf("%d\n", es.es_status);
	printf("size %u\n", sizeof(es));
}
EOF
echo "sparse /tmp/testcase.c"
sparse /tmp/testcase.c
echo " "
echo "sparse -m32 /tmp/testcase.c"
sparse -m32 /tmp/testcase.c
echo " "
echo "sparse -m64 /tmp/testcase.c"
sparse -m64 /tmp/testcase.c



--HcAYCG3uE/tztfnV--
--
To unsubscribe from this list: send the line "unsubscribe linux-ext4" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 1/2] Introduce the attribute structure. ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: [PATCH 1/2] Introduce the attribute structure.
Date: Wed, 27 Feb 2013 15:18:00 +0000
Message-ID: <CANeU7Qkq7DHCw1cJKy5AyscceVpRH-hqukMPXzd9e0TRazb18A () mail ! gmail ! com>
--------------------
--f46d04451a01979aaf04d6b647f3
Content-Type: text/plain; charset=ISO-8859-1

This duplicate the ctype->as and ctype->contexts into a
separate attribute structure. It also active check ans verify
the duplicated attribute bits are consistent.

Chris

--f46d04451a01979aaf04d6b647f3
Content-Type: application/octet-stream; 
	name="0001-Introduce-struct-attribute-into-ctype.patch"
Content-Disposition: attachment; 
	filename="0001-Introduce-struct-attribute-into-ctype.patch"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_hdomkwt50
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--f46d04451a01979aaf04d6b647f3--
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 1/2] fix result type of relational and logical operators ===

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: [PATCH 1/2] fix result type of relational and logical operators
Date: Fri, 24 May 2013 13:30:35 +0000
Message-ID: <1369402236-16871-1-git-send-email-xi.wang () gmail ! com>
--------------------
The result type of relational operators (e.g., x < y) and logical
operators (e.g., x && y) in C should be int, rather than bool.

For example, sparse incorrectly evaluates sizeof(x < y) to 1 (i.e.,
sizeof(int)), which should have been sizeof(int).

This patch fixes the result type of these operators in evaluation,
linearization, and the LLVM backend.

Cc: Christopher Li <sparse@chrisli.org>
Cc: Pekka Enberg <penberg@kernel.org>
Signed-off-by: Xi Wang <xi.wang@gmail.com>
---
 evaluate.c              | 15 +++++++++------
 linearize.c             |  4 ++--
 sparse-llvm.c           | 29 ++++++++++++++++++-----------
 validation/cond_expr3.c | 17 +++++++++++++++++
 4 files changed, 46 insertions(+), 19 deletions(-)
 create mode 100644 validation/cond_expr3.c

diff --git a/evaluate.c b/evaluate.c
index 0dfa519..5d87444 100644
--- a/evaluate.c
+++ b/evaluate.c
@@ -860,12 +860,13 @@ static struct symbol *evaluate_logical(struct expression *expr)
 	if (!evaluate_conditional(expr->right, 0))
 		return NULL;
 
-	expr->ctype = &bool_ctype;
+	/* the result is int [6.5.13(3), 6.5.14(3)] */
+	expr->ctype = &int_ctype;
 	if (expr->flags) {
 		if (!(expr->left->flags & expr->right->flags & Int_const_expr))
 			expr->flags = 0;
 	}
-	return &bool_ctype;
+	return &int_ctype;
 }
 
 static struct symbol *evaluate_binop(struct expression *expr)
@@ -1064,8 +1065,9 @@ static struct symbol *evaluate_compare(struct expression *expr)
 	return NULL;
 
 OK:
-	expr->ctype = &bool_ctype;
-	return &bool_ctype;
+	/* the result is int [6.5.8(6), 6.5.9(3)]*/
+	expr->ctype = &int_ctype;
+	return &int_ctype;
 }
 
 /*
@@ -1805,14 +1807,15 @@ static struct symbol *evaluate_preop(struct expression *expr)
 			warning(expr->pos, "%s degrades to integer",
 				show_typename(ctype->ctype.base_type));
 		}
-		ctype = &bool_ctype;
+		/* the result is int [6.5.3.3(5)]*/
+		ctype = &int_ctype;
 		break;
 
 	default:
 		break;
 	}
 	expr->ctype = ctype;
-	return &bool_ctype;
+	return ctype;
 }
 
 static struct symbol *find_identifier(struct ident *ident, struct symbol_list *_list, int *offset)
diff --git a/linearize.c b/linearize.c
index 1d15cfd..c6ada1e 100644
--- a/linearize.c
+++ b/linearize.c
@@ -1064,7 +1064,7 @@ static pseudo_t linearize_regular_preop(struct entrypoint *ep, struct expression
 		return pre;
 	case '!': {
 		pseudo_t zero = value_pseudo(0);
-		return add_binary_op(ep, expr->unop->ctype, OP_SET_EQ, pre, zero);
+		return add_binary_op(ep, expr->ctype, OP_SET_EQ, pre, zero);
 	}
 	case '~':
 		return add_uniop(ep, expr, OP_NOT, pre);
@@ -1418,7 +1418,7 @@ static pseudo_t linearize_compare(struct entrypoint *ep, struct expression *expr
 
 	pseudo_t src1 = linearize_expression(ep, expr->left);
 	pseudo_t src2 = linearize_expression(ep, expr->right);
-	pseudo_t dst = add_binary_op(ep, expr->left->ctype, cmpop[expr->op], src1, src2);
+	pseudo_t dst = add_binary_op(ep, expr->ctype, cmpop[expr->op], src1, src2);
 	return dst;
 }
 
diff --git a/sparse-llvm.c b/sparse-llvm.c
index 6f2fbd6..6ee4c1d 100644
--- a/sparse-llvm.c
+++ b/sparse-llvm.c
@@ -544,29 +544,34 @@ static void output_op_binary(struct function *fn, struct instruction *insn)
 		target = LLVMBuildXor(fn->builder, lhs, rhs, target_name);
 		break;
 	case OP_AND_BOOL: {
-		LLVMValueRef x, y;
+		LLVMValueRef lhs_nz, rhs_nz;
+		LLVMTypeRef dst_type;
 
-		assert(!symbol_is_fp_type(insn->type));
-
-		y = LLVMBuildICmp(fn->builder, LLVMIntNE, lhs, LLVMConstInt(LLVMTypeOf(lhs), 0, 0), "y");
-		x = LLVMBuildICmp(fn->builder, LLVMIntNE, rhs, LLVMConstInt(LLVMTypeOf(rhs), 0, 0), "x");
+		lhs_nz = LLVMBuildIsNotNull(fn->builder, lhs, "");
+		rhs_nz = LLVMBuildIsNotNull(fn->builder, rhs, "");
+		target = LLVMBuildAnd(fn->builder, lhs_nz, rhs_nz, target_name);
 
-		target = LLVMBuildAnd(fn->builder, y, x, target_name);
+		dst_type = insn_symbol_type(fn->module, insn);
+		target = LLVMBuildZExt(fn->builder, target, dst_type, target_name);
 		break;
 	}
 	case OP_OR_BOOL: {
-		LLVMValueRef tmp;
-
-		assert(!symbol_is_fp_type(insn->type));
+		LLVMValueRef lhs_nz, rhs_nz;
+		LLVMTypeRef dst_type;
 
-		tmp = LLVMBuildOr(fn->builder, rhs, lhs, "tmp");
+		lhs_nz = LLVMBuildIsNotNull(fn->builder, lhs, "");
+		rhs_nz = LLVMBuildIsNotNull(fn->builder, rhs, "");
+		target = LLVMBuildOr(fn->builder, lhs_nz, rhs_nz, target_name);
 
-		target = LLVMBuildICmp(fn->builder, LLVMIntNE, tmp, LLVMConstInt(LLVMTypeOf(tmp), 0, 0), target_name);
+		dst_type = insn_symbol_type(fn->module, insn);
+		target = LLVMBuildZExt(fn->builder, target, dst_type, target_name);
 		break;
 	}
 
 	/* Binary comparison */
 	case OP_BINCMP ... OP_BINCMP_END: {
+		LLVMTypeRef dst_type = insn_symbol_type(fn->module, insn);
+
 		if (LLVMGetTypeKind(LLVMTypeOf(lhs)) == LLVMIntegerTypeKind) {
 			LLVMIntPredicate op = translate_op(insn->opcode);
 
@@ -576,6 +581,8 @@ static void output_op_binary(struct function *fn, struct instruction *insn)
 
 			target = LLVMBuildFCmp(fn->builder, op, lhs, rhs, target_name);
 		}
+
+		target = LLVMBuildZExt(fn->builder, target, dst_type, target_name);
 		break;
 	}
 	default:
diff --git a/validation/cond_expr3.c b/validation/cond_expr3.c
new file mode 100644
index 0000000..748409e
--- /dev/null
+++ b/validation/cond_expr3.c
@@ -0,0 +1,17 @@
+static int icmp = 1 / (sizeof(int) - sizeof(1 > 0));
+static int fcmp = 1 / (sizeof(int) - sizeof(1.0 == 2.0 - 1.0));
+static int lnot = 1 / (sizeof(int) - sizeof(!!1.0));
+static int land = 1 / (sizeof(int) - sizeof(2 && 3));
+static int lor  = 1 / (sizeof(int) - sizeof('c' || 1.0f));
+
+/*
+ * check-name: result type of relational and logical operators
+ *
+ * check-error-start
+cond_expr3.c:1:21: warning: division by zero
+cond_expr3.c:2:21: warning: division by zero
+cond_expr3.c:3:21: warning: division by zero
+cond_expr3.c:4:21: warning: division by zero
+cond_expr3.c:5:21: warning: division by zero
+ * check-error-end
+ */
-- 
1.8.1.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] fix result type of relational and logical operators
Date: Mon, 27 May 2013 06:33:42 +0000
Message-ID: <CAOJsxLE9AEcAJwnPvPozpMDpzkgAgJex9qAYGPUT5XiwyWfr9A () mail ! gmail ! com>
--------------------
On Fri, May 24, 2013 at 4:30 PM, Xi Wang <xi.wang@gmail.com> wrote:
> The result type of relational operators (e.g., x < y) and logical
> operators (e.g., x && y) in C should be int, rather than bool.
>
> For example, sparse incorrectly evaluates sizeof(x < y) to 1 (i.e.,
> sizeof(int)), which should have been sizeof(int).
>
> This patch fixes the result type of these operators in evaluation,
> linearization, and the LLVM backend.
>
> Cc: Christopher Li <sparse@chrisli.org>
> Cc: Pekka Enberg <penberg@kernel.org>
> Signed-off-by: Xi Wang <xi.wang@gmail.com>
> ---
>  evaluate.c              | 15 +++++++++------
>  linearize.c             |  4 ++--
>  sparse-llvm.c           | 29 ++++++++++++++++++-----------
>  validation/cond_expr3.c | 17 +++++++++++++++++
>  4 files changed, 46 insertions(+), 19 deletions(-)
>  create mode 100644 validation/cond_expr3.c
>
> diff --git a/evaluate.c b/evaluate.c
> index 0dfa519..5d87444 100644
> --- a/evaluate.c
> +++ b/evaluate.c
> @@ -860,12 +860,13 @@ static struct symbol *evaluate_logical(struct expression *expr)
>         if (!evaluate_conditional(expr->right, 0))
>                 return NULL;
>
> -       expr->ctype = &bool_ctype;
> +       /* the result is int [6.5.13(3), 6.5.14(3)] */
> +       expr->ctype = &int_ctype;
>         if (expr->flags) {
>                 if (!(expr->left->flags & expr->right->flags & Int_const_expr))
>                         expr->flags = 0;
>         }
> -       return &bool_ctype;
> +       return &int_ctype;
>  }
>
>  static struct symbol *evaluate_binop(struct expression *expr)
> @@ -1064,8 +1065,9 @@ static struct symbol *evaluate_compare(struct expression *expr)
>         return NULL;
>
>  OK:
> -       expr->ctype = &bool_ctype;
> -       return &bool_ctype;
> +       /* the result is int [6.5.8(6), 6.5.9(3)]*/
> +       expr->ctype = &int_ctype;
> +       return &int_ctype;
>  }
>
>  /*
> @@ -1805,14 +1807,15 @@ static struct symbol *evaluate_preop(struct expression *expr)
>                         warning(expr->pos, "%s degrades to integer",
>                                 show_typename(ctype->ctype.base_type));
>                 }
> -               ctype = &bool_ctype;
> +               /* the result is int [6.5.3.3(5)]*/
> +               ctype = &int_ctype;
>                 break;
>
>         default:
>                 break;
>         }
>         expr->ctype = ctype;
> -       return &bool_ctype;
> +       return ctype;
>  }
>
>  static struct symbol *find_identifier(struct ident *ident, struct symbol_list *_list, int *offset)
> diff --git a/linearize.c b/linearize.c
> index 1d15cfd..c6ada1e 100644
> --- a/linearize.c
> +++ b/linearize.c
> @@ -1064,7 +1064,7 @@ static pseudo_t linearize_regular_preop(struct entrypoint *ep, struct expression
>                 return pre;
>         case '!': {
>                 pseudo_t zero = value_pseudo(0);
> -               return add_binary_op(ep, expr->unop->ctype, OP_SET_EQ, pre, zero);
> +               return add_binary_op(ep, expr->ctype, OP_SET_EQ, pre, zero);
>         }
>         case '~':
>                 return add_uniop(ep, expr, OP_NOT, pre);
> @@ -1418,7 +1418,7 @@ static pseudo_t linearize_compare(struct entrypoint *ep, struct expression *expr
>
>         pseudo_t src1 = linearize_expression(ep, expr->left);
>         pseudo_t src2 = linearize_expression(ep, expr->right);
> -       pseudo_t dst = add_binary_op(ep, expr->left->ctype, cmpop[expr->op], src1, src2);
> +       pseudo_t dst = add_binary_op(ep, expr->ctype, cmpop[expr->op], src1, src2);
>         return dst;
>  }
>
> diff --git a/sparse-llvm.c b/sparse-llvm.c
> index 6f2fbd6..6ee4c1d 100644
> --- a/sparse-llvm.c
> +++ b/sparse-llvm.c
> @@ -544,29 +544,34 @@ static void output_op_binary(struct function *fn, struct instruction *insn)
>                 target = LLVMBuildXor(fn->builder, lhs, rhs, target_name);
>                 break;
>         case OP_AND_BOOL: {
> -               LLVMValueRef x, y;
> +               LLVMValueRef lhs_nz, rhs_nz;
> +               LLVMTypeRef dst_type;
>
> -               assert(!symbol_is_fp_type(insn->type));
> -
> -               y = LLVMBuildICmp(fn->builder, LLVMIntNE, lhs, LLVMConstInt(LLVMTypeOf(lhs), 0, 0), "y");
> -               x = LLVMBuildICmp(fn->builder, LLVMIntNE, rhs, LLVMConstInt(LLVMTypeOf(rhs), 0, 0), "x");
> +               lhs_nz = LLVMBuildIsNotNull(fn->builder, lhs, "");
> +               rhs_nz = LLVMBuildIsNotNull(fn->builder, rhs, "");
> +               target = LLVMBuildAnd(fn->builder, lhs_nz, rhs_nz, target_name);
>
> -               target = LLVMBuildAnd(fn->builder, y, x, target_name);
> +               dst_type = insn_symbol_type(fn->module, insn);
> +               target = LLVMBuildZExt(fn->builder, target, dst_type, target_name);
>                 break;
>         }
>         case OP_OR_BOOL: {
> -               LLVMValueRef tmp;
> -
> -               assert(!symbol_is_fp_type(insn->type));
> +               LLVMValueRef lhs_nz, rhs_nz;
> +               LLVMTypeRef dst_type;
>
> -               tmp = LLVMBuildOr(fn->builder, rhs, lhs, "tmp");
> +               lhs_nz = LLVMBuildIsNotNull(fn->builder, lhs, "");
> +               rhs_nz = LLVMBuildIsNotNull(fn->builder, rhs, "");
> +               target = LLVMBuildOr(fn->builder, lhs_nz, rhs_nz, target_name);
>
> -               target = LLVMBuildICmp(fn->builder, LLVMIntNE, tmp, LLVMConstInt(LLVMTypeOf(tmp), 0, 0), target_name);
> +               dst_type = insn_symbol_type(fn->module, insn);
> +               target = LLVMBuildZExt(fn->builder, target, dst_type, target_name);
>                 break;
>         }
>
>         /* Binary comparison */
>         case OP_BINCMP ... OP_BINCMP_END: {
> +               LLVMTypeRef dst_type = insn_symbol_type(fn->module, insn);
> +
>                 if (LLVMGetTypeKind(LLVMTypeOf(lhs)) == LLVMIntegerTypeKind) {
>                         LLVMIntPredicate op = translate_op(insn->opcode);
>
> @@ -576,6 +581,8 @@ static void output_op_binary(struct function *fn, struct instruction *insn)
>
>                         target = LLVMBuildFCmp(fn->builder, op, lhs, rhs, target_name);
>                 }
> +
> +               target = LLVMBuildZExt(fn->builder, target, dst_type, target_name);
>                 break;
>         }
>         default:

Looks good to me. Chris, are you OK with me picking this up in the llvm tree?

                        Pekka
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] fix result type of relational and logical operators
Date: Mon, 27 May 2013 08:07:55 +0000
Message-ID: <20130527080701.GA2872 () gmail ! com>
--------------------
On Mon, May 27, 2013 at 09:33:42AM +0300, Pekka Enberg wrote:
> On Fri, May 24, 2013 at 4:30 PM, Xi Wang <xi.wang@gmail.com> wrote:
> > The result type of relational operators (e.g., x < y) and logical
> > operators (e.g., x && y) in C should be int, rather than bool.
> 
> Looks good to me. Chris, are you OK with me picking this up in the llvm tree?

Acked-By: Christopher Li <sparse@chrisli.org>

Chris

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB ===

From: =?UTF-8?q?Jonathan=20Neusch=C3=A4fer?= <j.neuschaefer () gmx ! net>
To: linux-sparse
Subject: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Tue, 09 Oct 2012 23:34:35 +0000
Message-ID: <1349825676-1713-1-git-send-email-j.neuschaefer () gmx ! net>
--------------------
This is required for producing valid LLVM bitcode.

Cc: Pekka Enberg <penberg@kernel.org>
Cc: Christopher Li <sparse@chrisli.org>
Cc: Jeff Garzik <jgarzik@redhat.com>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Jonathan NeuschÃ¤fer <j.neuschaefer@gmx.net>
---
 sparse-llvm.c              |   17 ++++++++++++++++-
 validation/backend/loop2.c |   13 +++++++++++++
 2 files changed, 29 insertions(+), 1 deletion(-)
 create mode 100644 validation/backend/loop2.c

diff --git a/sparse-llvm.c b/sparse-llvm.c
index 0fc0dae..2048a1b 100644
--- a/sparse-llvm.c
+++ b/sparse-llvm.c
@@ -1111,16 +1111,31 @@ static void output_insn(struct function *fn, struct instruction *insn)
 static void output_bb(struct function *fn, struct basic_block *bb, unsigned long generation)
 {
 	struct instruction *insn;
+	struct instruction_list *remaining = NULL;
 
 	bb->generation = generation;
 
+	/*
+	 * LLVM requires the phi instructions to be grouped at the top of each
+	 * basic block.
+	 */
+
 	FOR_EACH_PTR(bb->insns, insn) {
 		if (!insn->bb)
 			continue;
 
-		output_insn(fn, insn);
+		if (insn->opcode == OP_PHI)
+			output_insn(fn, insn);
+		else
+			add_instruction(&remaining, insn);
 	}
 	END_FOR_EACH_PTR(insn);
+
+	FOR_EACH_PTR(remaining, insn) {
+		output_insn(fn, insn);
+	} END_FOR_EACH_PTR(insn);
+
+	free_ptr_list(&remaining);
 }
 
 #define MAX_ARGS	64
diff --git a/validation/backend/loop2.c b/validation/backend/loop2.c
new file mode 100644
index 0000000..4e44a15
--- /dev/null
+++ b/validation/backend/loop2.c
@@ -0,0 +1,13 @@
+extern int op(void);
+
+static void test(void) {
+	int i;
+	for (i = 0; ; i++) {
+		op();
+	}
+}
+
+/*
+ * check-name: Loops with unused counter
+ * check-command: ./sparsec -c $file -o tmp.o
+ */
-- 
1.7.10.4

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Wed, 10 Oct 2012 06:31:31 +0000
Message-ID: <CAOJsxLF2AqK2N_R876jOOVmkHXyhe_OjyP_xfULUF5PAfKogMw () mail ! gmail ! com>
--------------------
On Wed, Oct 10, 2012 at 3:12 AM, Jeff Garzik <jgarzik@pobox.com> wrote:
> On 10/09/2012 07:34 PM, Jonathan Neuschäfer wrote:
>>
>> This is required for producing valid LLVM bitcode.
>>
>> Cc: Pekka Enberg <penberg@kernel.org>
>> Cc: Christopher Li <sparse@chrisli.org>
>> Cc: Jeff Garzik <jgarzik@redhat.com>
>> Cc: Linus Torvalds <torvalds@linux-foundation.org>
>> Signed-off-by: Jonathan Neuschäfer <j.neuschaefer@gmx.net>
>> ---
>>   sparse-llvm.c              |   17 ++++++++++++++++-
>>   validation/backend/loop2.c |   13 +++++++++++++
>>   2 files changed, 29 insertions(+), 1 deletion(-)
>>   create mode 100644 validation/backend/loop2.c
>
> Looks sane... but I did not verify whether or not this reordering is safe

Ditto. Jonathan, care to explain why you think it is safe? I still
don't know Sparse's linearized IR well enough to convince myself this
is OK.
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Jonathan =?utf-8?Q?Neusch=C3=A4fer?= <j.neuschaefer () gmx ! net>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Wed, 10 Oct 2012 16:33:06 +0000
Message-ID: <20121010163306.GA2846 () debian ! debian>
--------------------
On Wed, Oct 10, 2012 at 09:31:31AM +0300, Pekka Enberg wrote:
> On Wed, Oct 10, 2012 at 3:12 AM, Jeff Garzik <jgarzik@pobox.com> wrote:
> > On 10/09/2012 07:34 PM, Jonathan NeuschÃ¤fer wrote:
> >>
> >> This is required for producing valid LLVM bitcode.
> >>
> >> Cc: Pekka Enberg <penberg@kernel.org>
> >> Cc: Christopher Li <sparse@chrisli.org>
> >> Cc: Jeff Garzik <jgarzik@redhat.com>
> >> Cc: Linus Torvalds <torvalds@linux-foundation.org>
> >> Signed-off-by: Jonathan NeuschÃ¤fer <j.neuschaefer@gmx.net>
> >> ---
> >>   sparse-llvm.c              |   17 ++++++++++++++++-
> >>   validation/backend/loop2.c |   13 +++++++++++++
> >>   2 files changed, 29 insertions(+), 1 deletion(-)
> >>   create mode 100644 validation/backend/loop2.c
> >
> > Looks sane... but I did not verify whether or not this reordering is safe
> 
> Ditto. Jonathan, care to explain why you think it is safe? I still
> don't know Sparse's linearized IR well enough to convince myself this
> is OK.

I can't say with certainty that it's safe either, so I probably should
have marked the patch with "request for comments".

AFAICT there are three reasons an instruction cannot be moved up or down
within a basic block:
 1. If it takes previous SSA values as arguments, it can't be moved
    above the corresponding intructions.
 2. If its value is used as an argument of an instruction further down
    in the BB, it can't be moved below that instruction.
 3. Swapping two instructions that influence or are influenced by the
    "global state" (sorry for the loose wording), e.g. by doing memory
    accesses, performing I/O, or calling functions (which in turn can
    do about anything in general), is generally unsafe.

Case 1 doesn't apply because PHI nodes don't use values computed in the
same invocation of their basic block. Case 2 doesn't apply as I'm not
moving the PHI nodes down. Case 3 doesn't seem to apply either.

That's how I think this patch is safe.


HTH,
Jonathan
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Fri, 12 Oct 2012 18:25:42 +0000
Message-ID: <CAOJsxLE=UsuonXVPuDxL9jPGQj_M5xdvCUrk5u+m3U-s4Ao-hA () mail ! gmail ! com>
--------------------
On Wed, Oct 10, 2012 at 7:33 PM, Jonathan Neuschäfer
<j.neuschaefer@gmx.net> wrote:
> I can't say with certainty that it's safe either, so I probably should
> have marked the patch with "request for comments".
>
> AFAICT there are three reasons an instruction cannot be moved up or down
> within a basic block:
>  1. If it takes previous SSA values as arguments, it can't be moved
>     above the corresponding intructions.
>  2. If its value is used as an argument of an instruction further down
>     in the BB, it can't be moved below that instruction.
>  3. Swapping two instructions that influence or are influenced by the
>     "global state" (sorry for the loose wording), e.g. by doing memory
>     accesses, performing I/O, or calling functions (which in turn can
>     do about anything in general), is generally unsafe.
>
> Case 1 doesn't apply because PHI nodes don't use values computed in the
> same invocation of their basic block. Case 2 doesn't apply as I'm not
> moving the PHI nodes down. Case 3 doesn't seem to apply either.
>
> That's how I think this patch is safe.

Sounds plausible but I'm still uneasy with the idea that LLVM backend
needs to reshuffle instructions like this.

Would it be possible to solve this in the frontend?

                        Pekka
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Tue, 16 Oct 2012 17:59:27 +0000
Message-ID: <CAOJsxLEEBYMF4qcyBSpS7kaumzpQFm0McNexRtft3UJVwp==Xg () mail ! gmail ! com>
--------------------
On Fri, Oct 12, 2012 at 9:25 PM, Pekka Enberg <penberg@kernel.org> wrote:
> On Wed, Oct 10, 2012 at 7:33 PM, Jonathan Neuschäfer
> <j.neuschaefer@gmx.net> wrote:
>> I can't say with certainty that it's safe either, so I probably should
>> have marked the patch with "request for comments".
>>
>> AFAICT there are three reasons an instruction cannot be moved up or down
>> within a basic block:
>>  1. If it takes previous SSA values as arguments, it can't be moved
>>     above the corresponding intructions.
>>  2. If its value is used as an argument of an instruction further down
>>     in the BB, it can't be moved below that instruction.
>>  3. Swapping two instructions that influence or are influenced by the
>>     "global state" (sorry for the loose wording), e.g. by doing memory
>>     accesses, performing I/O, or calling functions (which in turn can
>>     do about anything in general), is generally unsafe.
>>
>> Case 1 doesn't apply because PHI nodes don't use values computed in the
>> same invocation of their basic block. Case 2 doesn't apply as I'm not
>> moving the PHI nodes down. Case 3 doesn't seem to apply either.
>>
>> That's how I think this patch is safe.
>
> Sounds plausible but I'm still uneasy with the idea that LLVM backend
> needs to reshuffle instructions like this.
>
> Would it be possible to solve this in the frontend?

Linus, Chris, any thoughts on this?
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Jonathan =?utf-8?Q?Neusch=C3=A4fer?= <j.neuschaefer () gmx ! net>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Tue, 16 Oct 2012 20:14:26 +0000
Message-ID: <20121016201426.GD2932 () debian ! debian>
--------------------
On Tue, Oct 16, 2012 at 08:59:27PM +0300, Pekka Enberg wrote:
> On Fri, Oct 12, 2012 at 9:25 PM, Pekka Enberg <penberg@kernel.org> wrote:
> > Sounds plausible but I'm still uneasy with the idea that LLVM backend
> > needs to reshuffle instructions like this.

Actually, the situation of Phi nodes in LLVM is actually slightly more
complex: They require "one pair (of value and BB) for each predecessor
basic block of the current block"[1]. This mean that we'll sometimes
need to insert phi nodes into BBs that don't directly use a value.
Consider the following piece of C code:

	extern int done(void);
	extern void foo(int);

	static void test(void) {
		int i;
		for (i = 0; ; i++) {
			if (done())
				break;
			foo(i);
		}
	}

Running it through test-linearize exhibits the problem:
[ I renamed the basic blocks to L0-L3 to increase readability. ]

	test:
	.L0:
		<entry-point>
		phisrc.32   %phi2(i) <- $0
		br          .L1

	.L1:
		call.32     %r1 <- done
		br          %r1, .L3, .L2

	.L2:
		phi.32      %r2(i) <- %phi2(i), %phi3(i)
		call        foo, %r2(i)
		add.32      %r4 <- %r2(i), $1
		phisrc.32   %phi3(i) <- %r4
		br          .L1

	.L3:
		ret

To comply with the "LLVM rules" we'd need to move the phi intruction up
into "L1".


regards,
Jonathan
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Wed, 17 Oct 2012 06:48:17 +0000
Message-ID: <CAOJsxLFXaWXcR8vF_DFPAaJZPJ_BTe47Q9GSkM-2MChaRBqkdw () mail ! gmail ! com>
--------------------
On 10/16/12 4:14 PM, Jonathan Neuschäfer wrote:
>> Actually, the situation of Phi nodes in LLVM is actually slightly more
>> complex: They require "one pair (of value and BB) for each predecessor
>> basic block of the current block"[1]. This mean that we'll sometimes
>> need to insert phi nodes into BBs that don't directly use a value.

On Tue, Oct 16, 2012 at 11:53 PM, Xi Wang <xi.wang@gmail.com> wrote:
> I ran into the same problem before.  I would suggest a simpler and safer
> way: don't emit LLVM phi; instead emit load/store (of some alloca).
>
> phi    => load from some alloca
> phisrc => store to some alloca

Is LLVM able to optimize away the allocas and use registers instead in
the emitted code? If not, that means we'll spill and reload at every
basic block boundary...
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Wed, 17 Oct 2012 06:53:48 +0000
Message-ID: <507E55FC.5010202 () gmail ! com>
--------------------
On 10/17/12 2:48 AM, Pekka Enberg wrote:
> Is LLVM able to optimize away the allocas and use registers instead in
> the emitted code?

Yes.  See the last part of my previous email, no load/store/alloca after
LLVM's -mem2reg pass.

- xi
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Wed, 17 Oct 2012 16:41:52 +0000
Message-ID: <CAOJsxLGWCoskGTsKefWoCYPGuR_b5_QsMTnYkzTNX14t0HkKhg () mail ! gmail ! com>
--------------------
On 10/17/12 2:48 AM, Pekka Enberg wrote:
>> Is LLVM able to optimize away the allocas and use registers instead in
>> the emitted code?

On Wed, Oct 17, 2012 at 9:53 AM, Xi Wang <xi.wang@gmail.com> wrote:
> Yes.  See the last part of my previous email, no load/store/alloca after
> LLVM's -mem2reg pass.

Right. Jonathan, does Xi's suggestion sound reasonable to you? I'd
certainly prefer that over instruction reordering.

                                Pekka
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: group PHI nodes at the top of each BB
Date: Wed, 15 May 2013 12:05:52 +0000
Message-ID: <CAOJsxLGizp=f5RziV2fKFR=wGQXWr+nvVZXLWGoeKa23gD_5Fw () mail ! gmail ! com>
--------------------
Hello,

On Tue, Oct 16, 2012 at 11:53 PM, Xi Wang <xi.wang@gmail.com> wrote:
> On 10/16/12 4:14 PM, Jonathan Neuschäfer wrote:
>> Actually, the situation of Phi nodes in LLVM is actually slightly more
>> complex: They require "one pair (of value and BB) for each predecessor
>> basic block of the current block"[1]. This mean that we'll sometimes
>> need to insert phi nodes into BBs that don't directly use a value.
>
> I ran into the same problem before.  I would suggest a simpler and safer
> way: don't emit LLVM phi; instead emit load/store (of some alloca).
>
> phi    => load from some alloca
> phisrc => store to some alloca
>
> You can find sample code from splay here (emit_phi & emit_phisrc):
>
> https://github.com/xiw/splay/blob/master/function.c#L356
>
>> Consider the following piece of C code:
>>
>>       extern int done(void);
>>       extern void foo(int);
>>
>>       static void test(void) {
>>               int i;
>>               for (i = 0; ; i++) {
>>                       if (done())
>>                               break;
>>                       foo(i);
>>               }
>>       }
>
> This is what splay emits:
>
> define internal void @test() {
> entry:
>   %0 = alloca i32
>   store i32 0, i32* %0
>   br label %bb
>
> bb:                                               ; preds = %bb1, %entry
>   %1 = call i32 @done()
>   %2 = icmp ne i32 %1, 0
>   br i1 %2, label %bb2, label %bb1
>
> bb1:                                              ; preds = %bb
>   %3 = load i32* %0
>   call void @foo(i32 %3)
>   %4 = add nsw i32 %3, 1
>   store i32 %4, i32* %0
>   br label %bb
>
> bb2:                                              ; preds = %bb
>   ret void
> }
>
> After "-mem2reg" you get:
>
> define internal void @test() {
> entry:
>   br label %bb
>
> bb:                                               ; preds = %bb1, %entry
>   %.0 = phi i32 [ 0, %entry ], [ %2, %bb1 ]
>   %0 = call i32 @done()
>   %1 = icmp ne i32 %0, 0
>   br i1 %1, label %bb2, label %bb1
>
> bb1:                                              ; preds = %bb
>   call void @foo(i32 %.0)
>   %2 = add nsw i32 %.0, 1
>   br label %bb
>
> bb2:                                              ; preds = %bb
>   ret void
> }

Ping, anyone interested in turning Xi's suggestion into a patch
against current sparse master?

                        Pekka
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 1/2] sparse, llvm: improve pointer arithmetic handling ===

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: [PATCH 1/2] sparse, llvm: improve pointer arithmetic handling
Date: Sun, 19 May 2013 12:13:09 +0000
Message-ID: <1368965590-6714-1-git-send-email-xi.wang () gmail ! com>
--------------------
Converting pointers to integers for pointer arithmetic effectively
disables pointer analysis and future optimizations.  A better way is to
use LLVM's GEP, by converting pointers to `char *' rather than integers.

Cc: Pekka Enberg <penberg@kernel.org>
Acked-by: Jonathan NeuschÃ¤fer <j.neuschaefer@gmx.net>
Signed-off-by: Xi Wang <xi.wang@gmail.com>
---
calc_gep() may be useful for fixing array access as well.
---
 sparse-llvm.c | 38 ++++++++++++++++++++++++++------------
 1 file changed, 26 insertions(+), 12 deletions(-)

diff --git a/sparse-llvm.c b/sparse-llvm.c
index 41e0ab7..02f43f7 100644
--- a/sparse-llvm.c
+++ b/sparse-llvm.c
@@ -370,6 +370,22 @@ static LLVMValueRef pseudo_to_value(struct function *fn, struct instruction *ins
 	return result;
 }
 
+static LLVMValueRef calc_gep(LLVMBuilderRef builder, LLVMValueRef base, LLVMValueRef off)
+{
+	LLVMTypeRef type = LLVMTypeOf(base);
+	unsigned int as = LLVMGetPointerAddressSpace(type);
+	LLVMTypeRef bytep = LLVMPointerType(LLVMInt8Type(), as);
+	LLVMValueRef addr;
+
+	/* convert base to char* type */
+	base = LLVMBuildPointerCast(builder, base, bytep, "");
+	/* addr = base + off */
+	addr = LLVMBuildInBoundsGEP(builder, base, &off, 1, "");
+	/* convert back to the actual pointer type */
+	addr = LLVMBuildPointerCast(builder, addr, type, "");
+	return addr;
+}
+
 static LLVMRealPredicate translate_fop(int opcode)
 {
 	static const LLVMRealPredicate trans_tbl[] = {
@@ -544,23 +560,21 @@ static void output_op_ret(struct function *fn, struct instruction *insn)
 static LLVMValueRef calc_memop_addr(struct function *fn, struct instruction *insn)
 {
 	LLVMTypeRef int_type, addr_type;
-	LLVMValueRef src_p, src_i, ofs_i, addr_i, addr;
+	LLVMValueRef src, off, addr;
+	unsigned int as;
 
 	/* int type large enough to hold a pointer */
 	int_type = LLVMIntType(bits_in_pointer);
+	off = LLVMConstInt(int_type, insn->offset, 0);
 
-	/* convert to integer, add src + offset */
-	src_p = pseudo_to_value(fn, insn, insn->src);
-	src_i = LLVMBuildPtrToInt(fn->builder, src_p, int_type, "src_i");
-
-	ofs_i = LLVMConstInt(int_type, insn->offset, 0);
-	addr_i = LLVMBuildAdd(fn->builder, src_i, ofs_i, "addr_i");
-
-	addr_type = LLVMPointerType(insn_symbol_type(fn->module, insn), 0);
-
-	/* convert address back to pointer */
-	addr = LLVMBuildIntToPtr(fn->builder, addr_i, addr_type, "addr");
+	/* convert src to the effective pointer type */
+	src = pseudo_to_value(fn, insn, insn->src);
+	as = LLVMGetPointerAddressSpace(LLVMTypeOf(src));
+	addr_type = LLVMPointerType(insn_symbol_type(fn->module, insn), as);
+	src = LLVMBuildPointerCast(fn->builder, src, addr_type, "");
 
+	/* addr = src + off */
+	addr = calc_gep(fn->builder, src, off);
 	return addr;
 }
 
-- 
1.8.1.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/2] sparse, llvm: improve pointer arithmetic handling
Date: Sun, 19 May 2013 12:49:58 +0000
Message-ID: <CAOJsxLErGy=US5DoegZWVHupHjCA=83MXXY2WOTmH0-wrJccmA () mail ! gmail ! com>
--------------------
On Sun, May 19, 2013 at 3:13 PM, Xi Wang <xi.wang@gmail.com> wrote:
> Converting pointers to integers for pointer arithmetic effectively
> disables pointer analysis and future optimizations.  A better way is to
> use LLVM's GEP, by converting pointers to `char *' rather than integers.
>
> Cc: Pekka Enberg <penberg@kernel.org>
> Acked-by: Jonathan Neuschäfer <j.neuschaefer@gmx.net>
> Signed-off-by: Xi Wang <xi.wang@gmail.com>

Applied both patches, thanks a lot Xi!
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 1/3] Warn about initialization of a char array with a too long constant C string. ===

From: Masatake YAMATO <yamato () redhat ! com>
To: linux-sparse
Subject: [PATCH 1/3] Warn about initialization of a char array with a too long constant C string.
Date: Sat, 06 Apr 2013 16:58:55 +0000
Message-ID: <1365267537-3787-1-git-send-email-yamato () redhat ! com>
--------------------
This patch adds new option -Winit-cstring to sparse.

With the option sparse can Warn about initialization of a char array
with a too long constant C string.  If the size of the char array and
the length of the string is the same, there is no space for the last
nul char of the string in the array.

              char s[3] = "abc";

If the array is used as just a byte array, not as C string, this
warning is just noise. However, if the array is passed to functions
dealing with C string like printf(%s) and strcmp, it may cause a
trouble.

Here is a example of such trouble:
     http://www.spinics.net/lists/netdev/msg229765.html
     http://www.spinics.net/lists/netdev/msg229870.html

Signed-off-by: Masatake YAMATO <yamato@redhat.com>
---
 evaluate.c | 12 ++++++++----
 lib.c      |  2 ++
 lib.h      |  1 +
 3 files changed, 11 insertions(+), 4 deletions(-)

diff --git a/evaluate.c b/evaluate.c
index d09f271..9f2c4ac 100644
--- a/evaluate.c
+++ b/evaluate.c
@@ -2592,10 +2592,14 @@ String:
 	p = alloc_expression(e->pos, EXPR_STRING);
 	*p = *e;
 	type = evaluate_expression(p);
-	if (ctype->bit_size != -1 &&
-	    ctype->bit_size + bits_in_char < type->bit_size) {
-		warning(e->pos,
-			"too long initializer-string for array of char");
+	if (ctype->bit_size != -1) {
+		if (ctype->bit_size + bits_in_char < type->bit_size)
+			warning(e->pos,
+				"too long initializer-string for array of char");
+		else if (Winit_cstring && ctype->bit_size + bits_in_char == type->bit_size) {
+			warning(e->pos,
+				"too long initializer-string for array of char(no space for nul char)");
+		}
 	}
 	*ep = p;
 	return 1;
diff --git a/lib.c b/lib.c
index 4f69e11..7c44414 100644
--- a/lib.c
+++ b/lib.c
@@ -199,6 +199,7 @@ int Wdecl = 1;
 int Wdefault_bitfield_sign = 0;
 int Wdesignated_init = 1;
 int Wdo_while = 0;
+int Winit_cstring = 0;
 int Wenum_mismatch = 1;
 int Wnon_pointer_null = 1;
 int Wold_initializer = 1;
@@ -410,6 +411,7 @@ static const struct warning {
 	{ "designated-init", &Wdesignated_init },
 	{ "do-while", &Wdo_while },
 	{ "enum-mismatch", &Wenum_mismatch },
+	{ "init-cstring", &Winit_cstring },
 	{ "non-pointer-null", &Wnon_pointer_null },
 	{ "old-initializer", &Wold_initializer },
 	{ "one-bit-signed-bitfield", &Wone_bit_signed_bitfield },
diff --git a/lib.h b/lib.h
index ee954fe..1227de9 100644
--- a/lib.h
+++ b/lib.h
@@ -95,6 +95,7 @@ extern int Wdefault_bitfield_sign;
 extern int Wdesignated_init;
 extern int Wdo_while;
 extern int Wenum_mismatch;
+extern int Winit_cstring;
 extern int Wnon_pointer_null;
 extern int Wold_initializer;
 extern int Wone_bit_signed_bitfield;
-- 
1.7.11.7

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH 1/3] Warn about initialization of a char array with a too long constant C string.
Date: Mon, 22 Apr 2013 16:42:12 +0000
Message-ID: <CANeU7Qmg15kHmR3_x20yBEa6dPGmYK7xms+vZzWzdRTjcB+OSw () mail ! gmail ! com>
--------------------
On Sat, Apr 6, 2013 at 9:58 AM, Masatake YAMATO <yamato@redhat.com> wrote:
> This patch adds new option -Winit-cstring to sparse.
>
> With the option sparse can Warn about initialization of a char array
> with a too long constant C string.  If the size of the char array and
> the length of the string is the same, there is no space for the last
> nul char of the string in the array.

Patches applied.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 1/3] char.c: Fix parsing of escapes ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH 1/3] char.c: Fix parsing of escapes
Date: Fri, 17 May 2013 18:27:49 +0000
Message-ID: <519676A5.4000706 () chrisli ! org>
--------------------
On 05/16/2013 12:41 PM, Ramsay Jones wrote:
> 
> When parsing a string or character constant, the parse_escape()
> function returns a pointer to the character at which to resume
> parsing. However, in the case of an hex or octal escape, it was
> returning a one-past-the-end pointer. Thus, a string like:
> 
>     char str[3] = "\x61\x62\x63";
> 
> was being parsed as:
> 
>     '\x61', 'x', '6', '2', '\x63'
> 
> which, in turn, provokes an 'too long initializer' warning.
> 
> Also, fix an off-by-one error in get_char_constant() when setting
> the 'end' pointer for a TOKEN_CHAR or TOKEN_WIDE_CHAR. Despite the
> name, the string->length of the token is actually the size of the
> allocated memory (ie len+1), so we need to compensate by using
> 'token->string->length - 1'.

Great patch. Applied.

Chris

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 1/4] sparse, llvm: Fix resulting type of store address calculations ===

From: =?UTF-8?q?Jonathan=20Neusch=C3=A4fer?= <j.neuschaefer () gmx ! net>
To: linux-sparse
Subject: [PATCH 1/4] sparse, llvm: Fix resulting type of store address calculations
Date: Sat, 18 May 2013 17:52:04 +0000
Message-ID: <1368899527-2350-1-git-send-email-j.neuschaefer () gmx ! net>
--------------------
Use the fix from d5bd3662 ("sparse, llvm: Fix type of loaded values").

Cc: Pekka Enberg <penberg@kernel.org>
Cc: Christopher Li <sparse@chrisli.org>
Cc: Jeff Garzik <jgarzik@redhat.com>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Cc: Xi Wang <xi.wang@gmail.com>
Signed-off-by: Jonathan NeuschÃ¤fer <j.neuschaefer@gmx.net>
---
 sparse-llvm.c                   |    2 +-
 validation/backend/store-type.c |   12 ++++++++++++
 2 files changed, 13 insertions(+), 1 deletion(-)
 create mode 100644 validation/backend/store-type.c

diff --git a/sparse-llvm.c b/sparse-llvm.c
index 6f2fbd6..837a96f 100644
--- a/sparse-llvm.c
+++ b/sparse-llvm.c
@@ -640,7 +640,7 @@ static void output_op_store(struct function *fn, struct instruction *insn)
 
 	/* convert address back to pointer */
 	addr = LLVMBuildIntToPtr(fn->builder, addr_i,
-				 LLVMPointerType(int_type, 0), "addr");
+				 LLVMTypeOf(src_p), "addr");
 
 	target_in = pseudo_to_value(fn, insn, insn->target);
 
diff --git a/validation/backend/store-type.c b/validation/backend/store-type.c
new file mode 100644
index 0000000..9e2ce73
--- /dev/null
+++ b/validation/backend/store-type.c
@@ -0,0 +1,12 @@
+struct foo;
+static struct foo *var;
+
+static void set(struct foo *f)
+{
+       var = f;
+}
+
+/*
+ * check-name: Type of stored objects
+ * check-command: ./sparsec -c $file -o tmp.o
+ */
-- 
1.7.10.4

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH 1/4] sparse, llvm: Fix resulting type of store address calculations
Date: Sun, 19 May 2013 08:01:46 +0000
Message-ID: <CAOJsxLF7r9xybRUAut7MsL9_xX5mhNxjw2mC8G2g2+NaWTbU1g () mail ! gmail ! com>
--------------------
Applied all four patches, thanks a lot Jonathan!
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 1/5] Add the __restrict__ keyword ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH 1/5] Add the __restrict__ keyword
Date: Thu, 23 May 2013 15:28:56 +0000
Message-ID: <519E35B8.5070300 () chrisli ! org>
--------------------
On 05/21/2013 12:15 PM, Ramsay Jones wrote:
> 
> 
> Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
> ---
>  ident-list.h          | 2 +-
>  parse.c               | 3 ++-
>  validation/reserved.c | 1 +
>  3 files changed, 4 insertions(+), 2 deletions(-)
> 


Looks good, will apply.

Chris

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 2/2] Remove the redundant attribute from ctype ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: [PATCH 2/2] Remove the redundant attribute from ctype
Date: Wed, 27 Feb 2013 15:23:13 +0000
Message-ID: <CANeU7QnxXTB8edDF9C72U==HHcWSVmprw4Rd+C4OWV3Y8B9TCg () mail ! gmail ! com>
--------------------
--bcaec54ee608445f4404d6b65af2
Content-Type: text/plain; charset=ISO-8859-1

This change removes the attribute data store in ctype struct.

Chris

--bcaec54ee608445f4404d6b65af2
Content-Type: application/octet-stream; 
	name="0002-Remove-the-redundant-attribute-from-ctype-structure.patch"
Content-Disposition: attachment; 
	filename="0002-Remove-the-redundant-attribute-from-ctype-structure.patch"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_hdomv4b81
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--bcaec54ee608445f4404d6b65af2--
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 2/2] sparse, llvm: set target specification ===

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: [PATCH 2/2] sparse, llvm: set target specification
Date: Sun, 19 May 2013 12:13:10 +0000
Message-ID: <1368965590-6714-2-git-send-email-xi.wang () gmail ! com>
--------------------
Set target triple and data layout, which are required by LLVM's backend.

Also export arch_m64 for choosing the target architecture.

Cc: Pekka Enberg <penberg@kernel.org>
Cc: Jonathan NeuschÃ¤fer <j.neuschaefer@gmx.net>
Signed-off-by: Xi Wang <xi.wang@gmail.com>
---
With the two patches, we will be able to recover struct access.

Consider t.c:

	struct A { int x, y; };

	void foo(struct A *a)
	{
		a->x = 123;
		a->y = 456;
	}

$ ./sparse-llvm t.c | opt -S -O2
...
define void @foo(%A* nocapture) #0 {
L0:
  %1 = getelementptr inbounds %A* %0, i64 0, i32 0
  store i32 123, i32* %1, align 4
  %2 = getelementptr inbounds %A* %0, i64 0, i32 1
  store i32 456, i32* %2, align 4
  ret void
}
---
 lib.h         |  2 ++
 sparse-llvm.c | 56 +++++++++++++++++++++++++++++++++++++++++++++++++++++---
 2 files changed, 55 insertions(+), 3 deletions(-)

diff --git a/lib.h b/lib.h
index 680ad8f..5ab2bd9 100644
--- a/lib.h
+++ b/lib.h
@@ -113,6 +113,8 @@ extern int Wvla;
 extern int dbg_entry;
 extern int dbg_dead;
 
+extern int arch_m64;
+
 extern void declare_builtin_functions(void);
 extern void create_builtin_stream(void);
 extern struct symbol_list *sparse_initialize(int argc, char **argv, struct string_list **files);
diff --git a/sparse-llvm.c b/sparse-llvm.c
index 02f43f7..09eedb8 100644
--- a/sparse-llvm.c
+++ b/sparse-llvm.c
@@ -6,6 +6,7 @@
 #include <llvm-c/Core.h>
 #include <llvm-c/BitWriter.h>
 #include <llvm-c/Analysis.h>
+#include <llvm-c/Target.h>
 
 #include <stdbool.h>
 #include <stdio.h>
@@ -1066,14 +1067,63 @@ static int compile(LLVMModuleRef module, struct symbol_list *list)
 	return 0;
 }
 
+#define X86_LINUX_LAYOUT \
+	"e-p:32:32:32-i1:8:8-i8:8:8-i16:16:16-i32:32:32-" \
+	"i64:32:64-f32:32:32-f64:32:64-v64:64:64-v128:128:128-" \
+	"a0:0:64-f80:32:32-n8:16:32-S128"
+
+#define X86_64_LINUX_LAYOUT \
+	"e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-" \
+	"i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-" \
+	"a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128"
+
+static void set_target(LLVMModuleRef module)
+{
+	char target[] = LLVM_DEFAULT_TARGET_TRIPLE;
+	const char *arch, *vendor, *os, *env, *layout = NULL;
+	char triple[256];
+
+	arch = strtok(target, "-");
+	vendor = strtok(NULL, "-");
+	os = strtok(NULL, "-");
+	env = strtok(NULL, "-");
+
+	if (!os)
+		return;
+	if (!env)
+		env = "unknown";
+
+	if (!strcmp(arch, "x86_64") && !strcmp(os, "linux")) {
+		if (arch_m64) {
+			layout = X86_64_LINUX_LAYOUT;
+		} else {
+			arch = "i386";
+			layout = X86_LINUX_LAYOUT;
+		}
+	}
+
+	/* unsupported target */
+	if (!layout)
+		return;
+
+	snprintf(triple, sizeof(triple), "%s-%s-%s-%s", arch, vendor, os, env);
+	LLVMSetTarget(module, triple);
+	LLVMSetDataLayout(module, layout);
+}
+
 int main(int argc, char **argv)
 {
-	struct string_list * filelist = NULL;
+	struct string_list *filelist = NULL;
+	struct symbol_list *symlist;
+	LLVMModuleRef module;
 	char *file;
 
-	LLVMModuleRef module = LLVMModuleCreateWithName("sparse");
+	symlist = sparse_initialize(argc, argv, &filelist);
+
+	module = LLVMModuleCreateWithName("sparse");
+	set_target(module);
 
-	compile(module, sparse_initialize(argc, argv, &filelist));
+	compile(module, symlist);
 
 	/* need ->phi_users */
 	dbg_dead = 1;
-- 
1.8.1.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 2/3] Makefile: Fix some macro redefinition warnings ===

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: [PATCH 2/3] Makefile: Fix some macro redefinition warnings
Date: Thu, 16 May 2013 19:42:45 +0000
Message-ID: <519536B5.7020603 () ramsay1 ! demon ! co ! uk>
--------------------

In particular, gcc complains as follows:

       CC       sparse-llvm.o
  <command line>:1:1: warning: "__STDC_CONSTANT_MACROS" redefined
  <command line>:1:1: warning: this is the location of the previous definition
  <command line>:1:1: warning: "__STDC_FORMAT_MACROS" redefined
  <command line>:1:1: warning: this is the location of the previous definition
  <command line>:1:1: warning: "__STDC_LIMIT_MACROS" redefined
  <command line>:1:1: warning: this is the location of the previous definition

The warnings are caused by the macros being defined twice on the
gcc command line. These command line -D macro definitions come
originally from the output of 'llvm-config --cflags', which is
recorded in the $(LLVM_CFLAGS) variable. This variable is then
included in the $(BASIC_CFLAGS) variable twice due to duplication
of the target-specific additions to the BASIC_CFLAGS, viz:

  sparse-llvm_EXTRA_DEPS := sparse-llvm.o
  sparse-llvm.o $(sparse-llvm_EXTRA_DEPS): BASIC_CFLAGS += $(LLVM_CFLAGS)

In order to suppress the warnings, we remove the duplication of
the sparse-llvm.o target in the above rule.

Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
---
 Makefile | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Makefile b/Makefile
index 35e3801..ba2ba85 100644
--- a/Makefile
+++ b/Makefile
@@ -90,7 +90,7 @@ LLVM_LIBS := $(shell llvm-config --libs)
 PROGRAMS += $(LLVM_PROGS)
 INST_PROGRAMS += sparse-llvm sparsec
 sparse-llvm_EXTRA_DEPS := sparse-llvm.o
-sparse-llvm.o $(sparse-llvm_EXTRA_DEPS): BASIC_CFLAGS += $(LLVM_CFLAGS)
+$(sparse-llvm_EXTRA_DEPS): BASIC_CFLAGS += $(LLVM_CFLAGS)
 sparse-llvm_EXTRA_OBJS := $(LLVM_LIBS)
 endif
 endif
-- 
1.8.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH 2/3] Makefile: Fix some macro redefinition warnings
Date: Fri, 17 May 2013 18:30:10 +0000
Message-ID: <51967732.40302 () chrisli ! org>
--------------------
On 05/16/2013 12:42 PM, Ramsay Jones wrote:
> 
> In particular, gcc complains as follows:
> 
>        CC       sparse-llvm.o
>   <command line>:1:1: warning: "__STDC_CONSTANT_MACROS" redefined
>   <command line>:1:1: warning: this is the location of the previous definition
>   <command line>:1:1: warning: "__STDC_FORMAT_MACROS" redefined
>   <command line>:1:1: warning: this is the location of the previous definition
>   <command line>:1:1: warning: "__STDC_LIMIT_MACROS" redefined
>   <command line>:1:1: warning: this is the location of the previous definition
> 
> The warnings are caused by the macros being defined twice on the
> gcc command line. These command line -D macro definitions come
> originally from the output of 'llvm-config --cflags', which is
> recorded in the $(LLVM_CFLAGS) variable. This variable is then
> included in the $(BASIC_CFLAGS) variable twice due to duplication
> of the target-specific additions to the BASIC_CFLAGS, viz:
> 
>   sparse-llvm_EXTRA_DEPS := sparse-llvm.o
>   sparse-llvm.o $(sparse-llvm_EXTRA_DEPS): BASIC_CFLAGS += $(LLVM_CFLAGS)
> 
> In order to suppress the warnings, we remove the duplication of
> the sparse-llvm.o target in the above rule.
> 
> Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>

I already commit a similar fix to remove the duplication.
I did not realize it can generate warning though.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 2/3] Test case for -Winit-cstring option ===

From: Masatake YAMATO <yamato () redhat ! com>
To: linux-sparse
Subject: [PATCH 2/3] Test case for -Winit-cstring option
Date: Sat, 06 Apr 2013 16:58:56 +0000
Message-ID: <1365267537-3787-2-git-send-email-yamato () redhat ! com>
--------------------
This patch added a test case for -Winit-cstring option
to validation directory.

Signed-off-by: Masatake YAMATO <yamato@redhat.com>
---
 validation/init_cstring.c | 11 +++++++++++
 1 file changed, 11 insertions(+)
 create mode 100644 validation/init_cstring.c

diff --git a/validation/init_cstring.c b/validation/init_cstring.c
new file mode 100644
index 0000000..00eca20
--- /dev/null
+++ b/validation/init_cstring.c
@@ -0,0 +1,11 @@
+static struct alpha {
+  char a[2];
+} x = { .a = "ab" };
+/*
+ * check-name: -Winit-cstring option
+ *
+ * check-command: sparse -Winit-cstring $file
+ * check-error-start
+init_cstring.c:3:14: warning: too long initializer-string for array of char(no space for nul char)
+ * check-error-end
+ */
-- 
1.7.11.7

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 2/4] sparse, llvm: de-duplicate load/store address calculation code ===

From: =?UTF-8?q?Jonathan=20Neusch=C3=A4fer?= <j.neuschaefer () gmx ! net>
To: linux-sparse
Subject: [PATCH 2/4] sparse, llvm: de-duplicate load/store address calculation code
Date: Sat, 18 May 2013 17:52:05 +0000
Message-ID: <1368899527-2350-2-git-send-email-j.neuschaefer () gmx ! net>
--------------------
Cc: Pekka Enberg <penberg@kernel.org>
Cc: Christopher Li <sparse@chrisli.org>
Cc: Jeff Garzik <jgarzik@redhat.com>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Cc: Xi Wang <xi.wang@gmail.com>
Signed-off-by: Jonathan NeuschÃ¤fer <j.neuschaefer@gmx.net>
---
 sparse-llvm.c |   31 ++++++++++++++-----------------
 1 file changed, 14 insertions(+), 17 deletions(-)

diff --git a/sparse-llvm.c b/sparse-llvm.c
index 837a96f..8573eda 100644
--- a/sparse-llvm.c
+++ b/sparse-llvm.c
@@ -598,10 +598,10 @@ static void output_op_ret(struct function *fn, struct instruction *insn)
 		LLVMBuildRetVoid(fn->builder);
 }
 
-static void output_op_load(struct function *fn, struct instruction *insn)
+static LLVMValueRef calc_memop_addr(struct function *fn, struct instruction *insn)
 {
 	LLVMTypeRef int_type;
-	LLVMValueRef src_p, src_i, ofs_i, addr_i, addr, target;
+	LLVMValueRef src_p, src_i, ofs_i, addr_i, addr;
 
 	/* int type large enough to hold a pointer */
 	int_type = LLVMIntType(bits_in_pointer);
@@ -617,6 +617,16 @@ static void output_op_load(struct function *fn, struct instruction *insn)
 	addr = LLVMBuildIntToPtr(fn->builder, addr_i,
 				 LLVMTypeOf(src_p), "addr");
 
+	return addr;
+}
+
+
+static void output_op_load(struct function *fn, struct instruction *insn)
+{
+	LLVMValueRef addr, target;
+
+	addr = calc_memop_addr(fn, insn);
+
 	/* perform load */
 	target = LLVMBuildLoad(fn->builder, addr, "load_target");
 
@@ -625,22 +635,9 @@ static void output_op_load(struct function *fn, struct instruction *insn)
 
 static void output_op_store(struct function *fn, struct instruction *insn)
 {
-	LLVMTypeRef int_type;
-	LLVMValueRef src_p, src_i, ofs_i, addr_i, addr, target, target_in;
-
-	/* int type large enough to hold a pointer */
-	int_type = LLVMIntType(bits_in_pointer);
-
-	/* convert to integer, add src + offset */
-	src_p = pseudo_to_value(fn, insn, insn->src);
-	src_i = LLVMBuildPtrToInt(fn->builder, src_p, int_type, "src_i");
+	LLVMValueRef addr, target, target_in;
 
-	ofs_i = LLVMConstInt(int_type, insn->offset, 0);
-	addr_i = LLVMBuildAdd(fn->builder, src_i, ofs_i, "addr_i");
-
-	/* convert address back to pointer */
-	addr = LLVMBuildIntToPtr(fn->builder, addr_i,
-				 LLVMTypeOf(src_p), "addr");
+	addr = calc_memop_addr(fn, insn);
 
 	target_in = pseudo_to_value(fn, insn, insn->target);
 
-- 
1.7.10.4

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 2/5] Add support for the MinGW platform ===

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: [PATCH 2/5] Add support for the MinGW platform
Date: Tue, 21 May 2013 19:16:38 +0000
Message-ID: <519BC816.3000304 () ramsay1 ! demon ! co ! uk>
--------------------


Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
---
 cgcc | 13 +++++++++++++
 1 file changed, 13 insertions(+)

diff --git a/cgcc b/cgcc
index c075e5f..e94a965 100755
--- a/cgcc
+++ b/cgcc
@@ -226,6 +226,19 @@ sub add_specs {
 	    ' -D__OpenBSD__=1';
     } elsif ($spec eq 'unix') {
 	return ' -Dunix=1 -D__unix=1 -D__unix__=1';
+    } elsif ($spec =~ /^mingw/) {
+	return ' -isystem /mingw/include' .
+	    ' -D__MINGW32__=1' .
+	    ' -D__MSVCRT__=1' .
+	    ' -DWIN32=1 -D_WIN32=1 -D__WIN32=1 -D__WIN32__=1' .
+	    ' -DWINNT=1 -D__WINNT=1 -D__WINNT__=1' .
+	    " -D'_cdecl=__attribute__((__cdecl__))'" .
+	    " -D'__cdecl=__attribute__((__cdecl__))'" .
+	    " -D'_stdcall=__attribute__((__stdcall__))'" .
+	    " -D'__stdcall=__attribute__((__stdcall__))'" .
+	    " -D'_fastcall=__attribute__((__fastcall__))'" .
+	    " -D'__fastcall=__attribute__((__fastcall__))'" .
+	    " -D'__declspec(x)=__attribute__((x))'";
     } elsif ( $spec =~ /^cygwin/) {
 	return &add_specs ('unix') .
 	    ' -D__CYGWIN__=1 -D__CYGWIN32__=1' .
-- 
1.8.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [PATCH 2/5] Add support for the MinGW platform
Date: Tue, 21 May 2013 22:09:07 +0000
Message-ID: <20130521220907.GE11463 () jtriplet-mobl1>
--------------------
On Tue, May 21, 2013 at 08:16:38PM +0100, Ramsay Jones wrote:
> Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>

I believe this will match both 32-bit and 64-bit MinGW, which seems
wrong.  Please do check the architecture strings for 32-bit and 64-bit
MinGW, and handle them separately.

> ---
>  cgcc | 13 +++++++++++++
>  1 file changed, 13 insertions(+)
> 
> diff --git a/cgcc b/cgcc
> index c075e5f..e94a965 100755
> --- a/cgcc
> +++ b/cgcc
> @@ -226,6 +226,19 @@ sub add_specs {
>  	    ' -D__OpenBSD__=1';
>      } elsif ($spec eq 'unix') {
>  	return ' -Dunix=1 -D__unix=1 -D__unix__=1';
> +    } elsif ($spec =~ /^mingw/) {
> +	return ' -isystem /mingw/include' .
> +	    ' -D__MINGW32__=1' .
> +	    ' -D__MSVCRT__=1' .
> +	    ' -DWIN32=1 -D_WIN32=1 -D__WIN32=1 -D__WIN32__=1' .
> +	    ' -DWINNT=1 -D__WINNT=1 -D__WINNT__=1' .
> +	    " -D'_cdecl=__attribute__((__cdecl__))'" .
> +	    " -D'__cdecl=__attribute__((__cdecl__))'" .
> +	    " -D'_stdcall=__attribute__((__stdcall__))'" .
> +	    " -D'__stdcall=__attribute__((__stdcall__))'" .
> +	    " -D'_fastcall=__attribute__((__fastcall__))'" .
> +	    " -D'__fastcall=__attribute__((__fastcall__))'" .
> +	    " -D'__declspec(x)=__attribute__((x))'";
>      } elsif ( $spec =~ /^cygwin/) {
>  	return &add_specs ('unix') .
>  	    ' -D__CYGWIN__=1 -D__CYGWIN32__=1' .
> -- 
> 1.8.2
> 
> --
> To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
> the body of a message to majordomo@vger.kernel.org
> More majordomo info at  http://vger.kernel.org/majordomo-info.html
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: Re: [PATCH 2/5] Add support for the MinGW platform
Date: Wed, 22 May 2013 22:07:27 +0000
Message-ID: <519D419F.8090000 () ramsay1 ! demon ! co ! uk>
--------------------
Josh Triplett wrote:
> On Tue, May 21, 2013 at 08:16:38PM +0100, Ramsay Jones wrote:
>> Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
> 
> I believe this will match both 32-bit and 64-bit MinGW, which seems
> wrong.  Please do check the architecture strings for 32-bit and 64-bit
> MinGW, and handle them separately.

Yes, given that, for me:

  $ uname -a
  MINGW32_NT-5.1 TOSHIBA 1.0.12(0.46/3/2) 2010-02-05 01:08 i686 unknown
  $

I'm hoping that the following change will be sufficient (I don't have
access to a 64-bit MinGW, so I don't know what 'uname -a' returns, but
I think this will work ... ;-):

  $ git diff
  diff --git a/cgcc b/cgcc
  index e94a965..68f96b9 100755
  --- a/cgcc
  +++ b/cgcc
  @@ -226,7 +226,7 @@ sub add_specs {
              ' -D__OpenBSD__=1';
       } elsif ($spec eq 'unix') {
          return ' -Dunix=1 -D__unix=1 -D__unix__=1';
  -    } elsif ($spec =~ /^mingw/) {
  +    } elsif ($spec =~ /^mingw32/) {
          return ' -isystem /mingw/include' .
              ' -D__MINGW32__=1' .
              ' -D__MSVCRT__=1' .
  $


ATB,
Ramsay Jones


--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: Re: [PATCH 2/5] Add support for the MinGW platform
Date: Sat, 25 May 2013 19:37:31 +0000
Message-ID: <51A112FB.9060101 () ramsay1 ! demon ! co ! uk>
--------------------
Josh Triplett wrote:
> On Wed, May 22, 2013 at 11:07:27PM +0100, Ramsay Jones wrote:
>> Josh Triplett wrote:
>>> On Tue, May 21, 2013 at 08:16:38PM +0100, Ramsay Jones wrote:
>>>> Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
>>>
>>> I believe this will match both 32-bit and 64-bit MinGW, which seems
>>> wrong.  Please do check the architecture strings for 32-bit and 64-bit
>>> MinGW, and handle them separately.
>>
>> Yes, given that, for me:
>>
>>   $ uname -a
>>   MINGW32_NT-5.1 TOSHIBA 1.0.12(0.46/3/2) 2010-02-05 01:08 i686 unknown
>>   $
>>
>> I'm hoping that the following change will be sufficient (I don't have
>> access to a 64-bit MinGW, so I don't know what 'uname -a' returns, but
>> I think this will work ... ;-):
>>
>>   $ git diff
>>   diff --git a/cgcc b/cgcc
>>   index e94a965..68f96b9 100755
>>   --- a/cgcc
>>   +++ b/cgcc
>>   @@ -226,7 +226,7 @@ sub add_specs {
>>               ' -D__OpenBSD__=1';
>>        } elsif ($spec eq 'unix') {
>>           return ' -Dunix=1 -D__unix=1 -D__unix__=1';
>>   -    } elsif ($spec =~ /^mingw/) {
>>   +    } elsif ($spec =~ /^mingw32/) {
> 
> Unfortunately, I don't think that suffices; I've seen a few different
> architecture triples used for 64-bit MinGW, some of which include
> "mingw32".

You are kidding, right?

>              I *think* it might work to match i[3-6]86-.*-mingw.

Is this pattern to be matched against "uname -s"?

Maybe I could match "uname -m" to i?86 *in addition* to the above?

At this point I'm guessing. Again, I don't have access to a 64-bit
MinGW system. Maybe support for 64-bit MinGW should be implemented
by a patch on top of this one (by someone who uses 64-bit MinGW).

ATB,
Ramsay Jones


--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 3/3] Add description for -Winit-cstring option ===

From: Masatake YAMATO <yamato () redhat ! com>
To: linux-sparse
Subject: [PATCH 3/3] Add description for -Winit-cstring option
Date: Sat, 06 Apr 2013 16:58:57 +0000
Message-ID: <1365267537-3787-3-git-send-email-yamato () redhat ! com>
--------------------
This patch added description for -Winit-cstring option
to sparse.1.

Signed-off-by: Masatake YAMATO <yamato@redhat.com>
---
 sparse.1 | 18 ++++++++++++++++++
 1 file changed, 18 insertions(+)

diff --git a/sparse.1 b/sparse.1
index ae85b54..cd6be26 100644
--- a/sparse.1
+++ b/sparse.1
@@ -189,6 +189,24 @@ Sparse issues these warnings by default.  To turn them off, use
 \fB\-Wno\-enum\-mismatch\fR.
 .
 .TP
+.B \-Winit\-cstring
+Warn about initialization of a char array with a too long constant C string.
+
+If the size of the char array and the length of the string is the same,
+there is no space for the last nul char of the string in the array:
+
+.nf
+char s[3] = "abc";
+.fi
+
+If the array is used as a byte array, not as C string, this
+warning is just noise. However, if the array is passed to functions
+dealing with C string like printf(%s) and strcmp, it may cause a
+trouble.
+
+Sparse does not issue these warnings by default.
+.
+.TP
 .B \-Wnon\-pointer\-null
 Warn about the use of 0 as a NULL pointer.
 
-- 
1.7.11.7

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 3/3] symbol.c: Set correct size of array from parenthesized string initializer ===

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: [PATCH 3/3] symbol.c: Set correct size of array from parenthesized string initializer
Date: Thu, 16 May 2013 19:44:11 +0000
Message-ID: <5195370B.9080702 () ramsay1 ! demon ! co ! uk>
--------------------


Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
---
 symbol.c                      | 10 ++++++++++
 validation/init-char-array1.c | 25 +++++++++++++++++++++++++
 2 files changed, 35 insertions(+)
 create mode 100644 validation/init-char-array1.c

diff --git a/symbol.c b/symbol.c
index 80a2f23..051a909 100644
--- a/symbol.c
+++ b/symbol.c
@@ -284,6 +284,15 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 	if (t->ctype.base_type == &int_type && t->ctype.modifiers & MOD_CHAR)
 		is_char = 1;
 
+	/* check for a parenthesized string: char x[] = ("string"); */
+	if (is_char && expr->type == EXPR_PREOP && expr->op == '(') {
+		struct expression *e = expr;
+		while (e && e->type == EXPR_PREOP && e->op == '(')
+			e = e->unop;
+		if (e && e->type == EXPR_STRING)
+			expr = e;
+	}
+
 	switch (expr->type) {
 	case EXPR_INITIALIZER: {
 		struct expression *entry;
@@ -310,6 +319,7 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 	case EXPR_STRING:
 		if (is_char)
 			nr = expr->string->length;
+		break;
 	default:
 		break;
 	}
diff --git a/validation/init-char-array1.c b/validation/init-char-array1.c
new file mode 100644
index 0000000..7427702
--- /dev/null
+++ b/validation/init-char-array1.c
@@ -0,0 +1,25 @@
+/*
+ * for array of char, ("...") as the initializer is an gcc language
+ * extension. check that a parenthesized string initializer is handled
+ * correctly and that -Wparen-string warns about it's use.
+ */
+static const char u[] = ("hello");
+static const char v[] = {"hello"};
+static const char w[] = "hello";
+static const char x[5] = "hello";
+
+static void f(void)
+{
+	char a[1/(sizeof(u) == 6)];
+	char b[1/(sizeof(v) == 6)];
+	char c[1/(sizeof(w) == 6)];
+	char d[1/(sizeof(x) == 5)];
+}
+/*
+ * check-name: parenthesized string initializer
+ * check-command: sparse -Wparen-string $file
+ *
+ * check-error-start
+init-char-array1.c:6:26: warning: array initialized from parenthesized string constant
+ * check-error-end
+ */
-- 
1.8.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Chris Li <christ.li () gmail ! com>
To: linux-sparse
Subject: Re: [PATCH 3/3] symbol.c: Set correct size of array from parenthesized string initializer
Date: Sat, 18 May 2013 08:14:54 +0000
Message-ID: <5197387E.5030000 () gmail ! com>
--------------------
This is a multi-part message in MIME format.
--------------060305040804000206000800
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On 05/18/2013 12:38 AM, Christopher Li wrote:
> I guess the rules is that parenthesized string can appear in
> any place where string was allowed.


I create an incremental patch to address the issue. Please
check if that works for you.

Chris


--------------060305040804000206000800
Content-Type: text/x-patch;
 name="parenthesed-string-improve.patch"
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment;
 filename="parenthesed-string-improve.patch"

diff --git a/symbol.c b/symbol.c
index 051a909..a59a4ca 100644
--- a/symbol.c
+++ b/symbol.c
@@ -284,15 +284,6 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 	if (t->ctype.base_type == &int_type && t->ctype.modifiers & MOD_CHAR)
 		is_char = 1;
 
-	/* check for a parenthesized string: char x[] = ("string"); */
-	if (is_char && expr->type == EXPR_PREOP && expr->op == '(') {
-		struct expression *e = expr;
-		while (e && e->type == EXPR_PREOP && e->op == '(')
-			e = e->unop;
-		if (e && e->type == EXPR_STRING)
-			expr = e;
-	}
-
 	switch (expr->type) {
 	case EXPR_INITIALIZER: {
 		struct expression *entry;
@@ -305,6 +296,15 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 				if (entry->idx_to >= nr)
 					nr = entry->idx_to+1;
 				break;
+			case EXPR_PREOP: {
+				struct expression *e = entry;
+				while (e && e->type == EXPR_PREOP && e->op == '(')
+					e = e->unop;
+				if (!(e && e->type == EXPR_STRING))
+					break;
+				entry = e;
+				/* fall through to strings. */
+			}
 			case EXPR_STRING:
 				if (is_char)
 					str_len = entry->string->length;
@@ -316,6 +316,15 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 			nr = str_len;
 		break;
 	}
+	case EXPR_PREOP: {
+		struct expression *e = expr;
+		while (e && e->type == EXPR_PREOP && e->op == '(')
+			e = e->unop;
+		if (!(e && e->type == EXPR_STRING))
+			break;
+		expr = e;
+		/* fall through to strings. */
+	}
 	case EXPR_STRING:
 		if (is_char)
 			nr = expr->string->length;
diff --git a/validation/init-char-array1.c b/validation/init-char-array1.c
index 7427702..24fd8d8 100644
--- a/validation/init-char-array1.c
+++ b/validation/init-char-array1.c
@@ -5,6 +5,7 @@
  */
 static const char u[] = ("hello");
 static const char v[] = {"hello"};
+static const char v1[] = {("hello")};
 static const char w[] = "hello";
 static const char x[5] = "hello";
 
@@ -21,5 +22,6 @@ static void f(void)
  *
  * check-error-start
 init-char-array1.c:6:26: warning: array initialized from parenthesized string constant
+init-char-array1.c:8:28: warning: array initialized from parenthesized string constant
  * check-error-end
  */

--------------060305040804000206000800--
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: Re: [PATCH 3/3] symbol.c: Set correct size of array from parenthesized string initializer
Date: Mon, 20 May 2013 18:37:14 +0000
Message-ID: <519A6D5A.8030808 () ramsay1 ! demon ! co ! uk>
--------------------
Christopher Li wrote:
> On 05/16/2013 12:44 PM, Ramsay Jones wrote:
> 
>> diff --git a/validation/init-char-array1.c b/validation/init-char-array1.c
>> new file mode 100644
>> index 0000000..7427702
>> --- /dev/null
>> +++ b/validation/init-char-array1.c
>> @@ -0,0 +1,25 @@
>> +/*
>> + * for array of char, ("...") as the initializer is an gcc language
>> + * extension. check that a parenthesized string initializer is handled
>> + * correctly and that -Wparen-string warns about it's use.
>> + */
>> +static const char u[] = ("hello");
>> +static const char v[] = {"hello"};
>> +static const char w[] = "hello";
>> +static const char x[5] = "hello";
> 
> That seems not complete. I haven't found the official gcc rules
> about parenthesized string. I just try the following forms and
> gcc takes it.
> 
> char x1[] = { ("hello") };
> char x2[] = { (("hello")) };
> 
> I guess the rules is that parenthesized string can appear in
> any place where string was allowed.

Until i18n work started on git, I didn't know this was a gcc
extension at all! ;-) I looked at the gcc documentation available
to me at the time, and could not find it mentioned at all, let
alone as a gcc language extension. However, if it wasn't for the
-Wparen-string sparse warning, I wouldn't have suspected that
sparse was supposed to support it.

Also, I was slightly surprised that MSVC supported this syntax.
So, I looked at fixing sparse and came up with my patch. I then
found that tcc didn't support this syntax, which is not standard
C after all, so I submitted a patch to fix the git gettext 'N_'
macro which was the cause of the problem.

ATB,
Ramsay Jones



--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: Re: [PATCH 3/3] symbol.c: Set correct size of array from parenthesized string initializer
Date: Mon, 20 May 2013 18:42:53 +0000
Message-ID: <519A6EAD.8070700 () ramsay1 ! demon ! co ! uk>
--------------------
Chris Li wrote:
> On 05/18/2013 12:38 AM, Christopher Li wrote:
>> I guess the rules is that parenthesized string can appear in
>> any place where string was allowed.
> 
> 
> I create an incremental patch to address the issue. Please
> check if that works for you.

Unfortunately not. :(

In my git repo, I just happen to be on the pu branch:

  $ pwd
  /home/ramsay/git
  $ git describe
  v1.8.3-rc3-347-gac05152
  $ 

Using an older version of sparse (I don't know exactly which version;
although I have had a patch to add --version for some years, I wasn't
actually using a version with it applied!).

  $ make sparse >psp-out0 2>&1
  $ grep warning psp-out0 | wc -l
  7
  $ grep error psp-out0 | wc -l
  0
  $ 

Note that the severn warnings all relate to the glibc headers using
an transparent union for the various sockaddr types, for example:

      SP connect.c
  connect.c:272:40: warning: incorrect type in argument 2 (invalid types)
  connect.c:272:40:    expected union __CONST_SOCKADDR_ARG [usertype] __addr
  connect.c:272:40:    got struct sockaddr *ai_addr

Installing a new version of sparse:

  $ sparse --version
  v0.4.5-rc1
  $ make sparse >psp-out1 2>&1
  $ grep warning psp-out1 | wc -l
  9
  $ grep error psp-out1 | wc -l
  1
  $ diff psp-out0 psp-out1
  77a78
  > notes-merge.c:111:9: warning: too long initializer-string for array of char
  111a113
  > sha1_file.c:54:9: warning: too long initializer-string for array of char
  152a155
  > compat/regex/regex_internal.c:926:1: error: symbol 're_string_context_at' redeclared with different type (originally declared at compat/regex/regex_internal.h:434) - different modifiers
  $ 

Note that the two new warnings are fixed by my first patch and the
error is the second regression that I mentioned.

So, now introduce an "parenthesized string initializer", thus:

  $ vim gettext.h
  $ git diff
  diff --git a/gettext.h b/gettext.h
  index 7671d09..d11a413 100644
  --- a/gettext.h
  +++ b/gettext.h
  @@ -63,6 +63,6 @@ const char *Q_(const char *msgid, const char *plu, unsigned lo
   }
   
   /* Mark msgid for translation but do not translate it. */
  -#define N_(msgid) msgid
  +#define N_(msgid) (msgid)
   
   #endif
  $ make sparse >psp-out2 2>&1
  $ grep warning psp-out2 | wc -l
  31
  $ grep error psp-out2 | wc -l
  2
  $ 

The new warnings all look like this:

  $ grep warning psp-out2 | head -3
  branch.c:216:1: warning: too long initializer-string for array of char
  branch.c:218:1: warning: too long initializer-string for array of char
  branch.c:220:1: warning: too long initializer-string for array of char
  $ 

The additional error is a simple syntax error:

  $ rm builtin/log.o
  $ make builtin/log.o
      CC builtin/log.o
  builtin/log.c:42: error: called object "git log [<options>] [<revision range>] [[--] <path>...]\012" is not a function
  make: *** [builtin/log.o] Error 1
  $ make builtin/log.sp
      SP builtin/log.c
  builtin/log.c:42:9: error: not a function <noident>
  $ 

Now install a version of sparse with my three patches applied:

  $ sparse --version
  v0.4.5-rc1-3-g14eceaa
  $ make sparse >psp-out3 2>&1
  $ grep warning psp-out3 | wc -l
  7
  $ grep error psp-out3 | wc -l
  2
  $ 

So, all of the additional "too long initializer-string" warnings
are no longer issued.

Now add your additional patch on top:

  $ sparse --version
  v0.4.5-rc1-4-g5ef4e35
  $ make sparse >psp-out4 2>&1
  $ grep warning psp-out4 | wc -l
  177
  $ grep error psp-out4 | wc -l
  2
  $ 

All of the additional warnings, look like:

  $ grep warning psp-out4 | head -3
  archive.c:14:9: warning: excessive elements in array initializer
  archive.c:221:39: warning: excessive elements in array initializer
  attr.c:327:9: warning: excessive elements in array initializer
  $ 

Note that the warnings don't all involve the use of the gettext
'N_' macro. Also, many (I haven't checked them all) are actually
arrays of 'char *' (_not_ array of char). For example, from the
above list, archive.c:221 looks like this:

        const char *paths[] = { path, NULL };

HTH

ATB,
Ramsay Jones




--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Chris Li <christ.li () gmail ! com>
To: linux-sparse
Subject: Re: [PATCH 3/3] symbol.c: Set correct size of array from parenthesized string initializer
Date: Thu, 23 May 2013 15:28:02 +0000
Message-ID: <519E3582.7060704 () gmail ! com>
--------------------
This is a multi-part message in MIME format.
--------------050800080209080905070203
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: 7bit

On 05/20/2013 11:42 AM, Ramsay Jones wrote:

> Unfortunately not. :(

Sorry about that.

>         const char *paths[] = { path, NULL };

I see where I make the mistake. I need to drop the parentheses
only for char type. Can you please try this patch again? It is a
replacement patch of your patch No3. Not a delta. It works for the
the test case above.

Let's hope this one works.

Chris


--------------050800080209080905070203
Content-Type: text/x-patch;
 name="0001-symbol.c-Set-correct-size-of-array-from-parenthesize.patch"
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment;
 filename*0="0001-symbol.c-Set-correct-size-of-array-from-parenthesize.pa";
 filename*1="tch"


================================================================================

From: Chris Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH 3/3] symbol.c: Set correct size of array from parenthesized string initializer
Date: Wed, 29 May 2013 10:02:09 +0000
Message-ID: <20130529100207.GA3005 () gmail ! com>
--------------------
On Sat, May 25, 2013 at 09:01:30PM +0100, Ramsay Jones wrote:
> Yes, this patch works.
> 
> However, it made me go cross-eyed trying to follow the flow of
> control. So, I created a new patch, added after the scissor mark
> below, which hopefully makes the flow of control easier to follow.

As my patch, you should just read the "case EXPR_STRING" as a label,
that is easier to understand.

Unfortunately I think your patch is not doing the same thing as mine,
control flow wise. Please see the later comment on your code.

> Also, note that I changed the test to add a check for the length
> of the v1 array. Having said that, I had intended to rename the
> variables in the test to u->y and a->e (this is a new test, after
> all), but I forgot! sorry about that.

Can you submit a separate delta  for the test part of the change?
I can smash the patch on top your original one.

> +static struct expression *paren_string(struct expression *expr)

Paren sounds very much like "parent". I would make the function name
"parenthesized_string" or "extract_parenthesized_string".


>  
> +	/* check for a parenthesized string: char x[] = ("string"); */
> +	if (is_char && (p = paren_string(expr)))
> +		expr = p;
> +

I want to move this test to inside the switch statement.
The parenthesized string is a very rare case. Adding the test
here make the common case pay a price.


>  	switch (expr->type) {
>  	case EXPR_INITIALIZER: {
>  		struct expression *entry;
> @@ -296,6 +313,10 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
>  				if (entry->idx_to >= nr)
>  					nr = entry->idx_to+1;
>  				break;
> +			case EXPR_PREOP:
> +				/* check for char x[] = {("string")}; */
> +				if (is_char && (p = paren_string(entry)))
> +					entry = p;
>  			case EXPR_STRING:
>  				if (is_char)
>  					str_len = entry->string->length;

OK, here is the subtle bug. Consider the case expr->type ==  EXPR_PREOP
and is_char == 1 and paren_string(entry) return false.

Before apply your patch, it will go to default case.
Now after your patch, it will go to execute "str_len =
entry->string->length", even entry expression is not a string.

So your patch is doing some thing not intended. In order to correct
that, you can't always allow EXPR_PREOP case fall through to
EXPR_STRING. It need to depend on the test condition paren_string()
return true or not.

You can add goto statement to the switch statement to fix that.
It will make the control flow hard to read as well.

If you have better way to write it I am open to it.

Chris



--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: Re: [PATCH 3/3] symbol.c: Set correct size of array from parenthesized string initializer
Date: Sat, 01 Jun 2013 17:42:39 +0000
Message-ID: <51AA328F.3040603 () ramsay1 ! demon ! co ! uk>
--------------------
Chris Li wrote:
> On Sat, May 25, 2013 at 09:01:30PM +0100, Ramsay Jones wrote:
>> +static struct expression *paren_string(struct expression *expr)
> 
> Paren sounds very much like "parent". I would make the function name
> "parenthesized_string" or "extract_parenthesized_string".

OK, see below.

> 
>>  
>> +	/* check for a parenthesized string: char x[] = ("string"); */
>> +	if (is_char && (p = paren_string(expr)))
>> +		expr = p;
>> +
> 
> I want to move this test to inside the switch statement.
> The parenthesized string is a very rare case. Adding the test
> here make the common case pay a price.

OK

> 
>>  	switch (expr->type) {
>>  	case EXPR_INITIALIZER: {
>>  		struct expression *entry;
>> @@ -296,6 +313,10 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
>>  				if (entry->idx_to >= nr)
>>  					nr = entry->idx_to+1;
>>  				break;
>> +			case EXPR_PREOP:
>> +				/* check for char x[] = {("string")}; */
>> +				if (is_char && (p = paren_string(entry)))
>> +					entry = p;
>>  			case EXPR_STRING:
>>  				if (is_char)
>>  					str_len = entry->string->length;
> 
> OK, here is the subtle bug. Consider the case expr->type ==  EXPR_PREOP
> and is_char == 1 and paren_string(entry) return false.

Heh, indeed.

> 
> If you have better way to write it I am open to it.
> 

Well, I don't know that it's better; but the following patch (with or
without the diff applied) *reads* better to me. :-D

Note that the patch given below, after the scissors mark, keeps the
"fall through" into the string case, but I actually prefer not to do
so, and would add this (at least) on top:

  diff --git a/symbol.c b/symbol.c
  index 4e7b6e2..06e9596 100644
  --- a/symbol.c
  +++ b/symbol.c
  @@ -312,12 +312,12 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
   			case EXPR_PREOP:
   				/* check for: char x[] = {("string")}; */
   				p = parenthesized_string(entry);
  -				if (!(is_char && p)) {
  -					nr++;
  -					break;
  +				if (is_char && p) {
  +					entry = p;
  +					str_len = entry->string->length;
   				}
  -				entry = p;
  -				/* fall through to string */
  +				nr++;
  +				break;
   			case EXPR_STRING:
   				if (is_char)
   					str_len = entry->string->length;
  @@ -332,10 +332,11 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
   	case EXPR_PREOP:
   		/* check for parenthesized string: char x[] = ("string"); */
   		p = parenthesized_string(expr);
  -		if (!(is_char && p))
  -			break;
  -		expr = p;
  -		/* fall through to string */
  +		if (is_char && p) {
  +			expr = p;
  +			nr = expr->string->length;
  +		}
  +		break;
   	case EXPR_STRING:
   		if (is_char)
   			nr = expr->string->length;
  
Actually, I've just noticed that the last hunk above can be simplified
even further (there is no need to assign p to expr, just use p directly
in the assignment to nr).

[I would also consider making the string case self contained and not
falling through to the default case; i.e. add the "nr++;" and "break;"
statements.]

I have tested the patch below as-is, *and* with the above squashed in, on
Linux, cygwin and MinGW. Note, also, that the test has been fixed up.

Anyway, I will leave to choice of solution to you. ;-)

HTH

ATB,
Ramsay Jones


-- >8 --
From: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
Date: Thu, 16 May 2013 20:44:11 +0100
Subject: [PATCH] symbol.c: Set correct size of array from parenthesized string initializer

Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
Signed-off-by: Christopher Li <sparse@chrisli.org>
---
 symbol.c                      | 30 ++++++++++++++++++++++++++++++
 validation/init-char-array1.c | 28 ++++++++++++++++++++++++++++
 2 files changed, 58 insertions(+)
 create mode 100644 validation/init-char-array1.c

diff --git a/symbol.c b/symbol.c
index 80a2f23..4e7b6e2 100644
--- a/symbol.c
+++ b/symbol.c
@@ -269,8 +269,21 @@ void merge_type(struct symbol *sym, struct symbol *base_type)
 		merge_type(sym, sym->ctype.base_type);
 }
 
+static struct expression *parenthesized_string(struct expression *expr)
+{
+	if (expr && expr->type == EXPR_PREOP && expr->op == '(') {
+		struct expression *e = expr;
+		while (e && e->type == EXPR_PREOP && e->op == '(')
+			e = e->unop;
+		if (e && e->type == EXPR_STRING)
+			return e;
+	}
+	return NULL;
+}
+
 static int count_array_initializer(struct symbol *t, struct expression *expr)
 {
+	struct expression *p;
 	int nr = 0;
 	int is_char = 0;
 
@@ -296,6 +309,15 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 				if (entry->idx_to >= nr)
 					nr = entry->idx_to+1;
 				break;
+			case EXPR_PREOP:
+				/* check for: char x[] = {("string")}; */
+				p = parenthesized_string(entry);
+				if (!(is_char && p)) {
+					nr++;
+					break;
+				}
+				entry = p;
+				/* fall through to string */
 			case EXPR_STRING:
 				if (is_char)
 					str_len = entry->string->length;
@@ -307,9 +329,17 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 			nr = str_len;
 		break;
 	}
+	case EXPR_PREOP:
+		/* check for parenthesized string: char x[] = ("string"); */
+		p = parenthesized_string(expr);
+		if (!(is_char && p))
+			break;
+		expr = p;
+		/* fall through to string */
 	case EXPR_STRING:
 		if (is_char)
 			nr = expr->string->length;
+		break;
 	default:
 		break;
 	}
diff --git a/validation/init-char-array1.c b/validation/init-char-array1.c
new file mode 100644
index 0000000..923741f
--- /dev/null
+++ b/validation/init-char-array1.c
@@ -0,0 +1,28 @@
+/*
+ * for array of char, ("...") as the initializer is an gcc language
+ * extension. check that a parenthesized string initializer is handled
+ * correctly and that -Wparen-string warns about it's use.
+ */
+static const char u[] = ("hello");
+static const char v[] = {"hello"};
+static const char w[] = {("hello")};
+static const char x[] = "hello";
+static const char y[5] = "hello";
+
+static void f(void)
+{
+	char a[1/(sizeof(u) == 6)];
+	char b[1/(sizeof(v) == 6)];
+	char c[1/(sizeof(w) == 6)];
+	char d[1/(sizeof(x) == 6)];
+	char e[1/(sizeof(y) == 5)];
+}
+/*
+ * check-name: parenthesized string initializer
+ * check-command: sparse -Wparen-string $file
+ *
+ * check-error-start
+init-char-array1.c:6:26: warning: array initialized from parenthesized string constant
+init-char-array1.c:8:27: warning: array initialized from parenthesized string constant
+ * check-error-end
+ */
-- 
1.8.3



--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: Re: [PATCH 3/3] symbol.c: Set correct size of array from parenthesized string initializer
Date: Sat, 01 Jun 2013 17:42:39 +0000
Message-ID: <51AA328F.3040603 () ramsay1 ! demon ! co ! uk>
--------------------
Chris Li wrote:
> On Sat, May 25, 2013 at 09:01:30PM +0100, Ramsay Jones wrote:
>> +static struct expression *paren_string(struct expression *expr)
> 
> Paren sounds very much like "parent". I would make the function name
> "parenthesized_string" or "extract_parenthesized_string".

OK, see below.

> 
>>  
>> +	/* check for a parenthesized string: char x[] = ("string"); */
>> +	if (is_char && (p = paren_string(expr)))
>> +		expr = p;
>> +
> 
> I want to move this test to inside the switch statement.
> The parenthesized string is a very rare case. Adding the test
> here make the common case pay a price.

OK

> 
>>  	switch (expr->type) {
>>  	case EXPR_INITIALIZER: {
>>  		struct expression *entry;
>> @@ -296,6 +313,10 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
>>  				if (entry->idx_to >= nr)
>>  					nr = entry->idx_to+1;
>>  				break;
>> +			case EXPR_PREOP:
>> +				/* check for char x[] = {("string")}; */
>> +				if (is_char && (p = paren_string(entry)))
>> +					entry = p;
>>  			case EXPR_STRING:
>>  				if (is_char)
>>  					str_len = entry->string->length;
> 
> OK, here is the subtle bug. Consider the case expr->type ==  EXPR_PREOP
> and is_char == 1 and paren_string(entry) return false.

Heh, indeed.

> 
> If you have better way to write it I am open to it.
> 

Well, I don't know that it's better; but the following patch (with or
without the diff applied) *reads* better to me. :-D

Note that the patch given below, after the scissors mark, keeps the
"fall through" into the string case, but I actually prefer not to do
so, and would add this (at least) on top:

  diff --git a/symbol.c b/symbol.c
  index 4e7b6e2..06e9596 100644
  --- a/symbol.c
  +++ b/symbol.c
  @@ -312,12 +312,12 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
   			case EXPR_PREOP:
   				/* check for: char x[] = {("string")}; */
   				p = parenthesized_string(entry);
  -				if (!(is_char && p)) {
  -					nr++;
  -					break;
  +				if (is_char && p) {
  +					entry = p;
  +					str_len = entry->string->length;
   				}
  -				entry = p;
  -				/* fall through to string */
  +				nr++;
  +				break;
   			case EXPR_STRING:
   				if (is_char)
   					str_len = entry->string->length;
  @@ -332,10 +332,11 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
   	case EXPR_PREOP:
   		/* check for parenthesized string: char x[] = ("string"); */
   		p = parenthesized_string(expr);
  -		if (!(is_char && p))
  -			break;
  -		expr = p;
  -		/* fall through to string */
  +		if (is_char && p) {
  +			expr = p;
  +			nr = expr->string->length;
  +		}
  +		break;
   	case EXPR_STRING:
   		if (is_char)
   			nr = expr->string->length;
  
Actually, I've just noticed that the last hunk above can be simplified
even further (there is no need to assign p to expr, just use p directly
in the assignment to nr).

[I would also consider making the string case self contained and not
falling through to the default case; i.e. add the "nr++;" and "break;"
statements.]

I have tested the patch below as-is, *and* with the above squashed in, on
Linux, cygwin and MinGW. Note, also, that the test has been fixed up.

Anyway, I will leave to choice of solution to you. ;-)

HTH

ATB,
Ramsay Jones


-- >8 --
From: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
Date: Thu, 16 May 2013 20:44:11 +0100
Subject: [PATCH] symbol.c: Set correct size of array from parenthesized string initializer

Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
Signed-off-by: Christopher Li <sparse@chrisli.org>
---
 symbol.c                      | 30 ++++++++++++++++++++++++++++++
 validation/init-char-array1.c | 28 ++++++++++++++++++++++++++++
 2 files changed, 58 insertions(+)
 create mode 100644 validation/init-char-array1.c

diff --git a/symbol.c b/symbol.c
index 80a2f23..4e7b6e2 100644
--- a/symbol.c
+++ b/symbol.c
@@ -269,8 +269,21 @@ void merge_type(struct symbol *sym, struct symbol *base_type)
 		merge_type(sym, sym->ctype.base_type);
 }
 
+static struct expression *parenthesized_string(struct expression *expr)
+{
+	if (expr && expr->type == EXPR_PREOP && expr->op == '(') {
+		struct expression *e = expr;
+		while (e && e->type == EXPR_PREOP && e->op == '(')
+			e = e->unop;
+		if (e && e->type == EXPR_STRING)
+			return e;
+	}
+	return NULL;
+}
+
 static int count_array_initializer(struct symbol *t, struct expression *expr)
 {
+	struct expression *p;
 	int nr = 0;
 	int is_char = 0;
 
@@ -296,6 +309,15 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 				if (entry->idx_to >= nr)
 					nr = entry->idx_to+1;
 				break;
+			case EXPR_PREOP:
+				/* check for: char x[] = {("string")}; */
+				p = parenthesized_string(entry);
+				if (!(is_char && p)) {
+					nr++;
+					break;
+				}
+				entry = p;
+				/* fall through to string */
 			case EXPR_STRING:
 				if (is_char)
 					str_len = entry->string->length;
@@ -307,9 +329,17 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 			nr = str_len;
 		break;
 	}
+	case EXPR_PREOP:
+		/* check for parenthesized string: char x[] = ("string"); */
+		p = parenthesized_string(expr);
+		if (!(is_char && p))
+			break;
+		expr = p;
+		/* fall through to string */
 	case EXPR_STRING:
 		if (is_char)
 			nr = expr->string->length;
+		break;
 	default:
 		break;
 	}
diff --git a/validation/init-char-array1.c b/validation/init-char-array1.c
new file mode 100644
index 0000000..923741f
--- /dev/null
+++ b/validation/init-char-array1.c
@@ -0,0 +1,28 @@
+/*
+ * for array of char, ("...") as the initializer is an gcc language
+ * extension. check that a parenthesized string initializer is handled
+ * correctly and that -Wparen-string warns about it's use.
+ */
+static const char u[] = ("hello");
+static const char v[] = {"hello"};
+static const char w[] = {("hello")};
+static const char x[] = "hello";
+static const char y[5] = "hello";
+
+static void f(void)
+{
+	char a[1/(sizeof(u) == 6)];
+	char b[1/(sizeof(v) == 6)];
+	char c[1/(sizeof(w) == 6)];
+	char d[1/(sizeof(x) == 6)];
+	char e[1/(sizeof(y) == 5)];
+}
+/*
+ * check-name: parenthesized string initializer
+ * check-command: sparse -Wparen-string $file
+ *
+ * check-error-start
+init-char-array1.c:6:26: warning: array initialized from parenthesized string constant
+init-char-array1.c:8:27: warning: array initialized from parenthesized string constant
+ * check-error-end
+ */
-- 
1.8.3



--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 3/4] sparse, llvm: base load/store address type on insn_symbol_type() ===

From: =?UTF-8?q?Jonathan=20Neusch=C3=A4fer?= <j.neuschaefer () gmx ! net>
To: linux-sparse
Subject: [PATCH 3/4] sparse, llvm: base load/store address type on insn_symbol_type()
Date: Sat, 18 May 2013 17:52:06 +0000
Message-ID: <1368899527-2350-3-git-send-email-j.neuschaefer () gmx ! net>
--------------------
LLVM needs to be correctly told about the type of the object
being accessed.

This patch also fixes code generation for struct accesses.

Cc: Pekka Enberg <penberg@kernel.org>
Cc: Christopher Li <sparse@chrisli.org>
Cc: Jeff Garzik <jgarzik@redhat.com>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Cc: Xi Wang <xi.wang@gmail.com>
Signed-off-by: Jonathan NeuschÃ¤fer <j.neuschaefer@gmx.net>
---
 sparse-llvm.c |    7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/sparse-llvm.c b/sparse-llvm.c
index 8573eda..a8ebeab 100644
--- a/sparse-llvm.c
+++ b/sparse-llvm.c
@@ -600,7 +600,7 @@ static void output_op_ret(struct function *fn, struct instruction *insn)
 
 static LLVMValueRef calc_memop_addr(struct function *fn, struct instruction *insn)
 {
-	LLVMTypeRef int_type;
+	LLVMTypeRef int_type, addr_type;
 	LLVMValueRef src_p, src_i, ofs_i, addr_i, addr;
 
 	/* int type large enough to hold a pointer */
@@ -613,9 +613,10 @@ static LLVMValueRef calc_memop_addr(struct function *fn, struct instruction *ins
 	ofs_i = LLVMConstInt(int_type, insn->offset, 0);
 	addr_i = LLVMBuildAdd(fn->builder, src_i, ofs_i, "addr_i");
 
+	addr_type = LLVMPointerType(insn_symbol_type(fn->module, insn), 0);
+
 	/* convert address back to pointer */
-	addr = LLVMBuildIntToPtr(fn->builder, addr_i,
-				 LLVMTypeOf(src_p), "addr");
+	addr = LLVMBuildIntToPtr(fn->builder, addr_i, addr_type, "addr");
 
 	return addr;
 }
-- 
1.7.10.4

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Jonathan =?utf-8?Q?Neusch=C3=A4fer?= <j.neuschaefer () gmx ! net>
To: linux-sparse
Subject: Re: [PATCH 3/4] sparse, llvm: base load/store address type on insn_symbol_type()
Date: Sun, 19 May 2013 00:17:43 +0000
Message-ID: <20130519001743.GF3154 () debian ! debian>
--------------------
On Sat, May 18, 2013 at 06:45:18PM -0400, Xi Wang wrote:
> On 05/18/2013 01:52 PM, Jonathan NeuschÃ¤fer wrote:
> >   	/* convert address back to pointer */
> > -	addr = LLVMBuildIntToPtr(fn->builder, addr_i,
> > -				 LLVMTypeOf(src_p), "addr");
> > +	addr = LLVMBuildIntToPtr(fn->builder, addr_i, addr_type, "addr");
> 
> Actually, we shouldn't convert pointers to integers in the first place.
> This effectively disables pointer analysis and future optimizations.
> 
> A better way is to use LLVM's GEP for pointer arithmetic, by converting
> pointers to `char *', rather than integers.
> 
> See more examples here:
> http://www.spinics.net/lists/linux-sparse/msg02768.html
> 
> Jonathan, how about this version using `char *' based on your patchset?

It looks good. ACK.

> +	LLVMTypeRef type = LLVMTypeOf(base);
> +	unsigned int as = LLVMGetPointerAddressSpace(type);

Right, I was sloppy about address spaces. :-)


Thanks,
Jonathan
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 3/5] Fix some "unknown format" warnings ===

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: [PATCH 3/5] Fix some "unknown format" warnings
Date: Tue, 21 May 2013 19:17:37 +0000
Message-ID: <519BC851.5090202 () ramsay1 ! demon ! co ! uk>
--------------------

Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
---
 compile-i386.c |  7 ++++---
 example.c      |  7 ++++---
 expand.c       |  5 +++--
 linearize.c    | 15 ++++++++++-----
 parse.c        |  3 ++-
 pre-process.c  |  7 ++++++-
 show-parse.c   | 15 ++++++++++-----
 sparse.c       |  3 ++-
 tokenize.c     |  4 ++--
 9 files changed, 43 insertions(+), 23 deletions(-)

diff --git a/compile-i386.c b/compile-i386.c
index b470952..8ac43d8 100644
--- a/compile-i386.c
+++ b/compile-i386.c
@@ -30,6 +30,7 @@
 #include <unistd.h>
 #include <fcntl.h>
 #include <assert.h>
+#include <inttypes.h>
 
 #include "lib.h"
 #include "allocate.h"
@@ -435,7 +436,7 @@ static const char *stor_op_name(struct storage *s)
 		strcpy(name, s->reg->name);
 		break;
 	case STOR_VALUE:
-		sprintf(name, "$%Ld", s->value);
+		sprintf(name, "$%"PRId64, s->value);
 		break;
 	case STOR_LABEL:
 		sprintf(name, "%s.L%d", s->flags & STOR_LABEL_VAL ? "$" : "",
@@ -920,7 +921,7 @@ static void emit_scalar(struct expression *expr, unsigned int bit_size)
 
 	assert(type != NULL);
 
-	printf("\t.%s\t%Ld\n", type, ll);
+	printf("\t.%s\t%"PRId64"\n", type, ll);
 }
 
 static void emit_global_noinit(const char *name, unsigned long modifiers,
@@ -2222,7 +2223,7 @@ static struct storage *x86_symbol_expr(struct symbol *sym)
 		return new;
 	}
 	if (sym->ctype.modifiers & MOD_ADDRESSABLE) {
-		printf("\taddi.%d\t\tv%d,vFP,$%lld\n", bits_in_pointer, new->pseudo, sym->value);
+		printf("\taddi.%d\t\tv%d,vFP,$%"PRId64"\n", bits_in_pointer, new->pseudo, sym->value);
 		return new;
 	}
 	printf("\taddi.%d\t\tv%d,vFP,$offsetof(%s:%p)\n", bits_in_pointer, new->pseudo, show_ident(sym->ident), sym);
diff --git a/example.c b/example.c
index 24444c6..db768e4 100644
--- a/example.c
+++ b/example.c
@@ -6,6 +6,7 @@
 #include <stdarg.h>
 #include <string.h>
 #include <assert.h>
+#include <inttypes.h>
 
 #include "symbol.h"
 #include "expression.h"
@@ -187,7 +188,7 @@ static const char *show_op(struct bb_state *state, struct operand *op)
 	case OP_REG:
 		return op->reg->name;
 	case OP_VAL:
-		sprintf(p, "$%lld", op->value);
+		sprintf(p, "$%"PRId64, op->value);
 		break;
 	case OP_MEM:
 	case OP_ADDR:
@@ -597,7 +598,7 @@ static struct hardreg *fill_reg(struct bb_state *state, struct hardreg *hardreg,
 
 	switch (pseudo->type) {
 	case PSEUDO_VAL:
-		output_insn(state, "movl $%lld,%s", pseudo->value, hardreg->name);
+		output_insn(state, "movl $%"PRId64",%s", pseudo->value, hardreg->name);
 		break;
 	case PSEUDO_SYM:
 		src = find_pseudo_storage(state, pseudo, NULL);
@@ -1050,7 +1051,7 @@ static void generate_cast(struct bb_state *state, struct instruction *insn)
 		unsigned long long mask;
 		mask = ~(~0ULL << old);
 		mask &= ~(~0ULL << new);
-		output_insn(state, "andl.%d $%#llx,%s", insn->size, mask, dst->name);
+		output_insn(state, "andl.%d $%#"PRIx64",%s", insn->size, mask, dst->name);
 	}
 	add_pseudo_reg(state, insn->target, dst);
 }
diff --git a/expand.c b/expand.c
index effd27b..67a1bfb 100644
--- a/expand.c
+++ b/expand.c
@@ -17,6 +17,7 @@
 #include <unistd.h>
 #include <fcntl.h>
 #include <limits.h>
+#include <inttypes.h>
 
 #include "lib.h"
 #include "allocate.h"
@@ -96,7 +97,7 @@ Int:
 	if (is_bool_type(newtype)) {
 		expr->value = !!value;
 		if (!conservative && value != 0 && value != 1)
-			warning(old->pos, "odd constant _Bool cast (%llx becomes 1)", value);
+			warning(old->pos, "odd constant _Bool cast (%"PRIx64" becomes 1)", value);
 		return;
 	}
 
@@ -117,7 +118,7 @@ Int:
 	// OK if the bits were (and still are) purely sign bits
 	if (value & dropped) {
 		if (!(value & oldsignmask) || !(value & signmask) || (value & dropped) != dropped)
-			warning(old->pos, "cast truncates bits from constant value (%llx becomes %llx)",
+			warning(old->pos, "cast truncates bits from constant value (%"PRIx64" becomes %"PRIx64")",
 				value & oldmask,
 				value & mask);
 	}
diff --git a/linearize.c b/linearize.c
index 1d15cfd..d587187 100644
--- a/linearize.c
+++ b/linearize.c
@@ -15,6 +15,7 @@
 #include <stdlib.h>
 #include <stdio.h>
 #include <assert.h>
+#include <inttypes.h>
 
 #include "parse.h"
 #include "expression.h"
@@ -121,7 +122,7 @@ const char *show_pseudo(pseudo_t pseudo)
 		if (expr) {
 			switch (expr->type) {
 			case EXPR_VALUE:
-				snprintf(buf, 64, "<symbol value: %lld>", expr->value);
+				snprintf(buf, 64, "<symbol value: %"PRId64">", expr->value);
 				break;
 			case EXPR_STRING:
 				return show_string(expr->string);
@@ -139,9 +140,9 @@ const char *show_pseudo(pseudo_t pseudo)
 	case PSEUDO_VAL: {
 		long long value = pseudo->value;
 		if (value > 1000 || value < -1000)
-			snprintf(buf, 64, "$%#llx", value);
+			snprintf(buf, 64, "$%#"PRIx64, value);
 		else
-			snprintf(buf, 64, "$%lld", value);
+			snprintf(buf, 64, "$%"PRId64, value);
 		break;
 	}
 	case PSEUDO_ARG:
@@ -336,10 +337,14 @@ const char *show_instruction(struct instruction *insn)
 			
 		switch (expr->type) {
 		case EXPR_VALUE:
-			buf += sprintf(buf, "%lld", expr->value);
+			buf += sprintf(buf, "%"PRId64, expr->value);
 			break;
 		case EXPR_FVALUE:
+#if !defined(__MINGW32__)
 			buf += sprintf(buf, "%Lf", expr->fvalue);
+#else
+			buf += sprintf(buf, "%f", (double)expr->fvalue);
+#endif
 			break;
 		case EXPR_STRING:
 			buf += sprintf(buf, "%.40s", show_string(expr->string));
@@ -463,7 +468,7 @@ const char *show_instruction(struct instruction *insn)
 	}
 
 	if (buf >= buffer + sizeof(buffer))
-		die("instruction buffer overflowed %td\n", buf - buffer);
+		die("instruction buffer overflowed %d\n", (int)(buf - buffer));
 	do { --buf; } while (*buf == ' ');
 	*++buf = 0;
 	return buffer;
diff --git a/parse.c b/parse.c
index 7b89cc3..151e6b1 100644
--- a/parse.c
+++ b/parse.c
@@ -18,6 +18,7 @@
 #include <unistd.h>
 #include <fcntl.h>
 #include <limits.h>
+#include <inttypes.h>
 
 #include "lib.h"
 #include "allocate.h"
@@ -1756,7 +1757,7 @@ static struct token *handle_bitfield(struct token *token, struct decl_state *ctx
 	bitfield->bit_size = width;
 
 	if (width < 0 || width > INT_MAX) {
-		sparse_error(token->pos, "invalid bitfield width, %lld.", width);
+		sparse_error(token->pos, "invalid bitfield width, %"PRId64".", width);
 		width = -1;
 	} else if (*ctx->ident && width == 0) {
 		sparse_error(token->pos, "invalid named zero-width bitfield `%s'",
diff --git a/pre-process.c b/pre-process.c
index d521318..0becdc4 100644
--- a/pre-process.c
+++ b/pre-process.c
@@ -158,12 +158,17 @@ static int expand_one_symbol(struct token **list)
 	} else if (token->ident == &__DATE___ident) {
 		if (!t)
 			time(&t);
+#if !defined(__MINGW32__)
 		strftime(buffer, 12, "%b %e %Y", localtime(&t));
+#else
+		strftime(buffer, 12, "%b %d %Y", localtime(&t));
+		if (buffer[4] == '0') buffer[4] = ' ';
+#endif
 		replace_with_string(token, buffer);
 	} else if (token->ident == &__TIME___ident) {
 		if (!t)
 			time(&t);
-		strftime(buffer, 9, "%T", localtime(&t));
+		strftime(buffer, 9, "%H:%M:%S", localtime(&t));
 		replace_with_string(token, buffer);
 	}
 	return 1;
diff --git a/show-parse.c b/show-parse.c
index 1333e30..ad1b1c6 100644
--- a/show-parse.c
+++ b/show-parse.c
@@ -15,6 +15,7 @@
 #include <ctype.h>
 #include <unistd.h>
 #include <fcntl.h>
+#include <inttypes.h>
 
 #include "lib.h"
 #include "allocate.h"
@@ -352,7 +353,7 @@ deeper:
 			append(name, " )");
 			was_ptr = 0;
 		}
-		append(name, "[%lld]", get_expression_value(sym->array_size));
+		append(name, "[%"PRId64"]", get_expression_value(sym->array_size));
 		break;
 
 	case SYM_RESTRICT:
@@ -502,10 +503,10 @@ static void show_switch_statement(struct statement *stmt)
 			printf("    default");
 		} else {
 			if (expr->type == EXPR_VALUE) {
-				printf("    case %lld", expr->value);
+				printf("    case %"PRId64, expr->value);
 				if (to) {
 					if (to->type == EXPR_VALUE) {
-						printf(" .. %lld", to->value);
+						printf(" .. %"PRId64, to->value);
 					} else {
 						printf(" .. what?");
 					}
@@ -911,7 +912,7 @@ static int show_symbol_expr(struct symbol *sym)
 		return new;
 	}
 	if (sym->ctype.modifiers & MOD_ADDRESSABLE) {
-		printf("\taddi.%d\t\tv%d,vFP,$%lld\n", bits_in_pointer, new, sym->value);
+		printf("\taddi.%d\t\tv%d,vFP,$%"PRId64"\n", bits_in_pointer, new, sym->value);
 		return new;
 	}
 	printf("\taddi.%d\t\tv%d,vFP,$offsetof(%s:%p)\n", bits_in_pointer, new, show_ident(sym->ident), sym);
@@ -971,7 +972,7 @@ static int show_value(struct expression *expr)
 	int new = new_pseudo();
 	unsigned long long value = expr->value;
 
-	printf("\tmovi.%d\t\tv%d,$%llu\n", expr->ctype->bit_size, new, value);
+	printf("\tmovi.%d\t\tv%d,$%"PRIu64"\n", expr->ctype->bit_size, new, value);
 	return new;
 }
 
@@ -980,7 +981,11 @@ static int show_fvalue(struct expression *expr)
 	int new = new_pseudo();
 	long double value = expr->fvalue;
 
+#if !defined(__MINGW32__)
 	printf("\tmovf.%d\t\tv%d,$%Lf\n", expr->ctype->bit_size, new, value);
+#else
+	printf("\tmovf.%d\t\tv%d,$%f\n", expr->ctype->bit_size, new, (double)value);
+#endif
 	return new;
 }
 
diff --git a/sparse.c b/sparse.c
index 67b7d9e..d0b7565 100644
--- a/sparse.c
+++ b/sparse.c
@@ -15,6 +15,7 @@
 #include <ctype.h>
 #include <unistd.h>
 #include <fcntl.h>
+#include <inttypes.h>
 
 #include "lib.h"
 #include "allocate.h"
@@ -138,7 +139,7 @@ static void check_byte_count(struct instruction *insn, pseudo_t count)
 	if (count->type == PSEUDO_VAL) {
 		long long val = count->value;
 		if (val <= 0 || val > 100000)
-			warning(insn->pos, "%s with byte count of %lld",
+			warning(insn->pos, "%s with byte count of %"PRId64,
 				show_ident(insn->func->sym->ident), val);
 		return;
 	}
diff --git a/tokenize.c b/tokenize.c
index 3eb643d..025dd84 100644
--- a/tokenize.c
+++ b/tokenize.c
@@ -547,8 +547,8 @@ static int get_one_number(int c, int next, stream_t *stream)
 	}
 
 	if (p == buffer_end) {
-		sparse_error(stream_pos(stream), "number token exceeds %td characters",
-		      buffer_end - buffer);
+		sparse_error(stream_pos(stream), "number token exceeds %d characters",
+		      (int)(buffer_end - buffer));
 		// Pretend we saw just "1".
 		buffer[0] = '1';
 		p = buffer + 1;
-- 
1.8.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [PATCH 3/5] Fix some "unknown format" warnings
Date: Tue, 21 May 2013 22:05:46 +0000
Message-ID: <20130521220546.GD11463 () jtriplet-mobl1>
--------------------
On Tue, May 21, 2013 at 08:17:37PM +0100, Ramsay Jones wrote:
> 
> Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
> ---

%Ld for a long long int is actually broken on all architectures; L only
works for long double.  Thanks for fixing that.

Formatting nit: I think this reads better when written as:

"... blah blah " PRIx64 " blah blah ..."

, leaving spaces between the macro and the close/open doublequotes.

Further comments below.

> @@ -336,10 +337,14 @@ const char *show_instruction(struct instruction *insn)
>  			
>  		switch (expr->type) {
>  		case EXPR_VALUE:
> -			buf += sprintf(buf, "%lld", expr->value);
> +			buf += sprintf(buf, "%"PRId64, expr->value);
>  			break;
>  		case EXPR_FVALUE:
> +#if !defined(__MINGW32__)
>  			buf += sprintf(buf, "%Lf", expr->fvalue);
> +#else
> +			buf += sprintf(buf, "%f", (double)expr->fvalue);
> +#endif

This seems really sad; does MinGW really have long double but no way to
print it?  Can we at least emit something here to indicate possible
truncation or loss of precision, if no means exists to print a long
double?

> @@ -463,7 +468,7 @@ const char *show_instruction(struct instruction *insn)
>  	}
>  
>  	if (buf >= buffer + sizeof(buffer))
> -		die("instruction buffer overflowed %td\n", buf - buffer);
> +		die("instruction buffer overflowed %d\n", (int)(buf - buffer));

No, ptrdiff_t does not portably fit in int; it generally has the same
size as size_t (64-bit on 64-bit platforms).  Cast to "long long" and
use PRId64 if you must.

> --- a/pre-process.c
> +++ b/pre-process.c
> @@ -158,12 +158,17 @@ static int expand_one_symbol(struct token **list)
>  	} else if (token->ident == &__DATE___ident) {
>  		if (!t)
>  			time(&t);
> +#if !defined(__MINGW32__)
>  		strftime(buffer, 12, "%b %e %Y", localtime(&t));
> +#else
> +		strftime(buffer, 12, "%b %d %Y", localtime(&t));
> +		if (buffer[4] == '0') buffer[4] = ' ';
> +#endif

To the best of my knowledge, nothing guarantees the length of %b, so the
[4] here seems wrong.

> @@ -980,7 +981,11 @@ static int show_fvalue(struct expression *expr)
>  	int new = new_pseudo();
>  	long double value = expr->fvalue;
>  
> +#if !defined(__MINGW32__)
>  	printf("\tmovf.%d\t\tv%d,$%Lf\n", expr->ctype->bit_size, new, value);
> +#else
> +	printf("\tmovf.%d\t\tv%d,$%f\n", expr->ctype->bit_size, new, (double)value);
> +#endif

Same comment as above regarding long double.

> --- a/tokenize.c
> +++ b/tokenize.c
> @@ -547,8 +547,8 @@ static int get_one_number(int c, int next, stream_t *stream)
>  	}
>  
>  	if (p == buffer_end) {
> -		sparse_error(stream_pos(stream), "number token exceeds %td characters",
> -		      buffer_end - buffer);
> +		sparse_error(stream_pos(stream), "number token exceeds %d characters",
> +		      (int)(buffer_end - buffer));

Same comment as above regarding ptrdiff_t.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: Re: [PATCH 3/5] Fix some "unknown format" warnings
Date: Wed, 22 May 2013 22:01:21 +0000
Message-ID: <519D4031.8010004 () ramsay1 ! demon ! co ! uk>
--------------------
Josh Triplett wrote:
> On Tue, May 21, 2013 at 08:17:37PM +0100, Ramsay Jones wrote:
>>
>> Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
>> ---
> 
> %Ld for a long long int is actually broken on all architectures; L only
> works for long double.  Thanks for fixing that.

Yep, I had forgotten about that change. I should have sent that four
years ago. Sorry about that.

> Formatting nit: I think this reads better when written as:
> 
> "... blah blah " PRIx64 " blah blah ..."
> 
> , leaving spaces between the macro and the close/open doublequotes.

OK, will do.

> 
> Further comments below.
> 
>> @@ -336,10 +337,14 @@ const char *show_instruction(struct instruction *insn)
>>  			
>>  		switch (expr->type) {
>>  		case EXPR_VALUE:
>> -			buf += sprintf(buf, "%lld", expr->value);
>> +			buf += sprintf(buf, "%"PRId64, expr->value);
>>  			break;
>>  		case EXPR_FVALUE:
>> +#if !defined(__MINGW32__)
>>  			buf += sprintf(buf, "%Lf", expr->fvalue);
>> +#else
>> +			buf += sprintf(buf, "%f", (double)expr->fvalue);
>> +#endif
> 
> This seems really sad; does MinGW really have long double but no way to
> print it?  Can we at least emit something here to indicate possible
> truncation or loss of precision, if no means exists to print a long
> double?

I couldn't find any means to do so, just from experimentation (I didn't
have any MinGW specific gcc documentation). Thus, I tried:

  $ cat -n junk.c
       1  #include <stdio.h>
       2
       3  int main(int argc, char *argv[])
       4  {
       5          long double f = 128.821L;
       6
       7          printf("sizeof(float) = %d\n", sizeof(float));
       8          printf("sizeof(double) = %d\n", sizeof(double));
       9          printf("sizeof(long double) = %d\n", sizeof(long double));
      10          printf("f = %Lf\n", f);
      11          return 0;
      12  }

  $ gcc -Wall -o junk junk.c
  junk.c: In function 'main':
  junk.c:10: warning: unknown conversion type character 'L' in format
  junk.c:10: warning: too many arguments for format
  $ ./junk.exe
  sizeof(float) = 4
  sizeof(double) = 8
  sizeof(long double) = 12
  f = -0.000000

  $ cl -W4 junk.c
  Microsoft (R) 32-bit C/C++ Optimizing Compiler Version 15.00.30729.01 for 80x86
  Copyright (C) Microsoft Corporation.  All rights reserved.

  junk.c
  junk.c(3) : warning C4100: 'argv' : unreferenced formal parameter
  junk.c(3) : warning C4100: 'argc' : unreferenced formal parameter
  Microsoft (R) Incremental Linker Version 9.00.30729.01
  Copyright (C) Microsoft Corporation.  All rights reserved.

  /out:junk.exe
  junk.obj
  $ ./junk.exe
  sizeof(float) = 4
  sizeof(double) = 8
  sizeof(long double) = 8
  f = 128.821000
  $

So, msvc knows about the L size modifier, but it treats a 'long double'
the same as a 'double'.

  $ vim junk.c # change format specifier %Lf => %lf
  $ gcc -Wall -o junk junk.c
  junk.c: In function 'main':
  junk.c:10: warning: format '%lf' expects type 'double', but argument 2 has type
  'long double'
  $ ./junk.exe
  sizeof(float) = 4
  sizeof(double) = 8
  sizeof(long double) = 12
  f = -0.000000
  $

I'm sure you can guess what happens if you try "%f" instead.

The current "compat" layer has an string_to_ld() function, so maybe
there should be an ld_to_string()? dunno.

[A 64-bit MinGW system probably doesn't have this problem, of course ...]

> 
>> @@ -463,7 +468,7 @@ const char *show_instruction(struct instruction *insn)
>>  	}
>>  
>>  	if (buf >= buffer + sizeof(buffer))
>> -		die("instruction buffer overflowed %td\n", buf - buffer);
>> +		die("instruction buffer overflowed %d\n", (int)(buf - buffer));
> 
> No, ptrdiff_t does not portably fit in int; it generally has the same
> size as size_t (64-bit on 64-bit platforms).  Cast to "long long" and
> use PRId64 if you must.

Yes, for the same reason, git does:

    printf("...%" PRIuMAX "...", (uintmax_t)(buf - buffer));

so I'll do that in the re-roll.

> 
>> --- a/pre-process.c
>> +++ b/pre-process.c
>> @@ -158,12 +158,17 @@ static int expand_one_symbol(struct token **list)
>>  	} else if (token->ident == &__DATE___ident) {
>>  		if (!t)
>>  			time(&t);
>> +#if !defined(__MINGW32__)
>>  		strftime(buffer, 12, "%b %e %Y", localtime(&t));
>> +#else
>> +		strftime(buffer, 12, "%b %d %Y", localtime(&t));
>> +		if (buffer[4] == '0') buffer[4] = ' ';
>> +#endif
> To the best of my knowledge, nothing guarantees the length of %b, so the
> [4] here seems wrong.

Yes, this was just a quick hack to compensate for the lack of the
"%e" format specifier in the msvc strftime(). (elsewhere the lack
of "%T" was easier to replace). I will have to think about this.
Any ideas?

>> @@ -980,7 +981,11 @@ static int show_fvalue(struct expression *expr)
>>  	int new = new_pseudo();
>>  	long double value = expr->fvalue;
>>  
>> +#if !defined(__MINGW32__)
>>  	printf("\tmovf.%d\t\tv%d,$%Lf\n", expr->ctype->bit_size, new, value);
>> +#else
>> +	printf("\tmovf.%d\t\tv%d,$%f\n", expr->ctype->bit_size, new, (double)value);
>> +#endif
> 
> Same comment as above regarding long double.
> 
>> --- a/tokenize.c
>> +++ b/tokenize.c
>> @@ -547,8 +547,8 @@ static int get_one_number(int c, int next, stream_t *stream)
>>  	}
>>  
>>  	if (p == buffer_end) {
>> -		sparse_error(stream_pos(stream), "number token exceeds %td characters",
>> -		      buffer_end - buffer);
>> +		sparse_error(stream_pos(stream), "number token exceeds %d characters",
>> +		      (int)(buffer_end - buffer));
> 
> Same comment as above regarding ptrdiff_t.
> 
> - Josh Triplett

Thanks Josh. You hit every part of the patch that I wanted to
tidy up! :-D

ATB,
Ramsay Jones



--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH 3/5] Fix some "unknown format" warnings
Date: Thu, 23 May 2013 15:42:51 +0000
Message-ID: <519E38FB.2020207 () chrisli ! org>
--------------------

On 05/21/2013 12:17 PM, Ramsay Jones wrote:

> +#if !defined(__MINGW32__)
>  			buf += sprintf(buf, "%Lf", expr->fvalue);
> +#else
> +			buf += sprintf(buf, "%f", (double)expr->fvalue);
> +#endif

I don't like to stash !define(__MINW32__) all over the sparse
code. Let's move this to the compat abstract layer. Can you create a
function "char *print_float(float value)" function in compat-mingw.c and
the normal implementation in compat/*.c


> +#if !defined(__MINGW32__)
>  		strftime(buffer, 12, "%b %e %Y", localtime(&t));
> +#else
> +		strftime(buffer, 12, "%b %d %Y", localtime(&t));
> +		if (buffer[4] == '0') buffer[4] = ' ';
> +#endif

Same here, try to move to the compat layer.

> +#if !defined(__MINGW32__)
>  	printf("\tmovf.%d\t\tv%d,$%Lf\n", expr->ctype->bit_size, new, value);
> +#else
> +	printf("\tmovf.%d\t\tv%d,$%f\n", expr->ctype->bit_size, new, (double)value);
> +#endif

Here we can reuse the previous print_float() function.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 4/4] sparse, llvm: add a struct access test case ===

From: =?UTF-8?q?Jonathan=20Neusch=C3=A4fer?= <j.neuschaefer () gmx ! net>
To: linux-sparse
Subject: [PATCH 4/4] sparse, llvm: add a struct access test case
Date: Sat, 18 May 2013 17:52:07 +0000
Message-ID: <1368899527-2350-4-git-send-email-j.neuschaefer () gmx ! net>
--------------------
Cc: Pekka Enberg <penberg@kernel.org>
Cc: Christopher Li <sparse@chrisli.org>
Cc: Jeff Garzik <jgarzik@redhat.com>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Cc: Xi Wang <xi.wang@gmail.com>
Signed-off-by: Jonathan NeuschÃ¤fer <j.neuschaefer@gmx.net>
---
 validation/backend/struct-access.c |   28 ++++++++++++++++++++++++++++
 1 file changed, 28 insertions(+)
 create mode 100644 validation/backend/struct-access.c

diff --git a/validation/backend/struct-access.c b/validation/backend/struct-access.c
new file mode 100644
index 0000000..884b470
--- /dev/null
+++ b/validation/backend/struct-access.c
@@ -0,0 +1,28 @@
+struct st {
+	int i, *d;
+};
+
+static int load_i(struct st *st)
+{
+	return st->i;
+}
+
+static void store_i(struct st *st, int i)
+{
+	st->i = i;
+}
+
+static int *load_d(struct st *st)
+{
+	return st->d;
+}
+
+static void store_d(struct st *st, int *d)
+{
+	st->d = d;
+}
+
+/*
+ * check-name: struct access code generation
+ * check-command: ./sparsec -c $file -o tmp.o
+ */
-- 
1.7.10.4

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 4/5] test-suite: Add -b option to ignore CR at eol on MinGW ===

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: [PATCH 4/5] test-suite: Add -b option to ignore CR at eol on MinGW
Date: Tue, 21 May 2013 19:18:21 +0000
Message-ID: <519BC87D.5080002 () ramsay1 ! demon ! co ! uk>
--------------------

Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
---
 validation/test-suite | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/validation/test-suite b/validation/test-suite
index 3c011c6..ded93fc 100755
--- a/validation/test-suite
+++ b/validation/test-suite
@@ -126,7 +126,7 @@ do_test()
 	actual_exit_value=$?
 
 	for stream in output error; do
-		diff -u "$file".$stream.expected "$file".$stream.got > "$file".$stream.diff
+		diff -ub "$file".$stream.expected "$file".$stream.got > "$file".$stream.diff
 		if [ "$?" -ne "0" ]; then
 			error "actual $stream text does not match expected $stream text."
 			error  "see $file.$stream.* for further investigation."
-- 
1.8.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [PATCH 4/5] test-suite: Add -b option to ignore CR at eol on MinGW
Date: Tue, 21 May 2013 21:16:50 +0000
Message-ID: <20130521211650.GA11463 () jtriplet-mobl1>
--------------------
On Tue, May 21, 2013 at 08:18:21PM +0100, Ramsay Jones wrote:
> Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>

-b doesn't just ignore CR at end of line; it would also ignore changes
in the amount of whitespace elsewhere on the line.  You might consider
piping the input that has CRs through sed before storing it, to delete
the CR at end of line before comparing, instead.

> ---
>  validation/test-suite | 2 +-
>  1 file changed, 1 insertion(+), 1 deletion(-)
> 
> diff --git a/validation/test-suite b/validation/test-suite
> index 3c011c6..ded93fc 100755
> --- a/validation/test-suite
> +++ b/validation/test-suite
> @@ -126,7 +126,7 @@ do_test()
>  	actual_exit_value=$?
>  
>  	for stream in output error; do
> -		diff -u "$file".$stream.expected "$file".$stream.got > "$file".$stream.diff
> +		diff -ub "$file".$stream.expected "$file".$stream.got > "$file".$stream.diff
>  		if [ "$?" -ne "0" ]; then
>  			error "actual $stream text does not match expected $stream text."
>  			error  "see $file.$stream.* for further investigation."
> -- 
> 1.8.2
> 
> --
> To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
> the body of a message to majordomo@vger.kernel.org
> More majordomo info at  http://vger.kernel.org/majordomo-info.html
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Johannes Berg <johannes () sipsolutions ! net>
To: linux-sparse
Subject: Re: [PATCH 4/5] test-suite: Add -b option to ignore CR at eol on MinGW
Date: Tue, 21 May 2013 21:27:00 +0000
Message-ID: <1369171620.10614.0.camel () jlt4 ! sipsolutions ! net>
--------------------
On Tue, 2013-05-21 at 14:16 -0700, Josh Triplett wrote:
> On Tue, May 21, 2013 at 08:18:21PM +0100, Ramsay Jones wrote:
> > Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
> 
> -b doesn't just ignore CR at end of line; it would also ignore changes
> in the amount of whitespace elsewhere on the line.  You might consider
> piping the input that has CRs through sed before storing it, to delete
> the CR at end of line before comparing, instead.

Or just use --strip-trailing-cr, no? Or maybe that's not available?

johannes

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [PATCH 4/5] test-suite: Add -b option to ignore CR at eol on MinGW
Date: Tue, 21 May 2013 21:46:07 +0000
Message-ID: <20130521214607.GB11463 () jtriplet-mobl1>
--------------------
On Tue, May 21, 2013 at 11:27:00PM +0200, Johannes Berg wrote:
> On Tue, 2013-05-21 at 14:16 -0700, Josh Triplett wrote:
> > On Tue, May 21, 2013 at 08:18:21PM +0100, Ramsay Jones wrote:
> > > Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
> > 
> > -b doesn't just ignore CR at end of line; it would also ignore changes
> > in the amount of whitespace elsewhere on the line.  You might consider
> > piping the input that has CRs through sed before storing it, to delete
> > the CR at end of line before comparing, instead.
> 
> Or just use --strip-trailing-cr, no? Or maybe that's not available?

Nice, I didn't know about that one.  Yes, if MinGW's diff has that, by
all means use it.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH 5/5] lib.c: Add __sync_lock_test_and_set as a builtin function ===

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: [PATCH 5/5] lib.c: Add __sync_lock_test_and_set as a builtin function
Date: Tue, 21 May 2013 19:19:11 +0000
Message-ID: <519BC8AF.8060804 () ramsay1 ! demon ! co ! uk>
--------------------

Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
---
 lib.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/lib.c b/lib.c
index 7e822eb..2dca810 100644
--- a/lib.c
+++ b/lib.c
@@ -779,6 +779,7 @@ void declare_builtin_functions(void)
 	add_pre_buffer("extern double __builtin_fabs(double);\n");
 	add_pre_buffer("extern void __sync_synchronize();\n");
 	add_pre_buffer("extern int __sync_bool_compare_and_swap(void *, ...);\n");
+	add_pre_buffer("extern int __sync_lock_test_and_set(volatile long *const, const long);\n");
 
 	/* Add Blackfin-specific stuff */
 	add_pre_buffer(
-- 
1.8.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH 5/5] lib.c: Add __sync_lock_test_and_set as a builtin function
Date: Thu, 23 May 2013 03:15:44 +0000
Message-ID: <CANeU7Qkv7UkmFnQ__6q5zRkM8CTAUhwWhronFh-c70GLz-Q7QA () mail ! gmail ! com>
--------------------
On Tue, May 21, 2013 at 12:19 PM, Ramsay Jones
<ramsay@ramsay1.demon.co.uk> wrote:
> +       add_pre_buffer("extern int __sync_lock_test_and_set(volatile long *const, const long);\n");

Looking at the gcc documents about atomic builtins.  quote:
"and further that they are overloaded such that they work on multiple types"

Sparse does not do type overload. Which means sparse can't properly support this
function right now. If some one try to use this function on an int
type, sparse will
complain about type mismatch.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Ramsay Jones <ramsay () ramsay1 ! demon ! co ! uk>
To: linux-sparse
Subject: Re: [PATCH 5/5] lib.c: Add __sync_lock_test_and_set as a builtin function
Date: Sat, 25 May 2013 19:40:09 +0000
Message-ID: <51A11399.3090709 () ramsay1 ! demon ! co ! uk>
--------------------
Christopher Li wrote:
> On Tue, May 21, 2013 at 12:19 PM, Ramsay Jones
> <ramsay@ramsay1.demon.co.uk> wrote:
>> +       add_pre_buffer("extern int __sync_lock_test_and_set(volatile long *const, const long);\n");
> 
> Looking at the gcc documents about atomic builtins.  quote:
> "and further that they are overloaded such that they work on multiple types"
> 

Ah, yes, I obviously didn't investigate this carefully enough! :(
OK, so we can forget about this patch.

Thanks!

ATB,
Ramsay Jones



--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH v2] sparse: add __builtin_va_arg_pack() and __builtin_va_arg_pack_len() ===

From: Jeff Layton <jlayton () redhat ! com>
To: linux-sparse
Subject: [PATCH v2] sparse: add __builtin_va_arg_pack() and __builtin_va_arg_pack_len()
Date: Fri, 19 Jul 2013 10:33:40 +0000
Message-ID: <1374230020-26826-1-git-send-email-jlayton () redhat ! com>
--------------------
this patch stops sparse from complaining about them not being defined:

    /usr/include/bits/stdio2.h:98:25: error: undefined identifier '__builtin_va_arg_pack'
    /usr/include/bits/stdio2.h:98:25: error: not a function <noident>

Signed-off-by: Jeff Layton <jlayton@redhat.com>
---
 lib.c                            |  2 ++
 validation/builtin_va_arg_pack.c | 20 ++++++++++++++++++++
 2 files changed, 22 insertions(+)
 create mode 100644 validation/builtin_va_arg_pack.c

diff --git a/lib.c b/lib.c
index 7e822eb..3f687ae 100644
--- a/lib.c
+++ b/lib.c
@@ -777,6 +777,7 @@ void declare_builtin_functions(void)
 	add_pre_buffer("extern long __builtin_alpha_cmpbge(long, long);\n");
 	add_pre_buffer("extern long __builtin_labs(long);\n");
 	add_pre_buffer("extern double __builtin_fabs(double);\n");
+	add_pre_buffer("extern __SIZE_TYPE__ __builtin_va_arg_pack_len(void);\n");
 	add_pre_buffer("extern void __sync_synchronize();\n");
 	add_pre_buffer("extern int __sync_bool_compare_and_swap(void *, ...);\n");
 
@@ -876,6 +877,7 @@ void create_builtin_stream(void)
 	add_pre_buffer("#define __builtin_va_copy(dest, src) ({ dest = src; (void)0; })\n");
 	add_pre_buffer("#define __builtin_va_end(arg)\n");
 	add_pre_buffer("#define __builtin_ms_va_end(arg)\n");
+	add_pre_buffer("#define __builtin_va_arg_pack()\n");
 
 	/* FIXME! We need to do these as special magic macros at expansion time! */
 	add_pre_buffer("#define __BASE_FILE__ \"base_file.c\"\n");
diff --git a/validation/builtin_va_arg_pack.c b/validation/builtin_va_arg_pack.c
new file mode 100644
index 0000000..3426b86
--- /dev/null
+++ b/validation/builtin_va_arg_pack.c
@@ -0,0 +1,20 @@
+extern void v(int a, ...);
+
+extern inline __attribute__((__always_inline__)) void f(int a, ...)
+{
+	__SIZE_TYPE__ b = __builtin_va_arg_pack_len();
+}
+
+extern inline __attribute__((__always_inline__)) void g(int a, ...)
+{
+	v(a, __builtin_va_arg_pack());
+}
+
+static void h(void)
+{
+	f(0, 0);
+	g(0, 0);
+}
+/*
+ * check-name: __builtin_va_arg_pack()
+ */
-- 
1.8.3.1

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH v2] sparse: add built-in byte swap identifiers ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH v2] sparse: add built-in byte swap identifiers
Date: Tue, 19 Feb 2013 19:13:09 +0000
Message-ID: <CANeU7QmfNK8tT2R3vKN95A7YSnJZvbVo+UkAd87sx8S2hX5jog () mail ! gmail ! com>
--------------------
On Tue, Feb 19, 2013 at 9:41 AM, Kim Phillips
<kim.phillips@freescale.com> wrote:
> this patch stops sparse from complaining about them not being
> defined:

> v2: add a test for builtin_bswap{16,32,64}

Looks good to me. I will apply that.

Thanks

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] Allow forced attribute in function argument ===

From: Christopher Li <sparse@chrisli.org>
To: Unknown
Subject: [PATCH] Allow forced attribute in function argument
Date: Thu, 25 Apr 2013 18:09:43 -0700
Message-ID: 
--------------------
It will indicate this argument will skip the compatible check.
---
 evaluate.c             |  2 +-
 parse.c                |  1 +
 symbol.h               |  3 ++-
 validation/fored_arg.c | 18 ++++++++++++++++++
 4 files changed, 22 insertions(+), 2 deletions(-)
 create mode 100644 validation/fored_arg.c

diff --git a/evaluate.c b/evaluate.c
index 9f2c4ac..0dfa519 100644
--- a/evaluate.c
+++ b/evaluate.c
@@ -2137,7 +2137,7 @@ static int evaluate_arguments(struct symbol *f, struct symbol *fn, struct expres
 				else
 					degenerate(expr);
 			}
-		} else {
+		} else if (!target->forced_arg){
 			static char where[30];
 			examine_symbol_type(target);
 			sprintf(where, "argument %d", i);
diff --git a/parse.c b/parse.c
index 45ffc10..890e56b 100644
--- a/parse.c
+++ b/parse.c
@@ -1841,6 +1841,7 @@ static struct token *parameter_declaration(struct token *token, struct symbol *s
 	sym->ctype = ctx.ctype;
 	sym->ctype.modifiers |= storage_modifiers(&ctx);
 	sym->endpos = token->pos;
+	sym->forced_arg = ctx.storage_class == SForced;
 	return token;
 }
 
diff --git a/symbol.h b/symbol.h
index 1e74579..1c6ad66 100644
--- a/symbol.h
+++ b/symbol.h
@@ -157,7 +157,8 @@ struct symbol {
 					expanding:1,
 					evaluated:1,
 					string:1,
-					designated_init:1;
+					designated_init:1,
+					forced_arg:1;
 			struct expression *array_size;
 			struct ctype ctype;
 			struct symbol_list *arguments;
diff --git a/validation/fored_arg.c b/validation/fored_arg.c
new file mode 100644
index 0000000..4ab7141
--- /dev/null
+++ b/validation/fored_arg.c
@@ -0,0 +1,18 @@
+/*
+ * check-name: Forced function argument type.
+ */
+
+#define __iomem	__attribute__((noderef, address_space(2)))
+#define __force __attribute__((force))
+
+static void foo(__force void * addr)
+{
+}
+
+
+static void bar(void)
+{
+	void __iomem  *a;
+	foo(a);
+}
+
-- 
1.8.1.4


--------------050208040901030504040708--
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse@chrisli.org>
To: Unknown
Subject: [PATCH] Allow forced attribute in function argument
Date: Thu, 25 Apr 2013 18:09:43 -0700
Message-ID: 
--------------------
It will indicate this argument will skip the compatible check.
---
 evaluate.c             |  2 +-
 parse.c                |  1 +
 symbol.h               |  3 ++-
 validation/fored_arg.c | 18 ++++++++++++++++++
 4 files changed, 22 insertions(+), 2 deletions(-)
 create mode 100644 validation/fored_arg.c

diff --git a/evaluate.c b/evaluate.c
index 9f2c4ac..0dfa519 100644
--- a/evaluate.c
+++ b/evaluate.c
@@ -2137,7 +2137,7 @@ static int evaluate_arguments(struct symbol *f, struct symbol *fn, struct expres
 				else
 					degenerate(expr);
 			}
-		} else {
+		} else if (!target->forced_arg){
 			static char where[30];
 			examine_symbol_type(target);
 			sprintf(where, "argument %d", i);
diff --git a/parse.c b/parse.c
index 45ffc10..890e56b 100644
--- a/parse.c
+++ b/parse.c
@@ -1841,6 +1841,7 @@ static struct token *parameter_declaration(struct token *token, struct symbol *s
 	sym->ctype = ctx.ctype;
 	sym->ctype.modifiers |= storage_modifiers(&ctx);
 	sym->endpos = token->pos;
+	sym->forced_arg = ctx.storage_class == SForced;
 	return token;
 }
 
diff --git a/symbol.h b/symbol.h
index 1e74579..1c6ad66 100644
--- a/symbol.h
+++ b/symbol.h
@@ -157,7 +157,8 @@ struct symbol {
 					expanding:1,
 					evaluated:1,
 					string:1,
-					designated_init:1;
+					designated_init:1,
+					forced_arg:1;
 			struct expression *array_size;
 			struct ctype ctype;
 			struct symbol_list *arguments;
diff --git a/validation/fored_arg.c b/validation/fored_arg.c
new file mode 100644
index 0000000..4ab7141
--- /dev/null
+++ b/validation/fored_arg.c
@@ -0,0 +1,18 @@
+/*
+ * check-name: Forced function argument type.
+ */
+
+#define __iomem	__attribute__((noderef, address_space(2)))
+#define __force __attribute__((force))
+
+static void foo(__force void * addr)
+{
+}
+
+
+static void bar(void)
+{
+	void __iomem  *a;
+	foo(a);
+}
+
-- 
1.8.1.4


--------------050208040901030504040708--
--
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
================================================================================


################################################################################

=== Thread: [PATCH] Define __SIZEOF_POINTER__ ===

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: [PATCH] Define __SIZEOF_POINTER__
Date: Thu, 18 Apr 2013 19:14:30 +0000
Message-ID: <20130418191428.GA19319 () jtriplet-mobl1>
--------------------
GCC defines a macro __SIZEOF_POINTER__ to the size of a pointer in
bytes.  Define it in sparse as well.

Signed-off-by: Josh Triplett <josh@joshtriplett.org>
---
 cgcc  |   15 ++++++++++-----
 lib.c |    1 +
 2 files changed, 11 insertions(+), 5 deletions(-)

diff --git a/cgcc b/cgcc
index 6636cc6..c075e5f 100755
--- a/cgcc
+++ b/cgcc
@@ -240,27 +240,32 @@ sub add_specs {
 	return (' -Di386=1 -D__i386=1 -D__i386__=1' .
 		&integer_types (8, 16, 32, $m64 ? 64 : 32, 64) .
 		&float_types (1, 1, 21, [24,8], [53,11], [64,15]) .
-		&define_size_t ($m64 ? "long unsigned int" : "unsigned int"));
+		&define_size_t ($m64 ? "long unsigned int" : "unsigned int") .
+		' -D__SIZEOF_POINTER__=' . ($m64 ? '8' : '4'));
     } elsif ($spec eq 'sparc') {
 	return (' -Dsparc=1 -D__sparc=1 -D__sparc__=1' .
 		&integer_types (8, 16, 32, $m64 ? 64 : 32, 64) .
 		&float_types (1, 1, 33, [24,8], [53,11], [113,15]) .
-		&define_size_t ($m64 ? "long unsigned int" : "unsigned int"));
+		&define_size_t ($m64 ? "long unsigned int" : "unsigned int") .
+		' -D__SIZEOF_POINTER__=' . ($m64 ? '8' : '4'));
     } elsif ($spec eq 'sparc64') {
 	return (' -Dsparc=1 -D__sparc=1 -D__sparc__=1 -D__sparcv9__=1 -D__sparc64__=1 -D__arch64__=1 -D__LP64__=1' .
 		&integer_types (8, 16, 32, 64, 64, 128) .
 		&float_types (1, 1, 33, [24,8], [53,11], [113,15]) .
-		&define_size_t ("long unsigned int"));
+		&define_size_t ("long unsigned int") .
+		' -D__SIZEOF_POINTER__=8');
     } elsif ($spec eq 'x86_64') {
 	return (' -Dx86_64=1 -D__x86_64=1 -D__x86_64__=1' . ($m32 ? '' : ' -D__LP64__=1') .
 		&integer_types (8, 16, 32, $m32 ? 32 : 64, 64, 128) .
 		&float_types (1, 1, 33, [24,8], [53,11], [113,15]) .
-		&define_size_t ($m32 ? "unsigned int" : "long unsigned int"));
+		&define_size_t ($m32 ? "unsigned int" : "long unsigned int") .
+		' -D__SIZEOF_POINTER__=' . ($m32 ? '4' : '8'));
     } elsif ($spec eq 'ppc') {
 	return (' -D__powerpc__=1 -D_BIG_ENDIAN -D_STRING_ARCH_unaligned=1' .
 		&integer_types (8, 16, 32, $m64 ? 64 : 32, 64) .
 		&float_types (1, 1, 21, [24,8], [53,11], [113,15]) .
-		&define_size_t ($m64 ? "long unsigned int" : "unsigned int"));
+		&define_size_t ($m64 ? "long unsigned int" : "unsigned int") .
+		' -D__SIZEOF_POINTER__=' . ($m64 ? '8' : '4'));
     } elsif ($spec eq 'host_os_specs') {
 	my $os = `uname -s`;
 	chomp $os;
diff --git a/lib.c b/lib.c
index 4f69e11..98a5515 100644
--- a/lib.c
+++ b/lib.c
@@ -863,6 +863,7 @@ void create_builtin_stream(void)
 	add_pre_buffer("#weak_define __LONG_MAX__ " STRINGIFY(__LONG_MAX__) "\n");
 	add_pre_buffer("#weak_define __LONG_LONG_MAX__ " STRINGIFY(__LONG_LONG_MAX__) "\n");
 	add_pre_buffer("#weak_define __WCHAR_MAX__ " STRINGIFY(__WCHAR_MAX__) "\n");
+	add_pre_buffer("#weak_define __SIZEOF_POINTER__ " STRINGIFY(__SIZEOF_POINTER__) "\n");
 }
 
 static struct symbol_list *sparse_tokenstream(struct token *token)
-- 
1.7.10.4

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] Make "break" and "continue" consistent with other label ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: [PATCH] Make "break" and "continue" consistent with other label
Date: Wed, 27 Feb 2013 14:45:28 +0000
Message-ID: <CANeU7Qmkcc5zQbXOjBvF8wCGc9=i_UEkKtT7jLtfOCHme=WmFQ () mail ! gmail ! com>
--------------------
--f46d0444ebbf3c1e7604d6b5d347
Content-Type: text/plain; charset=ISO-8859-1

Hi Xi,

I make some small improvement of your label checking change.

By setting the label->stmt, there is no need to do
keyword lookup. The keyword lookup can be incorrect
because it contain more than just  "break" and "continue".

Let me know if you found any thing wrong with it.

Chris

--f46d0444ebbf3c1e7604d6b5d347
Content-Type: application/octet-stream; 
	name="0001-Make-break-and-continue-consistent-with-other-label.patch"
Content-Disposition: attachment; 
	filename="0001-Make-break-and-continue-consistent-with-other-label.patch"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_hdolg8sr0
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--f46d0444ebbf3c1e7604d6b5d347--
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] Support #pragma once ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] Support #pragma once
Date: Mon, 22 Apr 2013 16:41:02 +0000
Message-ID: <CANeU7QmNEq9+v2VFiTcPc=fPWshVrEgh5JpBz3PvvExJ4LpxYw () mail ! gmail ! com>
--------------------
On Fri, Apr 19, 2013 at 12:10 PM, Josh Triplett <josh@joshtriplett.org> wrote:
> "#pragma once" acts like a multiple-inclusion guard affecting the entire file,
> without an associated preprocessor symbol.
>
> This allows use of sparse on projects that rely on #pragma once without
> also using an ifndef-based multiple-inclusion guard, such as systemd;
> without this change, sparse will get into an include loop.
>

Your two patches has been applied to the chrisl repository.

Thanks

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] Update the information in README about using the library. ===

From: Josh Triplett <josh () freedesktop ! org>
To: linux-sparse
Subject: Re: [PATCH] Update the information in README about using the library.
Date: Tue, 27 Feb 2007 19:05:47 +0000
Message-ID: <45E4810B.2030301 () freedesktop ! org>
--------------------
This is an OpenPGP/MIME signed message (RFC 2440 and 3156)
--------------enig0499B392E29F4A0D8C1B2EC0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable

James Westby wrote:
> Changes in the library have left the README giving out of date informat=
ion
> on how to intialise the library and get the symbols out of it. Update t=
he
> documentation to match the latest functions.
>=20
> Signed-off-by: James Westby <jw+debian@jameswestby.net>

Applied.

- Josh Triplett



--------------enig0499B392E29F4A0D8C1B2EC0
Content-Type: application/pgp-signature; name="signature.asc"
Content-Description: OpenPGP digital signature
Content-Disposition: attachment; filename="signature.asc"

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFF5IELGJuZRtD+evsRAotAAKCNaS7Ep5+pXFwgMNGEax15rI17pQCgozGH
QPsdgLztE2uiPI/dhn6NYTM=
=y8MY
-----END PGP SIGNATURE-----

--------------enig0499B392E29F4A0D8C1B2EC0--
-
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Franz Schrober <franzschrober () gmail ! com>
To: linux-sparse
Subject: [PATCH] Update the information in README about using the library.
Date: Tue, 03 Dec 2013 08:26:05 +0000
Message-ID: <1386059165-3812-1-git-send-email-franzschrober () gmail ! com>
--------------------
From: James Westby <james@jameswestby.net>

Changes in the library have left the README giving out of date information
on how to intialise the library and get the symbols out of it. Update the
documentation to match the latest functions.

Signed-off-by: James Westby <james@jameswestby.net>
Signed-off-by: Franz Schrober <franzschrober@gmail.com>
---
This patch was already submitted by James Westby and had to be reverted again
after he didn't responded in the 4 year relicense process. Now he accepted the
change to MIT license and I just resubmit it for him. So it is a revert for the
revert 01b00f59f2a6aba6b623c0a68827938c1f570877 ('Revert "Update the
information in README about using the library."')

Sorry for the inconveniences.

 README | 29 ++++++++---------------------
 1 file changed, 8 insertions(+), 21 deletions(-)

diff --git a/README b/README
index a731a82..033ae15 100644
--- a/README
+++ b/README
@@ -47,35 +47,22 @@ requires the information.
 
 This means that a user of the library will literally just need to do
 
-	struct token *token;
-	int fd = open(filename, O_RDONLY);
-	struct symbol_list *list = NULL;
+  struct string_list *filelist = NULL;
+  char *file;
 
-	if (fd < 0)
-		exit_with_complaint();
+  action(sparse_initialize(argc, argv, filelist));
 
-	// Initialize parse symbols
-	init_symbols();
-
-	// Tokenize the input stream
-	token = tokenize(filename, fd, NULL);
-
-	// Pre-process the stream
-	token = preprocess(token);
-
-	// Parse the resulting C code
-	translation_unit(token, &list);
-
-	// Evaluate the types now if we want to
-	// Or leave it until later.
-	symbol_iterate(list, evaluate_symbol, NULL);
+  FOR_EACH_PTR_NOTAG(filelist, file) {
+    action(sparse(file));
+  } END_FOR_EACH_PTR_NOTAG(file);
 
 and he is now done - having a full C parse of the file he opened.  The
 library doesn't need any more setup, and once done does not impose any
 more requirements.  The user is free to do whatever he wants with the
 parse tree that got built up, and needs not worry about the library ever
 again.  There is no extra state, there are no parser callbacks, there is
-only the parse tree that is described by the header files. 
+only the parse tree that is described by the header files. The action
+funtion takes a pointer to a symbol_list and does whatever it likes with it.
 
 The library also contains (as an example user) a few clients that do the
 preprocessing, parsing and type evaluation and just print out the
-- 
1.8.5

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [PATCH] Update the information in README about using the library.
Date: Tue, 03 Dec 2013 23:45:17 +0000
Message-ID: <20131203234517.GB15141 () jtriplet-mobl1>
--------------------
On Tue, Dec 03, 2013 at 03:17:37PM -0800, Christopher Li wrote:
> That will make you as the author of this commit.

The "From:" line at the top of the patch will make git set that person
as the author rather than the sender of the mail.

> I think not much people have pull from the sparse repository yet.

Bad assumption; if you've already pushed the patch, I'd suggest just
"git revert"ing the revert.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] Update the information in README about using the library.
Date: Wed, 04 Dec 2013 00:12:01 +0000
Message-ID: <CANeU7Qmy4k=9tJJ+sGr3DXAcROvZBkmkXOtwLnamLWZbitYvog () mail ! gmail ! com>
--------------------
On Tue, Dec 3, 2013 at 3:45 PM, Josh Triplett <josh@joshtriplett.org> wrote:
> On Tue, Dec 03, 2013 at 03:17:37PM -0800, Christopher Li wrote:
>> That will make you as the author of this commit.
>
> The "From:" line at the top of the patch will make git set that person
> as the author rather than the sender of the mail.
>
>> I think not much people have pull from the sparse repository yet.
>
> Bad assumption; if you've already pushed the patch, I'd suggest just
> "git revert"ing the revert.
>

Thanks, that is just what I need. I will just do that then.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] Update the information in README about using the library.
Date: Mon, 09 Dec 2013 09:21:30 +0000
Message-ID: <CANeU7QmDqNCs4C0vvYscp0snL1ss-fQvnE=319XJNnouT+kaDw () mail ! gmail ! com>
--------------------
On Tue, Dec 3, 2013 at 4:12 PM, Christopher Li <sparse@chrisli.org> wrote:
>> Bad assumption; if you've already pushed the patch, I'd suggest just
>> "git revert"ing the revert.
>>
>
> Thanks, that is just what I need. I will just do that then.

I need to revert 3 patch and there are change in between.
So I just apply the original patch. I push the change out already.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] fix SIGFPE caused by signed division overflow ===

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: [PATCH] fix SIGFPE caused by signed division overflow
Date: Fri, 10 May 2013 21:00:35 +0000
Message-ID: <1368219635-4524-1-git-send-email-xi.wang () gmail ! com>
--------------------
Avoid evaluating INT_MIN / -1 and INT_MIN % -1, which will trap on x86
and crash sparse.

Signed-off-by: Xi Wang <xi.wang@gmail.com>
---
 expand.c         |  2 ++
 simplify.c       |  4 ++++
 validation/div.c | 29 +++++++++++++++++++++++++++++
 3 files changed, 35 insertions(+)
 create mode 100644 validation/div.c

diff --git a/expand.c b/expand.c
index effd27b..2dfa5e5 100644
--- a/expand.c
+++ b/expand.c
@@ -239,6 +239,8 @@ static int simplify_int_binop(struct expression *expr, struct symbol *ctype)
 	case SIGNED('%'):
 		if (!r)
 			goto Div;
+		if (l == mask && sr == -1)
+			goto Overflow;
 		v = sl % sr;
 		break;
 
diff --git a/simplify.c b/simplify.c
index bda4a5b..b5cd0ea 100644
--- a/simplify.c
+++ b/simplify.c
@@ -406,6 +406,8 @@ static int simplify_constant_binop(struct instruction *insn)
 	case OP_DIVS:
 		if (!right)
 			return 0;
+		if (left == mask && right == -1)
+			return 0;
 		res = left / right;
 		break;
 	case OP_MODU:
@@ -416,6 +418,8 @@ static int simplify_constant_binop(struct instruction *insn)
 	case OP_MODS:
 		if (!right)
 			return 0;
+		if (left == mask && right == -1)
+			return 0;
 		res = left % right;
 		break;
 	case OP_SHL:
diff --git a/validation/div.c b/validation/div.c
new file mode 100644
index 0000000..3dcbfd5
--- /dev/null
+++ b/validation/div.c
@@ -0,0 +1,29 @@
+#include <limits.h>
+
+static int xd = 1 / 0;
+static int xl = 1L / 0;
+static int xll = 1LL / 0;
+
+static int yd = INT_MIN / -1;
+static long yl = LONG_MIN / -1;
+static long long yll = LLONG_MIN / -1;
+
+static int zd = INT_MIN % -1;
+static long zl = LONG_MIN % -1;
+static long long zll = LLONG_MIN % -1;
+
+/*
+ * check-name: division constants
+ *
+ * check-error-start
+div.c:3:19: warning: division by zero
+div.c:4:20: warning: division by zero
+div.c:5:22: warning: division by zero
+div.c:7:25: warning: constant integer operation overflow
+div.c:8:27: warning: constant integer operation overflow
+div.c:9:34: warning: constant integer operation overflow
+div.c:11:25: warning: constant integer operation overflow
+div.c:12:27: warning: constant integer operation overflow
+div.c:13:34: warning: constant integer operation overflow
+ * check-error-end
+ */
-- 
1.8.1.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] fix SIGFPE caused by signed division overflow
Date: Sat, 11 May 2013 18:25:26 +0000
Message-ID: <518E8D16.7040008 () chrisli ! org>
--------------------
On 05/10/2013 02:00 PM, Xi Wang wrote:
> Avoid evaluating INT_MIN / -1 and INT_MIN % -1, which will trap on x86
> and crash sparse.

Applied.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] fix casting to bool ===

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: [PATCH] fix casting to bool
Date: Thu, 16 May 2013 20:56:06 +0000
Message-ID: <1368737766-6517-1-git-send-email-xi.wang () gmail ! com>
--------------------
Consider the following function.

	static _Bool foo(int x) { return x; }

Currently sparse emits:

	scast.1     %r2 <- (32) %arg1
	ret.1       %r2

This is incorrect since bool requires a zero test.

	setne.32    %r2 <- %arg1, $0
	ret.1       %r2

This patch adds zero testing for bool in cast_to().

Signed-off-by: Xi Wang <xi.wang@gmail.com>
---
 evaluate.c | 12 ++++++++++++
 1 file changed, 12 insertions(+)

diff --git a/evaluate.c b/evaluate.c
index d9c767f..a090028 100644
--- a/evaluate.c
+++ b/evaluate.c
@@ -272,6 +272,18 @@ static struct expression * cast_to(struct expression *old, struct symbol *type)
 	if (old->ctype != &null_ctype && is_same_type(old, type))
 		return old;
 
+	/* bool requires a zero test */
+	if (is_bool_type(type)) {
+		expr = alloc_expression(old->pos, EXPR_COMPARE);
+		expr->op = SPECIAL_NOTEQUAL;
+		expr->ctype = type;
+		expr->left = old;
+		expr->right = alloc_expression(old->pos, EXPR_VALUE);
+		expr->right->ctype = old->ctype;
+		expr->right->value = 0;
+		return expr;
+	}
+
 	/*
 	 * See if we can simplify the op. Move the cast down.
 	 */
-- 
1.8.1.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH] fix casting to bool
Date: Sun, 19 May 2013 07:47:27 +0000
Message-ID: <CAOJsxLGWnegLeB-O6PQy_JkCV_06bqf9N8pTnsxsKAphgcZSnw () mail ! gmail ! com>
--------------------
On Thu, May 16, 2013 at 11:56 PM, Xi Wang <xi.wang@gmail.com> wrote:
> Consider the following function.
>
>         static _Bool foo(int x) { return x; }
>
> Currently sparse emits:
>
>         scast.1     %r2 <- (32) %arg1
>         ret.1       %r2
>
> This is incorrect since bool requires a zero test.
>
>         setne.32    %r2 <- %arg1, $0
>         ret.1       %r2
>
> This patch adds zero testing for bool in cast_to().
>
> Signed-off-by: Xi Wang <xi.wang@gmail.com>

Acked-by: Pekka Enberg <penberg@kernel.org>

> ---
>  evaluate.c | 12 ++++++++++++
>  1 file changed, 12 insertions(+)
>
> diff --git a/evaluate.c b/evaluate.c
> index d9c767f..a090028 100644
> --- a/evaluate.c
> +++ b/evaluate.c
> @@ -272,6 +272,18 @@ static struct expression * cast_to(struct expression *old, struct symbol *type)
>         if (old->ctype != &null_ctype && is_same_type(old, type))
>                 return old;
>
> +       /* bool requires a zero test */
> +       if (is_bool_type(type)) {
> +               expr = alloc_expression(old->pos, EXPR_COMPARE);
> +               expr->op = SPECIAL_NOTEQUAL;
> +               expr->ctype = type;
> +               expr->left = old;
> +               expr->right = alloc_expression(old->pos, EXPR_VALUE);
> +               expr->right->ctype = old->ctype;
> +               expr->right->value = 0;
> +               return expr;
> +       }
> +
>         /*
>          * See if we can simplify the op. Move the cast down.
>          */
> --
> 1.8.1.2
>
> --
> To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
> the body of a message to majordomo@vger.kernel.org
> More majordomo info at  http://vger.kernel.org/majordomo-info.html
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] fix floating point ! type ===

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: [PATCH] fix floating point ! type
Date: Thu, 16 May 2013 20:56:13 +0000
Message-ID: <1368737773-6559-1-git-send-email-xi.wang () gmail ! com>
--------------------
The expression type of zero testing should be EXPR_COMPARE, rather
than EXPR_BINOP.

Signed-off-by: Xi Wang <xi.wang@gmail.com>
---
 evaluate.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/evaluate.c b/evaluate.c
index a090028..c345a50 100644
--- a/evaluate.c
+++ b/evaluate.c
@@ -1807,7 +1807,7 @@ static struct symbol *evaluate_preop(struct expression *expr)
 			warning(expr->pos, "testing a 'safe expression'");
 		if (is_float_type(ctype)) {
 			struct expression *arg = expr->unop;
-			expr->type = EXPR_BINOP;
+			expr->type = EXPR_COMPARE;
 			expr->op = SPECIAL_EQUAL;
 			expr->left = arg;
 			expr->right = alloc_expression(expr->pos, EXPR_FVALUE);
-- 
1.8.1.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: Re: [PATCH] fix floating point ! type
Date: Fri, 17 May 2013 21:52:47 +0000
Message-ID: <CAKU6vybHWHHfQF8HgHnp8Qd5tpBGMRozrbt6actvbXmANXeLKA () mail ! gmail ! com>
--------------------
On Thu, May 16, 2013 at 4:56 PM, Xi Wang <xi.wang@gmail.com> wrote:
> The expression type of zero testing should be EXPR_COMPARE, rather
> than EXPR_BINOP.

There might be a bigger problem.  The C standard says the result type
of comparisons, !, &&, || should be int, rather than bool.
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] fix logical operand type ===

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: [PATCH] fix logical operand type
Date: Thu, 16 May 2013 20:56:19 +0000
Message-ID: <1368737779-6601-1-git-send-email-xi.wang () gmail ! com>
--------------------
The type of logical operands should be bool.

Signed-off-by: Xi Wang <xi.wang@gmail.com>
---
simplify.c seems to assume so.

	case OP_AND_BOOL:
		if (value == 1)
			return replace_with_pseudo(insn, insn->src1);
---
 evaluate.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/evaluate.c b/evaluate.c
index c345a50..8954ff2 100644
--- a/evaluate.c
+++ b/evaluate.c
@@ -873,6 +873,8 @@ static struct symbol *evaluate_logical(struct expression *expr)
 		return NULL;
 
 	expr->ctype = &bool_ctype;
+	expr->left = cast_to(expr->left, &bool_ctype);
+	expr->right = cast_to(expr->right, &bool_ctype);
 	if (expr->flags) {
 		if (!(expr->left->flags & expr->right->flags & Int_const_expr))
 			expr->flags = 0;
-- 
1.8.1.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] fix pointer casts in evaluate_compare() ===

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: [PATCH] fix pointer casts in evaluate_compare()
Date: Thu, 16 May 2013 20:55:33 +0000
Message-ID: <1368737733-6475-1-git-send-email-xi.wang () gmail ! com>
--------------------
The results of cast_to() seem unused.  Assign them to expr->left and
expr->right.

Signed-off-by: Xi Wang <xi.wang@gmail.com>
---
 evaluate.c | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/evaluate.c b/evaluate.c
index 0dfa519..d9c767f 100644
--- a/evaluate.c
+++ b/evaluate.c
@@ -1024,11 +1024,11 @@ static struct symbol *evaluate_compare(struct expression *expr)
 			goto OK;
 		}
 		if (is_null1 && (rclass & TYPE_PTR)) {
-			left = cast_to(left, rtype);
+			expr->left = cast_to(left, rtype);
 			goto OK;
 		}
 		if (is_null2 && (lclass & TYPE_PTR)) {
-			right = cast_to(right, ltype);
+			expr->right = cast_to(right, ltype);
 			goto OK;
 		}
 	}
@@ -1044,11 +1044,11 @@ static struct symbol *evaluate_compare(struct expression *expr)
 	if (expr->op == SPECIAL_EQUAL || expr->op == SPECIAL_NOTEQUAL) {
 		if (ltype->ctype.as == rtype->ctype.as) {
 			if (lbase == &void_ctype) {
-				right = cast_to(right, ltype);
+				expr->right = cast_to(right, ltype);
 				goto OK;
 			}
 			if (rbase == &void_ctype) {
-				left = cast_to(left, rtype);
+				expr->left = cast_to(left, rtype);
 				goto OK;
 			}
 		}
-- 
1.8.1.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: Re: [PATCH] fix pointer casts in evaluate_compare()
Date: Sun, 19 May 2013 12:29:03 +0000
Message-ID: <CAKU6vyYFnZh73QHOqj=B_Bp4M_e706eGhM57w29pCfhaseNfAw () mail ! gmail ! com>
--------------------
On Sun, May 19, 2013 at 3:48 AM, Pekka Enberg <penberg@kernel.org> wrote:
> How did you find about this? Is this needed to fix a reproducible issue?

I was debugging like (p == 0) and noticed that sparse lost this cast
to pointers.

A more serious problem in evaluate_compare() is that sparse evaluates
comparisons to bool, which should have been int, according to the C
standard.

For example, sparse incorrectly evaluates sizeof(1 == 0) to 1, while
gcc and clang evaluate this to 4 (i.e., sizeof(int)).

Similar problems exist when sparse evaluates other conditional
expressions, such as !, &&, ||.

This also confuses sparse-llvm.  For example, given OP_AND_BOOL x, y,
should sparse-llvm assume that x and y can be int, bool, or some other
type?

- xi
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] forced argument Was Re: sparse: incorrect type in argument 1 (different address spaces) ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: [PATCH] forced argument Was Re: sparse: incorrect type in argument 1 (different address spaces)
Date: Fri, 26 Apr 2013 02:09:37 +0000
Message-ID: <5179E1E1.4050304 () chrisli ! org>
--------------------
This is a multi-part message in MIME format.
--------------050208040901030504040708
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On 04/22/2013 11:16 PM, Dan Carpenter wrote:
> That didn't work.  It's the the void * in the parameter list that's
> the problem.  We'd need to do something like the patch below:
> 
> Otherwise we could add "__ok_to_cast" thing to Sparse maybe?

Thanks for the insight. I make a small patch to test the __ok_to_cast
feature. The syntax is adding the force attribute to the argument
declaration.

it will look like this:
static inline long __must_check PTR_ERR( __force const void *ptr)

That means the "ptr" argument will perform a forced cast when receiving
the argument. It is OK to pass __iomem pointer to "ptr".

The example are in the patch. It need to patch both sparse and the
Linux tree.

What do you say?

Chris


--------------050208040901030504040708
Content-Type: text/x-patch;
 name="0001-Allow-forced-attribute-in-function-argument.patch"
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment;
 filename*0="0001-Allow-forced-attribute-in-function-argument.patch"


================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-kernel
Subject: [PATCH] forced argument Was Re: sparse: incorrect type in argument 1 (different address spaces)
Date: Fri, 26 Apr 2013 02:09:37 +0000
Message-ID: <5179E1E1.4050304 () chrisli ! org>
--------------------
This is a multi-part message in MIME format.
--------------050208040901030504040708
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit

On 04/22/2013 11:16 PM, Dan Carpenter wrote:
> That didn't work.  It's the the void * in the parameter list that's
> the problem.  We'd need to do something like the patch below:
> 
> Otherwise we could add "__ok_to_cast" thing to Sparse maybe?

Thanks for the insight. I make a small patch to test the __ok_to_cast
feature. The syntax is adding the force attribute to the argument
declaration.

it will look like this:
static inline long __must_check PTR_ERR( __force const void *ptr)

That means the "ptr" argument will perform a forced cast when receiving
the argument. It is OK to pass __iomem pointer to "ptr".

The example are in the patch. It need to patch both sparse and the
Linux tree.

What do you say?

Chris


--------------050208040901030504040708
Content-Type: text/x-patch;
 name="0001-Allow-forced-attribute-in-function-argument.patch"
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment;
 filename*0="0001-Allow-forced-attribute-in-function-argument.patch"


================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-kernel
Subject: Re: [PATCH] forced argument Was Re: sparse: incorrect type in argument 1 (different address spaces)
Date: Fri, 26 Apr 2013 06:35:38 +0000
Message-ID: <20130426063538.GA5072 () mwanda>
--------------------
On Thu, Apr 25, 2013 at 07:09:37PM -0700, Christopher Li wrote:
> On 04/22/2013 11:16 PM, Dan Carpenter wrote:
> > That didn't work.  It's the the void * in the parameter list that's
> > the problem.  We'd need to do something like the patch below:
> > 
> > Otherwise we could add "__ok_to_cast" thing to Sparse maybe?
> 
> Thanks for the insight. I make a small patch to test the __ok_to_cast
> feature. The syntax is adding the force attribute to the argument
> declaration.
> 
> it will look like this:
> static inline long __must_check PTR_ERR( __force const void *ptr)
> 
> That means the "ptr" argument will perform a forced cast when receiving
> the argument. It is OK to pass __iomem pointer to "ptr".
> 
> The example are in the patch. It need to patch both sparse and the
> Linux tree.
> 
> What do you say?

That's looks great.  :)

I tested a patched kernel with an unpatched kernel as well and that
doesn't cause any new problems.

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-sparse
Subject: Re: [PATCH] forced argument Was Re: sparse: incorrect type in argument 1 (different address spaces)
Date: Fri, 26 Apr 2013 06:35:38 +0000
Message-ID: <20130426063538.GA5072 () mwanda>
--------------------
On Thu, Apr 25, 2013 at 07:09:37PM -0700, Christopher Li wrote:
> On 04/22/2013 11:16 PM, Dan Carpenter wrote:
> > That didn't work.  It's the the void * in the parameter list that's
> > the problem.  We'd need to do something like the patch below:
> > 
> > Otherwise we could add "__ok_to_cast" thing to Sparse maybe?
> 
> Thanks for the insight. I make a small patch to test the __ok_to_cast
> feature. The syntax is adding the force attribute to the argument
> declaration.
> 
> it will look like this:
> static inline long __must_check PTR_ERR( __force const void *ptr)
> 
> That means the "ptr" argument will perform a forced cast when receiving
> the argument. It is OK to pass __iomem pointer to "ptr".
> 
> The example are in the patch. It need to patch both sparse and the
> Linux tree.
> 
> What do you say?

That's looks great.  :)

I tested a patched kernel with an unpatched kernel as well and that
doesn't cause any new problems.

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] gitignore: add 'version.h' ===

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [PATCH] gitignore: add 'version.h'
Date: Sat, 28 Sep 2013 00:54:51 +0000
Message-ID: <20130928005451.GA16682 () leaf>
--------------------
On Fri, Sep 27, 2013 at 07:57:41PM -0400, Emilio G. Cota wrote:
> From: "Emilio G. Cota" <cota@braap.org>
> 
> Signed-off-by: Emilio G. Cota <cota@braap.org>

Reviewed-by: Josh Triplett <josh@joshtriplett.org>
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [PATCH] gitignore: add 'version.h'
Date: Sat, 28 Sep 2013 00:54:51 +0000
Message-ID: <20130928005451.GA16682 () leaf>
--------------------
On Fri, Sep 27, 2013 at 07:57:41PM -0400, Emilio G. Cota wrote:
> From: "Emilio G. Cota" <cota@braap.org>
> 
> Signed-off-by: Emilio G. Cota <cota@braap.org>

Reviewed-by: Josh Triplett <josh@joshtriplett.org>
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "Emilio G. Cota" <cota () braap ! org>
To: linux-sparse
Subject: Re: [PATCH] gitignore: add 'version.h'
Date: Thu, 19 Dec 2013 05:46:39 +0000
Message-ID: <20131219054639.GA22638 () flamenco ! cs ! columbia ! edu>
--------------------
On Sun, Sep 29, 2013 at 09:16:18 -0700, Christopher Li wrote:
> On Fri, Sep 27, 2013 at 5:54 PM, Josh Triplett <josh@joshtriplett.org>wrote:
> 
> > On Fri, Sep 27, 2013 at 07:57:41PM -0400, Emilio G. Cota wrote:
> > > From: "Emilio G. Cota" <cota@braap.org>
> > >
> > > Signed-off-by: Emilio G. Cota <cota@braap.org>
> >
> > Reviewed-by: Josh Triplett <josh@joshtriplett.org>
> >
> 
> Looks good.
> 
> Will apply.

This patch hasn't been applied yet.

Did you drop it or it just got forgotten?

Thanks,

		Emilio
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] gitignore: add 'version.h'
Date: Sat, 21 Dec 2013 17:22:10 +0000
Message-ID: <CANeU7Qn5LF3b4iJjPBOBtxXq8f=eazWO44vPFjQa-9R-DCC5QA () mail ! gmail ! com>
--------------------
On Wed, Dec 18, 2013 at 9:46 PM, Emilio G. Cota <cota@braap.org> wrote:
>
> This patch hasn't been applied yet.
>
> Did you drop it or it just got forgotten?
>

Sorry it fall through the cracks. Just applied and pushed to chrisl repository.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] lib: rename die_if_error to error_happened ===

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH] lib: rename die_if_error to error_happened
Date: Wed, 22 May 2013 06:49:10 +0000
Message-ID: <CAOJsxLEpzPpO7NCh+ED2bi+WF99g6O==A64=oxX1HXizNnoyVg () mail ! gmail ! com>
--------------------
On Tue, May 21, 2013 at 7:49 PM, Jonathan Neuschäfer
<j.neuschaefer@gmx.net> wrote:
> The variable in question is set when an error message is output,
> and doesn't control termination at all, so I think the new name
> matches the semantics better.
>
> Cc: Christopher Li <sparse@chrisli.org>
> Cc: Pekka Enberg <penberg@kernel.org>
> Cc: Xi Wang <xi.wang@gmail.com>
> Signed-off-by: Jonathan Neuschäfer <j.neuschaefer@gmx.net>

Chris, are you OK with me picking this up in the sparse-llvm tree?
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] rcu: Make rcu_assign_pointer's assignment volatile and type-safe ===

From: "Paul E. McKenney" <paulmck () linux ! vnet ! ibm ! com>
To: linux-sparse
Subject: Re: [PATCH] rcu: Make rcu_assign_pointer's assignment volatile and type-safe
Date: Mon, 02 Sep 2013 02:01:37 +0000
Message-ID: <20130902020137.GI3871 () linux ! vnet ! ibm ! com>
--------------------
On Sun, Sep 01, 2013 at 04:42:52PM -0700, Josh Triplett wrote:
> rcu_assign_pointer needs to use ACCESS_ONCE to make the assignment to
> the destination pointer volatile, to protect against compilers too
> clever for their own good.
> 
> In addition, since rcu_assign_pointer force-casts the source pointer to
> add the __rcu address space (overriding any existing address space), add
> an explicit check that the source pointer has the __kernel address space
> to start with.
> 
> This new check produces warnings like this, when attempting to assign
> from a __user pointer:
> 
> test.c:25:9: warning: incorrect type in argument 2 (different address spaces)
> test.c:25:9:    expected struct foo *<noident>
> test.c:25:9:    got struct foo [noderef] <asn:1>*badsrc
> 
> Signed-off-by: Josh Triplett <josh@joshtriplett.org>

Queued for 3.13, thank you very much!

							Thanx, Paul

> ---
>  include/linux/rcupdate.h | 12 +++++++++++-
>  1 file changed, 11 insertions(+), 1 deletion(-)
> 
> diff --git a/include/linux/rcupdate.h b/include/linux/rcupdate.h
> index 4b14bdc..3f62def 100644
> --- a/include/linux/rcupdate.h
> +++ b/include/linux/rcupdate.h
> @@ -510,8 +510,17 @@ static inline void rcu_preempt_sleep_check(void)
>  #ifdef __CHECKER__
>  #define rcu_dereference_sparse(p, space) \
>  	((void)(((typeof(*p) space *)p) == p))
> +/* The dummy first argument in __rcu_assign_pointer_typecheck makes the
> + * typechecked pointer the second argument, matching rcu_assign_pointer itself;
> + * this avoids confusion about argument numbers in warning messages. */
> +#define __rcu_assign_pointer_check_kernel(v) \
> +	do { \
> +		extern void __rcu_assign_pointer_typecheck(int, typeof(*(v)) __kernel *); \
> +		__rcu_assign_pointer_typecheck(0, v); \
> +	} while (0)
>  #else /* #ifdef __CHECKER__ */
>  #define rcu_dereference_sparse(p, space)
> +#define __rcu_assign_pointer_check_kernel(v) do { } while (0)
>  #endif /* #else #ifdef __CHECKER__ */
> 
>  #define __rcu_access_pointer(p, space) \
> @@ -555,7 +564,8 @@ static inline void rcu_preempt_sleep_check(void)
>  #define __rcu_assign_pointer(p, v, space) \
>  	do { \
>  		smp_wmb(); \
> -		(p) = (typeof(*v) __force space *)(v); \
> +		__rcu_assign_pointer_check_kernel(v); \
> +		ACCESS_ONCE(p) = (typeof(*(v)) __force space *)(v); \
>  	} while (0)
> 
> 
> --
> To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
> the body of a message to majordomo@vger.kernel.org
> More majordomo info at  http://vger.kernel.org/majordomo-info.html
> Please read the FAQ at  http://www.tux.org/lkml/
> 

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] sparse, llvm: fix link errors ===

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: [PATCH] sparse, llvm: fix link errors
Date: Fri, 10 May 2013 21:01:24 +0000
Message-ID: <1368219684-4567-1-git-send-email-xi.wang () gmail ! com>
--------------------
This patch fixes the following link errors.

    libLLVMSupport.a(Signals.o): In function `llvm::sys::PrintStackTrace(_IO_FILE*)':
    Signals.inc:269: undefined reference to `dladdr'
    Signals.inc:281: undefined reference to `dladdr'

Cc: Pekka Enberg <penberg@kernel.org>
Signed-off-by: Xi Wang <xi.wang@gmail.com>
---
 Makefile | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/Makefile b/Makefile
index 35e3801..4f53903 100644
--- a/Makefile
+++ b/Makefile
@@ -84,14 +84,14 @@ HAVE_LLVM=no
 else
 LLVM_PROGS := sparse-llvm
 $(LLVM_PROGS): LD := g++
-LDFLAGS += $(shell llvm-config --ldflags)
+LLVM_LDFLAGS := $(shell llvm-config --ldflags)
 LLVM_CFLAGS := $(shell llvm-config --cflags | sed -e "s/-DNDEBUG//g")
 LLVM_LIBS := $(shell llvm-config --libs)
 PROGRAMS += $(LLVM_PROGS)
 INST_PROGRAMS += sparse-llvm sparsec
 sparse-llvm_EXTRA_DEPS := sparse-llvm.o
 sparse-llvm.o $(sparse-llvm_EXTRA_DEPS): BASIC_CFLAGS += $(LLVM_CFLAGS)
-sparse-llvm_EXTRA_OBJS := $(LLVM_LIBS)
+sparse-llvm_EXTRA_OBJS := $(LLVM_LIBS) $(LLVM_LDFLAGS)
 endif
 endif
 
-- 
1.8.1.2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse, llvm: fix link errors
Date: Sat, 11 May 2013 18:24:46 +0000
Message-ID: <518E8CEE.6060001 () chrisli ! org>
--------------------


On 05/10/2013 02:01 PM, Xi Wang wrote:
> This patch fixes the following link errors.
> 
>     libLLVMSupport.a(Signals.o): In function `llvm::sys::PrintStackTrace(_IO_FILE*)':
>     Signals.inc:269: undefined reference to `dladdr'
>     Signals.inc:281: undefined reference to `dladdr'


> -sparse-llvm_EXTRA_OBJS := $(LLVM_LIBS)
> +sparse-llvm_EXTRA_OBJS := $(LLVM_LIBS) $(LLVM_LDFLAGS)

The EXTRA_OBJS is only mean for real objects.
the LDFLAGS should be not belong to here.

I can't duplicate the link error myself.
It seems that you only want the LLVM_LDFLAGS apply to
sparse-llvm only.

Can you try this patch?

Thanks


Chris

diff --git a/Makefile b/Makefile
index 35e3801..549e669 100644
--- a/Makefile
+++ b/Makefile
@@ -84,7 +84,7 @@ HAVE_LLVM=no
 else
 LLVM_PROGS := sparse-llvm
 $(LLVM_PROGS): LD := g++
-LDFLAGS += $(shell llvm-config --ldflags)
+$(LLVM_PROGS): LDFLAGS += $(shell llvm-config --ldflags)
 LLVM_CFLAGS := $(shell llvm-config --cflags | sed -e "s/-DNDEBUG//g")
 LLVM_LIBS := $(shell llvm-config --libs)
 PROGRAMS += $(LLVM_PROGS)

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Xi Wang <xi.wang () gmail ! com>
To: linux-sparse
Subject: Re: [PATCH] sparse, llvm: fix link errors
Date: Sun, 12 May 2013 02:10:24 +0000
Message-ID: <518EFA10.6040108 () gmail ! com>
--------------------
On 05/11/2013 02:24 PM, Christopher Li wrote:
> The EXTRA_OBJS is only mean for real objects.
> the LDFLAGS should be not belong to here.
> 
> I can't duplicate the link error myself.
> It seems that you only want the LLVM_LDFLAGS apply to
> sparse-llvm only.
> 
> Can you try this patch?

This doesn't work for me.

The problem is that -ldl (`llvm --ldflags`) must come _after_
-lLLVMSupport (`llvm --libs`).

Can we move LDFLAGS?

diff --git a/Makefile b/Makefile
index 35e3801..3cec8f0 100644
--- a/Makefile
+++ b/Makefile
@@ -84,7 +84,7 @@ HAVE_LLVM=no
 else
 LLVM_PROGS := sparse-llvm
 $(LLVM_PROGS): LD := g++
-LDFLAGS += $(shell llvm-config --ldflags)
+$(LLVM_PROGS): LDFLAGS += $(shell llvm-config --ldflags)
 LLVM_CFLAGS := $(shell llvm-config --cflags | sed -e "s/-DNDEBUG//g")
 LLVM_LIBS := $(shell llvm-config --libs)
 PROGRAMS += $(LLVM_PROGS)
@@ -173,7 +173,7 @@ compile_EXTRA_DEPS = compile-i386.o
 
 $(foreach p,$(PROGRAMS),$(eval $(p): $($(p)_EXTRA_DEPS) $(LIBS)))
 $(PROGRAMS): % : %.o 
-	$(QUIET_LINK)$(LD) $(LDFLAGS) -o $@ $^ $($@_EXTRA_OBJS)
+	$(QUIET_LINK)$(LD) -o $@ $^ $($@_EXTRA_OBJS) $(LDFLAGS)
 
 $(LIB_FILE): $(LIB_OBJS)
 	$(QUIET_AR)$(AR) rcs $@ $(LIB_OBJS)
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse, llvm: fix link errors
Date: Wed, 15 May 2013 10:09:50 +0000
Message-ID: <51935EEE.2060407 () chrisli ! org>
--------------------
On 05/11/2013 07:10 PM, Xi Wang wrote:
> 
> This doesn't work for me.
> 
> The problem is that -ldl (`llvm --ldflags`) must come _after_
> -lLLVMSupport (`llvm --libs`).
> 
> Can we move LDFLAGS?
> 

Sorry for the late reply.

In that case, your first patch is actually cleaner.
I apply your first patch instead.  Change pushed.

BTW, Pekka, I notice that "sparse-llvm_EXTRA_DEPS" is redundant
with the next line, which also have sparse-llvm.o. Am I miss some
thing?

 sparse-llvm_EXTRA_DEPS := sparse-llvm.o
 sparse-llvm.o $(sparse-llvm_EXTRA_DEPS): BASIC_CFLAGS += $(LLVM_CFLAGS)


Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse, llvm: fix link errors
Date: Wed, 15 May 2013 12:02:32 +0000
Message-ID: <CAOJsxLH_o8aGA1a4QMcy4Z+e0CXsNSWrh1SEtbfiT9fYXGKx5A () mail ! gmail ! com>
--------------------
On Wed, May 15, 2013 at 1:09 PM, Christopher Li <sparse@chrisli.org> wrote:
> BTW, Pekka, I notice that "sparse-llvm_EXTRA_DEPS" is redundant
> with the next line, which also have sparse-llvm.o. Am I miss some
> thing?
>
>  sparse-llvm_EXTRA_DEPS := sparse-llvm.o
>  sparse-llvm.o $(sparse-llvm_EXTRA_DEPS): BASIC_CFLAGS += $(LLVM_CFLAGS)

No, I you're not missing anything. Feel free to drop it.
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] sparse, llvm: fix phi generation ===

From: Pekka Enberg <penberg () kernel ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse, llvm: fix phi generation
Date: Sat, 18 May 2013 07:35:44 +0000
Message-ID: <CAOJsxLGLG8t65HrBi6AyBXAbjf7LJmHzLagaCOR0XwK=sU0AUA () mail ! gmail ! com>
--------------------
On Thu, May 16, 2013 at 9:33 AM, Xi Wang <xi.wang@gmail.com> wrote:
> PHI in LLVM is different from that in sparse.  LLVM requires PHI "for
> each predecessor basic block of the current block" even if the current
> block doesn't use it.  It's tricky to correctly place PHI.
>
> This patch implements a simpler and safer strategy:
> 1) allocate an alloca for each phi, and
> 2) translate phi/phisrc to load/store alloca.
> LLVM optimizations will promote load/store to registers.
>
> Cc: Pekka Enberg <penberg@kernel.org>
> Cc: Christopher Li <sparse@chrisli.org>
> Cc: Jeff Garzik <jgarzik@redhat.com>
> Cc: Linus Torvalds <torvalds@linux-foundation.org>
> Cc: Jonathan Neuschäfer <j.neuschaefer@gmx.net>
> Signed-off-by: Xi Wang <xi.wang@gmail.com>

Applied, thanks!
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] sparse: add __builtin_va_arg_pack() and __builtin_va_arg_pack_len() ===

From: Jeff Layton <jlayton () redhat ! com>
To: linux-sparse
Subject: [PATCH] sparse: add __builtin_va_arg_pack() and __builtin_va_arg_pack_len()
Date: Thu, 18 Jul 2013 15:36:39 +0000
Message-ID: <1374161799-2929-1-git-send-email-jlayton () redhat ! com>
--------------------
this patch stops sparse from complaining about them not being defined:

    /usr/include/bits/stdio2.h:98:25: error: undefined identifier '__builtin_va_arg_pack'
    /usr/include/bits/stdio2.h:98:25: error: not a function <noident>

Probably, there is some better way to do this that actually validates
this function, but I'm not clear on how to do it.

Signed-off-by: Jeff Layton <jlayton@redhat.com>
---
 lib.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/lib.c b/lib.c
index 7e822eb..3f687ae 100644
--- a/lib.c
+++ b/lib.c
@@ -777,6 +777,7 @@ void declare_builtin_functions(void)
 	add_pre_buffer("extern long __builtin_alpha_cmpbge(long, long);\n");
 	add_pre_buffer("extern long __builtin_labs(long);\n");
 	add_pre_buffer("extern double __builtin_fabs(double);\n");
+	add_pre_buffer("extern __SIZE_TYPE__ __builtin_va_arg_pack_len(void);\n");
 	add_pre_buffer("extern void __sync_synchronize();\n");
 	add_pre_buffer("extern int __sync_bool_compare_and_swap(void *, ...);\n");
 
@@ -876,6 +877,7 @@ void create_builtin_stream(void)
 	add_pre_buffer("#define __builtin_va_copy(dest, src) ({ dest = src; (void)0; })\n");
 	add_pre_buffer("#define __builtin_va_end(arg)\n");
 	add_pre_buffer("#define __builtin_ms_va_end(arg)\n");
+	add_pre_buffer("#define __builtin_va_arg_pack()\n");
 
 	/* FIXME! We need to do these as special magic macros at expansion time! */
 	add_pre_buffer("#define __BASE_FILE__ \"base_file.c\"\n");
-- 
1.8.3.1

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse: add __builtin_va_arg_pack() and __builtin_va_arg_pack_len()
Date: Fri, 19 Jul 2013 02:49:59 +0000
Message-ID: <CANeU7Qn5LFSKN9+vX+yGVovbcWNMmJT4HU6Se4ObsoJHh851fA () mail ! gmail ! com>
--------------------
On Thu, Jul 18, 2013 at 8:36 AM, Jeff Layton <jlayton@redhat.com> wrote:
> this patch stops sparse from complaining about them not being defined:
>
>     /usr/include/bits/stdio2.h:98:25: error: undefined identifier '__builtin_va_arg_pack'
>     /usr/include/bits/stdio2.h:98:25: error: not a function <noident>
>
> Probably, there is some better way to do this that actually validates
> this function, but I'm not clear on how to do it.
>

Please add a test case for the typical usage case of __buildin_va_arg_pack()
and __builtin_va_arg_pack_len(). At the very least, it needs to cover the real
world breakage that bother you enough to submit a patch.

The patch looks good otherwise.

Thanks

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] sparse: add built-in atomic memory access identifiers ===

From: Kim Phillips <kim.phillips () linaro ! org>
To: linux-sparse
Subject: [PATCH] sparse: add built-in atomic memory access identifiers
Date: Wed, 11 Dec 2013 21:00:13 +0000
Message-ID: <20131211150013.e009efdb3fa2321f113a8a8d () linaro ! org>
--------------------
this patch stops sparse from complaining about them not being
defined:

source/odp_spinlock.c:41:10: error: undefined identifier '__sync_lock_release'
source/odp_spinlock.c:54:10: error: undefined identifier '__sync_lock_release'
./odp_atomic.h:112:16: error: undefined identifier '__sync_fetch_and_add'

Reported-by: Mike Holmes <mike.holmes@linaro.org>
Signed-off-by: Kim Phillips <kim.phillips@linaro.org>
---
also available here:

git://git.linaro.org/people/kim.phillips/sparse.git

 lib.c                       | 21 +++++++++++++++++++--
 validation/builtin_atomic.c | 28 ++++++++++++++++++++++++++++
 2 files changed, 47 insertions(+), 2 deletions(-)
 create mode 100644 validation/builtin_atomic.c

diff --git a/lib.c b/lib.c
index fe20f93..bf3e91c 100644
--- a/lib.c
+++ b/lib.c
@@ -777,6 +777,25 @@ void declare_builtin_functions(void)
 	add_pre_buffer("extern unsigned int __builtin_bswap32(unsigned int);\n");
 	add_pre_buffer("extern unsigned long long __builtin_bswap64(unsigned long long);\n");
 
+	/* And atomic memory access functions.. */
+	add_pre_buffer("extern int __sync_fetch_and_add(void *, ...);\n");
+	add_pre_buffer("extern int __sync_fetch_and_sub(void *, ...);\n");
+	add_pre_buffer("extern int __sync_fetch_and_or(void *, ...);\n");
+	add_pre_buffer("extern int __sync_fetch_and_and(void *, ...);\n");
+	add_pre_buffer("extern int __sync_fetch_and_xor(void *, ...);\n");
+	add_pre_buffer("extern int __sync_fetch_and_nand(void *, ...);\n");
+	add_pre_buffer("extern int __sync_add_and_fetch(void *, ...);\n");
+	add_pre_buffer("extern int __sync_sub_and_fetch(void *, ...);\n");
+	add_pre_buffer("extern int __sync_or_and_fetch(void *, ...);\n");
+	add_pre_buffer("extern int __sync_and_and_fetch(void *, ...);\n");
+	add_pre_buffer("extern int __sync_xor_and_fetch(void *, ...);\n");
+	add_pre_buffer("extern int __sync_nand_and_fetch(void *, ...);\n");
+	add_pre_buffer("extern int __sync_bool_compare_and_swap(void *, ...);\n");
+	add_pre_buffer("extern int __sync_val_compare_and_swap(void *, ...);\n");
+	add_pre_buffer("extern void __sync_synchronize();\n");
+	add_pre_buffer("extern int __sync_lock_test_and_set(void *, ...);\n");
+	add_pre_buffer("extern void __sync_lock_release(void *, ...);\n");
+
 	/* And some random ones.. */
 	add_pre_buffer("extern void *__builtin_return_address(unsigned int);\n");
 	add_pre_buffer("extern void *__builtin_extract_return_addr(void *);\n");
@@ -794,8 +813,6 @@ void declare_builtin_functions(void)
 	add_pre_buffer("extern long __builtin_labs(long);\n");
 	add_pre_buffer("extern double __builtin_fabs(double);\n");
 	add_pre_buffer("extern __SIZE_TYPE__ __builtin_va_arg_pack_len(void);\n");
-	add_pre_buffer("extern void __sync_synchronize();\n");
-	add_pre_buffer("extern int __sync_bool_compare_and_swap(void *, ...);\n");
 
 	/* Add Blackfin-specific stuff */
 	add_pre_buffer(
diff --git a/validation/builtin_atomic.c b/validation/builtin_atomic.c
new file mode 100644
index 0000000..e56321a
--- /dev/null
+++ b/validation/builtin_atomic.c
@@ -0,0 +1,28 @@
+static void fn(void)
+{
+	static int i, *ptr = (void *)0;
+
+	i = __sync_fetch_and_add(ptr, 0);
+	i = __sync_fetch_and_sub(ptr, 0);
+	i = __sync_fetch_and_or(ptr, 0);
+	i = __sync_fetch_and_and(ptr, 0);
+	i = __sync_fetch_and_xor(ptr, 0);
+	i = __sync_fetch_and_nand(ptr, 0);
+	i = __sync_add_and_fetch(ptr, 0);
+	i = __sync_sub_and_fetch(ptr, 0);
+	i = __sync_or_and_fetch(ptr, 0);
+	i = __sync_and_and_fetch(ptr, 0);
+	i = __sync_xor_and_fetch(ptr, 0);
+	i = __sync_nand_and_fetch(ptr, 0);
+	i = __sync_bool_compare_and_swap(ptr, 0, 1);
+	i = __sync_val_compare_and_swap(ptr, 0, 1);
+	__sync_synchronize();
+	i = __sync_lock_test_and_set(ptr, 0);
+	__sync_lock_release(ptr);
+}
+
+/*
+ * check-name: __builtin_atomic
+ * check-error-start
+ * check-error-end
+ */
-- 
1.8.5.1

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse: add built-in atomic memory access identifiers
Date: Sat, 21 Dec 2013 17:22:55 +0000
Message-ID: <CANeU7QkkFaPrqZi0OW1-Myxm1ObdAHA4xLfCR2bS90PM_Y5VKw () mail ! gmail ! com>
--------------------
On Wed, Dec 11, 2013 at 1:00 PM, Kim Phillips <kim.phillips@linaro.org> wrote:
> this patch stops sparse from complaining about them not being
> defined:
>
> source/odp_spinlock.c:41:10: error: undefined identifier '__sync_lock_release'
> source/odp_spinlock.c:54:10: error: undefined identifier '__sync_lock_release'
> ./odp_atomic.h:112:16: error: undefined identifier '__sync_fetch_and_add'
>
> Reported-by: Mike Holmes <mike.holmes@linaro.org>
> Signed-off-by: Kim Phillips <kim.phillips@linaro.org>


Applied and pushed.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] sparse: add built-in byte swap identifiers ===

From: Kim Phillips <kim.phillips () freescale ! com>
To: linux-sparse
Subject: [PATCH] sparse: add built-in byte swap identifiers
Date: Tue, 19 Feb 2013 00:36:29 +0000
Message-ID: <20130218183629.d2a9238ac848758359582e28 () freescale ! com>
--------------------
this patch stops sparse from complaining about them not being
defined:

include/uapi/linux/swab.h:60:16: error: undefined identifier '__builtin_bswap32'
include/uapi/linux/swab.h:60:33: error: not a function <noident>

Signed-off-by: Kim Phillips <kim.phillips@freescale.com>
---
Based on:

git://git.kernel.org/pub/scm/devel/sparse/chrisl/sparse.git

since it's more up-to-date than:

git://git.kernel.org/pub/scm/devel/sparse/sparse.git

which is what's advertised as the main sparse tree, here:

https://sparse.wiki.kernel.org/index.php/Main_Page

 lib.c |    5 +++++
 1 file changed, 5 insertions(+)

diff --git a/lib.c b/lib.c
index 6bd10d3..4f69e11 100644
--- a/lib.c
+++ b/lib.c
@@ -727,6 +727,11 @@ void declare_builtin_functions(void)
 	add_pre_buffer("extern int __builtin_popcountl(unsigned long);\n");
 	add_pre_buffer("extern int __builtin_popcountll(unsigned long long);\n");
 
+	/* And byte swaps.. */
+	add_pre_buffer("extern unsigned short __builtin_bswap16(unsigned short);\n");
+	add_pre_buffer("extern unsigned int __builtin_bswap32(unsigned int);\n");
+	add_pre_buffer("extern unsigned long long __builtin_bswap64(unsigned long long);\n");
+
 	/* And some random ones.. */
 	add_pre_buffer("extern void *__builtin_return_address(unsigned int);\n");
 	add_pre_buffer("extern void *__builtin_extract_return_addr(void *);\n");
-- 
1.7.9.7

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [PATCH] sparse: add built-in byte swap identifiers
Date: Tue, 19 Feb 2013 05:59:00 +0000
Message-ID: <CANeU7Q=W8zZEngeweCGDkEpPGJMrADFgnibQVUFvGBwsppVq=A () mail ! gmail ! com>
--------------------
On Mon, Feb 18, 2013 at 4:36 PM, Kim Phillips
<kim.phillips@freescale.com> wrote:
>
> which is what's advertised as the main sparse tree, here:
>
> https://sparse.wiki.kernel.org/index.php/Main_Page
>
>  lib.c |    5 +++++
>  1 file changed, 5 insertions(+)
>
> diff --git a/lib.c b/lib.c
> index 6bd10d3..4f69e11 100644
> --- a/lib.c
> +++ b/lib.c
> @@ -727,6 +727,11 @@ void declare_builtin_functions(void)
>         add_pre_buffer("extern int __builtin_popcountl(unsigned long);\n");
>         add_pre_buffer("extern int __builtin_popcountll(unsigned long long);\n");
>
> +       /* And byte swaps.. */
> +       add_pre_buffer("extern unsigned short __builtin_bswap16(unsigned short);\n");
> +       add_pre_buffer("extern unsigned int __builtin_bswap32(unsigned int);\n");
> +       add_pre_buffer("extern unsigned long long __builtin_bswap64(unsigned long long);\n");
> +
>         /* And some random ones.. */

Looks good. Can you please add a test case for __buitin_bswap{16,32,64}?
You can look at "validations/" directory for the test case example.
To run the test case, use "make check".

Thanks

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCH] symbol.c: Set correct size of array from parenthesized string
 initializer ===

From: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
To: Unknown
Subject: [PATCH] symbol.c: Set correct size of array from parenthesized string
 initializer
Date: Thu, 16 May 2013 20:44:11 +0100
Message-ID: 
--------------------
Signed-off-by: Ramsay Jones <ramsay@ramsay1.demon.co.uk>
Signed-off-by: Christopher Li <sparse@chrisli.org>
---
 symbol.c                      | 30 ++++++++++++++++++++++++++----
 validation/init-char-array1.c | 27 +++++++++++++++++++++++++++
 2 files changed, 53 insertions(+), 4 deletions(-)
 create mode 100644 validation/init-char-array1.c

diff --git a/symbol.c b/symbol.c
index 80a2f23..2ec6200 100644
--- a/symbol.c
+++ b/symbol.c
@@ -296,9 +296,21 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 				if (entry->idx_to >= nr)
 					nr = entry->idx_to+1;
 				break;
+			case EXPR_PREOP: {
+				struct expression *e = entry;
+				if (is_char) {
+					while (e && e->type == EXPR_PREOP && e->op == '(')
+						e = e->unop;
+					if (e && e->type == EXPR_STRING) {
+						entry = e;
 			case EXPR_STRING:
-				if (is_char)
-					str_len = entry->string->length;
+						if (is_char)
+							str_len = entry->string->length;
+					}
+
+
+				}
+			}
 			default:
 				nr++;
 			}
@@ -307,9 +319,19 @@ static int count_array_initializer(struct symbol *t, struct expression *expr)
 			nr = str_len;
 		break;
 	}
+	case EXPR_PREOP:
+		if (is_char) { 
+			struct expression *e = expr;
+			while (e && e->type == EXPR_PREOP && e->op == '(')
+				e = e->unop;
+			if (e && e->type == EXPR_STRING) {
+				expr = e;
 	case EXPR_STRING:
-		if (is_char)
-			nr = expr->string->length;
+				if (is_char)
+					nr = expr->string->length;
+			}
+		}
+		break;
 	default:
 		break;
 	}
diff --git a/validation/init-char-array1.c b/validation/init-char-array1.c
new file mode 100644
index 0000000..24fd8d8
--- /dev/null
+++ b/validation/init-char-array1.c
@@ -0,0 +1,27 @@
+/*
+ * for array of char, ("...") as the initializer is an gcc language
+ * extension. check that a parenthesized string initializer is handled
+ * correctly and that -Wparen-string warns about it's use.
+ */
+static const char u[] = ("hello");
+static const char v[] = {"hello"};
+static const char v1[] = {("hello")};
+static const char w[] = "hello";
+static const char x[5] = "hello";
+
+static void f(void)
+{
+	char a[1/(sizeof(u) == 6)];
+	char b[1/(sizeof(v) == 6)];
+	char c[1/(sizeof(w) == 6)];
+	char d[1/(sizeof(x) == 5)];
+}
+/*
+ * check-name: parenthesized string initializer
+ * check-command: sparse -Wparen-string $file
+ *
+ * check-error-start
+init-char-array1.c:6:26: warning: array initialized from parenthesized string constant
+init-char-array1.c:8:28: warning: array initialized from parenthesized string constant
+ * check-error-end
+ */
-- 
1.8.1.4


--------------050800080209080905070203--
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [PATCHv2 0/5] sparse: Relicense from non-dfsg-free OSL 1.1 to MIT license ===

From: Franz Schrober <franzschrober () gmail ! com>
To: linux-sparse
Subject: [PATCHv2 0/5] sparse: Relicense from non-dfsg-free OSL 1.1 to MIT license
Date: Thu, 28 Nov 2013 10:16:17 +0000
Message-ID: <1385633782-775-1-git-send-email-franzschrober () gmail ! com>
--------------------
Hi,

many different people (especially Dan Carpenter) worked quite hard to contact
all people with significant contributions. The two changes are the ones which
should change the license from the problematic OSL[1] to the more liberal MIT
license. The initial agreement was reached when Novafora (successor in
interest to Transmeta Corporation) accepted such a license [2]. The commit
provided by them is attached as "relicense.bundle" [3] and has to be 
unbundled+merged in the sparse repository before the following patches can be
applied.

The changes can also be pulled from

        git pull https://github.com/franzschrober/sparse.git master

Btw. when somebody has to ask me in the future about a license change of these
two patches: do whatever you want. They can be considered public domain.

The change of this patchset compared to the first version are:

 * Benjamin Herrenschmidt and Chris Wedgwood were added to the Acked-by list
   because they've also agreed to the license change
 * Reverts for James Westby's contributions were added because it seems that he
   is the only person not agreeing to the license change (he was not reachable
   over social media or any of his email accounts)
 * An alternative patch for the implicit casting bug found James Westby was
   added

[1] https://wiki.debian.org/DFSGLicenses#Open_Software_License_.28OSL.29_v1.1
[2] http://lwn.net/Articles/328560/
[3] http://marc.info/?l=linux-sparse&m=138548610116314&w=2

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Franz Schrober <franzschrober () gmail ! com>
To: linux-sparse
Subject: Re: [PATCHv2 0/5] sparse: Relicense from non-dfsg-free OSL 1.1 to MIT license
Date: Sat, 30 Nov 2013 12:48:52 +0000
Message-ID: <CAJUvQwMn95jOYQnq_Y+k=VCtN4cbXEXOqoOREJxPQYudRxMLEA () mail ! gmail ! com>
--------------------
On Sat, Nov 30, 2013 at 12:13 AM, Christopher Li <sparse@chrisli.org> wrote:
> I push the result on the chrisl repository. Please check if I did any thing
> wrong. I will shortly push it to the official repository and cut a new
> release.

I think everything looks fine.

Thanks
--
Franz Schrober
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-sparse
Subject: Re: [PATCHv2 0/5] sparse: Relicense from non-dfsg-free OSL 1.1 to MIT license
Date: Tue, 03 Dec 2013 10:37:00 +0000
Message-ID: <20131203103700.GM28413 () mwanda>
--------------------
On Tue, Dec 03, 2013 at 09:17:59AM +0100, Franz Schrober wrote:
> >  * Reverts for James Westby's contributions were added because it seems that he
> >    is the only person not agreeing to the license change (he was not reachable
> >    over social media or any of his email accounts)
> 
> It seems James Westby detected that his changes were removed (at least it is my
> personal explanation) and now started to respond. I've attached his response and
> will resubmit his README patch in some minutes.

Actually I kept on harrassing him via his co-workers.  :P

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [RFC PATCH] sparse: Add cmd line  --version option ===

From: Joe Perches <joe () perches ! com>
To: linux-sparse
Subject: [RFC PATCH] sparse: Add cmd line  --version option
Date: Wed, 06 Mar 2013 17:22:58 +0000
Message-ID: <1362590578.1759.48.camel () joe-AO722>
--------------------
There's no current way to know the version
of sparse.  Add --version to see it.

---

I'm not at all tied to this implementation
but it's always nice to be able to see what
version is being used.

Likely it needs something to always recompile
lib.o whenever appropriate.

 Makefile | 11 +++++++++--
 lib.c    |  7 +++++++
 2 files changed, 16 insertions(+), 2 deletions(-)

diff --git a/Makefile b/Makefile
index b195528..8d2ffea 100644
--- a/Makefile
+++ b/Makefile
@@ -1,5 +1,12 @@
 VERSION=0.4.4
 
+HAVE_GIT:=$(shell git describe >/dev/null 2>&1 && echo 'yes')
+ifeq ($(HAVE_GIT),yes)
+SPARSE_VERSION=$(shell git describe)
+else
+SPARSE_VERSION=$(VERSION)
+endif
+
 OS = linux
 
 
@@ -27,7 +34,8 @@ HAVE_LLVM_VERSION:=$(shell llvm-config --version | grep "^[3-9].*" >/dev/null 2>
 LLVM_VERSION=$(shell llvm-config --version)
 
 GCC_BASE = $(shell $(CC) --print-file-name=)
-BASIC_CFLAGS = -DGCC_BASE=\"$(GCC_BASE)\"
+BASIC_CFLAGS = -DGCC_BASE=\"$(GCC_BASE)\" \
+	       -DSPARSE_VERSION=\"$(SPARSE_VERSION)\"
 
 ifeq ($(HAVE_GCC_DEP),yes)
 BASIC_CFLAGS += -Wp,-MD,$(@D)/.$(@F).d
@@ -160,7 +168,6 @@ install: all-installable
 sparse.pc: sparse.pc.in
 	$(QUIET_GEN)sed $(SED_PC_CMD) sparse.pc.in > sparse.pc
 
-
 compile_EXTRA_DEPS = compile-i386.o
 
 $(foreach p,$(PROGRAMS),$(eval $(p): $($(p)_EXTRA_DEPS) $(LIBS)))
diff --git a/lib.c b/lib.c
index 4f69e11..ddc9a93 100644
--- a/lib.c
+++ b/lib.c
@@ -646,6 +646,12 @@ static char **handle_base_dir(char *arg, char **next)
 	return next;
 }
 
+static char **handle_version(char *arg, char **next)
+{
+	die("%s", SPARSE_VERSION);
+	return next;
+}
+
 struct switches {
 	const char *name;
 	char **(*fn)(char *, char **);
@@ -656,6 +662,7 @@ static char **handle_switch(char *arg, char **next)
 	static struct switches cmd[] = {
 		{ "nostdinc", handle_nostdinc },
 		{ "gcc-base-dir", handle_base_dir},
+		{ "-version", handle_version },
 		{ NULL, NULL }
 	};
 	struct switches *s;


--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Joe Perches <joe () perches ! com>
To: linux-sparse
Subject: Re: [RFC PATCH] sparse: Add cmd line  --version option
Date: Wed, 06 Mar 2013 21:57:23 +0000
Message-ID: <1362607043.2093.19.camel () joe-AO722>
--------------------
On Wed, 2013-03-06 at 13:45 -0800, Josh Triplett wrote:
> On Wed, Mar 06, 2013 at 09:22:58AM -0800, Joe Perches wrote:
> > --- a/Makefile
> > +++ b/Makefile
> > @@ -1,5 +1,12 @@
> >  VERSION=0.4.4
> >  
> > +HAVE_GIT:=$(shell git describe >/dev/null 2>&1 && echo 'yes')
> > +ifeq ($(HAVE_GIT),yes)
> > +SPARSE_VERSION=$(shell git describe)
> > +else
> > +SPARSE_VERSION=$(VERSION)
> > +endif
> > +
> 
> The "dist" target already has a call to "git describe"; could you unify
> the two?  (And, ideally, avoid calling git describe twice, once for
> HAVE_GIT and once for SPARSE_VERSION?)

I think the overhead is low and not worth the bother.

Go for it if it bothers you.

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [RFC PATCH] sparse: Add cmd line --version option ===

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: [RFC PATCH] sparse: Add cmd line --version option
Date: Thu, 07 Mar 2013 05:10:45 +0000
Message-ID: <CANeU7QksQ5rnxNF1p5=MxHkWtPCOykeLWewy6m-gkNpOg_obGg () mail ! gmail ! com>
--------------------
On Wed, Mar 6, 2013 at 8:33 PM, Joe Perches <joe@perches.com> wrote:
> On Wed, 2013-03-06 at 20:18 -0800, Chris Li wrote:

> It's your patch now, I was just maybe an instigator.
> Looks good though.

Thanks. I start from your patch. I will just keep you
as the author for patch.

> Reviewed-by: Joe Perches <joe@perches.com>
>
> Maybe something like:
>
> git describe | cut -f1 -d"-"

You mean the first VERSION in the Makefile?
I want it to be there because sparse also release as
tar.gz package without the git tree. It is useful to keep a
version string outside of the git repository.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [RFC] adding into middle of RCU list ===

From: "Paul E. McKenney" <paulmck () linux ! vnet ! ibm ! com>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Fri, 30 Aug 2013 00:57:33 +0000
Message-ID: <20130830005733.GA20664 () linux ! vnet ! ibm ! com>
--------------------
On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > * Paul E. McKenney (paulmck@linux.vnet.ibm.com) wrote:
> > > On Thu, Aug 22, 2013 at 09:33:18PM -0700, Stephen Hemminger wrote:

[ . . . ]

> > > > +
> > > > +/**
> > > > + * Splice an RCU-protected list into an existing list.
> > > > + *
> > > > + * Note that this function blocks in synchronize_rcu()
> > > > + *
> > > > + * Important note: this function is not called concurrently
> > > > + *       with other updates to the list.
> > > > + */
> > > > +static inline void caa_list_splice_init_rcu(struct cds_list_head *list,
> > > > +					    struct cds_list_head *head)
> > > > +{
> > > > +	struct cds_list_head *first = list->next;
> > > > +	struct cds_list_head *last = list->prev;
> > > > +	struct cds_list_head *at = head->next;
> > > > +
> > > > +	if (cds_list_empty(list))
> > > > +		return;
> > > > +
> > > > +	/* "first" and "last" tracking list, so initialize it. */
> > > > +	CDS_INIT_LIST_HEAD(list);
> > > 
> > > This change is happening in the presence of readers on the list, right?
> > > For this to work reliably in the presence of mischievous compilers,
> > > wouldn't CDS_INIT_LIST_HEAD() need to use CMM_ACCESS_ONCE() for its
> > > pointer accesses?
> > 
> > Actually, we have rcu_assign_pointer()/rcu_set_pointer() exactly for
> > this. They even skip the memory barrier if they store a NULL pointer.
> > 
> > > Hmmm...  The kernel version seems to have the same issue...
> > 
> > The compiler memory model of the Linux kernel AFAIK does not require an
> > ACCESS_ONCE() for stores to word-aligned, word-sized integers/pointers,
> > even if those are expected to be read concurrently. For reference, see:
> > 
> > #define __rcu_assign_pointer(p, v, space) \
> >         do { \
> >                 smp_wmb(); \
> >                 (p) = (typeof(*v) __force space *)(v); \
> >         } while (0)
> 
> Or I need to fix this one as well.  ;-)

In that vein...  Is there anything like typeof() that also preserves
sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
"p" in the assignment above results in sparse errors.

							Thanx, Paul

							Thanx, Paul

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "Paul E. McKenney" <paulmck () linux ! vnet ! ibm ! com>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Fri, 30 Aug 2013 00:57:33 +0000
Message-ID: <20130830005733.GA20664 () linux ! vnet ! ibm ! com>
--------------------
On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > * Paul E. McKenney (paulmck@linux.vnet.ibm.com) wrote:
> > > On Thu, Aug 22, 2013 at 09:33:18PM -0700, Stephen Hemminger wrote:

[ . . . ]

> > > > +
> > > > +/**
> > > > + * Splice an RCU-protected list into an existing list.
> > > > + *
> > > > + * Note that this function blocks in synchronize_rcu()
> > > > + *
> > > > + * Important note: this function is not called concurrently
> > > > + *       with other updates to the list.
> > > > + */
> > > > +static inline void caa_list_splice_init_rcu(struct cds_list_head *list,
> > > > +					    struct cds_list_head *head)
> > > > +{
> > > > +	struct cds_list_head *first = list->next;
> > > > +	struct cds_list_head *last = list->prev;
> > > > +	struct cds_list_head *at = head->next;
> > > > +
> > > > +	if (cds_list_empty(list))
> > > > +		return;
> > > > +
> > > > +	/* "first" and "last" tracking list, so initialize it. */
> > > > +	CDS_INIT_LIST_HEAD(list);
> > > 
> > > This change is happening in the presence of readers on the list, right?
> > > For this to work reliably in the presence of mischievous compilers,
> > > wouldn't CDS_INIT_LIST_HEAD() need to use CMM_ACCESS_ONCE() for its
> > > pointer accesses?
> > 
> > Actually, we have rcu_assign_pointer()/rcu_set_pointer() exactly for
> > this. They even skip the memory barrier if they store a NULL pointer.
> > 
> > > Hmmm...  The kernel version seems to have the same issue...
> > 
> > The compiler memory model of the Linux kernel AFAIK does not require an
> > ACCESS_ONCE() for stores to word-aligned, word-sized integers/pointers,
> > even if those are expected to be read concurrently. For reference, see:
> > 
> > #define __rcu_assign_pointer(p, v, space) \
> >         do { \
> >                 smp_wmb(); \
> >                 (p) = (typeof(*v) __force space *)(v); \
> >         } while (0)
> 
> Or I need to fix this one as well.  ;-)

In that vein...  Is there anything like typeof() that also preserves
sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
"p" in the assignment above results in sparse errors.

							Thanx, Paul

							Thanx, Paul

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Fri, 30 Aug 2013 02:16:37 +0000
Message-ID: <20130830021637.GA21862 () leaf>
--------------------
On Thu, Aug 29, 2013 at 05:57:33PM -0700, Paul E. McKenney wrote:
> On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> > On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > > #define __rcu_assign_pointer(p, v, space) \
> > >         do { \
> > >                 smp_wmb(); \
> > >                 (p) = (typeof(*v) __force space *)(v); \
> > >         } while (0)
> > 
> > Or I need to fix this one as well.  ;-)
> 
> In that vein...  Is there anything like typeof() that also preserves
> sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
> "p" in the assignment above results in sparse errors.

typeof() will preserve sparse's notion of address space as long as you
do typeof(p), not typeof(*p):

$ cat test.c
#define as(n) __attribute__((address_space(n),noderef))
#define __force __attribute__((force))

int main(void)
{
    int target = 0;
    int as(1) *foo = (__force typeof(target) as(1) *) &target;
    typeof(foo) bar = foo;
    return *bar;
}
$ sparse test.c
test.c:9:13: warning: dereference of noderef expression

Notice that sparse didn't warn on the assignment of foo to bar (because
typeof propagated the address space of 1), and warned on the dereference
of bar (because typeof propagated noderef).

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "Paul E. McKenney" <paulmck () linux ! vnet ! ibm ! com>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Sat, 31 Aug 2013 21:32:28 +0000
Message-ID: <20130831213228.GF3871 () linux ! vnet ! ibm ! com>
--------------------
On Thu, Aug 29, 2013 at 07:16:37PM -0700, Josh Triplett wrote:
> On Thu, Aug 29, 2013 at 05:57:33PM -0700, Paul E. McKenney wrote:
> > On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> > > On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > > > #define __rcu_assign_pointer(p, v, space) \
> > > >         do { \
> > > >                 smp_wmb(); \
> > > >                 (p) = (typeof(*v) __force space *)(v); \
> > > >         } while (0)
> > > 
> > > Or I need to fix this one as well.  ;-)
> > 
> > In that vein...  Is there anything like typeof() that also preserves
> > sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
> > "p" in the assignment above results in sparse errors.
> 
> typeof() will preserve sparse's notion of address space as long as you
> do typeof(p), not typeof(*p):
> 
> $ cat test.c
> #define as(n) __attribute__((address_space(n),noderef))
> #define __force __attribute__((force))
> 
> int main(void)
> {
>     int target = 0;
>     int as(1) *foo = (__force typeof(target) as(1) *) &target;
>     typeof(foo) bar = foo;
>     return *bar;
> }
> $ sparse test.c
> test.c:9:13: warning: dereference of noderef expression
> 
> Notice that sparse didn't warn on the assignment of foo to bar (because
> typeof propagated the address space of 1), and warned on the dereference
> of bar (because typeof propagated noderef).

Thank you for the info!

Suppose that I want to do something like this:

#define __rcu_assign_pointer(p, v, space) \
        do { \
                smp_wmb(); \
                ACCESS_ONCE(p) = (typeof(*v) __force space *)(v); \
        } while (0)

Now, this does typeof(*p), so as you noted above sparse complains about
address-space mismatches.  Thus far, I haven't been able to come up with
something that (1) does sparse address-space checking, (2) does C type
checking, and (3) forces the assignment to be volatile.

Any thoughts on how to do this?

							Thanx, Paul

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "Paul E. McKenney" <paulmck () linux ! vnet ! ibm ! com>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Sat, 31 Aug 2013 21:32:28 +0000
Message-ID: <20130831213228.GF3871 () linux ! vnet ! ibm ! com>
--------------------
On Thu, Aug 29, 2013 at 07:16:37PM -0700, Josh Triplett wrote:
> On Thu, Aug 29, 2013 at 05:57:33PM -0700, Paul E. McKenney wrote:
> > On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> > > On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > > > #define __rcu_assign_pointer(p, v, space) \
> > > >         do { \
> > > >                 smp_wmb(); \
> > > >                 (p) = (typeof(*v) __force space *)(v); \
> > > >         } while (0)
> > > 
> > > Or I need to fix this one as well.  ;-)
> > 
> > In that vein...  Is there anything like typeof() that also preserves
> > sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
> > "p" in the assignment above results in sparse errors.
> 
> typeof() will preserve sparse's notion of address space as long as you
> do typeof(p), not typeof(*p):
> 
> $ cat test.c
> #define as(n) __attribute__((address_space(n),noderef))
> #define __force __attribute__((force))
> 
> int main(void)
> {
>     int target = 0;
>     int as(1) *foo = (__force typeof(target) as(1) *) &target;
>     typeof(foo) bar = foo;
>     return *bar;
> }
> $ sparse test.c
> test.c:9:13: warning: dereference of noderef expression
> 
> Notice that sparse didn't warn on the assignment of foo to bar (because
> typeof propagated the address space of 1), and warned on the dereference
> of bar (because typeof propagated noderef).

Thank you for the info!

Suppose that I want to do something like this:

#define __rcu_assign_pointer(p, v, space) \
        do { \
                smp_wmb(); \
                ACCESS_ONCE(p) = (typeof(*v) __force space *)(v); \
        } while (0)

Now, this does typeof(*p), so as you noted above sparse complains about
address-space mismatches.  Thus far, I haven't been able to come up with
something that (1) does sparse address-space checking, (2) does C type
checking, and (3) forces the assignment to be volatile.

Any thoughts on how to do this?

							Thanx, Paul

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Sun, 01 Sep 2013 20:42:10 +0000
Message-ID: <20130901204209.GA20802 () leaf>
--------------------
On Sat, Aug 31, 2013 at 02:32:28PM -0700, Paul E. McKenney wrote:
> On Thu, Aug 29, 2013 at 07:16:37PM -0700, Josh Triplett wrote:
> > On Thu, Aug 29, 2013 at 05:57:33PM -0700, Paul E. McKenney wrote:
> > > On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> > > > On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > > > > #define __rcu_assign_pointer(p, v, space) \
> > > > >         do { \
> > > > >                 smp_wmb(); \
> > > > >                 (p) = (typeof(*v) __force space *)(v); \
> > > > >         } while (0)
> > > > 
> > > > Or I need to fix this one as well.  ;-)
> > > 
> > > In that vein...  Is there anything like typeof() that also preserves
> > > sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
> > > "p" in the assignment above results in sparse errors.
> > 
> > typeof() will preserve sparse's notion of address space as long as you
> > do typeof(p), not typeof(*p):
> > 
> > $ cat test.c
> > #define as(n) __attribute__((address_space(n),noderef))
> > #define __force __attribute__((force))
> > 
> > int main(void)
> > {
> >     int target = 0;
> >     int as(1) *foo = (__force typeof(target) as(1) *) &target;
> >     typeof(foo) bar = foo;
> >     return *bar;
> > }
> > $ sparse test.c
> > test.c:9:13: warning: dereference of noderef expression
> > 
> > Notice that sparse didn't warn on the assignment of foo to bar (because
> > typeof propagated the address space of 1), and warned on the dereference
> > of bar (because typeof propagated noderef).
> 
> Thank you for the info!
> 
> Suppose that I want to do something like this:
> 
> #define __rcu_assign_pointer(p, v, space) \
>         do { \
>                 smp_wmb(); \
>                 ACCESS_ONCE(p) = (typeof(*v) __force space *)(v); \
>         } while (0)
> 
> Now, this does typeof(*p), so as you noted above sparse complains about
> address-space mismatches.  Thus far, I haven't been able to come up with
> something that (1) does sparse address-space checking, (2) does C type
> checking, and (3) forces the assignment to be volatile.
> 
> Any thoughts on how to do this?

First of all, if p and v had compatible types *including* address
spaces, you wouldn't need the "space" argument; the following
self-contained test case passes both sparse and GCC typechecking:

#define as(n) __attribute__((address_space(n),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        ACCESS_ONCE(p) = (v); \
    } while (0)

struct foo;

int main(void)
{
    struct foo as(1) *dest;
    struct foo as(1) *src = (void *)0;

    rcu_assign_pointer(dest, src);

    return 0;
}



But in this case, you want dest and src to have compatible types except
that dest must have the __rcu address space and src might not.  So,
let's change the types of dest and src, and add the appropriate cast.
The following also passes both GCC and sparse:

#define __rcu __attribute__((address_space(4),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
    } while (0)

struct foo { int x; };

int main(void)
{
    struct foo __rcu *dest;
    struct foo *src = (void *)0;

    rcu_assign_pointer(dest, src);

    return 0;
}


However, that cast forces the source to have the __rcu address space
without checking what address space it started out with.  If you want to
verify that the source has the kernel address space, you can cast to
that address space first, *without* __force, which will warn if the
source doesn't start out with that address space:

#define __kernel __attribute__((address_space(0)))
#define __user __attribute__((address_space(1),noderef))
#define __rcu __attribute__((address_space(4),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(typeof(*(v)) __kernel *)(v); \
    } while (0)

struct foo { int x; };

int main(void)
{
    struct foo __rcu *dest;
    struct foo *src = (void *)0;
    struct foo __user *badsrc = (void *)0;

    rcu_assign_pointer(dest, src);
    rcu_assign_pointer(dest, badsrc);

    return 0;
}


This produces a warning on the line using badsrc:

test.c:23:5: warning: cast removes address space of expression

However, that doesn't seem like the most obvious warning, since
rcu_assign_pointer doesn't look like a cast, and since it doesn't print
the full types involved like most address space warnings do.  So,
instead, let's add and use a __chk_kernel_ptr function, similar to
__chk_user_ptr in compiler.h:

#define __kernel __attribute__((address_space(0)))
#define __user __attribute__((address_space(1),noderef))
#define __rcu __attribute__((address_space(4),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void __chk_kernel_ptr(const volatile void *);
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        __chk_kernel_ptr(v); \
        ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
    } while (0)

struct foo { int x; };

int main(void)
{
    struct foo __rcu *dest;
    struct foo *src = (void *)0;
    struct foo __user *badsrc = (void *)0;

    rcu_assign_pointer(dest, src);
    rcu_assign_pointer(dest, badsrc);

    return 0;
}


This produces a somewhat better warning:

test.c:25:5: warning: incorrect type in argument 1 (different address spaces)
test.c:25:5:    expected void const volatile *<noident>
test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc

That at least shows the full type of badsrc, but it still seems
suboptimal for two reasons: it says it expects "void const volatile *"
rather than the actual type it wants, and it says "in argument 1" (of
__chk_kernel_ptr), which seems unnecessarily confusing when the type
error actually applies to argument 2 of rcu_assign_pointer.  We can do
better by declaring a fake local function for checking, instead:

#define __kernel __attribute__((address_space(0)))
#define __user __attribute__((address_space(1),noderef))
#define __rcu __attribute__((address_space(4),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        extern void __rcu_assign_pointer_typecheck(int, typeof(*(v)) __kernel *); \
        __rcu_assign_pointer_typecheck(0, v); \
        ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
    } while (0)

struct foo { int x; };

int main(void)
{
    struct foo __rcu *dest;
    struct foo *src = (void *)0;
    struct foo __user *badsrc = (void *)0;

    rcu_assign_pointer(dest, src);
    rcu_assign_pointer(dest, badsrc);

    return 0;
}


This last approach produces a very clear warning:

test.c:25:5: warning: incorrect type in argument 2 (different address spaces)
test.c:25:5:    expected struct foo *<noident>
test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc

If you want, you can even add an argument name for the second argument
of __rcu_assign_pointer_typecheck, and it'll replace the <noident> in
the second line of the warning.

So, that last approach meets all the criteria you mentioned:
> something that (1) does sparse address-space checking, (2) does C type
> checking, and (3) forces the assignment to be volatile.

Will that work for all the use cases you have in mind?  If so, I'll
submit a patch changing rcu_assign_pointer to use that approach.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Sun, 01 Sep 2013 20:42:10 +0000
Message-ID: <20130901204209.GA20802 () leaf>
--------------------
On Sat, Aug 31, 2013 at 02:32:28PM -0700, Paul E. McKenney wrote:
> On Thu, Aug 29, 2013 at 07:16:37PM -0700, Josh Triplett wrote:
> > On Thu, Aug 29, 2013 at 05:57:33PM -0700, Paul E. McKenney wrote:
> > > On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> > > > On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > > > > #define __rcu_assign_pointer(p, v, space) \
> > > > >         do { \
> > > > >                 smp_wmb(); \
> > > > >                 (p) = (typeof(*v) __force space *)(v); \
> > > > >         } while (0)
> > > > 
> > > > Or I need to fix this one as well.  ;-)
> > > 
> > > In that vein...  Is there anything like typeof() that also preserves
> > > sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
> > > "p" in the assignment above results in sparse errors.
> > 
> > typeof() will preserve sparse's notion of address space as long as you
> > do typeof(p), not typeof(*p):
> > 
> > $ cat test.c
> > #define as(n) __attribute__((address_space(n),noderef))
> > #define __force __attribute__((force))
> > 
> > int main(void)
> > {
> >     int target = 0;
> >     int as(1) *foo = (__force typeof(target) as(1) *) &target;
> >     typeof(foo) bar = foo;
> >     return *bar;
> > }
> > $ sparse test.c
> > test.c:9:13: warning: dereference of noderef expression
> > 
> > Notice that sparse didn't warn on the assignment of foo to bar (because
> > typeof propagated the address space of 1), and warned on the dereference
> > of bar (because typeof propagated noderef).
> 
> Thank you for the info!
> 
> Suppose that I want to do something like this:
> 
> #define __rcu_assign_pointer(p, v, space) \
>         do { \
>                 smp_wmb(); \
>                 ACCESS_ONCE(p) = (typeof(*v) __force space *)(v); \
>         } while (0)
> 
> Now, this does typeof(*p), so as you noted above sparse complains about
> address-space mismatches.  Thus far, I haven't been able to come up with
> something that (1) does sparse address-space checking, (2) does C type
> checking, and (3) forces the assignment to be volatile.
> 
> Any thoughts on how to do this?

First of all, if p and v had compatible types *including* address
spaces, you wouldn't need the "space" argument; the following
self-contained test case passes both sparse and GCC typechecking:

#define as(n) __attribute__((address_space(n),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        ACCESS_ONCE(p) = (v); \
    } while (0)

struct foo;

int main(void)
{
    struct foo as(1) *dest;
    struct foo as(1) *src = (void *)0;

    rcu_assign_pointer(dest, src);

    return 0;
}



But in this case, you want dest and src to have compatible types except
that dest must have the __rcu address space and src might not.  So,
let's change the types of dest and src, and add the appropriate cast.
The following also passes both GCC and sparse:

#define __rcu __attribute__((address_space(4),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
    } while (0)

struct foo { int x; };

int main(void)
{
    struct foo __rcu *dest;
    struct foo *src = (void *)0;

    rcu_assign_pointer(dest, src);

    return 0;
}


However, that cast forces the source to have the __rcu address space
without checking what address space it started out with.  If you want to
verify that the source has the kernel address space, you can cast to
that address space first, *without* __force, which will warn if the
source doesn't start out with that address space:

#define __kernel __attribute__((address_space(0)))
#define __user __attribute__((address_space(1),noderef))
#define __rcu __attribute__((address_space(4),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(typeof(*(v)) __kernel *)(v); \
    } while (0)

struct foo { int x; };

int main(void)
{
    struct foo __rcu *dest;
    struct foo *src = (void *)0;
    struct foo __user *badsrc = (void *)0;

    rcu_assign_pointer(dest, src);
    rcu_assign_pointer(dest, badsrc);

    return 0;
}


This produces a warning on the line using badsrc:

test.c:23:5: warning: cast removes address space of expression

However, that doesn't seem like the most obvious warning, since
rcu_assign_pointer doesn't look like a cast, and since it doesn't print
the full types involved like most address space warnings do.  So,
instead, let's add and use a __chk_kernel_ptr function, similar to
__chk_user_ptr in compiler.h:

#define __kernel __attribute__((address_space(0)))
#define __user __attribute__((address_space(1),noderef))
#define __rcu __attribute__((address_space(4),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void __chk_kernel_ptr(const volatile void *);
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        __chk_kernel_ptr(v); \
        ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
    } while (0)

struct foo { int x; };

int main(void)
{
    struct foo __rcu *dest;
    struct foo *src = (void *)0;
    struct foo __user *badsrc = (void *)0;

    rcu_assign_pointer(dest, src);
    rcu_assign_pointer(dest, badsrc);

    return 0;
}


This produces a somewhat better warning:

test.c:25:5: warning: incorrect type in argument 1 (different address spaces)
test.c:25:5:    expected void const volatile *<noident>
test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc

That at least shows the full type of badsrc, but it still seems
suboptimal for two reasons: it says it expects "void const volatile *"
rather than the actual type it wants, and it says "in argument 1" (of
__chk_kernel_ptr), which seems unnecessarily confusing when the type
error actually applies to argument 2 of rcu_assign_pointer.  We can do
better by declaring a fake local function for checking, instead:

#define __kernel __attribute__((address_space(0)))
#define __user __attribute__((address_space(1),noderef))
#define __rcu __attribute__((address_space(4),noderef))
#define __force __attribute__((force))
#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
extern void smp_wmb(void);

#define rcu_assign_pointer(p, v) \
    do { \
        smp_wmb(); \
        extern void __rcu_assign_pointer_typecheck(int, typeof(*(v)) __kernel *); \
        __rcu_assign_pointer_typecheck(0, v); \
        ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
    } while (0)

struct foo { int x; };

int main(void)
{
    struct foo __rcu *dest;
    struct foo *src = (void *)0;
    struct foo __user *badsrc = (void *)0;

    rcu_assign_pointer(dest, src);
    rcu_assign_pointer(dest, badsrc);

    return 0;
}


This last approach produces a very clear warning:

test.c:25:5: warning: incorrect type in argument 2 (different address spaces)
test.c:25:5:    expected struct foo *<noident>
test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc

If you want, you can even add an argument name for the second argument
of __rcu_assign_pointer_typecheck, and it'll replace the <noident> in
the second line of the warning.

So, that last approach meets all the criteria you mentioned:
> something that (1) does sparse address-space checking, (2) does C type
> checking, and (3) forces the assignment to be volatile.

Will that work for all the use cases you have in mind?  If so, I'll
submit a patch changing rcu_assign_pointer to use that approach.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "Paul E. McKenney" <paulmck () linux ! vnet ! ibm ! com>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Sun, 01 Sep 2013 22:26:19 +0000
Message-ID: <20130901222619.GH3871 () linux ! vnet ! ibm ! com>
--------------------
On Sun, Sep 01, 2013 at 01:42:10PM -0700, Josh Triplett wrote:
> On Sat, Aug 31, 2013 at 02:32:28PM -0700, Paul E. McKenney wrote:
> > On Thu, Aug 29, 2013 at 07:16:37PM -0700, Josh Triplett wrote:
> > > On Thu, Aug 29, 2013 at 05:57:33PM -0700, Paul E. McKenney wrote:
> > > > On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> > > > > On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > > > > > #define __rcu_assign_pointer(p, v, space) \
> > > > > >         do { \
> > > > > >                 smp_wmb(); \
> > > > > >                 (p) = (typeof(*v) __force space *)(v); \
> > > > > >         } while (0)
> > > > > 
> > > > > Or I need to fix this one as well.  ;-)
> > > > 
> > > > In that vein...  Is there anything like typeof() that also preserves
> > > > sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
> > > > "p" in the assignment above results in sparse errors.
> > > 
> > > typeof() will preserve sparse's notion of address space as long as you
> > > do typeof(p), not typeof(*p):
> > > 
> > > $ cat test.c
> > > #define as(n) __attribute__((address_space(n),noderef))
> > > #define __force __attribute__((force))
> > > 
> > > int main(void)
> > > {
> > >     int target = 0;
> > >     int as(1) *foo = (__force typeof(target) as(1) *) &target;
> > >     typeof(foo) bar = foo;
> > >     return *bar;
> > > }
> > > $ sparse test.c
> > > test.c:9:13: warning: dereference of noderef expression
> > > 
> > > Notice that sparse didn't warn on the assignment of foo to bar (because
> > > typeof propagated the address space of 1), and warned on the dereference
> > > of bar (because typeof propagated noderef).
> > 
> > Thank you for the info!
> > 
> > Suppose that I want to do something like this:
> > 
> > #define __rcu_assign_pointer(p, v, space) \
> >         do { \
> >                 smp_wmb(); \
> >                 ACCESS_ONCE(p) = (typeof(*v) __force space *)(v); \
> >         } while (0)
> > 
> > Now, this does typeof(*p), so as you noted above sparse complains about
> > address-space mismatches.  Thus far, I haven't been able to come up with
> > something that (1) does sparse address-space checking, (2) does C type
> > checking, and (3) forces the assignment to be volatile.
> > 
> > Any thoughts on how to do this?
> 
> First of all, if p and v had compatible types *including* address
> spaces, you wouldn't need the "space" argument; the following
> self-contained test case passes both sparse and GCC typechecking:
> 
> #define as(n) __attribute__((address_space(n),noderef))
> #define __force __attribute__((force))
> #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> extern void smp_wmb(void);
> 
> #define rcu_assign_pointer(p, v) \
>     do { \
>         smp_wmb(); \
>         ACCESS_ONCE(p) = (v); \
>     } while (0)
> 
> struct foo;
> 
> int main(void)
> {
>     struct foo as(1) *dest;
>     struct foo as(1) *src = (void *)0;
> 
>     rcu_assign_pointer(dest, src);
> 
>     return 0;
> }
> 
> 
> 
> But in this case, you want dest and src to have compatible types except
> that dest must have the __rcu address space and src might not.  So,
> let's change the types of dest and src, and add the appropriate cast.
> The following also passes both GCC and sparse:
> 
> #define __rcu __attribute__((address_space(4),noderef))
> #define __force __attribute__((force))
> #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> extern void smp_wmb(void);
> 
> #define rcu_assign_pointer(p, v) \
>     do { \
>         smp_wmb(); \
>         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
>     } while (0)
> 
> struct foo { int x; };
> 
> int main(void)
> {
>     struct foo __rcu *dest;
>     struct foo *src = (void *)0;
> 
>     rcu_assign_pointer(dest, src);
> 
>     return 0;
> }
> 
> 
> However, that cast forces the source to have the __rcu address space
> without checking what address space it started out with.  If you want to
> verify that the source has the kernel address space, you can cast to
> that address space first, *without* __force, which will warn if the
> source doesn't start out with that address space:
> 
> #define __kernel __attribute__((address_space(0)))
> #define __user __attribute__((address_space(1),noderef))
> #define __rcu __attribute__((address_space(4),noderef))
> #define __force __attribute__((force))
> #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> extern void smp_wmb(void);
> 
> #define rcu_assign_pointer(p, v) \
>     do { \
>         smp_wmb(); \
>         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(typeof(*(v)) __kernel *)(v); \
>     } while (0)
> 
> struct foo { int x; };
> 
> int main(void)
> {
>     struct foo __rcu *dest;
>     struct foo *src = (void *)0;
>     struct foo __user *badsrc = (void *)0;
> 
>     rcu_assign_pointer(dest, src);
>     rcu_assign_pointer(dest, badsrc);
> 
>     return 0;
> }
> 
> 
> This produces a warning on the line using badsrc:
> 
> test.c:23:5: warning: cast removes address space of expression
> 
> However, that doesn't seem like the most obvious warning, since
> rcu_assign_pointer doesn't look like a cast, and since it doesn't print
> the full types involved like most address space warnings do.  So,
> instead, let's add and use a __chk_kernel_ptr function, similar to
> __chk_user_ptr in compiler.h:
> 
> #define __kernel __attribute__((address_space(0)))
> #define __user __attribute__((address_space(1),noderef))
> #define __rcu __attribute__((address_space(4),noderef))
> #define __force __attribute__((force))
> #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> extern void __chk_kernel_ptr(const volatile void *);
> extern void smp_wmb(void);
> 
> #define rcu_assign_pointer(p, v) \
>     do { \
>         smp_wmb(); \
>         __chk_kernel_ptr(v); \
>         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
>     } while (0)
> 
> struct foo { int x; };
> 
> int main(void)
> {
>     struct foo __rcu *dest;
>     struct foo *src = (void *)0;
>     struct foo __user *badsrc = (void *)0;
> 
>     rcu_assign_pointer(dest, src);
>     rcu_assign_pointer(dest, badsrc);
> 
>     return 0;
> }
> 
> 
> This produces a somewhat better warning:
> 
> test.c:25:5: warning: incorrect type in argument 1 (different address spaces)
> test.c:25:5:    expected void const volatile *<noident>
> test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc
> 
> That at least shows the full type of badsrc, but it still seems
> suboptimal for two reasons: it says it expects "void const volatile *"
> rather than the actual type it wants, and it says "in argument 1" (of
> __chk_kernel_ptr), which seems unnecessarily confusing when the type
> error actually applies to argument 2 of rcu_assign_pointer.  We can do
> better by declaring a fake local function for checking, instead:
> 
> #define __kernel __attribute__((address_space(0)))
> #define __user __attribute__((address_space(1),noderef))
> #define __rcu __attribute__((address_space(4),noderef))
> #define __force __attribute__((force))
> #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> extern void smp_wmb(void);
> 
> #define rcu_assign_pointer(p, v) \
>     do { \
>         smp_wmb(); \
>         extern void __rcu_assign_pointer_typecheck(int, typeof(*(v)) __kernel *); \
>         __rcu_assign_pointer_typecheck(0, v); \
>         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
>     } while (0)
> 
> struct foo { int x; };
> 
> int main(void)
> {
>     struct foo __rcu *dest;
>     struct foo *src = (void *)0;
>     struct foo __user *badsrc = (void *)0;
> 
>     rcu_assign_pointer(dest, src);
>     rcu_assign_pointer(dest, badsrc);
> 
>     return 0;
> }
> 
> 
> This last approach produces a very clear warning:
> 
> test.c:25:5: warning: incorrect type in argument 2 (different address spaces)
> test.c:25:5:    expected struct foo *<noident>
> test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc
> 
> If you want, you can even add an argument name for the second argument
> of __rcu_assign_pointer_typecheck, and it'll replace the <noident> in
> the second line of the warning.
> 
> So, that last approach meets all the criteria you mentioned:
> > something that (1) does sparse address-space checking, (2) does C type
> > checking, and (3) forces the assignment to be volatile.
> 
> Will that work for all the use cases you have in mind?  If so, I'll
> submit a patch changing rcu_assign_pointer to use that approach.

Looks like it does the right thing, thank you!

Would it also be possible for the call to __rcu_assign_pointer_typecheck()
to be only present when building under sparse?

							Thanx, Paul

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Sun, 01 Sep 2013 22:43:17 +0000
Message-ID: <20130901224317.GA25057 () leaf>
--------------------
On Sun, Sep 01, 2013 at 03:26:19PM -0700, Paul E. McKenney wrote:
> On Sun, Sep 01, 2013 at 01:42:10PM -0700, Josh Triplett wrote:
> > On Sat, Aug 31, 2013 at 02:32:28PM -0700, Paul E. McKenney wrote:
> > > On Thu, Aug 29, 2013 at 07:16:37PM -0700, Josh Triplett wrote:
> > > > On Thu, Aug 29, 2013 at 05:57:33PM -0700, Paul E. McKenney wrote:
> > > > > On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> > > > > > On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > > > > > > #define __rcu_assign_pointer(p, v, space) \
> > > > > > >         do { \
> > > > > > >                 smp_wmb(); \
> > > > > > >                 (p) = (typeof(*v) __force space *)(v); \
> > > > > > >         } while (0)
> > > > > > 
> > > > > > Or I need to fix this one as well.  ;-)
> > > > > 
> > > > > In that vein...  Is there anything like typeof() that also preserves
> > > > > sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
> > > > > "p" in the assignment above results in sparse errors.
> > > > 
> > > > typeof() will preserve sparse's notion of address space as long as you
> > > > do typeof(p), not typeof(*p):
> > > > 
> > > > $ cat test.c
> > > > #define as(n) __attribute__((address_space(n),noderef))
> > > > #define __force __attribute__((force))
> > > > 
> > > > int main(void)
> > > > {
> > > >     int target = 0;
> > > >     int as(1) *foo = (__force typeof(target) as(1) *) &target;
> > > >     typeof(foo) bar = foo;
> > > >     return *bar;
> > > > }
> > > > $ sparse test.c
> > > > test.c:9:13: warning: dereference of noderef expression
> > > > 
> > > > Notice that sparse didn't warn on the assignment of foo to bar (because
> > > > typeof propagated the address space of 1), and warned on the dereference
> > > > of bar (because typeof propagated noderef).
> > > 
> > > Thank you for the info!
> > > 
> > > Suppose that I want to do something like this:
> > > 
> > > #define __rcu_assign_pointer(p, v, space) \
> > >         do { \
> > >                 smp_wmb(); \
> > >                 ACCESS_ONCE(p) = (typeof(*v) __force space *)(v); \
> > >         } while (0)
> > > 
> > > Now, this does typeof(*p), so as you noted above sparse complains about
> > > address-space mismatches.  Thus far, I haven't been able to come up with
> > > something that (1) does sparse address-space checking, (2) does C type
> > > checking, and (3) forces the assignment to be volatile.
> > > 
> > > Any thoughts on how to do this?
> > 
> > First of all, if p and v had compatible types *including* address
> > spaces, you wouldn't need the "space" argument; the following
> > self-contained test case passes both sparse and GCC typechecking:
> > 
> > #define as(n) __attribute__((address_space(n),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         ACCESS_ONCE(p) = (v); \
> >     } while (0)
> > 
> > struct foo;
> > 
> > int main(void)
> > {
> >     struct foo as(1) *dest;
> >     struct foo as(1) *src = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> > 
> >     return 0;
> > }
> > 
> > 
> > 
> > But in this case, you want dest and src to have compatible types except
> > that dest must have the __rcu address space and src might not.  So,
> > let's change the types of dest and src, and add the appropriate cast.
> > The following also passes both GCC and sparse:
> > 
> > #define __rcu __attribute__((address_space(4),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
> >     } while (0)
> > 
> > struct foo { int x; };
> > 
> > int main(void)
> > {
> >     struct foo __rcu *dest;
> >     struct foo *src = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> > 
> >     return 0;
> > }
> > 
> > 
> > However, that cast forces the source to have the __rcu address space
> > without checking what address space it started out with.  If you want to
> > verify that the source has the kernel address space, you can cast to
> > that address space first, *without* __force, which will warn if the
> > source doesn't start out with that address space:
> > 
> > #define __kernel __attribute__((address_space(0)))
> > #define __user __attribute__((address_space(1),noderef))
> > #define __rcu __attribute__((address_space(4),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(typeof(*(v)) __kernel *)(v); \
> >     } while (0)
> > 
> > struct foo { int x; };
> > 
> > int main(void)
> > {
> >     struct foo __rcu *dest;
> >     struct foo *src = (void *)0;
> >     struct foo __user *badsrc = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> >     rcu_assign_pointer(dest, badsrc);
> > 
> >     return 0;
> > }
> > 
> > 
> > This produces a warning on the line using badsrc:
> > 
> > test.c:23:5: warning: cast removes address space of expression
> > 
> > However, that doesn't seem like the most obvious warning, since
> > rcu_assign_pointer doesn't look like a cast, and since it doesn't print
> > the full types involved like most address space warnings do.  So,
> > instead, let's add and use a __chk_kernel_ptr function, similar to
> > __chk_user_ptr in compiler.h:
> > 
> > #define __kernel __attribute__((address_space(0)))
> > #define __user __attribute__((address_space(1),noderef))
> > #define __rcu __attribute__((address_space(4),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void __chk_kernel_ptr(const volatile void *);
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         __chk_kernel_ptr(v); \
> >         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
> >     } while (0)
> > 
> > struct foo { int x; };
> > 
> > int main(void)
> > {
> >     struct foo __rcu *dest;
> >     struct foo *src = (void *)0;
> >     struct foo __user *badsrc = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> >     rcu_assign_pointer(dest, badsrc);
> > 
> >     return 0;
> > }
> > 
> > 
> > This produces a somewhat better warning:
> > 
> > test.c:25:5: warning: incorrect type in argument 1 (different address spaces)
> > test.c:25:5:    expected void const volatile *<noident>
> > test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc
> > 
> > That at least shows the full type of badsrc, but it still seems
> > suboptimal for two reasons: it says it expects "void const volatile *"
> > rather than the actual type it wants, and it says "in argument 1" (of
> > __chk_kernel_ptr), which seems unnecessarily confusing when the type
> > error actually applies to argument 2 of rcu_assign_pointer.  We can do
> > better by declaring a fake local function for checking, instead:
> > 
> > #define __kernel __attribute__((address_space(0)))
> > #define __user __attribute__((address_space(1),noderef))
> > #define __rcu __attribute__((address_space(4),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         extern void __rcu_assign_pointer_typecheck(int, typeof(*(v)) __kernel *); \
> >         __rcu_assign_pointer_typecheck(0, v); \
> >         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
> >     } while (0)
> > 
> > struct foo { int x; };
> > 
> > int main(void)
> > {
> >     struct foo __rcu *dest;
> >     struct foo *src = (void *)0;
> >     struct foo __user *badsrc = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> >     rcu_assign_pointer(dest, badsrc);
> > 
> >     return 0;
> > }
> > 
> > 
> > This last approach produces a very clear warning:
> > 
> > test.c:25:5: warning: incorrect type in argument 2 (different address spaces)
> > test.c:25:5:    expected struct foo *<noident>
> > test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc
> > 
> > If you want, you can even add an argument name for the second argument
> > of __rcu_assign_pointer_typecheck, and it'll replace the <noident> in
> > the second line of the warning.
> > 
> > So, that last approach meets all the criteria you mentioned:
> > > something that (1) does sparse address-space checking, (2) does C type
> > > checking, and (3) forces the assignment to be volatile.
> > 
> > Will that work for all the use cases you have in mind?  If so, I'll
> > submit a patch changing rcu_assign_pointer to use that approach.
> 
> Looks like it does the right thing, thank you!
> 
> Would it also be possible for the call to __rcu_assign_pointer_typecheck()
> to be only present when building under sparse?

Sure; it just needs to go in a separate macro that only gets a non-empty
definition ifdef __CHECKER__.

Patch momentarily.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [RFC] adding into middle of RCU list
Date: Sun, 01 Sep 2013 22:43:17 +0000
Message-ID: <20130901224317.GA25057 () leaf>
--------------------
On Sun, Sep 01, 2013 at 03:26:19PM -0700, Paul E. McKenney wrote:
> On Sun, Sep 01, 2013 at 01:42:10PM -0700, Josh Triplett wrote:
> > On Sat, Aug 31, 2013 at 02:32:28PM -0700, Paul E. McKenney wrote:
> > > On Thu, Aug 29, 2013 at 07:16:37PM -0700, Josh Triplett wrote:
> > > > On Thu, Aug 29, 2013 at 05:57:33PM -0700, Paul E. McKenney wrote:
> > > > > On Fri, Aug 23, 2013 at 02:08:22PM -0700, Paul E. McKenney wrote:
> > > > > > On Fri, Aug 23, 2013 at 01:16:53PM -0400, Mathieu Desnoyers wrote:
> > > > > > > #define __rcu_assign_pointer(p, v, space) \
> > > > > > >         do { \
> > > > > > >                 smp_wmb(); \
> > > > > > >                 (p) = (typeof(*v) __force space *)(v); \
> > > > > > >         } while (0)
> > > > > > 
> > > > > > Or I need to fix this one as well.  ;-)
> > > > > 
> > > > > In that vein...  Is there anything like typeof() that also preserves
> > > > > sparse's notion of address space?  Wrapping an ACCESS_ONCE() around
> > > > > "p" in the assignment above results in sparse errors.
> > > > 
> > > > typeof() will preserve sparse's notion of address space as long as you
> > > > do typeof(p), not typeof(*p):
> > > > 
> > > > $ cat test.c
> > > > #define as(n) __attribute__((address_space(n),noderef))
> > > > #define __force __attribute__((force))
> > > > 
> > > > int main(void)
> > > > {
> > > >     int target = 0;
> > > >     int as(1) *foo = (__force typeof(target) as(1) *) &target;
> > > >     typeof(foo) bar = foo;
> > > >     return *bar;
> > > > }
> > > > $ sparse test.c
> > > > test.c:9:13: warning: dereference of noderef expression
> > > > 
> > > > Notice that sparse didn't warn on the assignment of foo to bar (because
> > > > typeof propagated the address space of 1), and warned on the dereference
> > > > of bar (because typeof propagated noderef).
> > > 
> > > Thank you for the info!
> > > 
> > > Suppose that I want to do something like this:
> > > 
> > > #define __rcu_assign_pointer(p, v, space) \
> > >         do { \
> > >                 smp_wmb(); \
> > >                 ACCESS_ONCE(p) = (typeof(*v) __force space *)(v); \
> > >         } while (0)
> > > 
> > > Now, this does typeof(*p), so as you noted above sparse complains about
> > > address-space mismatches.  Thus far, I haven't been able to come up with
> > > something that (1) does sparse address-space checking, (2) does C type
> > > checking, and (3) forces the assignment to be volatile.
> > > 
> > > Any thoughts on how to do this?
> > 
> > First of all, if p and v had compatible types *including* address
> > spaces, you wouldn't need the "space" argument; the following
> > self-contained test case passes both sparse and GCC typechecking:
> > 
> > #define as(n) __attribute__((address_space(n),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         ACCESS_ONCE(p) = (v); \
> >     } while (0)
> > 
> > struct foo;
> > 
> > int main(void)
> > {
> >     struct foo as(1) *dest;
> >     struct foo as(1) *src = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> > 
> >     return 0;
> > }
> > 
> > 
> > 
> > But in this case, you want dest and src to have compatible types except
> > that dest must have the __rcu address space and src might not.  So,
> > let's change the types of dest and src, and add the appropriate cast.
> > The following also passes both GCC and sparse:
> > 
> > #define __rcu __attribute__((address_space(4),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
> >     } while (0)
> > 
> > struct foo { int x; };
> > 
> > int main(void)
> > {
> >     struct foo __rcu *dest;
> >     struct foo *src = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> > 
> >     return 0;
> > }
> > 
> > 
> > However, that cast forces the source to have the __rcu address space
> > without checking what address space it started out with.  If you want to
> > verify that the source has the kernel address space, you can cast to
> > that address space first, *without* __force, which will warn if the
> > source doesn't start out with that address space:
> > 
> > #define __kernel __attribute__((address_space(0)))
> > #define __user __attribute__((address_space(1),noderef))
> > #define __rcu __attribute__((address_space(4),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(typeof(*(v)) __kernel *)(v); \
> >     } while (0)
> > 
> > struct foo { int x; };
> > 
> > int main(void)
> > {
> >     struct foo __rcu *dest;
> >     struct foo *src = (void *)0;
> >     struct foo __user *badsrc = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> >     rcu_assign_pointer(dest, badsrc);
> > 
> >     return 0;
> > }
> > 
> > 
> > This produces a warning on the line using badsrc:
> > 
> > test.c:23:5: warning: cast removes address space of expression
> > 
> > However, that doesn't seem like the most obvious warning, since
> > rcu_assign_pointer doesn't look like a cast, and since it doesn't print
> > the full types involved like most address space warnings do.  So,
> > instead, let's add and use a __chk_kernel_ptr function, similar to
> > __chk_user_ptr in compiler.h:
> > 
> > #define __kernel __attribute__((address_space(0)))
> > #define __user __attribute__((address_space(1),noderef))
> > #define __rcu __attribute__((address_space(4),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void __chk_kernel_ptr(const volatile void *);
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         __chk_kernel_ptr(v); \
> >         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
> >     } while (0)
> > 
> > struct foo { int x; };
> > 
> > int main(void)
> > {
> >     struct foo __rcu *dest;
> >     struct foo *src = (void *)0;
> >     struct foo __user *badsrc = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> >     rcu_assign_pointer(dest, badsrc);
> > 
> >     return 0;
> > }
> > 
> > 
> > This produces a somewhat better warning:
> > 
> > test.c:25:5: warning: incorrect type in argument 1 (different address spaces)
> > test.c:25:5:    expected void const volatile *<noident>
> > test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc
> > 
> > That at least shows the full type of badsrc, but it still seems
> > suboptimal for two reasons: it says it expects "void const volatile *"
> > rather than the actual type it wants, and it says "in argument 1" (of
> > __chk_kernel_ptr), which seems unnecessarily confusing when the type
> > error actually applies to argument 2 of rcu_assign_pointer.  We can do
> > better by declaring a fake local function for checking, instead:
> > 
> > #define __kernel __attribute__((address_space(0)))
> > #define __user __attribute__((address_space(1),noderef))
> > #define __rcu __attribute__((address_space(4),noderef))
> > #define __force __attribute__((force))
> > #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
> > extern void smp_wmb(void);
> > 
> > #define rcu_assign_pointer(p, v) \
> >     do { \
> >         smp_wmb(); \
> >         extern void __rcu_assign_pointer_typecheck(int, typeof(*(v)) __kernel *); \
> >         __rcu_assign_pointer_typecheck(0, v); \
> >         ACCESS_ONCE(p) = (typeof(*(v)) __rcu __force *)(v); \
> >     } while (0)
> > 
> > struct foo { int x; };
> > 
> > int main(void)
> > {
> >     struct foo __rcu *dest;
> >     struct foo *src = (void *)0;
> >     struct foo __user *badsrc = (void *)0;
> > 
> >     rcu_assign_pointer(dest, src);
> >     rcu_assign_pointer(dest, badsrc);
> > 
> >     return 0;
> > }
> > 
> > 
> > This last approach produces a very clear warning:
> > 
> > test.c:25:5: warning: incorrect type in argument 2 (different address spaces)
> > test.c:25:5:    expected struct foo *<noident>
> > test.c:25:5:    got struct foo [noderef] <asn:1>*badsrc
> > 
> > If you want, you can even add an argument name for the second argument
> > of __rcu_assign_pointer_typecheck, and it'll replace the <noident> in
> > the second line of the warning.
> > 
> > So, that last approach meets all the criteria you mentioned:
> > > something that (1) does sparse address-space checking, (2) does C type
> > > checking, and (3) forces the assignment to be volatile.
> > 
> > Will that work for all the use cases you have in mind?  If so, I'll
> > submit a patch changing rcu_assign_pointer to use that approach.
> 
> Looks like it does the right thing, thank you!
> 
> Would it also be possible for the call to __rcu_assign_pointer_typecheck()
> to be only present when building under sparse?

Sure; it just needs to go in a separate macro that only gets a non-empty
definition ifdef __CHECKER__.

Patch momentarily.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [next:akpm 798/1000] drivers/rtc/rtc-ds1286.c:343:24: sparse: incorrect type in argument 1 (diff ===

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-sparse
Subject: Re: [next:akpm 798/1000] drivers/rtc/rtc-ds1286.c:343:24: sparse: incorrect type in argument 1 (diff
Date: Tue, 23 Apr 2013 06:16:00 +0000
Message-ID: <20130423061600.GN6638 () mwanda>
--------------------
On Mon, Apr 22, 2013 at 07:56:19PM -0700, Christopher Li wrote:
> On Mon, Apr 22, 2013 at 4:56 PM, Andrew Morton
> <akpm@linux-foundation.org> wrote:
> > I think doing IS_ERR() and PTR_ERR() on __iomem pointers is a natural
> > thing, and we should be able to do this without adding call-site
> > trickery to make sparse happy.
> >
> > Is there some sort of annotation which we can add to the
> > IS_ERR()/PTR_ERR() definitions so that sparse will stop warning about
> > this usage?
> 
> Yes, the force attribute should silent the address check on conversion.
> 
> Can some one try this patch (totally untested).
> 

That didn't work.  It's the the void * in the parameter list that's
the problem.  We'd need to do something like the patch below:

Otherwise we could add "__ok_to_cast" thing to Sparse maybe?

regards,
dan carpenter

diff --git a/include/linux/err.h b/include/linux/err.h
index f2edce2..2cbe8fb 100644
--- a/include/linux/err.h
+++ b/include/linux/err.h
@@ -24,20 +24,23 @@ static inline void * __must_check ERR_PTR(long error)
 	return (void *) error;
 }
 
-static inline long __must_check PTR_ERR(const void *ptr)
+static inline long __must_check _PTR_ERR(const void *ptr)
 {
 	return (long) ptr;
 }
+#define PTR_ERR(x) _PTR_ERR((const void __force *)(x))
 
-static inline long __must_check IS_ERR(const void *ptr)
+static inline long __must_check _IS_ERR(const void *ptr)
 {
 	return IS_ERR_VALUE((unsigned long)ptr);
 }
+#define IS_ERR(x) _IS_ERR((const void __force *)(x))
 
-static inline long __must_check IS_ERR_OR_NULL(const void *ptr)
+static inline long __must_check _IS_ERR_OR_NULL(const void *ptr)
 {
 	return !ptr || IS_ERR_VALUE((unsigned long)ptr);
 }
+#define IS_ERR_OR_NULL(x) _IS_ERR_OR_NULL((const void __force *)(x))
 
 /**
  * ERR_CAST - Explicitly cast an error-valued pointer to another pointer type
@@ -46,19 +49,21 @@ static inline long __must_check IS_ERR_OR_NULL(const void *ptr)
  * Explicitly cast an error-valued pointer to another pointer type in such a
  * way as to make it clear that's what's going on.
  */
-static inline void * __must_check ERR_CAST(const void *ptr)
+static inline void * __must_check _ERR_CAST(const void *ptr)
 {
 	/* cast away the const */
 	return (void *) ptr;
 }
+#define ERR_CAST(x) _ERR_CAST((const void __force *)(x))
 
-static inline int __must_check PTR_RET(const void *ptr)
+static inline int __must_check _PTR_RET(const void *ptr)
 {
 	if (IS_ERR(ptr))
 		return PTR_ERR(ptr);
 	else
 		return 0;
 }
+#define PTR_RET(x) _PTR_RET((const void __force *)(x))
 
 #endif
 
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [patch] allow char to be unsigned ===

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-sparse
Subject: [patch] allow char to be unsigned
Date: Wed, 16 Oct 2013 11:22:34 +0000
Message-ID: <20131016112234.GA18544 () longonot ! mountain>
--------------------
On s390x machines the char type is unsigned.  We can detect these at
build time using the GCC __CHAR_UNSIGNED__ macro.

Reported-by: Peter Oberparleiter <oberpar@linux.vnet.ibm.com>
Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>

diff --git a/symbol.c b/symbol.c
index 86aef1c..9e0a27a 100644
--- a/symbol.c
+++ b/symbol.c
@@ -784,6 +784,12 @@ void init_symbols(void)
 	}
 }
 
+#ifdef __CHAR_UNSIGNED__
+#define CHAR_SIGNEDNESS MOD_UNSIGNED
+#else
+#define CHAR_SIGNEDNESS MOD_SIGNED
+#endif
+
 #define MOD_ESIGNED (MOD_SIGNED | MOD_EXPLICITLY_SIGNED)
 #define MOD_LL (MOD_LONG | MOD_LONGLONG)
 #define MOD_LLL MOD_LONGLONGLONG
@@ -801,7 +807,7 @@ static const struct ctype_declare {
 	{ &incomplete_ctype,SYM_BASETYPE, 0,			    NULL,		     NULL,		 NULL },
 	{ &bad_ctype,	    SYM_BASETYPE, 0,			    NULL,		     NULL,		 NULL },
 
-	{ &char_ctype,	    SYM_BASETYPE, MOD_SIGNED | MOD_CHAR,    &bits_in_char,	     &max_int_alignment, &int_type },
+	{ &char_ctype,	    SYM_BASETYPE, CHAR_SIGNEDNESS | MOD_CHAR,    &bits_in_char,	     &max_int_alignment, &int_type },
 	{ &schar_ctype,	    SYM_BASETYPE, MOD_ESIGNED | MOD_CHAR,   &bits_in_char,	     &max_int_alignment, &int_type },
 	{ &uchar_ctype,	    SYM_BASETYPE, MOD_UNSIGNED | MOD_CHAR,  &bits_in_char,	     &max_int_alignment, &int_type },
 	{ &short_ctype,	    SYM_BASETYPE, MOD_SIGNED | MOD_SHORT,   &bits_in_short,	     &max_int_alignment, &int_type },
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: [tip:sched/core 16/27] fs/jbd/commit.c:105:12: sparse: context imbalance in 'inverted_lock' - wr ===

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-sparse
Subject: Re: [tip:sched/core 16/27] fs/jbd/commit.c:105:12: sparse: context imbalance in 'inverted_lock' - wr
Date: Wed, 25 Sep 2013 18:59:25 +0000
Message-ID: <20130925185925.GD3657 () laptop ! programming ! kicks-ass ! net>
--------------------
On Thu, Sep 26, 2013 at 02:31:09AM +0800, kbuild test robot wrote:
> tree:   git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git sched/core
> head:   1a338ac32ca630f67df25b4a16436cccc314e997
> commit: 0c44c2d0f459cd7e275242b72f500137c4fa834d [16/27] x86: Use asm goto to implement better modify_and_test() functions
> reproduce: make C=1 CF=-D__CHECK_ENDIAN__
> 
> 
> sparse warnings: (new ones prefixed by >>)
> 
> >> fs/jbd/commit.c:105:12: sparse: context imbalance in 'inverted_lock' - wrong count at exit
>    fs/jbd/commit.c:205:9: sparse: context imbalance in 'journal_submit_data_buffers' - different lock contexts for basic block
>    fs/jbd/commit.c:456:9: sparse: context imbalance in 'journal_commit_transaction' - different lock contexts for basic block
> --
>    include/linux/bit_spinlock.h:62:25: sparse: context imbalance in '__try_to_free_cp_buf' - unexpected unlock
>    fs/jbd/checkpoint.c:155:36: sparse: context imbalance in '__log_wait_for_space' - unexpected unlock
>    include/linux/bit_spinlock.h:62:25: sparse: context imbalance in '__wait_cp_io' - unexpected unlock
>    fs/jbd/checkpoint.c:294:23: sparse: context imbalance in '__process_buffer' - unexpected unlock
>    fs/jbd/checkpoint.c:390:9: sparse: context imbalance in 'log_do_checkpoint' - different lock contexts for basic block
> >> fs/jbd/checkpoint.c:557:12: sparse: context imbalance in 'journal_clean_one_cp_list' - wrong count at exit
> --
> >> drivers/infiniband/hw/qib/qib_verbs.h:1061:36: sparse: crazy programmer
> 
> vim +/inverted_lock +105 fs/jbd/commit.c
> 
>     89			WARN_ON_ONCE(buffer_dirty(bh));
>     90			clear_buffer_freed(bh);
>     91			clear_buffer_mapped(bh);
>     92			clear_buffer_new(bh);
>     93			clear_buffer_req(bh);
>     94			bh->b_bdev = NULL;
>     95			release_buffer_page(bh);
>     96		} else
>     97			put_bh(bh);
>     98	}
>     99	
>    100	/*
>    101	 * Try to acquire jbd_lock_bh_state() against the buffer, when j_list_lock is
>    102	 * held.  For ranking reasons we must trylock.  If we lose, schedule away and
>    103	 * return 0.  j_list_lock is dropped in this case.
>    104	 */
>  > 105	static int inverted_lock(journal_t *journal, struct buffer_head *bh)
>    106	{
>    107		if (!jbd_trylock_bh_state(bh)) {
>    108			spin_unlock(&journal->j_list_lock);
>    109			schedule();
>    110			return 0;
>    111		}
>    112		return 1;
>    113	}

I've really no idea how that patch can cause sparse warnings. Patch
included below for the sparse people. Does sparse presume to understand
inline asm?

---
Subject: x86: Use asm goto to implement better modify_and_test() functions
From: Peter Zijlstra <peterz@infradead.org>
Date: Wed Sep 11 15:19:24 CEST 2013

Linus suggested using asm goto to get rid of the typical SETcc + TEST
instruction pair -- which also clobbers an extra register -- for our
typical modify_and_test() functions.

Because asm goto doesn't allow output fields it has to include an
unconditinal memory clobber when it changes a memory variable to force
a reload.

Luckily all atomic ops already imply a compiler barrier to go along
with their memory barrier semantics.

Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Peter Zijlstra <peterz@infradead.org>
---
 arch/x86/include/asm/atomic.h      |   29 ++++----------------------
 arch/x86/include/asm/atomic64_64.h |   28 +++----------------------
 arch/x86/include/asm/bitops.h      |   24 +++------------------
 arch/x86/include/asm/local.h       |   28 +++----------------------
 arch/x86/include/asm/rmwcc.h       |   41 +++++++++++++++++++++++++++++++++++++
 5 files changed, 58 insertions(+), 92 deletions(-)

--- a/arch/x86/include/asm/atomic.h
+++ b/arch/x86/include/asm/atomic.h
@@ -6,6 +6,7 @@
 #include <asm/processor.h>
 #include <asm/alternative.h>
 #include <asm/cmpxchg.h>
+#include <asm/rmwcc.h>
 
 /*
  * Atomic operations that C can't guarantee us.  Useful for
@@ -76,12 +77,7 @@ static inline void atomic_sub(int i, ato
  */
 static inline int atomic_sub_and_test(int i, atomic_t *v)
 {
-	unsigned char c;
-
-	asm volatile(LOCK_PREFIX "subl %2,%0; sete %1"
-		     : "+m" (v->counter), "=qm" (c)
-		     : "ir" (i) : "memory");
-	return c;
+	GEN_BINARY_RMWcc(LOCK_PREFIX "subl", v->counter, i, "%0", "e");
 }
 
 /**
@@ -118,12 +114,7 @@ static inline void atomic_dec(atomic_t *
  */
 static inline int atomic_dec_and_test(atomic_t *v)
 {
-	unsigned char c;
-
-	asm volatile(LOCK_PREFIX "decl %0; sete %1"
-		     : "+m" (v->counter), "=qm" (c)
-		     : : "memory");
-	return c != 0;
+	GEN_UNARY_RMWcc(LOCK_PREFIX "decl", v->counter, "%0", "e");
 }
 
 /**
@@ -136,12 +127,7 @@ static inline int atomic_dec_and_test(at
  */
 static inline int atomic_inc_and_test(atomic_t *v)
 {
-	unsigned char c;
-
-	asm volatile(LOCK_PREFIX "incl %0; sete %1"
-		     : "+m" (v->counter), "=qm" (c)
-		     : : "memory");
-	return c != 0;
+	GEN_UNARY_RMWcc(LOCK_PREFIX "incl", v->counter, "%0", "e");
 }
 
 /**
@@ -155,12 +141,7 @@ static inline int atomic_inc_and_test(at
  */
 static inline int atomic_add_negative(int i, atomic_t *v)
 {
-	unsigned char c;
-
-	asm volatile(LOCK_PREFIX "addl %2,%0; sets %1"
-		     : "+m" (v->counter), "=qm" (c)
-		     : "ir" (i) : "memory");
-	return c;
+	GEN_BINARY_RMWcc(LOCK_PREFIX "addl", v->counter, i, "%0", "s");
 }
 
 /**
--- a/arch/x86/include/asm/atomic64_64.h
+++ b/arch/x86/include/asm/atomic64_64.h
@@ -72,12 +72,7 @@ static inline void atomic64_sub(long i,
  */
 static inline int atomic64_sub_and_test(long i, atomic64_t *v)
 {
-	unsigned char c;
-
-	asm volatile(LOCK_PREFIX "subq %2,%0; sete %1"
-		     : "=m" (v->counter), "=qm" (c)
-		     : "er" (i), "m" (v->counter) : "memory");
-	return c;
+	GEN_BINARY_RMWcc(LOCK_PREFIX "subq", v->counter, i, "%0", "e");
 }
 
 /**
@@ -116,12 +111,7 @@ static inline void atomic64_dec(atomic64
  */
 static inline int atomic64_dec_and_test(atomic64_t *v)
 {
-	unsigned char c;
-
-	asm volatile(LOCK_PREFIX "decq %0; sete %1"
-		     : "=m" (v->counter), "=qm" (c)
-		     : "m" (v->counter) : "memory");
-	return c != 0;
+	GEN_UNARY_RMWcc(LOCK_PREFIX "decq", v->counter, "%0", "e");
 }
 
 /**
@@ -134,12 +124,7 @@ static inline int atomic64_dec_and_test(
  */
 static inline int atomic64_inc_and_test(atomic64_t *v)
 {
-	unsigned char c;
-
-	asm volatile(LOCK_PREFIX "incq %0; sete %1"
-		     : "=m" (v->counter), "=qm" (c)
-		     : "m" (v->counter) : "memory");
-	return c != 0;
+	GEN_UNARY_RMWcc(LOCK_PREFIX "incq", v->counter, "%0", "e");
 }
 
 /**
@@ -153,12 +138,7 @@ static inline int atomic64_inc_and_test(
  */
 static inline int atomic64_add_negative(long i, atomic64_t *v)
 {
-	unsigned char c;
-
-	asm volatile(LOCK_PREFIX "addq %2,%0; sets %1"
-		     : "=m" (v->counter), "=qm" (c)
-		     : "er" (i), "m" (v->counter) : "memory");
-	return c;
+	GEN_BINARY_RMWcc(LOCK_PREFIX "addq", v->counter, i, "%0", "s");
 }
 
 /**
--- a/arch/x86/include/asm/bitops.h
+++ b/arch/x86/include/asm/bitops.h
@@ -14,6 +14,7 @@
 
 #include <linux/compiler.h>
 #include <asm/alternative.h>
+#include <asm/rmwcc.h>
 
 #if BITS_PER_LONG == 32
 # define _BITOPS_LONG_SHIFT 5
@@ -204,12 +205,7 @@ static inline void change_bit(long nr, v
  */
 static inline int test_and_set_bit(long nr, volatile unsigned long *addr)
 {
-	int oldbit;
-
-	asm volatile(LOCK_PREFIX "bts %2,%1\n\t"
-		     "sbb %0,%0" : "=r" (oldbit), ADDR : "Ir" (nr) : "memory");
-
-	return oldbit;
+	GEN_BINARY_RMWcc(LOCK_PREFIX "bts", *addr, nr, "%0", "c");
 }
 
 /**
@@ -255,13 +251,7 @@ static inline int __test_and_set_bit(lon
  */
 static inline int test_and_clear_bit(long nr, volatile unsigned long *addr)
 {
-	int oldbit;
-
-	asm volatile(LOCK_PREFIX "btr %2,%1\n\t"
-		     "sbb %0,%0"
-		     : "=r" (oldbit), ADDR : "Ir" (nr) : "memory");
-
-	return oldbit;
+	GEN_BINARY_RMWcc(LOCK_PREFIX "btr", *addr, nr, "%0", "c");
 }
 
 /**
@@ -314,13 +304,7 @@ static inline int __test_and_change_bit(
  */
 static inline int test_and_change_bit(long nr, volatile unsigned long *addr)
 {
-	int oldbit;
-
-	asm volatile(LOCK_PREFIX "btc %2,%1\n\t"
-		     "sbb %0,%0"
-		     : "=r" (oldbit), ADDR : "Ir" (nr) : "memory");
-
-	return oldbit;
+	GEN_BINARY_RMWcc(LOCK_PREFIX "btc", *addr, nr, "%0", "c");
 }
 
 static __always_inline int constant_test_bit(long nr, const volatile unsigned long *addr)
--- a/arch/x86/include/asm/local.h
+++ b/arch/x86/include/asm/local.h
@@ -52,12 +52,7 @@ static inline void local_sub(long i, loc
  */
 static inline int local_sub_and_test(long i, local_t *l)
 {
-	unsigned char c;
-
-	asm volatile(_ASM_SUB "%2,%0; sete %1"
-		     : "+m" (l->a.counter), "=qm" (c)
-		     : "ir" (i) : "memory");
-	return c;
+	GEN_BINARY_RMWcc(_ASM_SUB, l->a.counter, i, "%0", "e");
 }
 
 /**
@@ -70,12 +65,7 @@ static inline int local_sub_and_test(lon
  */
 static inline int local_dec_and_test(local_t *l)
 {
-	unsigned char c;
-
-	asm volatile(_ASM_DEC "%0; sete %1"
-		     : "+m" (l->a.counter), "=qm" (c)
-		     : : "memory");
-	return c != 0;
+	GEN_UNARY_RMWcc(_ASM_DEC, l->a.counter, "%0", "e");
 }
 
 /**
@@ -88,12 +78,7 @@ static inline int local_dec_and_test(loc
  */
 static inline int local_inc_and_test(local_t *l)
 {
-	unsigned char c;
-
-	asm volatile(_ASM_INC "%0; sete %1"
-		     : "+m" (l->a.counter), "=qm" (c)
-		     : : "memory");
-	return c != 0;
+	GEN_UNARY_RMWcc(_ASM_INC, l->a.counter, "%0", "e");
 }
 
 /**
@@ -107,12 +92,7 @@ static inline int local_inc_and_test(loc
  */
 static inline int local_add_negative(long i, local_t *l)
 {
-	unsigned char c;
-
-	asm volatile(_ASM_ADD "%2,%0; sets %1"
-		     : "+m" (l->a.counter), "=qm" (c)
-		     : "ir" (i) : "memory");
-	return c;
+	GEN_BINARY_RMWcc(_ASM_ADD, l->a.counter, i, "%0", "s");
 }
 
 /**
--- /dev/null
+++ b/arch/x86/include/asm/rmwcc.h
@@ -0,0 +1,41 @@
+#ifndef _ASM_X86_RMWcc
+#define _ASM_X86_RMWcc
+
+#ifdef CC_HAVE_ASM_GOTO
+
+#define __GEN_RMWcc(fullop, var, cc, ...)				\
+do {									\
+	asm volatile goto (fullop "; j" cc " %l[cc_label]"		\
+			: : "m" (var), ## __VA_ARGS__ 			\
+			: "memory" : cc_label);				\
+	return 0;							\
+cc_label:								\
+	return 1;							\
+} while (0)
+
+#define GEN_UNARY_RMWcc(op, var, arg0, cc) 				\
+	__GEN_RMWcc(op " " arg0, var, cc)
+
+#define GEN_BINARY_RMWcc(op, var, val, arg0, cc)			\
+	__GEN_RMWcc(op " %1, " arg0, var, cc, "er" (val))
+
+#else /* !CC_HAVE_ASM_GOTO */
+
+#define __GEN_RMWcc(fullop, var, cc, ...)				\
+do {									\
+	char c;								\
+	asm volatile (fullop "; set" cc " %1"				\
+			: "+m" (var), "=qm" (c)				\
+			: __VA_ARGS__ : "memory");			\
+	return c != 0;							\
+} while (0)
+
+#define GEN_UNARY_RMWcc(op, var, arg0, cc)				\
+	__GEN_RMWcc(op " " arg0, var, cc)
+
+#define GEN_BINARY_RMWcc(op, var, val, arg0, cc)			\
+	__GEN_RMWcc(op " %2, " arg0, var, cc, "er" (val))
+
+#endif /* CC_HAVE_ASM_GOTO */
+
+#endif /* _ASM_X86_RMWcc */
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [tip:sched/core 16/27] fs/jbd/commit.c:105:12: sparse: context imbalance in 'inverted_lock' - wr
Date: Wed, 25 Sep 2013 21:58:05 +0000
Message-ID: <20130925215805.GB7716 () jtriplet-mobl1>
--------------------
On Wed, Sep 25, 2013 at 08:59:25PM +0200, Peter Zijlstra wrote:
> On Thu, Sep 26, 2013 at 02:31:09AM +0800, kbuild test robot wrote:
> > tree:   git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git sched/core
> > head:   1a338ac32ca630f67df25b4a16436cccc314e997
> > commit: 0c44c2d0f459cd7e275242b72f500137c4fa834d [16/27] x86: Use asm goto to implement better modify_and_test() functions
> > reproduce: make C=1 CF=-D__CHECK_ENDIAN__
> > 
> > 
> > sparse warnings: (new ones prefixed by >>)
> > 
> > >> drivers/infiniband/hw/qib/qib_verbs.h:1061:36: sparse: crazy programmer

This one, by the way, seems like a sparse internal error, which ought to
have a better message.  The patch below does that; Chris, does this
patch seem reasonable to you?  (The message itself might need accuracy
improvements; it's still pretty vague about what went wrong.)

---8<---
From: Josh Triplett <josh@joshtriplett.org>
Date: Wed, 25 Sep 2013 14:55:44 -0700
Subject: [PATCH] Change "crazy programmer" into a proper internal error message

Signed-off-by: Josh Triplett <josh@joshtriplett.org>
---
 ident-list.h | 1 +
 simplify.c   | 2 +-
 2 files changed, 2 insertions(+), 1 deletion(-)

diff --git a/ident-list.h b/ident-list.h
index e93aae7..5f1da5e 100644
--- a/ident-list.h
+++ b/ident-list.h
@@ -91,6 +91,7 @@ IDENT(artificial); IDENT(__artificial__);
 IDENT(leaf); IDENT(__leaf__);
 IDENT(vector_size); IDENT(__vector_size__);
 IDENT(error); IDENT(__error__);
+IDENT(cleanup); IDENT(__cleanup__);
 
 
 /* Preprocessor idents.  Direct use of __IDENT avoids mentioning the keyword
diff --git a/simplify.c b/simplify.c
index bda4a5b..2c266f9 100644
--- a/simplify.c
+++ b/simplify.c
@@ -619,7 +619,7 @@ offset:
 		if (new == VOID)
 			return 0;
 		new = VOID;
-		warning(insn->pos, "crazy programmer");
+		sparse_error(insn->pos, "internal error: failed to simplify a memory operation");
 	}
 	insn->offset += off->value;
 	use_pseudo(insn, new, &insn->src);
-- 
1.8.4.rc3

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: [tip:sched/core 16/27] fs/jbd/commit.c:105:12: sparse: context imbalance in 'inverted_lock' - wr
Date: Mon, 30 Sep 2013 15:25:51 +0000
Message-ID: <20130930152550.GA1269 () leaf>
--------------------
On Mon, Sep 30, 2013 at 03:44:34PM +0200, Peter Zijlstra wrote:
> On Wed, Sep 25, 2013 at 02:47:20PM -0700, Josh Triplett wrote:
> > That's expressible in Sparse; look at how spin_trylock and _cond_lock,
> > and write a _cond_unlock.
> 
> Yeah, I know about __cond_lock() its an abomination that should die.

Can't argue with that.

> I
> did take a stab at teach sparse something saner but got stuck.. was
> years ago, can't remember more.

I only see two obvious ways to extend Sparse to remove the need for
__cond_lock, and only one makes sense.

First, you could add an attribute for conditional context changes, which
takes an expression; however, that would require an expression
evaluator, which internally would construct code a lot like __cond_lock,
and it would require some syntax to reference the return value.  That
seems excessively painful, and not significantly better than
__cond_lock.

Second, the real solution: teach Sparse to do whole-program
analysis, similar to GCC LTO.

Alternatively, someone could write a GCC plugin that understands the
context attribute and __context__ statement, and then does whole-program
context analysis using GCC; that seems easiest, relatively speaking.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Peter Zijlstra <peterz () infradead ! org>
To: linux-sparse
Subject: Re: [tip:sched/core 16/27] fs/jbd/commit.c:105:12: sparse: context imbalance in 'inverted_lock' - wr
Date: Mon, 30 Sep 2013 15:35:17 +0000
Message-ID: <20130930153517.GD3081 () twins ! programming ! kicks-ass ! net>
--------------------
On Mon, Sep 30, 2013 at 08:25:51AM -0700, Josh Triplett wrote:
> First, you could add an attribute for conditional context changes, which
> takes an expression; however, that would require an expression
> evaluator, which internally would construct code a lot like __cond_lock,
> and it would require some syntax to reference the return value.  That
> seems excessively painful, and not significantly better than
> __cond_lock.

This sounds somewhat familiar; its better in that it doesn't pollute the
actual kernel source ;-)
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: looking for loan ===

From: Aijaz Lending <yin01 () aijaz527 ! onmicrosoft ! com>
To: linux-sparse
Subject: looking for loan
Date: Thu, 03 Oct 2013 20:16:11 +0000
Message-ID: <bf21e0c5-5504-450d-949d-291cc8dbfa24 () HKXPR02MB213 ! apcprd02 ! prod ! outlook ! com>
--------------------
Do you have a firm or company that need loan to start up a business or need,personal loan, Debt consolidation? For more information,Contact us now for a guarantee loan with low interest rate. We will provide you with loan to meet your needs. For more information contact us with the following information's.
Full name:
country:
Address:
Phone Number:
Amount needed:
Duration of loan:

sg.loan.sg@outlook.com
Kind regards
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: mlx5: Add driver for Mellanox Connect-IB adapters ===

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-sparse
Subject: re: mlx5: Add driver for Mellanox Connect-IB adapters
Date: Wed, 10 Jul 2013 10:54:15 +0000
Message-ID: <20130710105415.GA31232 () longonot ! mountain>
--------------------
---
Side note: Sparse should warn about endian bugs but in linux-next
endian checking is disabled because we hit:

include/uapi/linux/swab.h:71:16: error: undefined identifier '__builtin_bswap64'
include/uapi/linux/swab.h:71:33: error: not a function <noident>

do_error() in Sparse disables warning messages.  I feel like we
shouldn't do that.

        /* Shut up warnings after an error */
        max_warnings = 0;
---

Hello Eli Cohen,

The patch e126ba97dba9: "mlx5: Add driver for Mellanox Connect-IB 
adapters" from Jul 7, 2013, has an endian related bug:

drivers/net/ethernet/mellanox/mlx5/core/main.c
   214          memset(&set_out, 0, sizeof(set_out));
   215          set_ctx->hca_cap.uar_page_sz = cpu_to_be16(PAGE_SHIFT - 12);
                         ^^^^^^^^^^^^^^^^^^^
This is defined in the header as be32 but we are saving a be16 to it.
My guess is the header is correct and the be16 is wrong.

   216          set_ctx->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_SET_HCA_CAP);
   217          err = mlx5_cmd_exec(dev, set_ctx, sizeof(*set_ctx),
   218                                   &set_out, sizeof(set_out));

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Dan Carpenter <dan.carpenter () oracle ! com>
To: linux-rdma
Subject: re: mlx5: Add driver for Mellanox Connect-IB adapters
Date: Wed, 10 Jul 2013 10:54:15 +0000
Message-ID: <20130710105415.GA31232 () longonot ! mountain>
--------------------
---
Side note: Sparse should warn about endian bugs but in linux-next
endian checking is disabled because we hit:

include/uapi/linux/swab.h:71:16: error: undefined identifier '__builtin_bswap64'
include/uapi/linux/swab.h:71:33: error: not a function <noident>

do_error() in Sparse disables warning messages.  I feel like we
shouldn't do that.

        /* Shut up warnings after an error */
        max_warnings = 0;
---

Hello Eli Cohen,

The patch e126ba97dba9: "mlx5: Add driver for Mellanox Connect-IB 
adapters" from Jul 7, 2013, has an endian related bug:

drivers/net/ethernet/mellanox/mlx5/core/main.c
   214          memset(&set_out, 0, sizeof(set_out));
   215          set_ctx->hca_cap.uar_page_sz = cpu_to_be16(PAGE_SHIFT - 12);
                         ^^^^^^^^^^^^^^^^^^^
This is defined in the header as be32 but we are saving a be16 to it.
My guess is the header is correct and the be16 is wrong.

   216          set_ctx->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_SET_HCA_CAP);
   217          err = mlx5_cmd_exec(dev, set_ctx, sizeof(*set_ctx),
   218                                   &set_out, sizeof(set_out));

regards,
dan carpenter

--
To unsubscribe from this list: send the line "unsubscribe linux-rdma" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Or Gerlitz <ogerlitz () mellanox ! com>
To: linux-rdma
Subject: Re: mlx5: Add driver for Mellanox Connect-IB adapters
Date: Wed, 10 Jul 2013 11:28:45 +0000
Message-ID: <51DD456D.70205 () mellanox ! com>
--------------------
On 10/07/2013 13:54, Dan Carpenter wrote:
> ---
> Side note: Sparse should warn about endian bugs but in linux-next
> endian checking is disabled because we hit:
>
> include/uapi/linux/swab.h:71:16: error: undefined identifier '__builtin_bswap64'
> include/uapi/linux/swab.h:71:33: error: not a function <noident>
>
> do_error() in Sparse disables warning messages.  I feel like we
> shouldn't do that.
>
>          /* Shut up warnings after an error */
>          max_warnings = 0;
> ---
>
> Hello Eli Cohen,
>
> The patch e126ba97dba9: "mlx5: Add driver for Mellanox Connect-IB
> adapters" from Jul 7, 2013, has an endian related bug:
>
> drivers/net/ethernet/mellanox/mlx5/core/main.c
>     214          memset(&set_out, 0, sizeof(set_out));
>     215          set_ctx->hca_cap.uar_page_sz = cpu_to_be16(PAGE_SHIFT - 12);
>                           ^^^^^^^^^^^^^^^^^^^
> This is defined in the header as be32 but we are saving a be16 to it.
> My guess is the header is correct and the be16 is wrong.
>
>     216          set_ctx->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_SET_HCA_CAP);
>     217          err = mlx5_cmd_exec(dev, set_ctx, sizeof(*set_ctx),
>     218                                   &set_out, sizeof(set_out));
>
> regards,
> dan carpenter
>

Dan, this sparse catch was reported earlier by Fengguang Wu 
<fengguang.wu@intel.com>, we have a fix, will send now

Or.
--
To unsubscribe from this list: send the line "unsubscribe linux-rdma" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Or Gerlitz <ogerlitz () mellanox ! com>
To: linux-sparse
Subject: Re: mlx5: Add driver for Mellanox Connect-IB adapters
Date: Wed, 10 Jul 2013 11:28:45 +0000
Message-ID: <51DD456D.70205 () mellanox ! com>
--------------------
On 10/07/2013 13:54, Dan Carpenter wrote:
> ---
> Side note: Sparse should warn about endian bugs but in linux-next
> endian checking is disabled because we hit:
>
> include/uapi/linux/swab.h:71:16: error: undefined identifier '__builtin_bswap64'
> include/uapi/linux/swab.h:71:33: error: not a function <noident>
>
> do_error() in Sparse disables warning messages.  I feel like we
> shouldn't do that.
>
>          /* Shut up warnings after an error */
>          max_warnings = 0;
> ---
>
> Hello Eli Cohen,
>
> The patch e126ba97dba9: "mlx5: Add driver for Mellanox Connect-IB
> adapters" from Jul 7, 2013, has an endian related bug:
>
> drivers/net/ethernet/mellanox/mlx5/core/main.c
>     214          memset(&set_out, 0, sizeof(set_out));
>     215          set_ctx->hca_cap.uar_page_sz = cpu_to_be16(PAGE_SHIFT - 12);
>                           ^^^^^^^^^^^^^^^^^^^
> This is defined in the header as be32 but we are saving a be16 to it.
> My guess is the header is correct and the be16 is wrong.
>
>     216          set_ctx->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_SET_HCA_CAP);
>     217          err = mlx5_cmd_exec(dev, set_ctx, sizeof(*set_ctx),
>     218                                   &set_out, sizeof(set_out));
>
> regards,
> dan carpenter
>

Dan, this sparse catch was reported earlier by Fengguang Wu 
<fengguang.wu@intel.com>, we have a fix, will send now

Or.
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: mlx5: Add driver for Mellanox Connect-IB adapters
Date: Wed, 10 Jul 2013 20:16:28 +0000
Message-ID: <20130710201627.GA16689 () jtriplet-mobl1>
--------------------
On Wed, Jul 10, 2013 at 01:54:15PM +0300, Dan Carpenter wrote:
> ---
> Side note: Sparse should warn about endian bugs but in linux-next
> endian checking is disabled because we hit:
> 
> include/uapi/linux/swab.h:71:16: error: undefined identifier '__builtin_bswap64'
> include/uapi/linux/swab.h:71:33: error: not a function <noident>
> 
> do_error() in Sparse disables warning messages.  I feel like we
> shouldn't do that.

No, I think that's the correct behavior: sparse should only generate
*errors* rather than warnings when it hits something that prevents it
from handling some chunk of code, in which case we'd get a huge number
of spurious warnings if not suppressed.

In any case, current Sparse has __builtin_bswap64, so you shouldn't get
that error.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-rdma
Subject: Re: mlx5: Add driver for Mellanox Connect-IB adapters
Date: Wed, 10 Jul 2013 20:16:28 +0000
Message-ID: <20130710201627.GA16689 () jtriplet-mobl1>
--------------------
On Wed, Jul 10, 2013 at 01:54:15PM +0300, Dan Carpenter wrote:
> ---
> Side note: Sparse should warn about endian bugs but in linux-next
> endian checking is disabled because we hit:
> 
> include/uapi/linux/swab.h:71:16: error: undefined identifier '__builtin_bswap64'
> include/uapi/linux/swab.h:71:33: error: not a function <noident>
> 
> do_error() in Sparse disables warning messages.  I feel like we
> shouldn't do that.

No, I think that's the correct behavior: sparse should only generate
*errors* rather than warnings when it hits something that prevents it
from handling some chunk of code, in which case we'd get a huge number
of spurious warnings if not suppressed.

In any case, current Sparse has __builtin_bswap64, so you shouldn't get
that error.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-rdma" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: "Linux Kernel Mailing List" <linux-kernel () vger ! kernel ! org>
To: git-commits-head
Subject: mlx5: Add driver for Mellanox Connect-IB adapters
Date: Sat, 13 Jul 2013 20:20:36 +0000
Message-ID: <20130713202036.64262660AE7 () gitolite ! kernel ! org>
--------------------
Gitweb:     http://git.kernel.org/linus/;a=commit;h=e126ba97dba9edeb6fafa3665b5f8497fc9cdf8c
Commit:     e126ba97dba9edeb6fafa3665b5f8497fc9cdf8c
Parent:     0134f16bc91cc15a38c867b81568b791c9b626aa
Author:     Eli Cohen <eli@mellanox.com>
AuthorDate: Sun Jul 7 17:25:49 2013 +0300
Committer:  Roland Dreier <roland@purestorage.com>
CommitDate: Mon Jul 8 10:32:24 2013 -0700

    mlx5: Add driver for Mellanox Connect-IB adapters
    
    The driver is comprised of two kernel modules: mlx5_ib and mlx5_core.
    This partitioning resembles what we have for mlx4, except that mlx5_ib
    is the pci device driver and not mlx5_core.
    
    mlx5_core is essentially a library that provides general functionality
    that is intended to be used by other Mellanox devices that will be
    introduced in the future.  mlx5_ib has a similar role as any hardware
    device under drivers/infiniband/hw.
    
    Signed-off-by: Eli Cohen <eli@mellanox.com>
    Signed-off-by: Jack Morgenstein <jackm@dev.mellanox.co.il>
    Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
    
    [ Merge in coccinelle fixes from Fengguang Wu <fengguang.wu@intel.com>.
      - Roland ]
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>
---
 MAINTAINERS                                        |   22 +
 drivers/infiniband/Kconfig                         |    1 +
 drivers/infiniband/Makefile                        |    1 +
 drivers/infiniband/hw/mlx5/Kconfig                 |   10 +
 drivers/infiniband/hw/mlx5/Makefile                |    3 +
 drivers/infiniband/hw/mlx5/ah.c                    |   92 +
 drivers/infiniband/hw/mlx5/cq.c                    |  843 +++++++
 drivers/infiniband/hw/mlx5/doorbell.c              |  100 +
 drivers/infiniband/hw/mlx5/mad.c                   |  139 ++
 drivers/infiniband/hw/mlx5/main.c                  | 1504 ++++++++++++
 drivers/infiniband/hw/mlx5/mem.c                   |  162 ++
 drivers/infiniband/hw/mlx5/mlx5_ib.h               |  545 +++++
 drivers/infiniband/hw/mlx5/mr.c                    | 1007 ++++++++
 drivers/infiniband/hw/mlx5/qp.c                    | 2524 ++++++++++++++++++++
 drivers/infiniband/hw/mlx5/srq.c                   |  473 ++++
 drivers/infiniband/hw/mlx5/user.h                  |  121 +
 drivers/net/ethernet/mellanox/Kconfig              |    1 +
 drivers/net/ethernet/mellanox/Makefile             |    1 +
 drivers/net/ethernet/mellanox/mlx5/core/Kconfig    |   18 +
 drivers/net/ethernet/mellanox/mlx5/core/Makefile   |    5 +
 drivers/net/ethernet/mellanox/mlx5/core/alloc.c    |  238 ++
 drivers/net/ethernet/mellanox/mlx5/core/cmd.c      | 1515 ++++++++++++
 drivers/net/ethernet/mellanox/mlx5/core/cq.c       |  224 ++
 drivers/net/ethernet/mellanox/mlx5/core/debugfs.c  |  587 +++++
 drivers/net/ethernet/mellanox/mlx5/core/eq.c       |  521 ++++
 drivers/net/ethernet/mellanox/mlx5/core/fw.c       |  185 ++
 drivers/net/ethernet/mellanox/mlx5/core/health.c   |  217 ++
 drivers/net/ethernet/mellanox/mlx5/core/mad.c      |   78 +
 drivers/net/ethernet/mellanox/mlx5/core/main.c     |  475 ++++
 drivers/net/ethernet/mellanox/mlx5/core/mcg.c      |  106 +
 .../net/ethernet/mellanox/mlx5/core/mlx5_core.h    |   73 +
 drivers/net/ethernet/mellanox/mlx5/core/mr.c       |  136 ++
 .../net/ethernet/mellanox/mlx5/core/pagealloc.c    |  435 ++++
 drivers/net/ethernet/mellanox/mlx5/core/pd.c       |  101 +
 drivers/net/ethernet/mellanox/mlx5/core/port.c     |  104 +
 drivers/net/ethernet/mellanox/mlx5/core/qp.c       |  301 +++
 drivers/net/ethernet/mellanox/mlx5/core/srq.c      |  223 ++
 drivers/net/ethernet/mellanox/mlx5/core/uar.c      |  223 ++
 include/linux/mlx5/cmd.h                           |   51 +
 include/linux/mlx5/cq.h                            |  165 ++
 include/linux/mlx5/device.h                        |  893 +++++++
 include/linux/mlx5/doorbell.h                      |   79 +
 include/linux/mlx5/driver.h                        |  769 ++++++
 include/linux/mlx5/qp.h                            |  467 ++++
 include/linux/mlx5/srq.h                           |   41 +
 45 files changed, 15779 insertions(+), 0 deletions(-)

diff --git a/MAINTAINERS b/MAINTAINERS
index 60d6a33..b426536 100644
--- a/MAINTAINERS
+++ b/MAINTAINERS
@@ -5365,6 +5365,28 @@ W:	http://linuxtv.org
 S:	Odd Fixes
 F:	drivers/media/radio/radio-miropcm20*
 
+Mellanox MLX5 core VPI driver
+M:	Eli Cohen <eli@mellanox.com>
+L:	netdev@vger.kernel.org
+L:	linux-rdma@vger.kernel.org
+W:	http://www.mellanox.com
+Q:	http://patchwork.ozlabs.org/project/netdev/list/
+Q:	http://patchwork.kernel.org/project/linux-rdma/list/
+T:	git://openfabrics.org/~eli/connect-ib.git
+S:	Supported
+F:	drivers/net/ethernet/mellanox/mlx5/core/
+F:	include/linux/mlx5/
+
+Mellanox MLX5 IB driver
+M:      Eli Cohen <eli@mellanox.com>
+L:      linux-rdma@vger.kernel.org
+W:      http://www.mellanox.com
+Q:      http://patchwork.kernel.org/project/linux-rdma/list/
+T:      git://openfabrics.org/~eli/connect-ib.git
+S:      Supported
+F:      include/linux/mlx5/
+F:      drivers/infiniband/hw/mlx5/
+
 MODULE SUPPORT
 M:	Rusty Russell <rusty@rustcorp.com.au>
 S:	Maintained
diff --git a/drivers/infiniband/Kconfig b/drivers/infiniband/Kconfig
index c85b56c..5ceda71 100644
--- a/drivers/infiniband/Kconfig
+++ b/drivers/infiniband/Kconfig
@@ -50,6 +50,7 @@ source "drivers/infiniband/hw/amso1100/Kconfig"
 source "drivers/infiniband/hw/cxgb3/Kconfig"
 source "drivers/infiniband/hw/cxgb4/Kconfig"
 source "drivers/infiniband/hw/mlx4/Kconfig"
+source "drivers/infiniband/hw/mlx5/Kconfig"
 source "drivers/infiniband/hw/nes/Kconfig"
 source "drivers/infiniband/hw/ocrdma/Kconfig"
 
diff --git a/drivers/infiniband/Makefile b/drivers/infiniband/Makefile
index b126fef..1fe6988 100644
--- a/drivers/infiniband/Makefile
+++ b/drivers/infiniband/Makefile
@@ -7,6 +7,7 @@ obj-$(CONFIG_INFINIBAND_AMSO1100)	+= hw/amso1100/
 obj-$(CONFIG_INFINIBAND_CXGB3)		+= hw/cxgb3/
 obj-$(CONFIG_INFINIBAND_CXGB4)		+= hw/cxgb4/
 obj-$(CONFIG_MLX4_INFINIBAND)		+= hw/mlx4/
+obj-$(CONFIG_MLX5_INFINIBAND)		+= hw/mlx5/
 obj-$(CONFIG_INFINIBAND_NES)		+= hw/nes/
 obj-$(CONFIG_INFINIBAND_OCRDMA)		+= hw/ocrdma/
 obj-$(CONFIG_INFINIBAND_IPOIB)		+= ulp/ipoib/
diff --git a/drivers/infiniband/hw/mlx5/Kconfig b/drivers/infiniband/hw/mlx5/Kconfig
new file mode 100644
index 0000000..8e6aebf
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/Kconfig
@@ -0,0 +1,10 @@
+config MLX5_INFINIBAND
+	tristate "Mellanox Connect-IB HCA support"
+	depends on NETDEVICES && ETHERNET && PCI && X86
+	select NET_VENDOR_MELLANOX
+	select MLX5_CORE
+	---help---
+	  This driver provides low-level InfiniBand support for
+	  Mellanox Connect-IB PCI Express host channel adapters (HCAs).
+	  This is required to use InfiniBand protocols such as
+	  IP-over-IB or SRP with these devices.
diff --git a/drivers/infiniband/hw/mlx5/Makefile b/drivers/infiniband/hw/mlx5/Makefile
new file mode 100644
index 0000000..4ea0135
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/Makefile
@@ -0,0 +1,3 @@
+obj-$(CONFIG_MLX5_INFINIBAND)	+= mlx5_ib.o
+
+mlx5_ib-y :=	main.o cq.o doorbell.o qp.o mem.o srq.o mr.o ah.o mad.o
diff --git a/drivers/infiniband/hw/mlx5/ah.c b/drivers/infiniband/hw/mlx5/ah.c
new file mode 100644
index 0000000..39ab0ca
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/ah.c
@@ -0,0 +1,92 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "mlx5_ib.h"
+
+struct ib_ah *create_ib_ah(struct ib_ah_attr *ah_attr,
+			   struct mlx5_ib_ah *ah)
+{
+	if (ah_attr->ah_flags & IB_AH_GRH) {
+		memcpy(ah->av.rgid, &ah_attr->grh.dgid, 16);
+		ah->av.grh_gid_fl = cpu_to_be32(ah_attr->grh.flow_label |
+						(1 << 30) |
+						ah_attr->grh.sgid_index << 20);
+		ah->av.hop_limit = ah_attr->grh.hop_limit;
+		ah->av.tclass = ah_attr->grh.traffic_class;
+	}
+
+	ah->av.rlid = cpu_to_be16(ah_attr->dlid);
+	ah->av.fl_mlid = ah_attr->src_path_bits & 0x7f;
+	ah->av.stat_rate_sl = (ah_attr->static_rate << 4) | (ah_attr->sl & 0xf);
+
+	return &ah->ibah;
+}
+
+struct ib_ah *mlx5_ib_create_ah(struct ib_pd *pd, struct ib_ah_attr *ah_attr)
+{
+	struct mlx5_ib_ah *ah;
+
+	ah = kzalloc(sizeof(*ah), GFP_ATOMIC);
+	if (!ah)
+		return ERR_PTR(-ENOMEM);
+
+	return create_ib_ah(ah_attr, ah); /* never fails */
+}
+
+int mlx5_ib_query_ah(struct ib_ah *ibah, struct ib_ah_attr *ah_attr)
+{
+	struct mlx5_ib_ah *ah = to_mah(ibah);
+	u32 tmp;
+
+	memset(ah_attr, 0, sizeof(*ah_attr));
+
+	tmp = be32_to_cpu(ah->av.grh_gid_fl);
+	if (tmp & (1 << 30)) {
+		ah_attr->ah_flags = IB_AH_GRH;
+		ah_attr->grh.sgid_index = (tmp >> 20) & 0xff;
+		ah_attr->grh.flow_label = tmp & 0xfffff;
+		memcpy(&ah_attr->grh.dgid, ah->av.rgid, 16);
+		ah_attr->grh.hop_limit = ah->av.hop_limit;
+		ah_attr->grh.traffic_class = ah->av.tclass;
+	}
+	ah_attr->dlid = be16_to_cpu(ah->av.rlid);
+	ah_attr->static_rate = ah->av.stat_rate_sl >> 4;
+	ah_attr->sl = ah->av.stat_rate_sl & 0xf;
+
+	return 0;
+}
+
+int mlx5_ib_destroy_ah(struct ib_ah *ah)
+{
+	kfree(to_mah(ah));
+	return 0;
+}
diff --git a/drivers/infiniband/hw/mlx5/cq.c b/drivers/infiniband/hw/mlx5/cq.c
new file mode 100644
index 0000000..344ab03
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/cq.c
@@ -0,0 +1,843 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kref.h>
+#include <rdma/ib_umem.h>
+#include "mlx5_ib.h"
+#include "user.h"
+
+static void mlx5_ib_cq_comp(struct mlx5_core_cq *cq)
+{
+	struct ib_cq *ibcq = &to_mibcq(cq)->ibcq;
+
+	ibcq->comp_handler(ibcq, ibcq->cq_context);
+}
+
+static void mlx5_ib_cq_event(struct mlx5_core_cq *mcq, enum mlx5_event type)
+{
+	struct mlx5_ib_cq *cq = container_of(mcq, struct mlx5_ib_cq, mcq);
+	struct mlx5_ib_dev *dev = to_mdev(cq->ibcq.device);
+	struct ib_cq *ibcq = &cq->ibcq;
+	struct ib_event event;
+
+	if (type != MLX5_EVENT_TYPE_CQ_ERROR) {
+		mlx5_ib_warn(dev, "Unexpected event type %d on CQ %06x\n",
+			     type, mcq->cqn);
+		return;
+	}
+
+	if (ibcq->event_handler) {
+		event.device     = &dev->ib_dev;
+		event.event      = IB_EVENT_CQ_ERR;
+		event.element.cq = ibcq;
+		ibcq->event_handler(&event, ibcq->cq_context);
+	}
+}
+
+static void *get_cqe_from_buf(struct mlx5_ib_cq_buf *buf, int n, int size)
+{
+	return mlx5_buf_offset(&buf->buf, n * size);
+}
+
+static void *get_cqe(struct mlx5_ib_cq *cq, int n)
+{
+	return get_cqe_from_buf(&cq->buf, n, cq->mcq.cqe_sz);
+}
+
+static void *get_sw_cqe(struct mlx5_ib_cq *cq, int n)
+{
+	void *cqe = get_cqe(cq, n & cq->ibcq.cqe);
+	struct mlx5_cqe64 *cqe64;
+
+	cqe64 = (cq->mcq.cqe_sz == 64) ? cqe : cqe + 64;
+	return ((cqe64->op_own & MLX5_CQE_OWNER_MASK) ^
+		!!(n & (cq->ibcq.cqe + 1))) ? NULL : cqe;
+}
+
+static void *next_cqe_sw(struct mlx5_ib_cq *cq)
+{
+	return get_sw_cqe(cq, cq->mcq.cons_index);
+}
+
+static enum ib_wc_opcode get_umr_comp(struct mlx5_ib_wq *wq, int idx)
+{
+	switch (wq->wr_data[idx]) {
+	case MLX5_IB_WR_UMR:
+		return 0;
+
+	case IB_WR_LOCAL_INV:
+		return IB_WC_LOCAL_INV;
+
+	case IB_WR_FAST_REG_MR:
+		return IB_WC_FAST_REG_MR;
+
+	default:
+		pr_warn("unknown completion status\n");
+		return 0;
+	}
+}
+
+static void handle_good_req(struct ib_wc *wc, struct mlx5_cqe64 *cqe,
+			    struct mlx5_ib_wq *wq, int idx)
+{
+	wc->wc_flags = 0;
+	switch (be32_to_cpu(cqe->sop_drop_qpn) >> 24) {
+	case MLX5_OPCODE_RDMA_WRITE_IMM:
+		wc->wc_flags |= IB_WC_WITH_IMM;
+	case MLX5_OPCODE_RDMA_WRITE:
+		wc->opcode    = IB_WC_RDMA_WRITE;
+		break;
+	case MLX5_OPCODE_SEND_IMM:
+		wc->wc_flags |= IB_WC_WITH_IMM;
+	case MLX5_OPCODE_SEND:
+	case MLX5_OPCODE_SEND_INVAL:
+		wc->opcode    = IB_WC_SEND;
+		break;
+	case MLX5_OPCODE_RDMA_READ:
+		wc->opcode    = IB_WC_RDMA_READ;
+		wc->byte_len  = be32_to_cpu(cqe->byte_cnt);
+		break;
+	case MLX5_OPCODE_ATOMIC_CS:
+		wc->opcode    = IB_WC_COMP_SWAP;
+		wc->byte_len  = 8;
+		break;
+	case MLX5_OPCODE_ATOMIC_FA:
+		wc->opcode    = IB_WC_FETCH_ADD;
+		wc->byte_len  = 8;
+		break;
+	case MLX5_OPCODE_ATOMIC_MASKED_CS:
+		wc->opcode    = IB_WC_MASKED_COMP_SWAP;
+		wc->byte_len  = 8;
+		break;
+	case MLX5_OPCODE_ATOMIC_MASKED_FA:
+		wc->opcode    = IB_WC_MASKED_FETCH_ADD;
+		wc->byte_len  = 8;
+		break;
+	case MLX5_OPCODE_BIND_MW:
+		wc->opcode    = IB_WC_BIND_MW;
+		break;
+	case MLX5_OPCODE_UMR:
+		wc->opcode = get_umr_comp(wq, idx);
+		break;
+	}
+}
+
+enum {
+	MLX5_GRH_IN_BUFFER = 1,
+	MLX5_GRH_IN_CQE	   = 2,
+};
+
+static void handle_responder(struct ib_wc *wc, struct mlx5_cqe64 *cqe,
+			     struct mlx5_ib_qp *qp)
+{
+	struct mlx5_ib_dev *dev = to_mdev(qp->ibqp.device);
+	struct mlx5_ib_srq *srq;
+	struct mlx5_ib_wq *wq;
+	u16 wqe_ctr;
+	u8 g;
+
+	if (qp->ibqp.srq || qp->ibqp.xrcd) {
+		struct mlx5_core_srq *msrq = NULL;
+
+		if (qp->ibqp.xrcd) {
+			msrq = mlx5_core_get_srq(&dev->mdev,
+						 be32_to_cpu(cqe->srqn));
+			srq = to_mibsrq(msrq);
+		} else {
+			srq = to_msrq(qp->ibqp.srq);
+		}
+		if (srq) {
+			wqe_ctr = be16_to_cpu(cqe->wqe_counter);
+			wc->wr_id = srq->wrid[wqe_ctr];
+			mlx5_ib_free_srq_wqe(srq, wqe_ctr);
+			if (msrq && atomic_dec_and_test(&msrq->refcount))
+				complete(&msrq->free);
+		}
+	} else {
+		wq	  = &qp->rq;
+		wc->wr_id = wq->wrid[wq->tail & (wq->wqe_cnt - 1)];
+		++wq->tail;
+	}
+	wc->byte_len = be32_to_cpu(cqe->byte_cnt);
+
+	switch (cqe->op_own >> 4) {
+	case MLX5_CQE_RESP_WR_IMM:
+		wc->opcode	= IB_WC_RECV_RDMA_WITH_IMM;
+		wc->wc_flags	= IB_WC_WITH_IMM;
+		wc->ex.imm_data = cqe->imm_inval_pkey;
+		break;
+	case MLX5_CQE_RESP_SEND:
+		wc->opcode   = IB_WC_RECV;
+		wc->wc_flags = 0;
+		break;
+	case MLX5_CQE_RESP_SEND_IMM:
+		wc->opcode	= IB_WC_RECV;
+		wc->wc_flags	= IB_WC_WITH_IMM;
+		wc->ex.imm_data = cqe->imm_inval_pkey;
+		break;
+	case MLX5_CQE_RESP_SEND_INV:
+		wc->opcode	= IB_WC_RECV;
+		wc->wc_flags	= IB_WC_WITH_INVALIDATE;
+		wc->ex.invalidate_rkey = be32_to_cpu(cqe->imm_inval_pkey);
+		break;
+	}
+	wc->slid	   = be16_to_cpu(cqe->slid);
+	wc->sl		   = (be32_to_cpu(cqe->flags_rqpn) >> 24) & 0xf;
+	wc->src_qp	   = be32_to_cpu(cqe->flags_rqpn) & 0xffffff;
+	wc->dlid_path_bits = cqe->ml_path;
+	g = (be32_to_cpu(cqe->flags_rqpn) >> 28) & 3;
+	wc->wc_flags |= g ? IB_WC_GRH : 0;
+	wc->pkey_index     = be32_to_cpu(cqe->imm_inval_pkey) & 0xffff;
+}
+
+static void dump_cqe(struct mlx5_ib_dev *dev, struct mlx5_err_cqe *cqe)
+{
+	__be32 *p = (__be32 *)cqe;
+	int i;
+
+	mlx5_ib_warn(dev, "dump error cqe\n");
+	for (i = 0; i < sizeof(*cqe) / 16; i++, p += 4)
+		pr_info("%08x %08x %08x %08x\n", be32_to_cpu(p[0]),
+			be32_to_cpu(p[1]), be32_to_cpu(p[2]),
+			be32_to_cpu(p[3]));
+}
+
+static void mlx5_handle_error_cqe(struct mlx5_ib_dev *dev,
+				  struct mlx5_err_cqe *cqe,
+				  struct ib_wc *wc)
+{
+	int dump = 1;
+
+	switch (cqe->syndrome) {
+	case MLX5_CQE_SYNDROME_LOCAL_LENGTH_ERR:
+		wc->status = IB_WC_LOC_LEN_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_LOCAL_QP_OP_ERR:
+		wc->status = IB_WC_LOC_QP_OP_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_LOCAL_PROT_ERR:
+		wc->status = IB_WC_LOC_PROT_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_WR_FLUSH_ERR:
+		dump = 0;
+		wc->status = IB_WC_WR_FLUSH_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_MW_BIND_ERR:
+		wc->status = IB_WC_MW_BIND_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_BAD_RESP_ERR:
+		wc->status = IB_WC_BAD_RESP_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_LOCAL_ACCESS_ERR:
+		wc->status = IB_WC_LOC_ACCESS_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_REMOTE_INVAL_REQ_ERR:
+		wc->status = IB_WC_REM_INV_REQ_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_REMOTE_ACCESS_ERR:
+		wc->status = IB_WC_REM_ACCESS_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_REMOTE_OP_ERR:
+		wc->status = IB_WC_REM_OP_ERR;
+		break;
+	case MLX5_CQE_SYNDROME_TRANSPORT_RETRY_EXC_ERR:
+		wc->status = IB_WC_RETRY_EXC_ERR;
+		dump = 0;
+		break;
+	case MLX5_CQE_SYNDROME_RNR_RETRY_EXC_ERR:
+		wc->status = IB_WC_RNR_RETRY_EXC_ERR;
+		dump = 0;
+		break;
+	case MLX5_CQE_SYNDROME_REMOTE_ABORTED_ERR:
+		wc->status = IB_WC_REM_ABORT_ERR;
+		break;
+	default:
+		wc->status = IB_WC_GENERAL_ERR;
+		break;
+	}
+
+	wc->vendor_err = cqe->vendor_err_synd;
+	if (dump)
+		dump_cqe(dev, cqe);
+}
+
+static int is_atomic_response(struct mlx5_ib_qp *qp, uint16_t idx)
+{
+	/* TBD: waiting decision
+	*/
+	return 0;
+}
+
+static void *mlx5_get_atomic_laddr(struct mlx5_ib_qp *qp, uint16_t idx)
+{
+	struct mlx5_wqe_data_seg *dpseg;
+	void *addr;
+
+	dpseg = mlx5_get_send_wqe(qp, idx) + sizeof(struct mlx5_wqe_ctrl_seg) +
+		sizeof(struct mlx5_wqe_raddr_seg) +
+		sizeof(struct mlx5_wqe_atomic_seg);
+	addr = (void *)(unsigned long)be64_to_cpu(dpseg->addr);
+	return addr;
+}
+
+static void handle_atomic(struct mlx5_ib_qp *qp, struct mlx5_cqe64 *cqe64,
+			  uint16_t idx)
+{
+	void *addr;
+	int byte_count;
+	int i;
+
+	if (!is_atomic_response(qp, idx))
+		return;
+
+	byte_count = be32_to_cpu(cqe64->byte_cnt);
+	addr = mlx5_get_atomic_laddr(qp, idx);
+
+	if (byte_count == 4) {
+		*(uint32_t *)addr = be32_to_cpu(*((__be32 *)addr));
+	} else {
+		for (i = 0; i < byte_count; i += 8) {
+			*(uint64_t *)addr = be64_to_cpu(*((__be64 *)addr));
+			addr += 8;
+		}
+	}
+
+	return;
+}
+
+static void handle_atomics(struct mlx5_ib_qp *qp, struct mlx5_cqe64 *cqe64,
+			   u16 tail, u16 head)
+{
+	int idx;
+
+	do {
+		idx = tail & (qp->sq.wqe_cnt - 1);
+		handle_atomic(qp, cqe64, idx);
+		if (idx == head)
+			break;
+
+		tail = qp->sq.w_list[idx].next;
+	} while (1);
+	tail = qp->sq.w_list[idx].next;
+	qp->sq.last_poll = tail;
+}
+
+static int mlx5_poll_one(struct mlx5_ib_cq *cq,
+			 struct mlx5_ib_qp **cur_qp,
+			 struct ib_wc *wc)
+{
+	struct mlx5_ib_dev *dev = to_mdev(cq->ibcq.device);
+	struct mlx5_err_cqe *err_cqe;
+	struct mlx5_cqe64 *cqe64;
+	struct mlx5_core_qp *mqp;
+	struct mlx5_ib_wq *wq;
+	uint8_t opcode;
+	uint32_t qpn;
+	u16 wqe_ctr;
+	void *cqe;
+	int idx;
+
+	cqe = next_cqe_sw(cq);
+	if (!cqe)
+		return -EAGAIN;
+
+	cqe64 = (cq->mcq.cqe_sz == 64) ? cqe : cqe + 64;
+
+	++cq->mcq.cons_index;
+
+	/* Make sure we read CQ entry contents after we've checked the
+	 * ownership bit.
+	 */
+	rmb();
+
+	/* TBD: resize CQ */
+
+	qpn = ntohl(cqe64->sop_drop_qpn) & 0xffffff;
+	if (!*cur_qp || (qpn != (*cur_qp)->ibqp.qp_num)) {
+		/* We do not have to take the QP table lock here,
+		 * because CQs will be locked while QPs are removed
+		 * from the table.
+		 */
+		mqp = __mlx5_qp_lookup(&dev->mdev, qpn);
+		if (unlikely(!mqp)) {
+			mlx5_ib_warn(dev, "CQE@CQ %06x for unknown QPN %6x\n",
+				     cq->mcq.cqn, qpn);
+			return -EINVAL;
+		}
+
+		*cur_qp = to_mibqp(mqp);
+	}
+
+	wc->qp  = &(*cur_qp)->ibqp;
+	opcode = cqe64->op_own >> 4;
+	switch (opcode) {
+	case MLX5_CQE_REQ:
+		wq = &(*cur_qp)->sq;
+		wqe_ctr = be16_to_cpu(cqe64->wqe_counter);
+		idx = wqe_ctr & (wq->wqe_cnt - 1);
+		handle_good_req(wc, cqe64, wq, idx);
+		handle_atomics(*cur_qp, cqe64, wq->last_poll, idx);
+		wc->wr_id = wq->wrid[idx];
+		wq->tail = wq->wqe_head[idx] + 1;
+		wc->status = IB_WC_SUCCESS;
+		break;
+	case MLX5_CQE_RESP_WR_IMM:
+	case MLX5_CQE_RESP_SEND:
+	case MLX5_CQE_RESP_SEND_IMM:
+	case MLX5_CQE_RESP_SEND_INV:
+		handle_responder(wc, cqe64, *cur_qp);
+		wc->status = IB_WC_SUCCESS;
+		break;
+	case MLX5_CQE_RESIZE_CQ:
+		break;
+	case MLX5_CQE_REQ_ERR:
+	case MLX5_CQE_RESP_ERR:
+		err_cqe = (struct mlx5_err_cqe *)cqe64;
+		mlx5_handle_error_cqe(dev, err_cqe, wc);
+		mlx5_ib_dbg(dev, "%s error cqe on cqn 0x%x:\n",
+			    opcode == MLX5_CQE_REQ_ERR ?
+			    "Requestor" : "Responder", cq->mcq.cqn);
+		mlx5_ib_dbg(dev, "syndrome 0x%x, vendor syndrome 0x%x\n",
+			    err_cqe->syndrome, err_cqe->vendor_err_synd);
+		if (opcode == MLX5_CQE_REQ_ERR) {
+			wq = &(*cur_qp)->sq;
+			wqe_ctr = be16_to_cpu(cqe64->wqe_counter);
+			idx = wqe_ctr & (wq->wqe_cnt - 1);
+			wc->wr_id = wq->wrid[idx];
+			wq->tail = wq->wqe_head[idx] + 1;
+		} else {
+			struct mlx5_ib_srq *srq;
+
+			if ((*cur_qp)->ibqp.srq) {
+				srq = to_msrq((*cur_qp)->ibqp.srq);
+				wqe_ctr = be16_to_cpu(cqe64->wqe_counter);
+				wc->wr_id = srq->wrid[wqe_ctr];
+				mlx5_ib_free_srq_wqe(srq, wqe_ctr);
+			} else {
+				wq = &(*cur_qp)->rq;
+				wc->wr_id = wq->wrid[wq->tail & (wq->wqe_cnt - 1)];
+				++wq->tail;
+			}
+		}
+		break;
+	}
+
+	return 0;
+}
+
+int mlx5_ib_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc)
+{
+	struct mlx5_ib_cq *cq = to_mcq(ibcq);
+	struct mlx5_ib_qp *cur_qp = NULL;
+	unsigned long flags;
+	int npolled;
+	int err = 0;
+
+	spin_lock_irqsave(&cq->lock, flags);
+
+	for (npolled = 0; npolled < num_entries; npolled++) {
+		err = mlx5_poll_one(cq, &cur_qp, wc + npolled);
+		if (err)
+			break;
+	}
+
+	if (npolled)
+		mlx5_cq_set_ci(&cq->mcq);
+
+	spin_unlock_irqrestore(&cq->lock, flags);
+
+	if (err == 0 || err == -EAGAIN)
+		return npolled;
+	else
+		return err;
+}
+
+int mlx5_ib_arm_cq(struct ib_cq *ibcq, enum ib_cq_notify_flags flags)
+{
+	mlx5_cq_arm(&to_mcq(ibcq)->mcq,
+		    (flags & IB_CQ_SOLICITED_MASK) == IB_CQ_SOLICITED ?
+		    MLX5_CQ_DB_REQ_NOT_SOL : MLX5_CQ_DB_REQ_NOT,
+		    to_mdev(ibcq->device)->mdev.priv.uuari.uars[0].map,
+		    MLX5_GET_DOORBELL_LOCK(&to_mdev(ibcq->device)->mdev.priv.cq_uar_lock));
+
+	return 0;
+}
+
+static int alloc_cq_buf(struct mlx5_ib_dev *dev, struct mlx5_ib_cq_buf *buf,
+			int nent, int cqe_size)
+{
+	int err;
+
+	err = mlx5_buf_alloc(&dev->mdev, nent * cqe_size,
+			     PAGE_SIZE * 2, &buf->buf);
+	if (err)
+		return err;
+
+	buf->cqe_size = cqe_size;
+
+	return 0;
+}
+
+static void free_cq_buf(struct mlx5_ib_dev *dev, struct mlx5_ib_cq_buf *buf)
+{
+	mlx5_buf_free(&dev->mdev, &buf->buf);
+}
+
+static int create_cq_user(struct mlx5_ib_dev *dev, struct ib_udata *udata,
+			  struct ib_ucontext *context, struct mlx5_ib_cq *cq,
+			  int entries, struct mlx5_create_cq_mbox_in **cqb,
+			  int *cqe_size, int *index, int *inlen)
+{
+	struct mlx5_ib_create_cq ucmd;
+	int page_shift;
+	int npages;
+	int ncont;
+	int err;
+
+	if (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd)))
+		return -EFAULT;
+
+	if (ucmd.cqe_size != 64 && ucmd.cqe_size != 128)
+		return -EINVAL;
+
+	*cqe_size = ucmd.cqe_size;
+
+	cq->buf.umem = ib_umem_get(context, ucmd.buf_addr,
+				   entries * ucmd.cqe_size,
+				   IB_ACCESS_LOCAL_WRITE, 1);
+	if (IS_ERR(cq->buf.umem)) {
+		err = PTR_ERR(cq->buf.umem);
+		return err;
+	}
+
+	err = mlx5_ib_db_map_user(to_mucontext(context), ucmd.db_addr,
+				  &cq->db);
+	if (err)
+		goto err_umem;
+
+	mlx5_ib_cont_pages(cq->buf.umem, ucmd.buf_addr, &npages, &page_shift,
+			   &ncont, NULL);
+	mlx5_ib_dbg(dev, "addr 0x%llx, size %u, npages %d, page_shift %d, ncont %d\n",
+		    ucmd.buf_addr, entries * ucmd.cqe_size, npages, page_shift, ncont);
+
+	*inlen = sizeof(**cqb) + sizeof(*(*cqb)->pas) * ncont;
+	*cqb = mlx5_vzalloc(*inlen);
+	if (!*cqb) {
+		err = -ENOMEM;
+		goto err_db;
+	}
+	mlx5_ib_populate_pas(dev, cq->buf.umem, page_shift, (*cqb)->pas, 0);
+	(*cqb)->ctx.log_pg_sz = page_shift - PAGE_SHIFT;
+
+	*index = to_mucontext(context)->uuari.uars[0].index;
+
+	return 0;
+
+err_db:
+	mlx5_ib_db_unmap_user(to_mucontext(context), &cq->db);
+
+err_umem:
+	ib_umem_release(cq->buf.umem);
+	return err;
+}
+
+static void destroy_cq_user(struct mlx5_ib_cq *cq, struct ib_ucontext *context)
+{
+	mlx5_ib_db_unmap_user(to_mucontext(context), &cq->db);
+	ib_umem_release(cq->buf.umem);
+}
+
+static void init_cq_buf(struct mlx5_ib_cq *cq, int nent)
+{
+	int i;
+	void *cqe;
+	struct mlx5_cqe64 *cqe64;
+
+	for (i = 0; i < nent; i++) {
+		cqe = get_cqe(cq, i);
+		cqe64 = (cq->buf.cqe_size == 64) ? cqe : cqe + 64;
+		cqe64->op_own = 0xf1;
+	}
+}
+
+static int create_cq_kernel(struct mlx5_ib_dev *dev, struct mlx5_ib_cq *cq,
+			    int entries, int cqe_size,
+			    struct mlx5_create_cq_mbox_in **cqb,
+			    int *index, int *inlen)
+{
+	int err;
+
+	err = mlx5_db_alloc(&dev->mdev, &cq->db);
+	if (err)
+		return err;
+
+	cq->mcq.set_ci_db  = cq->db.db;
+	cq->mcq.arm_db     = cq->db.db + 1;
+	*cq->mcq.set_ci_db = 0;
+	*cq->mcq.arm_db    = 0;
+	cq->mcq.cqe_sz = cqe_size;
+
+	err = alloc_cq_buf(dev, &cq->buf, entries, cqe_size);
+	if (err)
+		goto err_db;
+
+	init_cq_buf(cq, entries);
+
+	*inlen = sizeof(**cqb) + sizeof(*(*cqb)->pas) * cq->buf.buf.npages;
+	*cqb = mlx5_vzalloc(*inlen);
+	if (!*cqb) {
+		err = -ENOMEM;
+		goto err_buf;
+	}
+	mlx5_fill_page_array(&cq->buf.buf, (*cqb)->pas);
+
+	(*cqb)->ctx.log_pg_sz = cq->buf.buf.page_shift - PAGE_SHIFT;
+	*index = dev->mdev.priv.uuari.uars[0].index;
+
+	return 0;
+
+err_buf:
+	free_cq_buf(dev, &cq->buf);
+
+err_db:
+	mlx5_db_free(&dev->mdev, &cq->db);
+	return err;
+}
+
+static void destroy_cq_kernel(struct mlx5_ib_dev *dev, struct mlx5_ib_cq *cq)
+{
+	free_cq_buf(dev, &cq->buf);
+	mlx5_db_free(&dev->mdev, &cq->db);
+}
+
+struct ib_cq *mlx5_ib_create_cq(struct ib_device *ibdev, int entries,
+				int vector, struct ib_ucontext *context,
+				struct ib_udata *udata)
+{
+	struct mlx5_create_cq_mbox_in *cqb = NULL;
+	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+	struct mlx5_ib_cq *cq;
+	int uninitialized_var(index);
+	int uninitialized_var(inlen);
+	int cqe_size;
+	int irqn;
+	int eqn;
+	int err;
+
+	entries = roundup_pow_of_two(entries + 1);
+	if (entries < 1 || entries > dev->mdev.caps.max_cqes)
+		return ERR_PTR(-EINVAL);
+
+	cq = kzalloc(sizeof(*cq), GFP_KERNEL);
+	if (!cq)
+		return ERR_PTR(-ENOMEM);
+
+	cq->ibcq.cqe = entries - 1;
+	mutex_init(&cq->resize_mutex);
+	spin_lock_init(&cq->lock);
+	cq->resize_buf = NULL;
+	cq->resize_umem = NULL;
+
+	if (context) {
+		err = create_cq_user(dev, udata, context, cq, entries,
+				     &cqb, &cqe_size, &index, &inlen);
+		if (err)
+			goto err_create;
+	} else {
+		/* for now choose 64 bytes till we have a proper interface */
+		cqe_size = 64;
+		err = create_cq_kernel(dev, cq, entries, cqe_size, &cqb,
+				       &index, &inlen);
+		if (err)
+			goto err_create;
+	}
+
+	cq->cqe_size = cqe_size;
+	cqb->ctx.cqe_sz_flags = cqe_sz_to_mlx_sz(cqe_size) << 5;
+	cqb->ctx.log_sz_usr_page = cpu_to_be32((ilog2(entries) << 24) | index);
+	err = mlx5_vector2eqn(dev, vector, &eqn, &irqn);
+	if (err)
+		goto err_cqb;
+
+	cqb->ctx.c_eqn = cpu_to_be16(eqn);
+	cqb->ctx.db_record_addr = cpu_to_be64(cq->db.dma);
+
+	err = mlx5_core_create_cq(&dev->mdev, &cq->mcq, cqb, inlen);
+	if (err)
+		goto err_cqb;
+
+	mlx5_ib_dbg(dev, "cqn 0x%x\n", cq->mcq.cqn);
+	cq->mcq.irqn = irqn;
+	cq->mcq.comp  = mlx5_ib_cq_comp;
+	cq->mcq.event = mlx5_ib_cq_event;
+
+	if (context)
+		if (ib_copy_to_udata(udata, &cq->mcq.cqn, sizeof(__u32))) {
+			err = -EFAULT;
+			goto err_cmd;
+		}
+
+
+	mlx5_vfree(cqb);
+	return &cq->ibcq;
+
+err_cmd:
+	mlx5_core_destroy_cq(&dev->mdev, &cq->mcq);
+
+err_cqb:
+	mlx5_vfree(cqb);
+	if (context)
+		destroy_cq_user(cq, context);
+	else
+		destroy_cq_kernel(dev, cq);
+
+err_create:
+	kfree(cq);
+
+	return ERR_PTR(err);
+}
+
+
+int mlx5_ib_destroy_cq(struct ib_cq *cq)
+{
+	struct mlx5_ib_dev *dev = to_mdev(cq->device);
+	struct mlx5_ib_cq *mcq = to_mcq(cq);
+	struct ib_ucontext *context = NULL;
+
+	if (cq->uobject)
+		context = cq->uobject->context;
+
+	mlx5_core_destroy_cq(&dev->mdev, &mcq->mcq);
+	if (context)
+		destroy_cq_user(mcq, context);
+	else
+		destroy_cq_kernel(dev, mcq);
+
+	kfree(mcq);
+
+	return 0;
+}
+
+static int is_equal_rsn(struct mlx5_cqe64 *cqe64, struct mlx5_ib_srq *srq,
+			u32 rsn)
+{
+	u32 lrsn;
+
+	if (srq)
+		lrsn = be32_to_cpu(cqe64->srqn) & 0xffffff;
+	else
+		lrsn = be32_to_cpu(cqe64->sop_drop_qpn) & 0xffffff;
+
+	return rsn == lrsn;
+}
+
+void __mlx5_ib_cq_clean(struct mlx5_ib_cq *cq, u32 rsn, struct mlx5_ib_srq *srq)
+{
+	struct mlx5_cqe64 *cqe64, *dest64;
+	void *cqe, *dest;
+	u32 prod_index;
+	int nfreed = 0;
+	u8 owner_bit;
+
+	if (!cq)
+		return;
+
+	/* First we need to find the current producer index, so we
+	 * know where to start cleaning from.  It doesn't matter if HW
+	 * adds new entries after this loop -- the QP we're worried
+	 * about is already in RESET, so the new entries won't come
+	 * from our QP and therefore don't need to be checked.
+	 */
+	for (prod_index = cq->mcq.cons_index; get_sw_cqe(cq, prod_index); prod_index++)
+		if (prod_index == cq->mcq.cons_index + cq->ibcq.cqe)
+			break;
+
+	/* Now sweep backwards through the CQ, removing CQ entries
+	 * that match our QP by copying older entries on top of them.
+	 */
+	while ((int) --prod_index - (int) cq->mcq.cons_index >= 0) {
+		cqe = get_cqe(cq, prod_index & cq->ibcq.cqe);
+		cqe64 = (cq->mcq.cqe_sz == 64) ? cqe : cqe + 64;
+		if (is_equal_rsn(cqe64, srq, rsn)) {
+			if (srq)
+				mlx5_ib_free_srq_wqe(srq, be16_to_cpu(cqe64->wqe_counter));
+			++nfreed;
+		} else if (nfreed) {
+			dest = get_cqe(cq, (prod_index + nfreed) & cq->ibcq.cqe);
+			dest64 = (cq->mcq.cqe_sz == 64) ? dest : dest + 64;
+			owner_bit = dest64->op_own & MLX5_CQE_OWNER_MASK;
+			memcpy(dest, cqe, cq->mcq.cqe_sz);
+			dest64->op_own = owner_bit |
+				(dest64->op_own & ~MLX5_CQE_OWNER_MASK);
+		}
+	}
+
+	if (nfreed) {
+		cq->mcq.cons_index += nfreed;
+		/* Make sure update of buffer contents is done before
+		 * updating consumer index.
+		 */
+		wmb();
+		mlx5_cq_set_ci(&cq->mcq);
+	}
+}
+
+void mlx5_ib_cq_clean(struct mlx5_ib_cq *cq, u32 qpn, struct mlx5_ib_srq *srq)
+{
+	if (!cq)
+		return;
+
+	spin_lock_irq(&cq->lock);
+	__mlx5_ib_cq_clean(cq, qpn, srq);
+	spin_unlock_irq(&cq->lock);
+}
+
+int mlx5_ib_modify_cq(struct ib_cq *cq, u16 cq_count, u16 cq_period)
+{
+	return -ENOSYS;
+}
+
+int mlx5_ib_resize_cq(struct ib_cq *ibcq, int entries, struct ib_udata *udata)
+{
+	return -ENOSYS;
+}
+
+int mlx5_ib_get_cqe_size(struct mlx5_ib_dev *dev, struct ib_cq *ibcq)
+{
+	struct mlx5_ib_cq *cq;
+
+	if (!ibcq)
+		return 128;
+
+	cq = to_mcq(ibcq);
+	return cq->cqe_size;
+}
diff --git a/drivers/infiniband/hw/mlx5/doorbell.c b/drivers/infiniband/hw/mlx5/doorbell.c
new file mode 100644
index 0000000..256a233
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/doorbell.c
@@ -0,0 +1,100 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kref.h>
+#include <linux/slab.h>
+#include <rdma/ib_umem.h>
+
+#include "mlx5_ib.h"
+
+struct mlx5_ib_user_db_page {
+	struct list_head	list;
+	struct ib_umem	       *umem;
+	unsigned long		user_virt;
+	int			refcnt;
+};
+
+int mlx5_ib_db_map_user(struct mlx5_ib_ucontext *context, unsigned long virt,
+			struct mlx5_db *db)
+{
+	struct mlx5_ib_user_db_page *page;
+	struct ib_umem_chunk *chunk;
+	int err = 0;
+
+	mutex_lock(&context->db_page_mutex);
+
+	list_for_each_entry(page, &context->db_page_list, list)
+		if (page->user_virt == (virt & PAGE_MASK))
+			goto found;
+
+	page = kmalloc(sizeof(*page), GFP_KERNEL);
+	if (!page) {
+		err = -ENOMEM;
+		goto out;
+	}
+
+	page->user_virt = (virt & PAGE_MASK);
+	page->refcnt    = 0;
+	page->umem      = ib_umem_get(&context->ibucontext, virt & PAGE_MASK,
+				      PAGE_SIZE, 0, 0);
+	if (IS_ERR(page->umem)) {
+		err = PTR_ERR(page->umem);
+		kfree(page);
+		goto out;
+	}
+
+	list_add(&page->list, &context->db_page_list);
+
+found:
+	chunk = list_entry(page->umem->chunk_list.next, struct ib_umem_chunk, list);
+	db->dma		= sg_dma_address(chunk->page_list) + (virt & ~PAGE_MASK);
+	db->u.user_page = page;
+	++page->refcnt;
+
+out:
+	mutex_unlock(&context->db_page_mutex);
+
+	return err;
+}
+
+void mlx5_ib_db_unmap_user(struct mlx5_ib_ucontext *context, struct mlx5_db *db)
+{
+	mutex_lock(&context->db_page_mutex);
+
+	if (!--db->u.user_page->refcnt) {
+		list_del(&db->u.user_page->list);
+		ib_umem_release(db->u.user_page->umem);
+		kfree(db->u.user_page);
+	}
+
+	mutex_unlock(&context->db_page_mutex);
+}
diff --git a/drivers/infiniband/hw/mlx5/mad.c b/drivers/infiniband/hw/mlx5/mad.c
new file mode 100644
index 0000000..5c8938b
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/mad.c
@@ -0,0 +1,139 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/mlx5/cmd.h>
+#include <rdma/ib_mad.h>
+#include <rdma/ib_smi.h>
+#include "mlx5_ib.h"
+
+enum {
+	MLX5_IB_VENDOR_CLASS1 = 0x9,
+	MLX5_IB_VENDOR_CLASS2 = 0xa
+};
+
+int mlx5_MAD_IFC(struct mlx5_ib_dev *dev, int ignore_mkey, int ignore_bkey,
+		 int port, struct ib_wc *in_wc, struct ib_grh *in_grh,
+		 void *in_mad, void *response_mad)
+{
+	u8 op_modifier = 0;
+
+	/* Key check traps can't be generated unless we have in_wc to
+	 * tell us where to send the trap.
+	 */
+	if (ignore_mkey || !in_wc)
+		op_modifier |= 0x1;
+	if (ignore_bkey || !in_wc)
+		op_modifier |= 0x2;
+
+	return mlx5_core_mad_ifc(&dev->mdev, in_mad, response_mad, op_modifier, port);
+}
+
+int mlx5_ib_process_mad(struct ib_device *ibdev, int mad_flags, u8 port_num,
+			struct ib_wc *in_wc, struct ib_grh *in_grh,
+			struct ib_mad *in_mad, struct ib_mad *out_mad)
+{
+	u16 slid;
+	int err;
+
+	slid = in_wc ? in_wc->slid : be16_to_cpu(IB_LID_PERMISSIVE);
+
+	if (in_mad->mad_hdr.method == IB_MGMT_METHOD_TRAP && slid == 0)
+		return IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_CONSUMED;
+
+	if (in_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_LID_ROUTED ||
+	    in_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE) {
+		if (in_mad->mad_hdr.method   != IB_MGMT_METHOD_GET &&
+		    in_mad->mad_hdr.method   != IB_MGMT_METHOD_SET &&
+		    in_mad->mad_hdr.method   != IB_MGMT_METHOD_TRAP_REPRESS)
+			return IB_MAD_RESULT_SUCCESS;
+
+		/* Don't process SMInfo queries -- the SMA can't handle them.
+		 */
+		if (in_mad->mad_hdr.attr_id == IB_SMP_ATTR_SM_INFO)
+			return IB_MAD_RESULT_SUCCESS;
+	} else if (in_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_PERF_MGMT ||
+		   in_mad->mad_hdr.mgmt_class == MLX5_IB_VENDOR_CLASS1   ||
+		   in_mad->mad_hdr.mgmt_class == MLX5_IB_VENDOR_CLASS2   ||
+		   in_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_CONG_MGMT) {
+		if (in_mad->mad_hdr.method  != IB_MGMT_METHOD_GET &&
+		    in_mad->mad_hdr.method  != IB_MGMT_METHOD_SET)
+			return IB_MAD_RESULT_SUCCESS;
+	} else {
+		return IB_MAD_RESULT_SUCCESS;
+	}
+
+	err = mlx5_MAD_IFC(to_mdev(ibdev),
+			   mad_flags & IB_MAD_IGNORE_MKEY,
+			   mad_flags & IB_MAD_IGNORE_BKEY,
+			   port_num, in_wc, in_grh, in_mad, out_mad);
+	if (err)
+		return IB_MAD_RESULT_FAILURE;
+
+	/* set return bit in status of directed route responses */
+	if (in_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE)
+		out_mad->mad_hdr.status |= cpu_to_be16(1 << 15);
+
+	if (in_mad->mad_hdr.method == IB_MGMT_METHOD_TRAP_REPRESS)
+		/* no response for trap repress */
+		return IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_CONSUMED;
+
+	return IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_REPLY;
+}
+
+int mlx5_query_ext_port_caps(struct mlx5_ib_dev *dev, u8 port)
+{
+	struct ib_smp *in_mad  = NULL;
+	struct ib_smp *out_mad = NULL;
+	int err = -ENOMEM;
+	u16 packet_error;
+
+	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
+	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
+	if (!in_mad || !out_mad)
+		goto out;
+
+	init_query_mad(in_mad);
+	in_mad->attr_id = MLX5_ATTR_EXTENDED_PORT_INFO;
+	in_mad->attr_mod = cpu_to_be32(port);
+
+	err = mlx5_MAD_IFC(dev, 1, 1, 1, NULL, NULL, in_mad, out_mad);
+
+	packet_error = be16_to_cpu(out_mad->status);
+
+	dev->mdev.caps.ext_port_cap[port - 1] = (!err && !packet_error) ?
+		MLX_EXT_PORT_CAP_FLAG_EXTENDED_PORT_INFO : 0;
+
+out:
+	kfree(in_mad);
+	kfree(out_mad);
+	return err;
+}
diff --git a/drivers/infiniband/hw/mlx5/main.c b/drivers/infiniband/hw/mlx5/main.c
new file mode 100644
index 0000000..6b1007f
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/main.c
@@ -0,0 +1,1504 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <asm-generic/kmap_types.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/pci.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/io-mapping.h>
+#include <linux/sched.h>
+#include <rdma/ib_user_verbs.h>
+#include <rdma/ib_smi.h>
+#include <rdma/ib_umem.h>
+#include "user.h"
+#include "mlx5_ib.h"
+
+#define DRIVER_NAME "mlx5_ib"
+#define DRIVER_VERSION "1.0"
+#define DRIVER_RELDATE	"June 2013"
+
+MODULE_AUTHOR("Eli Cohen <eli@mellanox.com>");
+MODULE_DESCRIPTION("Mellanox Connect-IB HCA IB driver");
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_VERSION(DRIVER_VERSION);
+
+static int prof_sel = 2;
+module_param_named(prof_sel, prof_sel, int, 0444);
+MODULE_PARM_DESC(prof_sel, "profile selector. Valid range 0 - 2");
+
+static char mlx5_version[] =
+	DRIVER_NAME ": Mellanox Connect-IB Infiniband driver v"
+	DRIVER_VERSION " (" DRIVER_RELDATE ")\n";
+
+struct mlx5_profile profile[] = {
+	[0] = {
+		.mask		= 0,
+	},
+	[1] = {
+		.mask		= MLX5_PROF_MASK_QP_SIZE,
+		.log_max_qp	= 12,
+	},
+	[2] = {
+		.mask		= MLX5_PROF_MASK_QP_SIZE |
+				  MLX5_PROF_MASK_MR_CACHE,
+		.log_max_qp	= 17,
+		.mr_cache[0]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[1]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[2]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[3]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[4]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[5]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[6]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[7]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[8]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[9]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[10]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[11]	= {
+			.size	= 500,
+			.limit	= 250
+		},
+		.mr_cache[12]	= {
+			.size	= 64,
+			.limit	= 32
+		},
+		.mr_cache[13]	= {
+			.size	= 32,
+			.limit	= 16
+		},
+		.mr_cache[14]	= {
+			.size	= 16,
+			.limit	= 8
+		},
+		.mr_cache[15]	= {
+			.size	= 8,
+			.limit	= 4
+		},
+	},
+};
+
+int mlx5_vector2eqn(struct mlx5_ib_dev *dev, int vector, int *eqn, int *irqn)
+{
+	struct mlx5_eq_table *table = &dev->mdev.priv.eq_table;
+	struct mlx5_eq *eq, *n;
+	int err = -ENOENT;
+
+	spin_lock(&table->lock);
+	list_for_each_entry_safe(eq, n, &dev->eqs_list, list) {
+		if (eq->index == vector) {
+			*eqn = eq->eqn;
+			*irqn = eq->irqn;
+			err = 0;
+			break;
+		}
+	}
+	spin_unlock(&table->lock);
+
+	return err;
+}
+
+static int alloc_comp_eqs(struct mlx5_ib_dev *dev)
+{
+	struct mlx5_eq_table *table = &dev->mdev.priv.eq_table;
+	struct mlx5_eq *eq, *n;
+	int ncomp_vec;
+	int nent;
+	int err;
+	int i;
+
+	INIT_LIST_HEAD(&dev->eqs_list);
+	ncomp_vec = table->num_comp_vectors;
+	nent = MLX5_COMP_EQ_SIZE;
+	for (i = 0; i < ncomp_vec; i++) {
+		eq = kzalloc(sizeof(*eq), GFP_KERNEL);
+		if (!eq) {
+			err = -ENOMEM;
+			goto clean;
+		}
+
+		snprintf(eq->name, MLX5_MAX_EQ_NAME, "mlx5_comp%d", i);
+		err = mlx5_create_map_eq(&dev->mdev, eq,
+					 i + MLX5_EQ_VEC_COMP_BASE, nent, 0,
+					 eq->name,
+					 &dev->mdev.priv.uuari.uars[0]);
+		if (err) {
+			kfree(eq);
+			goto clean;
+		}
+		mlx5_ib_dbg(dev, "allocated completion EQN %d\n", eq->eqn);
+		eq->index = i;
+		spin_lock(&table->lock);
+		list_add_tail(&eq->list, &dev->eqs_list);
+		spin_unlock(&table->lock);
+	}
+
+	dev->num_comp_vectors = ncomp_vec;
+	return 0;
+
+clean:
+	spin_lock(&table->lock);
+	list_for_each_entry_safe(eq, n, &dev->eqs_list, list) {
+		list_del(&eq->list);
+		spin_unlock(&table->lock);
+		if (mlx5_destroy_unmap_eq(&dev->mdev, eq))
+			mlx5_ib_warn(dev, "failed to destroy EQ 0x%x\n", eq->eqn);
+		kfree(eq);
+		spin_lock(&table->lock);
+	}
+	spin_unlock(&table->lock);
+	return err;
+}
+
+static void free_comp_eqs(struct mlx5_ib_dev *dev)
+{
+	struct mlx5_eq_table *table = &dev->mdev.priv.eq_table;
+	struct mlx5_eq *eq, *n;
+
+	spin_lock(&table->lock);
+	list_for_each_entry_safe(eq, n, &dev->eqs_list, list) {
+		list_del(&eq->list);
+		spin_unlock(&table->lock);
+		if (mlx5_destroy_unmap_eq(&dev->mdev, eq))
+			mlx5_ib_warn(dev, "failed to destroy EQ 0x%x\n", eq->eqn);
+		kfree(eq);
+		spin_lock(&table->lock);
+	}
+	spin_unlock(&table->lock);
+}
+
+static int mlx5_ib_query_device(struct ib_device *ibdev,
+				struct ib_device_attr *props)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+	struct ib_smp *in_mad  = NULL;
+	struct ib_smp *out_mad = NULL;
+	int err = -ENOMEM;
+	int max_rq_sg;
+	int max_sq_sg;
+	u64 flags;
+
+	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
+	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
+	if (!in_mad || !out_mad)
+		goto out;
+
+	init_query_mad(in_mad);
+	in_mad->attr_id = IB_SMP_ATTR_NODE_INFO;
+
+	err = mlx5_MAD_IFC(to_mdev(ibdev), 1, 1, 1, NULL, NULL, in_mad, out_mad);
+	if (err)
+		goto out;
+
+	memset(props, 0, sizeof(*props));
+
+	props->fw_ver = ((u64)fw_rev_maj(&dev->mdev) << 32) |
+		(fw_rev_min(&dev->mdev) << 16) |
+		fw_rev_sub(&dev->mdev);
+	props->device_cap_flags    = IB_DEVICE_CHANGE_PHY_PORT |
+		IB_DEVICE_PORT_ACTIVE_EVENT		|
+		IB_DEVICE_SYS_IMAGE_GUID		|
+		IB_DEVICE_RC_RNR_NAK_GEN		|
+		IB_DEVICE_BLOCK_MULTICAST_LOOPBACK;
+	flags = dev->mdev.caps.flags;
+	if (flags & MLX5_DEV_CAP_FLAG_BAD_PKEY_CNTR)
+		props->device_cap_flags |= IB_DEVICE_BAD_PKEY_CNTR;
+	if (flags & MLX5_DEV_CAP_FLAG_BAD_QKEY_CNTR)
+		props->device_cap_flags |= IB_DEVICE_BAD_QKEY_CNTR;
+	if (flags & MLX5_DEV_CAP_FLAG_APM)
+		props->device_cap_flags |= IB_DEVICE_AUTO_PATH_MIG;
+	props->device_cap_flags |= IB_DEVICE_LOCAL_DMA_LKEY;
+	if (flags & MLX5_DEV_CAP_FLAG_XRC)
+		props->device_cap_flags |= IB_DEVICE_XRC;
+	props->device_cap_flags |= IB_DEVICE_MEM_MGT_EXTENSIONS;
+
+	props->vendor_id	   = be32_to_cpup((__be32 *)(out_mad->data + 36)) &
+		0xffffff;
+	props->vendor_part_id	   = be16_to_cpup((__be16 *)(out_mad->data + 30));
+	props->hw_ver		   = be32_to_cpup((__be32 *)(out_mad->data + 32));
+	memcpy(&props->sys_image_guid, out_mad->data +	4, 8);
+
+	props->max_mr_size	   = ~0ull;
+	props->page_size_cap	   = dev->mdev.caps.min_page_sz;
+	props->max_qp		   = 1 << dev->mdev.caps.log_max_qp;
+	props->max_qp_wr	   = dev->mdev.caps.max_wqes;
+	max_rq_sg = dev->mdev.caps.max_rq_desc_sz / sizeof(struct mlx5_wqe_data_seg);
+	max_sq_sg = (dev->mdev.caps.max_sq_desc_sz - sizeof(struct mlx5_wqe_ctrl_seg)) /
+		sizeof(struct mlx5_wqe_data_seg);
+	props->max_sge = min(max_rq_sg, max_sq_sg);
+	props->max_cq		   = 1 << dev->mdev.caps.log_max_cq;
+	props->max_cqe		   = dev->mdev.caps.max_cqes - 1;
+	props->max_mr		   = 1 << dev->mdev.caps.log_max_mkey;
+	props->max_pd		   = 1 << dev->mdev.caps.log_max_pd;
+	props->max_qp_rd_atom	   = dev->mdev.caps.max_ra_req_qp;
+	props->max_qp_init_rd_atom = dev->mdev.caps.max_ra_res_qp;
+	props->max_res_rd_atom	   = props->max_qp_rd_atom * props->max_qp;
+	props->max_srq		   = 1 << dev->mdev.caps.log_max_srq;
+	props->max_srq_wr	   = dev->mdev.caps.max_srq_wqes - 1;
+	props->max_srq_sge	   = max_rq_sg - 1;
+	props->max_fast_reg_page_list_len = (unsigned int)-1;
+	props->local_ca_ack_delay  = dev->mdev.caps.local_ca_ack_delay;
+	props->atomic_cap	   = dev->mdev.caps.flags & MLX5_DEV_CAP_FLAG_ATOMIC ?
+		IB_ATOMIC_HCA : IB_ATOMIC_NONE;
+	props->masked_atomic_cap   = IB_ATOMIC_HCA;
+	props->max_pkeys	   = be16_to_cpup((__be16 *)(out_mad->data + 28));
+	props->max_mcast_grp	   = 1 << dev->mdev.caps.log_max_mcg;
+	props->max_mcast_qp_attach = dev->mdev.caps.max_qp_mcg;
+	props->max_total_mcast_qp_attach = props->max_mcast_qp_attach *
+					   props->max_mcast_grp;
+	props->max_map_per_fmr = INT_MAX; /* no limit in ConnectIB */
+
+out:
+	kfree(in_mad);
+	kfree(out_mad);
+
+	return err;
+}
+
+int mlx5_ib_query_port(struct ib_device *ibdev, u8 port,
+		       struct ib_port_attr *props)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+	struct ib_smp *in_mad  = NULL;
+	struct ib_smp *out_mad = NULL;
+	int ext_active_speed;
+	int err = -ENOMEM;
+
+	if (port < 1 || port > dev->mdev.caps.num_ports) {
+		mlx5_ib_warn(dev, "invalid port number %d\n", port);
+		return -EINVAL;
+	}
+
+	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
+	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
+	if (!in_mad || !out_mad)
+		goto out;
+
+	memset(props, 0, sizeof(*props));
+
+	init_query_mad(in_mad);
+	in_mad->attr_id  = IB_SMP_ATTR_PORT_INFO;
+	in_mad->attr_mod = cpu_to_be32(port);
+
+	err = mlx5_MAD_IFC(dev, 1, 1, port, NULL, NULL, in_mad, out_mad);
+	if (err) {
+		mlx5_ib_warn(dev, "err %d\n", err);
+		goto out;
+	}
+
+
+	props->lid		= be16_to_cpup((__be16 *)(out_mad->data + 16));
+	props->lmc		= out_mad->data[34] & 0x7;
+	props->sm_lid		= be16_to_cpup((__be16 *)(out_mad->data + 18));
+	props->sm_sl		= out_mad->data[36] & 0xf;
+	props->state		= out_mad->data[32] & 0xf;
+	props->phys_state	= out_mad->data[33] >> 4;
+	props->port_cap_flags	= be32_to_cpup((__be32 *)(out_mad->data + 20));
+	props->gid_tbl_len	= out_mad->data[50];
+	props->max_msg_sz	= 1 << to_mdev(ibdev)->mdev.caps.log_max_msg;
+	props->pkey_tbl_len	= to_mdev(ibdev)->mdev.caps.port[port - 1].pkey_table_len;
+	props->bad_pkey_cntr	= be16_to_cpup((__be16 *)(out_mad->data + 46));
+	props->qkey_viol_cntr	= be16_to_cpup((__be16 *)(out_mad->data + 48));
+	props->active_width	= out_mad->data[31] & 0xf;
+	props->active_speed	= out_mad->data[35] >> 4;
+	props->max_mtu		= out_mad->data[41] & 0xf;
+	props->active_mtu	= out_mad->data[36] >> 4;
+	props->subnet_timeout	= out_mad->data[51] & 0x1f;
+	props->max_vl_num	= out_mad->data[37] >> 4;
+	props->init_type_reply	= out_mad->data[41] >> 4;
+
+	/* Check if extended speeds (EDR/FDR/...) are supported */
+	if (props->port_cap_flags & IB_PORT_EXTENDED_SPEEDS_SUP) {
+		ext_active_speed = out_mad->data[62] >> 4;
+
+		switch (ext_active_speed) {
+		case 1:
+			props->active_speed = 16; /* FDR */
+			break;
+		case 2:
+			props->active_speed = 32; /* EDR */
+			break;
+		}
+	}
+
+	/* If reported active speed is QDR, check if is FDR-10 */
+	if (props->active_speed == 4) {
+		if (dev->mdev.caps.ext_port_cap[port - 1] &
+		    MLX_EXT_PORT_CAP_FLAG_EXTENDED_PORT_INFO) {
+			init_query_mad(in_mad);
+			in_mad->attr_id = MLX5_ATTR_EXTENDED_PORT_INFO;
+			in_mad->attr_mod = cpu_to_be32(port);
+
+			err = mlx5_MAD_IFC(dev, 1, 1, port,
+					   NULL, NULL, in_mad, out_mad);
+			if (err)
+				goto out;
+
+			/* Checking LinkSpeedActive for FDR-10 */
+			if (out_mad->data[15] & 0x1)
+				props->active_speed = 8;
+		}
+	}
+
+out:
+	kfree(in_mad);
+	kfree(out_mad);
+
+	return err;
+}
+
+static int mlx5_ib_query_gid(struct ib_device *ibdev, u8 port, int index,
+			     union ib_gid *gid)
+{
+	struct ib_smp *in_mad  = NULL;
+	struct ib_smp *out_mad = NULL;
+	int err = -ENOMEM;
+
+	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
+	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
+	if (!in_mad || !out_mad)
+		goto out;
+
+	init_query_mad(in_mad);
+	in_mad->attr_id  = IB_SMP_ATTR_PORT_INFO;
+	in_mad->attr_mod = cpu_to_be32(port);
+
+	err = mlx5_MAD_IFC(to_mdev(ibdev), 1, 1, port, NULL, NULL, in_mad, out_mad);
+	if (err)
+		goto out;
+
+	memcpy(gid->raw, out_mad->data + 8, 8);
+
+	init_query_mad(in_mad);
+	in_mad->attr_id  = IB_SMP_ATTR_GUID_INFO;
+	in_mad->attr_mod = cpu_to_be32(index / 8);
+
+	err = mlx5_MAD_IFC(to_mdev(ibdev), 1, 1, port, NULL, NULL, in_mad, out_mad);
+	if (err)
+		goto out;
+
+	memcpy(gid->raw + 8, out_mad->data + (index % 8) * 8, 8);
+
+out:
+	kfree(in_mad);
+	kfree(out_mad);
+	return err;
+}
+
+static int mlx5_ib_query_pkey(struct ib_device *ibdev, u8 port, u16 index,
+			      u16 *pkey)
+{
+	struct ib_smp *in_mad  = NULL;
+	struct ib_smp *out_mad = NULL;
+	int err = -ENOMEM;
+
+	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
+	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
+	if (!in_mad || !out_mad)
+		goto out;
+
+	init_query_mad(in_mad);
+	in_mad->attr_id  = IB_SMP_ATTR_PKEY_TABLE;
+	in_mad->attr_mod = cpu_to_be32(index / 32);
+
+	err = mlx5_MAD_IFC(to_mdev(ibdev), 1, 1, port, NULL, NULL, in_mad, out_mad);
+	if (err)
+		goto out;
+
+	*pkey = be16_to_cpu(((__be16 *)out_mad->data)[index % 32]);
+
+out:
+	kfree(in_mad);
+	kfree(out_mad);
+	return err;
+}
+
+struct mlx5_reg_node_desc {
+	u8	desc[64];
+};
+
+static int mlx5_ib_modify_device(struct ib_device *ibdev, int mask,
+				 struct ib_device_modify *props)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+	struct mlx5_reg_node_desc in;
+	struct mlx5_reg_node_desc out;
+	int err;
+
+	if (mask & ~IB_DEVICE_MODIFY_NODE_DESC)
+		return -EOPNOTSUPP;
+
+	if (!(mask & IB_DEVICE_MODIFY_NODE_DESC))
+		return 0;
+
+	/*
+	 * If possible, pass node desc to FW, so it can generate
+	 * a 144 trap.  If cmd fails, just ignore.
+	 */
+	memcpy(&in, props->node_desc, 64);
+	err = mlx5_core_access_reg(&dev->mdev, &in, sizeof(in), &out,
+				   sizeof(out), MLX5_REG_NODE_DESC, 0, 1);
+	if (err)
+		return err;
+
+	memcpy(ibdev->node_desc, props->node_desc, 64);
+
+	return err;
+}
+
+static int mlx5_ib_modify_port(struct ib_device *ibdev, u8 port, int mask,
+			       struct ib_port_modify *props)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+	struct ib_port_attr attr;
+	u32 tmp;
+	int err;
+
+	mutex_lock(&dev->cap_mask_mutex);
+
+	err = mlx5_ib_query_port(ibdev, port, &attr);
+	if (err)
+		goto out;
+
+	tmp = (attr.port_cap_flags | props->set_port_cap_mask) &
+		~props->clr_port_cap_mask;
+
+	err = mlx5_set_port_caps(&dev->mdev, port, tmp);
+
+out:
+	mutex_unlock(&dev->cap_mask_mutex);
+	return err;
+}
+
+static struct ib_ucontext *mlx5_ib_alloc_ucontext(struct ib_device *ibdev,
+						  struct ib_udata *udata)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+	struct mlx5_ib_alloc_ucontext_req req;
+	struct mlx5_ib_alloc_ucontext_resp resp;
+	struct mlx5_ib_ucontext *context;
+	struct mlx5_uuar_info *uuari;
+	struct mlx5_uar *uars;
+	int num_uars;
+	int uuarn;
+	int err;
+	int i;
+
+	if (!dev->ib_active)
+		return ERR_PTR(-EAGAIN);
+
+	err = ib_copy_from_udata(&req, udata, sizeof(req));
+	if (err)
+		return ERR_PTR(err);
+
+	if (req.total_num_uuars > MLX5_MAX_UUARS)
+		return ERR_PTR(-ENOMEM);
+
+	if (req.total_num_uuars == 0)
+		return ERR_PTR(-EINVAL);
+
+	req.total_num_uuars = ALIGN(req.total_num_uuars, MLX5_BF_REGS_PER_PAGE);
+	if (req.num_low_latency_uuars > req.total_num_uuars - 1)
+		return ERR_PTR(-EINVAL);
+
+	num_uars = req.total_num_uuars / MLX5_BF_REGS_PER_PAGE;
+	resp.qp_tab_size      = 1 << dev->mdev.caps.log_max_qp;
+	resp.bf_reg_size      = dev->mdev.caps.bf_reg_size;
+	resp.cache_line_size  = L1_CACHE_BYTES;
+	resp.max_sq_desc_sz = dev->mdev.caps.max_sq_desc_sz;
+	resp.max_rq_desc_sz = dev->mdev.caps.max_rq_desc_sz;
+	resp.max_send_wqebb = dev->mdev.caps.max_wqes;
+	resp.max_recv_wr = dev->mdev.caps.max_wqes;
+	resp.max_srq_recv_wr = dev->mdev.caps.max_srq_wqes;
+
+	context = kzalloc(sizeof(*context), GFP_KERNEL);
+	if (!context)
+		return ERR_PTR(-ENOMEM);
+
+	uuari = &context->uuari;
+	mutex_init(&uuari->lock);
+	uars = kcalloc(num_uars, sizeof(*uars), GFP_KERNEL);
+	if (!uars) {
+		err = -ENOMEM;
+		goto out_ctx;
+	}
+
+	uuari->bitmap = kcalloc(BITS_TO_LONGS(req.total_num_uuars),
+				sizeof(*uuari->bitmap),
+				GFP_KERNEL);
+	if (!uuari->bitmap) {
+		err = -ENOMEM;
+		goto out_uar_ctx;
+	}
+	/*
+	 * clear all fast path uuars
+	 */
+	for (i = 0; i < req.total_num_uuars; i++) {
+		uuarn = i & 3;
+		if (uuarn == 2 || uuarn == 3)
+			set_bit(i, uuari->bitmap);
+	}
+
+	uuari->count = kcalloc(req.total_num_uuars, sizeof(*uuari->count), GFP_KERNEL);
+	if (!uuari->count) {
+		err = -ENOMEM;
+		goto out_bitmap;
+	}
+
+	for (i = 0; i < num_uars; i++) {
+		err = mlx5_cmd_alloc_uar(&dev->mdev, &uars[i].index);
+		if (err)
+			goto out_count;
+	}
+
+	INIT_LIST_HEAD(&context->db_page_list);
+	mutex_init(&context->db_page_mutex);
+
+	resp.tot_uuars = req.total_num_uuars;
+	resp.num_ports = dev->mdev.caps.num_ports;
+	err = ib_copy_to_udata(udata, &resp, sizeof(resp));
+	if (err)
+		goto out_uars;
+
+	uuari->num_low_latency_uuars = req.num_low_latency_uuars;
+	uuari->uars = uars;
+	uuari->num_uars = num_uars;
+	return &context->ibucontext;
+
+out_uars:
+	for (i--; i >= 0; i--)
+		mlx5_cmd_free_uar(&dev->mdev, uars[i].index);
+out_count:
+	kfree(uuari->count);
+
+out_bitmap:
+	kfree(uuari->bitmap);
+
+out_uar_ctx:
+	kfree(uars);
+
+out_ctx:
+	kfree(context);
+	return ERR_PTR(err);
+}
+
+static int mlx5_ib_dealloc_ucontext(struct ib_ucontext *ibcontext)
+{
+	struct mlx5_ib_ucontext *context = to_mucontext(ibcontext);
+	struct mlx5_ib_dev *dev = to_mdev(ibcontext->device);
+	struct mlx5_uuar_info *uuari = &context->uuari;
+	int i;
+
+	for (i = 0; i < uuari->num_uars; i++) {
+		if (mlx5_cmd_free_uar(&dev->mdev, uuari->uars[i].index))
+			mlx5_ib_warn(dev, "failed to free UAR 0x%x\n", uuari->uars[i].index);
+	}
+
+	kfree(uuari->count);
+	kfree(uuari->bitmap);
+	kfree(uuari->uars);
+	kfree(context);
+
+	return 0;
+}
+
+static phys_addr_t uar_index2pfn(struct mlx5_ib_dev *dev, int index)
+{
+	return (pci_resource_start(dev->mdev.pdev, 0) >> PAGE_SHIFT) + index;
+}
+
+static int get_command(unsigned long offset)
+{
+	return (offset >> MLX5_IB_MMAP_CMD_SHIFT) & MLX5_IB_MMAP_CMD_MASK;
+}
+
+static int get_arg(unsigned long offset)
+{
+	return offset & ((1 << MLX5_IB_MMAP_CMD_SHIFT) - 1);
+}
+
+static int get_index(unsigned long offset)
+{
+	return get_arg(offset);
+}
+
+static int mlx5_ib_mmap(struct ib_ucontext *ibcontext, struct vm_area_struct *vma)
+{
+	struct mlx5_ib_ucontext *context = to_mucontext(ibcontext);
+	struct mlx5_ib_dev *dev = to_mdev(ibcontext->device);
+	struct mlx5_uuar_info *uuari = &context->uuari;
+	unsigned long command;
+	unsigned long idx;
+	phys_addr_t pfn;
+
+	command = get_command(vma->vm_pgoff);
+	switch (command) {
+	case MLX5_IB_MMAP_REGULAR_PAGE:
+		if (vma->vm_end - vma->vm_start != PAGE_SIZE)
+			return -EINVAL;
+
+		idx = get_index(vma->vm_pgoff);
+		pfn = uar_index2pfn(dev, uuari->uars[idx].index);
+		mlx5_ib_dbg(dev, "uar idx 0x%lx, pfn 0x%llx\n", idx,
+			    (unsigned long long)pfn);
+
+		if (idx >= uuari->num_uars)
+			return -EINVAL;
+
+		vma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);
+		if (io_remap_pfn_range(vma, vma->vm_start, pfn,
+				       PAGE_SIZE, vma->vm_page_prot))
+			return -EAGAIN;
+
+		mlx5_ib_dbg(dev, "mapped WC at 0x%lx, PA 0x%llx\n",
+			    vma->vm_start,
+			    (unsigned long long)pfn << PAGE_SHIFT);
+		break;
+
+	case MLX5_IB_MMAP_GET_CONTIGUOUS_PAGES:
+		return -ENOSYS;
+
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int alloc_pa_mkey(struct mlx5_ib_dev *dev, u32 *key, u32 pdn)
+{
+	struct mlx5_create_mkey_mbox_in *in;
+	struct mlx5_mkey_seg *seg;
+	struct mlx5_core_mr mr;
+	int err;
+
+	in = kzalloc(sizeof(*in), GFP_KERNEL);
+	if (!in)
+		return -ENOMEM;
+
+	seg = &in->seg;
+	seg->flags = MLX5_PERM_LOCAL_READ | MLX5_ACCESS_MODE_PA;
+	seg->flags_pd = cpu_to_be32(pdn | MLX5_MKEY_LEN64);
+	seg->qpn_mkey7_0 = cpu_to_be32(0xffffff << 8);
+	seg->start_addr = 0;
+
+	err = mlx5_core_create_mkey(&dev->mdev, &mr, in, sizeof(*in));
+	if (err) {
+		mlx5_ib_warn(dev, "failed to create mkey, %d\n", err);
+		goto err_in;
+	}
+
+	kfree(in);
+	*key = mr.key;
+
+	return 0;
+
+err_in:
+	kfree(in);
+
+	return err;
+}
+
+static void free_pa_mkey(struct mlx5_ib_dev *dev, u32 key)
+{
+	struct mlx5_core_mr mr;
+	int err;
+
+	memset(&mr, 0, sizeof(mr));
+	mr.key = key;
+	err = mlx5_core_destroy_mkey(&dev->mdev, &mr);
+	if (err)
+		mlx5_ib_warn(dev, "failed to destroy mkey 0x%x\n", key);
+}
+
+static struct ib_pd *mlx5_ib_alloc_pd(struct ib_device *ibdev,
+				      struct ib_ucontext *context,
+				      struct ib_udata *udata)
+{
+	struct mlx5_ib_alloc_pd_resp resp;
+	struct mlx5_ib_pd *pd;
+	int err;
+
+	pd = kmalloc(sizeof(*pd), GFP_KERNEL);
+	if (!pd)
+		return ERR_PTR(-ENOMEM);
+
+	err = mlx5_core_alloc_pd(&to_mdev(ibdev)->mdev, &pd->pdn);
+	if (err) {
+		kfree(pd);
+		return ERR_PTR(err);
+	}
+
+	if (context) {
+		resp.pdn = pd->pdn;
+		if (ib_copy_to_udata(udata, &resp, sizeof(resp))) {
+			mlx5_core_dealloc_pd(&to_mdev(ibdev)->mdev, pd->pdn);
+			kfree(pd);
+			return ERR_PTR(-EFAULT);
+		}
+	} else {
+		err = alloc_pa_mkey(to_mdev(ibdev), &pd->pa_lkey, pd->pdn);
+		if (err) {
+			mlx5_core_dealloc_pd(&to_mdev(ibdev)->mdev, pd->pdn);
+			kfree(pd);
+			return ERR_PTR(err);
+		}
+	}
+
+	return &pd->ibpd;
+}
+
+static int mlx5_ib_dealloc_pd(struct ib_pd *pd)
+{
+	struct mlx5_ib_dev *mdev = to_mdev(pd->device);
+	struct mlx5_ib_pd *mpd = to_mpd(pd);
+
+	if (!pd->uobject)
+		free_pa_mkey(mdev, mpd->pa_lkey);
+
+	mlx5_core_dealloc_pd(&mdev->mdev, mpd->pdn);
+	kfree(mpd);
+
+	return 0;
+}
+
+static int mlx5_ib_mcg_attach(struct ib_qp *ibqp, union ib_gid *gid, u16 lid)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibqp->device);
+	int err;
+
+	err = mlx5_core_attach_mcg(&dev->mdev, gid, ibqp->qp_num);
+	if (err)
+		mlx5_ib_warn(dev, "failed attaching QPN 0x%x, MGID %pI6\n",
+			     ibqp->qp_num, gid->raw);
+
+	return err;
+}
+
+static int mlx5_ib_mcg_detach(struct ib_qp *ibqp, union ib_gid *gid, u16 lid)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibqp->device);
+	int err;
+
+	err = mlx5_core_detach_mcg(&dev->mdev, gid, ibqp->qp_num);
+	if (err)
+		mlx5_ib_warn(dev, "failed detaching QPN 0x%x, MGID %pI6\n",
+			     ibqp->qp_num, gid->raw);
+
+	return err;
+}
+
+static int init_node_data(struct mlx5_ib_dev *dev)
+{
+	struct ib_smp *in_mad  = NULL;
+	struct ib_smp *out_mad = NULL;
+	int err = -ENOMEM;
+
+	in_mad  = kzalloc(sizeof(*in_mad), GFP_KERNEL);
+	out_mad = kmalloc(sizeof(*out_mad), GFP_KERNEL);
+	if (!in_mad || !out_mad)
+		goto out;
+
+	init_query_mad(in_mad);
+	in_mad->attr_id = IB_SMP_ATTR_NODE_DESC;
+
+	err = mlx5_MAD_IFC(dev, 1, 1, 1, NULL, NULL, in_mad, out_mad);
+	if (err)
+		goto out;
+
+	memcpy(dev->ib_dev.node_desc, out_mad->data, 64);
+
+	in_mad->attr_id = IB_SMP_ATTR_NODE_INFO;
+
+	err = mlx5_MAD_IFC(dev, 1, 1, 1, NULL, NULL, in_mad, out_mad);
+	if (err)
+		goto out;
+
+	dev->mdev.rev_id = be32_to_cpup((__be32 *)(out_mad->data + 32));
+	memcpy(&dev->ib_dev.node_guid, out_mad->data + 12, 8);
+
+out:
+	kfree(in_mad);
+	kfree(out_mad);
+	return err;
+}
+
+static ssize_t show_fw_pages(struct device *device, struct device_attribute *attr,
+			     char *buf)
+{
+	struct mlx5_ib_dev *dev =
+		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
+
+	return sprintf(buf, "%d\n", dev->mdev.priv.fw_pages);
+}
+
+static ssize_t show_reg_pages(struct device *device,
+			      struct device_attribute *attr, char *buf)
+{
+	struct mlx5_ib_dev *dev =
+		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
+
+	return sprintf(buf, "%d\n", dev->mdev.priv.reg_pages);
+}
+
+static ssize_t show_hca(struct device *device, struct device_attribute *attr,
+			char *buf)
+{
+	struct mlx5_ib_dev *dev =
+		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
+	return sprintf(buf, "MT%d\n", dev->mdev.pdev->device);
+}
+
+static ssize_t show_fw_ver(struct device *device, struct device_attribute *attr,
+			   char *buf)
+{
+	struct mlx5_ib_dev *dev =
+		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
+	return sprintf(buf, "%d.%d.%d\n", fw_rev_maj(&dev->mdev),
+		       fw_rev_min(&dev->mdev), fw_rev_sub(&dev->mdev));
+}
+
+static ssize_t show_rev(struct device *device, struct device_attribute *attr,
+			char *buf)
+{
+	struct mlx5_ib_dev *dev =
+		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
+	return sprintf(buf, "%x\n", dev->mdev.rev_id);
+}
+
+static ssize_t show_board(struct device *device, struct device_attribute *attr,
+			  char *buf)
+{
+	struct mlx5_ib_dev *dev =
+		container_of(device, struct mlx5_ib_dev, ib_dev.dev);
+	return sprintf(buf, "%.*s\n", MLX5_BOARD_ID_LEN,
+		       dev->mdev.board_id);
+}
+
+static DEVICE_ATTR(hw_rev,   S_IRUGO, show_rev,    NULL);
+static DEVICE_ATTR(fw_ver,   S_IRUGO, show_fw_ver, NULL);
+static DEVICE_ATTR(hca_type, S_IRUGO, show_hca,    NULL);
+static DEVICE_ATTR(board_id, S_IRUGO, show_board,  NULL);
+static DEVICE_ATTR(fw_pages, S_IRUGO, show_fw_pages, NULL);
+static DEVICE_ATTR(reg_pages, S_IRUGO, show_reg_pages, NULL);
+
+static struct device_attribute *mlx5_class_attributes[] = {
+	&dev_attr_hw_rev,
+	&dev_attr_fw_ver,
+	&dev_attr_hca_type,
+	&dev_attr_board_id,
+	&dev_attr_fw_pages,
+	&dev_attr_reg_pages,
+};
+
+static void mlx5_ib_event(struct mlx5_core_dev *dev, enum mlx5_dev_event event,
+			  void *data)
+{
+	struct mlx5_ib_dev *ibdev = container_of(dev, struct mlx5_ib_dev, mdev);
+	struct ib_event ibev;
+	u8 port = 0;
+
+	switch (event) {
+	case MLX5_DEV_EVENT_SYS_ERROR:
+		ibdev->ib_active = false;
+		ibev.event = IB_EVENT_DEVICE_FATAL;
+		break;
+
+	case MLX5_DEV_EVENT_PORT_UP:
+		ibev.event = IB_EVENT_PORT_ACTIVE;
+		port = *(u8 *)data;
+		break;
+
+	case MLX5_DEV_EVENT_PORT_DOWN:
+		ibev.event = IB_EVENT_PORT_ERR;
+		port = *(u8 *)data;
+		break;
+
+	case MLX5_DEV_EVENT_PORT_INITIALIZED:
+		/* not used by ULPs */
+		return;
+
+	case MLX5_DEV_EVENT_LID_CHANGE:
+		ibev.event = IB_EVENT_LID_CHANGE;
+		port = *(u8 *)data;
+		break;
+
+	case MLX5_DEV_EVENT_PKEY_CHANGE:
+		ibev.event = IB_EVENT_PKEY_CHANGE;
+		port = *(u8 *)data;
+		break;
+
+	case MLX5_DEV_EVENT_GUID_CHANGE:
+		ibev.event = IB_EVENT_GID_CHANGE;
+		port = *(u8 *)data;
+		break;
+
+	case MLX5_DEV_EVENT_CLIENT_REREG:
+		ibev.event = IB_EVENT_CLIENT_REREGISTER;
+		port = *(u8 *)data;
+		break;
+	}
+
+	ibev.device	      = &ibdev->ib_dev;
+	ibev.element.port_num = port;
+
+	if (ibdev->ib_active)
+		ib_dispatch_event(&ibev);
+}
+
+static void get_ext_port_caps(struct mlx5_ib_dev *dev)
+{
+	int port;
+
+	for (port = 1; port <= dev->mdev.caps.num_ports; port++)
+		mlx5_query_ext_port_caps(dev, port);
+}
+
+static int get_port_caps(struct mlx5_ib_dev *dev)
+{
+	struct ib_device_attr *dprops = NULL;
+	struct ib_port_attr *pprops = NULL;
+	int err = 0;
+	int port;
+
+	pprops = kmalloc(sizeof(*pprops), GFP_KERNEL);
+	if (!pprops)
+		goto out;
+
+	dprops = kmalloc(sizeof(*dprops), GFP_KERNEL);
+	if (!dprops)
+		goto out;
+
+	err = mlx5_ib_query_device(&dev->ib_dev, dprops);
+	if (err) {
+		mlx5_ib_warn(dev, "query_device failed %d\n", err);
+		goto out;
+	}
+
+	for (port = 1; port <= dev->mdev.caps.num_ports; port++) {
+		err = mlx5_ib_query_port(&dev->ib_dev, port, pprops);
+		if (err) {
+			mlx5_ib_warn(dev, "query_port %d failed %d\n", port, err);
+			break;
+		}
+		dev->mdev.caps.port[port - 1].pkey_table_len = dprops->max_pkeys;
+		dev->mdev.caps.port[port - 1].gid_table_len = pprops->gid_tbl_len;
+		mlx5_ib_dbg(dev, "pkey_table_len %d, gid_table_len %d\n",
+			    dprops->max_pkeys, pprops->gid_tbl_len);
+	}
+
+out:
+	kfree(pprops);
+	kfree(dprops);
+
+	return err;
+}
+
+static void destroy_umrc_res(struct mlx5_ib_dev *dev)
+{
+	int err;
+
+	err = mlx5_mr_cache_cleanup(dev);
+	if (err)
+		mlx5_ib_warn(dev, "mr cache cleanup failed\n");
+
+	mlx5_ib_destroy_qp(dev->umrc.qp);
+	ib_destroy_cq(dev->umrc.cq);
+	ib_dereg_mr(dev->umrc.mr);
+	ib_dealloc_pd(dev->umrc.pd);
+}
+
+enum {
+	MAX_UMR_WR = 128,
+};
+
+static int create_umr_res(struct mlx5_ib_dev *dev)
+{
+	struct ib_qp_init_attr *init_attr = NULL;
+	struct ib_qp_attr *attr = NULL;
+	struct ib_pd *pd;
+	struct ib_cq *cq;
+	struct ib_qp *qp;
+	struct ib_mr *mr;
+	int ret;
+
+	attr = kzalloc(sizeof(*attr), GFP_KERNEL);
+	init_attr = kzalloc(sizeof(*init_attr), GFP_KERNEL);
+	if (!attr || !init_attr) {
+		ret = -ENOMEM;
+		goto error_0;
+	}
+
+	pd = ib_alloc_pd(&dev->ib_dev);
+	if (IS_ERR(pd)) {
+		mlx5_ib_dbg(dev, "Couldn't create PD for sync UMR QP\n");
+		ret = PTR_ERR(pd);
+		goto error_0;
+	}
+
+	mr = ib_get_dma_mr(pd,  IB_ACCESS_LOCAL_WRITE);
+	if (IS_ERR(mr)) {
+		mlx5_ib_dbg(dev, "Couldn't create DMA MR for sync UMR QP\n");
+		ret = PTR_ERR(mr);
+		goto error_1;
+	}
+
+	cq = ib_create_cq(&dev->ib_dev, mlx5_umr_cq_handler, NULL, NULL, 128,
+			  0);
+	if (IS_ERR(cq)) {
+		mlx5_ib_dbg(dev, "Couldn't create CQ for sync UMR QP\n");
+		ret = PTR_ERR(cq);
+		goto error_2;
+	}
+	ib_req_notify_cq(cq, IB_CQ_NEXT_COMP);
+
+	init_attr->send_cq = cq;
+	init_attr->recv_cq = cq;
+	init_attr->sq_sig_type = IB_SIGNAL_ALL_WR;
+	init_attr->cap.max_send_wr = MAX_UMR_WR;
+	init_attr->cap.max_send_sge = 1;
+	init_attr->qp_type = MLX5_IB_QPT_REG_UMR;
+	init_attr->port_num = 1;
+	qp = mlx5_ib_create_qp(pd, init_attr, NULL);
+	if (IS_ERR(qp)) {
+		mlx5_ib_dbg(dev, "Couldn't create sync UMR QP\n");
+		ret = PTR_ERR(qp);
+		goto error_3;
+	}
+	qp->device     = &dev->ib_dev;
+	qp->real_qp    = qp;
+	qp->uobject    = NULL;
+	qp->qp_type    = MLX5_IB_QPT_REG_UMR;
+
+	attr->qp_state = IB_QPS_INIT;
+	attr->port_num = 1;
+	ret = mlx5_ib_modify_qp(qp, attr, IB_QP_STATE | IB_QP_PKEY_INDEX |
+				IB_QP_PORT, NULL);
+	if (ret) {
+		mlx5_ib_dbg(dev, "Couldn't modify UMR QP\n");
+		goto error_4;
+	}
+
+	memset(attr, 0, sizeof(*attr));
+	attr->qp_state = IB_QPS_RTR;
+	attr->path_mtu = IB_MTU_256;
+
+	ret = mlx5_ib_modify_qp(qp, attr, IB_QP_STATE, NULL);
+	if (ret) {
+		mlx5_ib_dbg(dev, "Couldn't modify umr QP to rtr\n");
+		goto error_4;
+	}
+
+	memset(attr, 0, sizeof(*attr));
+	attr->qp_state = IB_QPS_RTS;
+	ret = mlx5_ib_modify_qp(qp, attr, IB_QP_STATE, NULL);
+	if (ret) {
+		mlx5_ib_dbg(dev, "Couldn't modify umr QP to rts\n");
+		goto error_4;
+	}
+
+	dev->umrc.qp = qp;
+	dev->umrc.cq = cq;
+	dev->umrc.mr = mr;
+	dev->umrc.pd = pd;
+
+	sema_init(&dev->umrc.sem, MAX_UMR_WR);
+	ret = mlx5_mr_cache_init(dev);
+	if (ret) {
+		mlx5_ib_warn(dev, "mr cache init failed %d\n", ret);
+		goto error_4;
+	}
+
+	kfree(attr);
+	kfree(init_attr);
+
+	return 0;
+
+error_4:
+	mlx5_ib_destroy_qp(qp);
+
+error_3:
+	ib_destroy_cq(cq);
+
+error_2:
+	ib_dereg_mr(mr);
+
+error_1:
+	ib_dealloc_pd(pd);
+
+error_0:
+	kfree(attr);
+	kfree(init_attr);
+	return ret;
+}
+
+static int create_dev_resources(struct mlx5_ib_resources *devr)
+{
+	struct ib_srq_init_attr attr;
+	struct mlx5_ib_dev *dev;
+	int ret = 0;
+
+	dev = container_of(devr, struct mlx5_ib_dev, devr);
+
+	devr->p0 = mlx5_ib_alloc_pd(&dev->ib_dev, NULL, NULL);
+	if (IS_ERR(devr->p0)) {
+		ret = PTR_ERR(devr->p0);
+		goto error0;
+	}
+	devr->p0->device  = &dev->ib_dev;
+	devr->p0->uobject = NULL;
+	atomic_set(&devr->p0->usecnt, 0);
+
+	devr->c0 = mlx5_ib_create_cq(&dev->ib_dev, 1, 0, NULL, NULL);
+	if (IS_ERR(devr->c0)) {
+		ret = PTR_ERR(devr->c0);
+		goto error1;
+	}
+	devr->c0->device        = &dev->ib_dev;
+	devr->c0->uobject       = NULL;
+	devr->c0->comp_handler  = NULL;
+	devr->c0->event_handler = NULL;
+	devr->c0->cq_context    = NULL;
+	atomic_set(&devr->c0->usecnt, 0);
+
+	devr->x0 = mlx5_ib_alloc_xrcd(&dev->ib_dev, NULL, NULL);
+	if (IS_ERR(devr->x0)) {
+		ret = PTR_ERR(devr->x0);
+		goto error2;
+	}
+	devr->x0->device = &dev->ib_dev;
+	devr->x0->inode = NULL;
+	atomic_set(&devr->x0->usecnt, 0);
+	mutex_init(&devr->x0->tgt_qp_mutex);
+	INIT_LIST_HEAD(&devr->x0->tgt_qp_list);
+
+	devr->x1 = mlx5_ib_alloc_xrcd(&dev->ib_dev, NULL, NULL);
+	if (IS_ERR(devr->x1)) {
+		ret = PTR_ERR(devr->x1);
+		goto error3;
+	}
+	devr->x1->device = &dev->ib_dev;
+	devr->x1->inode = NULL;
+	atomic_set(&devr->x1->usecnt, 0);
+	mutex_init(&devr->x1->tgt_qp_mutex);
+	INIT_LIST_HEAD(&devr->x1->tgt_qp_list);
+
+	memset(&attr, 0, sizeof(attr));
+	attr.attr.max_sge = 1;
+	attr.attr.max_wr = 1;
+	attr.srq_type = IB_SRQT_XRC;
+	attr.ext.xrc.cq = devr->c0;
+	attr.ext.xrc.xrcd = devr->x0;
+
+	devr->s0 = mlx5_ib_create_srq(devr->p0, &attr, NULL);
+	if (IS_ERR(devr->s0)) {
+		ret = PTR_ERR(devr->s0);
+		goto error4;
+	}
+	devr->s0->device	= &dev->ib_dev;
+	devr->s0->pd		= devr->p0;
+	devr->s0->uobject       = NULL;
+	devr->s0->event_handler = NULL;
+	devr->s0->srq_context   = NULL;
+	devr->s0->srq_type      = IB_SRQT_XRC;
+	devr->s0->ext.xrc.xrcd	= devr->x0;
+	devr->s0->ext.xrc.cq	= devr->c0;
+	atomic_inc(&devr->s0->ext.xrc.xrcd->usecnt);
+	atomic_inc(&devr->s0->ext.xrc.cq->usecnt);
+	atomic_inc(&devr->p0->usecnt);
+	atomic_set(&devr->s0->usecnt, 0);
+
+	return 0;
+
+error4:
+	mlx5_ib_dealloc_xrcd(devr->x1);
+error3:
+	mlx5_ib_dealloc_xrcd(devr->x0);
+error2:
+	mlx5_ib_destroy_cq(devr->c0);
+error1:
+	mlx5_ib_dealloc_pd(devr->p0);
+error0:
+	return ret;
+}
+
+static void destroy_dev_resources(struct mlx5_ib_resources *devr)
+{
+	mlx5_ib_destroy_srq(devr->s0);
+	mlx5_ib_dealloc_xrcd(devr->x0);
+	mlx5_ib_dealloc_xrcd(devr->x1);
+	mlx5_ib_destroy_cq(devr->c0);
+	mlx5_ib_dealloc_pd(devr->p0);
+}
+
+static int init_one(struct pci_dev *pdev,
+		    const struct pci_device_id *id)
+{
+	struct mlx5_core_dev *mdev;
+	struct mlx5_ib_dev *dev;
+	int err;
+	int i;
+
+	printk_once(KERN_INFO "%s", mlx5_version);
+
+	dev = (struct mlx5_ib_dev *)ib_alloc_device(sizeof(*dev));
+	if (!dev)
+		return -ENOMEM;
+
+	mdev = &dev->mdev;
+	mdev->event = mlx5_ib_event;
+	if (prof_sel >= ARRAY_SIZE(profile)) {
+		pr_warn("selected pofile out of range, selceting default\n");
+		prof_sel = 0;
+	}
+	mdev->profile = &profile[prof_sel];
+	err = mlx5_dev_init(mdev, pdev);
+	if (err)
+		goto err_free;
+
+	err = get_port_caps(dev);
+	if (err)
+		goto err_cleanup;
+
+	get_ext_port_caps(dev);
+
+	err = alloc_comp_eqs(dev);
+	if (err)
+		goto err_cleanup;
+
+	MLX5_INIT_DOORBELL_LOCK(&dev->uar_lock);
+
+	strlcpy(dev->ib_dev.name, "mlx5_%d", IB_DEVICE_NAME_MAX);
+	dev->ib_dev.owner		= THIS_MODULE;
+	dev->ib_dev.node_type		= RDMA_NODE_IB_CA;
+	dev->ib_dev.local_dma_lkey	= mdev->caps.reserved_lkey;
+	dev->num_ports		= mdev->caps.num_ports;
+	dev->ib_dev.phys_port_cnt     = dev->num_ports;
+	dev->ib_dev.num_comp_vectors	= dev->num_comp_vectors;
+	dev->ib_dev.dma_device	= &mdev->pdev->dev;
+
+	dev->ib_dev.uverbs_abi_ver	= MLX5_IB_UVERBS_ABI_VERSION;
+	dev->ib_dev.uverbs_cmd_mask	=
+		(1ull << IB_USER_VERBS_CMD_GET_CONTEXT)		|
+		(1ull << IB_USER_VERBS_CMD_QUERY_DEVICE)	|
+		(1ull << IB_USER_VERBS_CMD_QUERY_PORT)		|
+		(1ull << IB_USER_VERBS_CMD_ALLOC_PD)		|
+		(1ull << IB_USER_VERBS_CMD_DEALLOC_PD)		|
+		(1ull << IB_USER_VERBS_CMD_REG_MR)		|
+		(1ull << IB_USER_VERBS_CMD_DEREG_MR)		|
+		(1ull << IB_USER_VERBS_CMD_CREATE_COMP_CHANNEL)	|
+		(1ull << IB_USER_VERBS_CMD_CREATE_CQ)		|
+		(1ull << IB_USER_VERBS_CMD_RESIZE_CQ)		|
+		(1ull << IB_USER_VERBS_CMD_DESTROY_CQ)		|
+		(1ull << IB_USER_VERBS_CMD_CREATE_QP)		|
+		(1ull << IB_USER_VERBS_CMD_MODIFY_QP)		|
+		(1ull << IB_USER_VERBS_CMD_QUERY_QP)		|
+		(1ull << IB_USER_VERBS_CMD_DESTROY_QP)		|
+		(1ull << IB_USER_VERBS_CMD_ATTACH_MCAST)	|
+		(1ull << IB_USER_VERBS_CMD_DETACH_MCAST)	|
+		(1ull << IB_USER_VERBS_CMD_CREATE_SRQ)		|
+		(1ull << IB_USER_VERBS_CMD_MODIFY_SRQ)		|
+		(1ull << IB_USER_VERBS_CMD_QUERY_SRQ)		|
+		(1ull << IB_USER_VERBS_CMD_DESTROY_SRQ)		|
+		(1ull << IB_USER_VERBS_CMD_CREATE_XSRQ)		|
+		(1ull << IB_USER_VERBS_CMD_OPEN_QP);
+
+	dev->ib_dev.query_device	= mlx5_ib_query_device;
+	dev->ib_dev.query_port		= mlx5_ib_query_port;
+	dev->ib_dev.query_gid		= mlx5_ib_query_gid;
+	dev->ib_dev.query_pkey		= mlx5_ib_query_pkey;
+	dev->ib_dev.modify_device	= mlx5_ib_modify_device;
+	dev->ib_dev.modify_port		= mlx5_ib_modify_port;
+	dev->ib_dev.alloc_ucontext	= mlx5_ib_alloc_ucontext;
+	dev->ib_dev.dealloc_ucontext	= mlx5_ib_dealloc_ucontext;
+	dev->ib_dev.mmap		= mlx5_ib_mmap;
+	dev->ib_dev.alloc_pd		= mlx5_ib_alloc_pd;
+	dev->ib_dev.dealloc_pd		= mlx5_ib_dealloc_pd;
+	dev->ib_dev.create_ah		= mlx5_ib_create_ah;
+	dev->ib_dev.query_ah		= mlx5_ib_query_ah;
+	dev->ib_dev.destroy_ah		= mlx5_ib_destroy_ah;
+	dev->ib_dev.create_srq		= mlx5_ib_create_srq;
+	dev->ib_dev.modify_srq		= mlx5_ib_modify_srq;
+	dev->ib_dev.query_srq		= mlx5_ib_query_srq;
+	dev->ib_dev.destroy_srq		= mlx5_ib_destroy_srq;
+	dev->ib_dev.post_srq_recv	= mlx5_ib_post_srq_recv;
+	dev->ib_dev.create_qp		= mlx5_ib_create_qp;
+	dev->ib_dev.modify_qp		= mlx5_ib_modify_qp;
+	dev->ib_dev.query_qp		= mlx5_ib_query_qp;
+	dev->ib_dev.destroy_qp		= mlx5_ib_destroy_qp;
+	dev->ib_dev.post_send		= mlx5_ib_post_send;
+	dev->ib_dev.post_recv		= mlx5_ib_post_recv;
+	dev->ib_dev.create_cq		= mlx5_ib_create_cq;
+	dev->ib_dev.modify_cq		= mlx5_ib_modify_cq;
+	dev->ib_dev.resize_cq		= mlx5_ib_resize_cq;
+	dev->ib_dev.destroy_cq		= mlx5_ib_destroy_cq;
+	dev->ib_dev.poll_cq		= mlx5_ib_poll_cq;
+	dev->ib_dev.req_notify_cq	= mlx5_ib_arm_cq;
+	dev->ib_dev.get_dma_mr		= mlx5_ib_get_dma_mr;
+	dev->ib_dev.reg_user_mr		= mlx5_ib_reg_user_mr;
+	dev->ib_dev.dereg_mr		= mlx5_ib_dereg_mr;
+	dev->ib_dev.attach_mcast	= mlx5_ib_mcg_attach;
+	dev->ib_dev.detach_mcast	= mlx5_ib_mcg_detach;
+	dev->ib_dev.process_mad		= mlx5_ib_process_mad;
+	dev->ib_dev.alloc_fast_reg_mr	= mlx5_ib_alloc_fast_reg_mr;
+	dev->ib_dev.alloc_fast_reg_page_list = mlx5_ib_alloc_fast_reg_page_list;
+	dev->ib_dev.free_fast_reg_page_list  = mlx5_ib_free_fast_reg_page_list;
+
+	if (mdev->caps.flags & MLX5_DEV_CAP_FLAG_XRC) {
+		dev->ib_dev.alloc_xrcd = mlx5_ib_alloc_xrcd;
+		dev->ib_dev.dealloc_xrcd = mlx5_ib_dealloc_xrcd;
+		dev->ib_dev.uverbs_cmd_mask |=
+			(1ull << IB_USER_VERBS_CMD_OPEN_XRCD) |
+			(1ull << IB_USER_VERBS_CMD_CLOSE_XRCD);
+	}
+
+	err = init_node_data(dev);
+	if (err)
+		goto err_eqs;
+
+	mutex_init(&dev->cap_mask_mutex);
+	spin_lock_init(&dev->mr_lock);
+
+	err = create_dev_resources(&dev->devr);
+	if (err)
+		goto err_eqs;
+
+	if (ib_register_device(&dev->ib_dev, NULL))
+		goto err_rsrc;
+
+	err = create_umr_res(dev);
+	if (err)
+		goto err_dev;
+
+	for (i = 0; i < ARRAY_SIZE(mlx5_class_attributes); i++) {
+		if (device_create_file(&dev->ib_dev.dev,
+				       mlx5_class_attributes[i]))
+			goto err_umrc;
+	}
+
+	dev->ib_active = true;
+
+	return 0;
+
+err_umrc:
+	destroy_umrc_res(dev);
+
+err_dev:
+	ib_unregister_device(&dev->ib_dev);
+
+err_rsrc:
+	destroy_dev_resources(&dev->devr);
+
+err_eqs:
+	free_comp_eqs(dev);
+
+err_cleanup:
+	mlx5_dev_cleanup(mdev);
+
+err_free:
+	ib_dealloc_device((struct ib_device *)dev);
+
+	return err;
+}
+
+static void remove_one(struct pci_dev *pdev)
+{
+	struct mlx5_ib_dev *dev = mlx5_pci2ibdev(pdev);
+
+	destroy_umrc_res(dev);
+	ib_unregister_device(&dev->ib_dev);
+	destroy_dev_resources(&dev->devr);
+	free_comp_eqs(dev);
+	mlx5_dev_cleanup(&dev->mdev);
+	ib_dealloc_device(&dev->ib_dev);
+}
+
+static DEFINE_PCI_DEVICE_TABLE(mlx5_ib_pci_table) = {
+	{ PCI_VDEVICE(MELLANOX, 4113) }, /* MT4113 Connect-IB */
+	{ 0, }
+};
+
+MODULE_DEVICE_TABLE(pci, mlx5_ib_pci_table);
+
+static struct pci_driver mlx5_ib_driver = {
+	.name		= DRIVER_NAME,
+	.id_table	= mlx5_ib_pci_table,
+	.probe		= init_one,
+	.remove		= remove_one
+};
+
+static int __init mlx5_ib_init(void)
+{
+	return pci_register_driver(&mlx5_ib_driver);
+}
+
+static void __exit mlx5_ib_cleanup(void)
+{
+	pci_unregister_driver(&mlx5_ib_driver);
+}
+
+module_init(mlx5_ib_init);
+module_exit(mlx5_ib_cleanup);
diff --git a/drivers/infiniband/hw/mlx5/mem.c b/drivers/infiniband/hw/mlx5/mem.c
new file mode 100644
index 0000000..3a53228
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/mem.c
@@ -0,0 +1,162 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/module.h>
+#include <rdma/ib_umem.h>
+#include "mlx5_ib.h"
+
+/* @umem: umem object to scan
+ * @addr: ib virtual address requested by the user
+ * @count: number of PAGE_SIZE pages covered by umem
+ * @shift: page shift for the compound pages found in the region
+ * @ncont: number of compund pages
+ * @order: log2 of the number of compound pages
+ */
+void mlx5_ib_cont_pages(struct ib_umem *umem, u64 addr, int *count, int *shift,
+			int *ncont, int *order)
+{
+	struct ib_umem_chunk *chunk;
+	unsigned long tmp;
+	unsigned long m;
+	int i, j, k;
+	u64 base = 0;
+	int p = 0;
+	int skip;
+	int mask;
+	u64 len;
+	u64 pfn;
+
+	addr = addr >> PAGE_SHIFT;
+	tmp = (unsigned long)addr;
+	m = find_first_bit(&tmp, sizeof(tmp));
+	skip = 1 << m;
+	mask = skip - 1;
+	i = 0;
+	list_for_each_entry(chunk, &umem->chunk_list, list)
+		for (j = 0; j < chunk->nmap; j++) {
+			len = sg_dma_len(&chunk->page_list[j]) >> PAGE_SHIFT;
+			pfn = sg_dma_address(&chunk->page_list[j]) >> PAGE_SHIFT;
+			for (k = 0; k < len; k++) {
+				if (!(i & mask)) {
+					tmp = (unsigned long)pfn;
+					m = min(m, find_first_bit(&tmp, sizeof(tmp)));
+					skip = 1 << m;
+					mask = skip - 1;
+					base = pfn;
+					p = 0;
+				} else {
+					if (base + p != pfn) {
+						tmp = (unsigned long)p;
+						m = find_first_bit(&tmp, sizeof(tmp));
+						skip = 1 << m;
+						mask = skip - 1;
+						base = pfn;
+						p = 0;
+					}
+				}
+				p++;
+				i++;
+			}
+		}
+
+	if (i) {
+		m = min_t(unsigned long, ilog2(roundup_pow_of_two(i)), m);
+
+		if (order)
+			*order = ilog2(roundup_pow_of_two(i) >> m);
+
+		*ncont = DIV_ROUND_UP(i, (1 << m));
+	} else {
+		m  = 0;
+
+		if (order)
+			*order = 0;
+
+		*ncont = 0;
+	}
+	*shift = PAGE_SHIFT + m;
+	*count = i;
+}
+
+void mlx5_ib_populate_pas(struct mlx5_ib_dev *dev, struct ib_umem *umem,
+			  int page_shift, __be64 *pas, int umr)
+{
+	int shift = page_shift - PAGE_SHIFT;
+	int mask = (1 << shift) - 1;
+	struct ib_umem_chunk *chunk;
+	int i, j, k;
+	u64 cur = 0;
+	u64 base;
+	int len;
+
+	i = 0;
+	list_for_each_entry(chunk, &umem->chunk_list, list)
+		for (j = 0; j < chunk->nmap; j++) {
+			len = sg_dma_len(&chunk->page_list[j]) >> PAGE_SHIFT;
+			base = sg_dma_address(&chunk->page_list[j]);
+			for (k = 0; k < len; k++) {
+				if (!(i & mask)) {
+					cur = base + (k << PAGE_SHIFT);
+					if (umr)
+						cur |= 3;
+
+					pas[i >> shift] = cpu_to_be64(cur);
+					mlx5_ib_dbg(dev, "pas[%d] 0x%llx\n",
+						    i >> shift, be64_to_cpu(pas[i >> shift]));
+				}  else
+					mlx5_ib_dbg(dev, "=====> 0x%llx\n",
+						    base + (k << PAGE_SHIFT));
+				i++;
+			}
+		}
+}
+
+int mlx5_ib_get_buf_offset(u64 addr, int page_shift, u32 *offset)
+{
+	u64 page_size;
+	u64 page_mask;
+	u64 off_size;
+	u64 off_mask;
+	u64 buf_off;
+
+	page_size = 1 << page_shift;
+	page_mask = page_size - 1;
+	buf_off = addr & page_mask;
+	off_size = page_size >> 6;
+	off_mask = off_size - 1;
+
+	if (buf_off & off_mask)
+		return -EINVAL;
+
+	*offset = buf_off >> ilog2(off_size);
+	return 0;
+}
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
new file mode 100644
index 0000000..836be91
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -0,0 +1,545 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_IB_H
+#define MLX5_IB_H
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <rdma/ib_verbs.h>
+#include <rdma/ib_smi.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cq.h>
+#include <linux/mlx5/qp.h>
+#include <linux/mlx5/srq.h>
+#include <linux/types.h>
+
+#define mlx5_ib_dbg(dev, format, arg...)				\
+pr_debug("%s:%s:%d:(pid %d): " format, (dev)->ib_dev.name, __func__,	\
+	 __LINE__, current->pid, ##arg)
+
+#define mlx5_ib_err(dev, format, arg...)				\
+pr_err("%s:%s:%d:(pid %d): " format, (dev)->ib_dev.name, __func__,	\
+	__LINE__, current->pid, ##arg)
+
+#define mlx5_ib_warn(dev, format, arg...)				\
+pr_warn("%s:%s:%d:(pid %d): " format, (dev)->ib_dev.name, __func__,	\
+	__LINE__, current->pid, ##arg)
+
+enum {
+	MLX5_IB_MMAP_CMD_SHIFT	= 8,
+	MLX5_IB_MMAP_CMD_MASK	= 0xff,
+};
+
+enum mlx5_ib_mmap_cmd {
+	MLX5_IB_MMAP_REGULAR_PAGE		= 0,
+	MLX5_IB_MMAP_GET_CONTIGUOUS_PAGES	= 1, /* always last */
+};
+
+enum {
+	MLX5_RES_SCAT_DATA32_CQE	= 0x1,
+	MLX5_RES_SCAT_DATA64_CQE	= 0x2,
+	MLX5_REQ_SCAT_DATA32_CQE	= 0x11,
+	MLX5_REQ_SCAT_DATA64_CQE	= 0x22,
+};
+
+enum mlx5_ib_latency_class {
+	MLX5_IB_LATENCY_CLASS_LOW,
+	MLX5_IB_LATENCY_CLASS_MEDIUM,
+	MLX5_IB_LATENCY_CLASS_HIGH,
+	MLX5_IB_LATENCY_CLASS_FAST_PATH
+};
+
+enum mlx5_ib_mad_ifc_flags {
+	MLX5_MAD_IFC_IGNORE_MKEY	= 1,
+	MLX5_MAD_IFC_IGNORE_BKEY	= 2,
+	MLX5_MAD_IFC_NET_VIEW		= 4,
+};
+
+struct mlx5_ib_ucontext {
+	struct ib_ucontext	ibucontext;
+	struct list_head	db_page_list;
+
+	/* protect doorbell record alloc/free
+	 */
+	struct mutex		db_page_mutex;
+	struct mlx5_uuar_info	uuari;
+};
+
+static inline struct mlx5_ib_ucontext *to_mucontext(struct ib_ucontext *ibucontext)
+{
+	return container_of(ibucontext, struct mlx5_ib_ucontext, ibucontext);
+}
+
+struct mlx5_ib_pd {
+	struct ib_pd		ibpd;
+	u32			pdn;
+	u32			pa_lkey;
+};
+
+/* Use macros here so that don't have to duplicate
+ * enum ib_send_flags and enum ib_qp_type for low-level driver
+ */
+
+#define MLX5_IB_SEND_UMR_UNREG	IB_SEND_RESERVED_START
+#define MLX5_IB_QPT_REG_UMR	IB_QPT_RESERVED1
+#define MLX5_IB_WR_UMR		IB_WR_RESERVED1
+
+struct wr_list {
+	u16	opcode;
+	u16	next;
+};
+
+struct mlx5_ib_wq {
+	u64		       *wrid;
+	u32		       *wr_data;
+	struct wr_list	       *w_list;
+	unsigned	       *wqe_head;
+	u16		        unsig_count;
+
+	/* serialize post to the work queue
+	 */
+	spinlock_t		lock;
+	int			wqe_cnt;
+	int			max_post;
+	int			max_gs;
+	int			offset;
+	int			wqe_shift;
+	unsigned		head;
+	unsigned		tail;
+	u16			cur_post;
+	u16			last_poll;
+	void		       *qend;
+};
+
+enum {
+	MLX5_QP_USER,
+	MLX5_QP_KERNEL,
+	MLX5_QP_EMPTY
+};
+
+struct mlx5_ib_qp {
+	struct ib_qp		ibqp;
+	struct mlx5_core_qp	mqp;
+	struct mlx5_buf		buf;
+
+	struct mlx5_db		db;
+	struct mlx5_ib_wq	rq;
+
+	u32			doorbell_qpn;
+	u8			sq_signal_bits;
+	u8			fm_cache;
+	int			sq_max_wqes_per_wr;
+	int			sq_spare_wqes;
+	struct mlx5_ib_wq	sq;
+
+	struct ib_umem	       *umem;
+	int			buf_size;
+
+	/* serialize qp state modifications
+	 */
+	struct mutex		mutex;
+	u16			xrcdn;
+	u32			flags;
+	u8			port;
+	u8			alt_port;
+	u8			atomic_rd_en;
+	u8			resp_depth;
+	u8			state;
+	int			mlx_type;
+	int			wq_sig;
+	int			scat_cqe;
+	int			max_inline_data;
+	struct mlx5_bf	       *bf;
+	int			has_rq;
+
+	/* only for user space QPs. For kernel
+	 * we have it from the bf object
+	 */
+	int			uuarn;
+
+	int			create_type;
+	u32			pa_lkey;
+};
+
+struct mlx5_ib_cq_buf {
+	struct mlx5_buf		buf;
+	struct ib_umem		*umem;
+	int			cqe_size;
+};
+
+enum mlx5_ib_qp_flags {
+	MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK     = 1 << 0,
+	MLX5_IB_QP_SIGNATURE_HANDLING           = 1 << 1,
+};
+
+struct mlx5_shared_mr_info {
+	int mr_id;
+	struct ib_umem		*umem;
+};
+
+struct mlx5_ib_cq {
+	struct ib_cq		ibcq;
+	struct mlx5_core_cq	mcq;
+	struct mlx5_ib_cq_buf	buf;
+	struct mlx5_db		db;
+
+	/* serialize access to the CQ
+	 */
+	spinlock_t		lock;
+
+	/* protect resize cq
+	 */
+	struct mutex		resize_mutex;
+	struct mlx5_ib_cq_resize *resize_buf;
+	struct ib_umem	       *resize_umem;
+	int			cqe_size;
+};
+
+struct mlx5_ib_srq {
+	struct ib_srq		ibsrq;
+	struct mlx5_core_srq	msrq;
+	struct mlx5_buf		buf;
+	struct mlx5_db		db;
+	u64		       *wrid;
+	/* protect SRQ hanlding
+	 */
+	spinlock_t		lock;
+	int			head;
+	int			tail;
+	u16			wqe_ctr;
+	struct ib_umem	       *umem;
+	/* serialize arming a SRQ
+	 */
+	struct mutex		mutex;
+	int			wq_sig;
+};
+
+struct mlx5_ib_xrcd {
+	struct ib_xrcd		ibxrcd;
+	u32			xrcdn;
+};
+
+struct mlx5_ib_mr {
+	struct ib_mr		ibmr;
+	struct mlx5_core_mr	mmr;
+	struct ib_umem	       *umem;
+	struct mlx5_shared_mr_info	*smr_info;
+	struct list_head	list;
+	int			order;
+	int			umred;
+	__be64			*pas;
+	dma_addr_t		dma;
+	int			npages;
+	struct completion	done;
+	enum ib_wc_status	status;
+};
+
+struct mlx5_ib_fast_reg_page_list {
+	struct ib_fast_reg_page_list	ibfrpl;
+	__be64			       *mapped_page_list;
+	dma_addr_t			map;
+};
+
+struct umr_common {
+	struct ib_pd	*pd;
+	struct ib_cq	*cq;
+	struct ib_qp	*qp;
+	struct ib_mr	*mr;
+	/* control access to UMR QP
+	 */
+	struct semaphore	sem;
+};
+
+enum {
+	MLX5_FMR_INVALID,
+	MLX5_FMR_VALID,
+	MLX5_FMR_BUSY,
+};
+
+struct mlx5_ib_fmr {
+	struct ib_fmr			ibfmr;
+	struct mlx5_core_mr		mr;
+	int				access_flags;
+	int				state;
+	/* protect fmr state
+	 */
+	spinlock_t			lock;
+	u64				wrid;
+	struct ib_send_wr		wr[2];
+	u8				page_shift;
+	struct ib_fast_reg_page_list	page_list;
+};
+
+struct mlx5_cache_ent {
+	struct list_head	head;
+	/* sync access to the cahce entry
+	 */
+	spinlock_t		lock;
+
+
+	struct dentry	       *dir;
+	char                    name[4];
+	u32                     order;
+	u32			size;
+	u32                     cur;
+	u32                     miss;
+	u32			limit;
+
+	struct dentry          *fsize;
+	struct dentry          *fcur;
+	struct dentry          *fmiss;
+	struct dentry          *flimit;
+
+	struct mlx5_ib_dev     *dev;
+	struct work_struct	work;
+	struct delayed_work	dwork;
+};
+
+struct mlx5_mr_cache {
+	struct workqueue_struct *wq;
+	struct mlx5_cache_ent	ent[MAX_MR_CACHE_ENTRIES];
+	int			stopped;
+	struct dentry		*root;
+	unsigned long		last_add;
+};
+
+struct mlx5_ib_resources {
+	struct ib_cq	*c0;
+	struct ib_xrcd	*x0;
+	struct ib_xrcd	*x1;
+	struct ib_pd	*p0;
+	struct ib_srq	*s0;
+};
+
+struct mlx5_ib_dev {
+	struct ib_device		ib_dev;
+	struct mlx5_core_dev		mdev;
+	MLX5_DECLARE_DOORBELL_LOCK(uar_lock);
+	struct list_head		eqs_list;
+	int				num_ports;
+	int				num_comp_vectors;
+	/* serialize update of capability mask
+	 */
+	struct mutex			cap_mask_mutex;
+	bool				ib_active;
+	struct umr_common		umrc;
+	/* sync used page count stats
+	 */
+	spinlock_t			mr_lock;
+	struct mlx5_ib_resources	devr;
+	struct mlx5_mr_cache		cache;
+};
+
+static inline struct mlx5_ib_cq *to_mibcq(struct mlx5_core_cq *mcq)
+{
+	return container_of(mcq, struct mlx5_ib_cq, mcq);
+}
+
+static inline struct mlx5_ib_xrcd *to_mxrcd(struct ib_xrcd *ibxrcd)
+{
+	return container_of(ibxrcd, struct mlx5_ib_xrcd, ibxrcd);
+}
+
+static inline struct mlx5_ib_dev *to_mdev(struct ib_device *ibdev)
+{
+	return container_of(ibdev, struct mlx5_ib_dev, ib_dev);
+}
+
+static inline struct mlx5_ib_fmr *to_mfmr(struct ib_fmr *ibfmr)
+{
+	return container_of(ibfmr, struct mlx5_ib_fmr, ibfmr);
+}
+
+static inline struct mlx5_ib_cq *to_mcq(struct ib_cq *ibcq)
+{
+	return container_of(ibcq, struct mlx5_ib_cq, ibcq);
+}
+
+static inline struct mlx5_ib_qp *to_mibqp(struct mlx5_core_qp *mqp)
+{
+	return container_of(mqp, struct mlx5_ib_qp, mqp);
+}
+
+static inline struct mlx5_ib_pd *to_mpd(struct ib_pd *ibpd)
+{
+	return container_of(ibpd, struct mlx5_ib_pd, ibpd);
+}
+
+static inline struct mlx5_ib_srq *to_msrq(struct ib_srq *ibsrq)
+{
+	return container_of(ibsrq, struct mlx5_ib_srq, ibsrq);
+}
+
+static inline struct mlx5_ib_qp *to_mqp(struct ib_qp *ibqp)
+{
+	return container_of(ibqp, struct mlx5_ib_qp, ibqp);
+}
+
+static inline struct mlx5_ib_srq *to_mibsrq(struct mlx5_core_srq *msrq)
+{
+	return container_of(msrq, struct mlx5_ib_srq, msrq);
+}
+
+static inline struct mlx5_ib_mr *to_mmr(struct ib_mr *ibmr)
+{
+	return container_of(ibmr, struct mlx5_ib_mr, ibmr);
+}
+
+static inline struct mlx5_ib_fast_reg_page_list *to_mfrpl(struct ib_fast_reg_page_list *ibfrpl)
+{
+	return container_of(ibfrpl, struct mlx5_ib_fast_reg_page_list, ibfrpl);
+}
+
+struct mlx5_ib_ah {
+	struct ib_ah		ibah;
+	struct mlx5_av		av;
+};
+
+static inline struct mlx5_ib_ah *to_mah(struct ib_ah *ibah)
+{
+	return container_of(ibah, struct mlx5_ib_ah, ibah);
+}
+
+static inline struct mlx5_ib_dev *mlx5_core2ibdev(struct mlx5_core_dev *dev)
+{
+	return container_of(dev, struct mlx5_ib_dev, mdev);
+}
+
+static inline struct mlx5_ib_dev *mlx5_pci2ibdev(struct pci_dev *pdev)
+{
+	return mlx5_core2ibdev(pci2mlx5_core_dev(pdev));
+}
+
+int mlx5_ib_db_map_user(struct mlx5_ib_ucontext *context, unsigned long virt,
+			struct mlx5_db *db);
+void mlx5_ib_db_unmap_user(struct mlx5_ib_ucontext *context, struct mlx5_db *db);
+void __mlx5_ib_cq_clean(struct mlx5_ib_cq *cq, u32 qpn, struct mlx5_ib_srq *srq);
+void mlx5_ib_cq_clean(struct mlx5_ib_cq *cq, u32 qpn, struct mlx5_ib_srq *srq);
+void mlx5_ib_free_srq_wqe(struct mlx5_ib_srq *srq, int wqe_index);
+int mlx5_MAD_IFC(struct mlx5_ib_dev *dev, int ignore_mkey, int ignore_bkey,
+		 int port, struct ib_wc *in_wc, struct ib_grh *in_grh,
+		 void *in_mad, void *response_mad);
+struct ib_ah *create_ib_ah(struct ib_ah_attr *ah_attr,
+			   struct mlx5_ib_ah *ah);
+struct ib_ah *mlx5_ib_create_ah(struct ib_pd *pd, struct ib_ah_attr *ah_attr);
+int mlx5_ib_query_ah(struct ib_ah *ibah, struct ib_ah_attr *ah_attr);
+int mlx5_ib_destroy_ah(struct ib_ah *ah);
+struct ib_srq *mlx5_ib_create_srq(struct ib_pd *pd,
+				  struct ib_srq_init_attr *init_attr,
+				  struct ib_udata *udata);
+int mlx5_ib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
+		       enum ib_srq_attr_mask attr_mask, struct ib_udata *udata);
+int mlx5_ib_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *srq_attr);
+int mlx5_ib_destroy_srq(struct ib_srq *srq);
+int mlx5_ib_post_srq_recv(struct ib_srq *ibsrq, struct ib_recv_wr *wr,
+			  struct ib_recv_wr **bad_wr);
+struct ib_qp *mlx5_ib_create_qp(struct ib_pd *pd,
+				struct ib_qp_init_attr *init_attr,
+				struct ib_udata *udata);
+int mlx5_ib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
+		      int attr_mask, struct ib_udata *udata);
+int mlx5_ib_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *qp_attr, int qp_attr_mask,
+		     struct ib_qp_init_attr *qp_init_attr);
+int mlx5_ib_destroy_qp(struct ib_qp *qp);
+int mlx5_ib_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
+		      struct ib_send_wr **bad_wr);
+int mlx5_ib_post_recv(struct ib_qp *ibqp, struct ib_recv_wr *wr,
+		      struct ib_recv_wr **bad_wr);
+void *mlx5_get_send_wqe(struct mlx5_ib_qp *qp, int n);
+struct ib_cq *mlx5_ib_create_cq(struct ib_device *ibdev, int entries,
+				int vector, struct ib_ucontext *context,
+				struct ib_udata *udata);
+int mlx5_ib_destroy_cq(struct ib_cq *cq);
+int mlx5_ib_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc);
+int mlx5_ib_arm_cq(struct ib_cq *ibcq, enum ib_cq_notify_flags flags);
+int mlx5_ib_modify_cq(struct ib_cq *cq, u16 cq_count, u16 cq_period);
+int mlx5_ib_resize_cq(struct ib_cq *ibcq, int entries, struct ib_udata *udata);
+struct ib_mr *mlx5_ib_get_dma_mr(struct ib_pd *pd, int acc);
+struct ib_mr *mlx5_ib_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
+				  u64 virt_addr, int access_flags,
+				  struct ib_udata *udata);
+int mlx5_ib_dereg_mr(struct ib_mr *ibmr);
+struct ib_mr *mlx5_ib_alloc_fast_reg_mr(struct ib_pd *pd,
+					int max_page_list_len);
+struct ib_fast_reg_page_list *mlx5_ib_alloc_fast_reg_page_list(struct ib_device *ibdev,
+							       int page_list_len);
+void mlx5_ib_free_fast_reg_page_list(struct ib_fast_reg_page_list *page_list);
+struct ib_fmr *mlx5_ib_fmr_alloc(struct ib_pd *pd, int acc,
+				 struct ib_fmr_attr *fmr_attr);
+int mlx5_ib_map_phys_fmr(struct ib_fmr *ibfmr, u64 *page_list,
+		      int npages, u64 iova);
+int mlx5_ib_unmap_fmr(struct list_head *fmr_list);
+int mlx5_ib_fmr_dealloc(struct ib_fmr *ibfmr);
+int mlx5_ib_process_mad(struct ib_device *ibdev, int mad_flags, u8 port_num,
+			struct ib_wc *in_wc, struct ib_grh *in_grh,
+			struct ib_mad *in_mad, struct ib_mad *out_mad);
+struct ib_xrcd *mlx5_ib_alloc_xrcd(struct ib_device *ibdev,
+					  struct ib_ucontext *context,
+					  struct ib_udata *udata);
+int mlx5_ib_dealloc_xrcd(struct ib_xrcd *xrcd);
+int mlx5_vector2eqn(struct mlx5_ib_dev *dev, int vector, int *eqn, int *irqn);
+int mlx5_ib_get_buf_offset(u64 addr, int page_shift, u32 *offset);
+int mlx5_query_ext_port_caps(struct mlx5_ib_dev *dev, u8 port);
+int mlx5_ib_query_port(struct ib_device *ibdev, u8 port,
+		       struct ib_port_attr *props);
+int mlx5_ib_init_fmr(struct mlx5_ib_dev *dev);
+void mlx5_ib_cleanup_fmr(struct mlx5_ib_dev *dev);
+void mlx5_ib_cont_pages(struct ib_umem *umem, u64 addr, int *count, int *shift,
+			int *ncont, int *order);
+void mlx5_ib_populate_pas(struct mlx5_ib_dev *dev, struct ib_umem *umem,
+			  int page_shift, __be64 *pas, int umr);
+void mlx5_ib_copy_pas(u64 *old, u64 *new, int step, int num);
+int mlx5_ib_get_cqe_size(struct mlx5_ib_dev *dev, struct ib_cq *ibcq);
+int mlx5_mr_cache_init(struct mlx5_ib_dev *dev);
+int mlx5_mr_cache_cleanup(struct mlx5_ib_dev *dev);
+int mlx5_mr_ib_cont_pages(struct ib_umem *umem, u64 addr, int *count, int *shift);
+void mlx5_umr_cq_handler(struct ib_cq *cq, void *cq_context);
+
+static inline void init_query_mad(struct ib_smp *mad)
+{
+	mad->base_version  = 1;
+	mad->mgmt_class    = IB_MGMT_CLASS_SUBN_LID_ROUTED;
+	mad->class_version = 1;
+	mad->method	   = IB_MGMT_METHOD_GET;
+}
+
+static inline u8 convert_access(int acc)
+{
+	return (acc & IB_ACCESS_REMOTE_ATOMIC ? MLX5_PERM_ATOMIC       : 0) |
+	       (acc & IB_ACCESS_REMOTE_WRITE  ? MLX5_PERM_REMOTE_WRITE : 0) |
+	       (acc & IB_ACCESS_REMOTE_READ   ? MLX5_PERM_REMOTE_READ  : 0) |
+	       (acc & IB_ACCESS_LOCAL_WRITE   ? MLX5_PERM_LOCAL_WRITE  : 0) |
+	       MLX5_PERM_LOCAL_READ;
+}
+
+#endif /* MLX5_IB_H */
diff --git a/drivers/infiniband/hw/mlx5/mr.c b/drivers/infiniband/hw/mlx5/mr.c
new file mode 100644
index 0000000..e2daa8f
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@ -0,0 +1,1007 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+
+#include <linux/kref.h>
+#include <linux/random.h>
+#include <linux/debugfs.h>
+#include <linux/export.h>
+#include <rdma/ib_umem.h>
+#include "mlx5_ib.h"
+
+enum {
+	DEF_CACHE_SIZE	= 10,
+};
+
+static __be64 *mr_align(__be64 *ptr, int align)
+{
+	unsigned long mask = align - 1;
+
+	return (__be64 *)(((unsigned long)ptr + mask) & ~mask);
+}
+
+static int order2idx(struct mlx5_ib_dev *dev, int order)
+{
+	struct mlx5_mr_cache *cache = &dev->cache;
+
+	if (order < cache->ent[0].order)
+		return 0;
+	else
+		return order - cache->ent[0].order;
+}
+
+static int add_keys(struct mlx5_ib_dev *dev, int c, int num)
+{
+	struct device *ddev = dev->ib_dev.dma_device;
+	struct mlx5_mr_cache *cache = &dev->cache;
+	struct mlx5_cache_ent *ent = &cache->ent[c];
+	struct mlx5_create_mkey_mbox_in *in;
+	struct mlx5_ib_mr *mr;
+	int npages = 1 << ent->order;
+	int size = sizeof(u64) * npages;
+	int err = 0;
+	int i;
+
+	in = kzalloc(sizeof(*in), GFP_KERNEL);
+	if (!in)
+		return -ENOMEM;
+
+	for (i = 0; i < num; i++) {
+		mr = kzalloc(sizeof(*mr), GFP_KERNEL);
+		if (!mr) {
+			err = -ENOMEM;
+			goto out;
+		}
+		mr->order = ent->order;
+		mr->umred = 1;
+		mr->pas = kmalloc(size + 0x3f, GFP_KERNEL);
+		if (!mr->pas) {
+			kfree(mr);
+			err = -ENOMEM;
+			goto out;
+		}
+		mr->dma = dma_map_single(ddev, mr_align(mr->pas, 0x40), size,
+					 DMA_TO_DEVICE);
+		if (dma_mapping_error(ddev, mr->dma)) {
+			kfree(mr->pas);
+			kfree(mr);
+			err = -ENOMEM;
+			goto out;
+		}
+
+		in->seg.status = 1 << 6;
+		in->seg.xlt_oct_size = cpu_to_be32((npages + 1) / 2);
+		in->seg.qpn_mkey7_0 = cpu_to_be32(0xffffff << 8);
+		in->seg.flags = MLX5_ACCESS_MODE_MTT | MLX5_PERM_UMR_EN;
+		in->seg.log2_page_size = 12;
+
+		err = mlx5_core_create_mkey(&dev->mdev, &mr->mmr, in,
+					    sizeof(*in));
+		if (err) {
+			mlx5_ib_warn(dev, "create mkey failed %d\n", err);
+			dma_unmap_single(ddev, mr->dma, size, DMA_TO_DEVICE);
+			kfree(mr->pas);
+			kfree(mr);
+			goto out;
+		}
+		cache->last_add = jiffies;
+
+		spin_lock(&ent->lock);
+		list_add_tail(&mr->list, &ent->head);
+		ent->cur++;
+		ent->size++;
+		spin_unlock(&ent->lock);
+	}
+
+out:
+	kfree(in);
+	return err;
+}
+
+static void remove_keys(struct mlx5_ib_dev *dev, int c, int num)
+{
+	struct device *ddev = dev->ib_dev.dma_device;
+	struct mlx5_mr_cache *cache = &dev->cache;
+	struct mlx5_cache_ent *ent = &cache->ent[c];
+	struct mlx5_ib_mr *mr;
+	int size;
+	int err;
+	int i;
+
+	for (i = 0; i < num; i++) {
+		spin_lock(&ent->lock);
+		if (list_empty(&ent->head)) {
+			spin_unlock(&ent->lock);
+			return;
+		}
+		mr = list_first_entry(&ent->head, struct mlx5_ib_mr, list);
+		list_del(&mr->list);
+		ent->cur--;
+		ent->size--;
+		spin_unlock(&ent->lock);
+		err = mlx5_core_destroy_mkey(&dev->mdev, &mr->mmr);
+		if (err) {
+			mlx5_ib_warn(dev, "failed destroy mkey\n");
+		} else {
+			size = ALIGN(sizeof(u64) * (1 << mr->order), 0x40);
+			dma_unmap_single(ddev, mr->dma, size, DMA_TO_DEVICE);
+			kfree(mr->pas);
+			kfree(mr);
+		}
+	}
+}
+
+static ssize_t size_write(struct file *filp, const char __user *buf,
+			  size_t count, loff_t *pos)
+{
+	struct mlx5_cache_ent *ent = filp->private_data;
+	struct mlx5_ib_dev *dev = ent->dev;
+	char lbuf[20];
+	u32 var;
+	int err;
+	int c;
+
+	if (copy_from_user(lbuf, buf, sizeof(lbuf)))
+		return -EPERM;
+
+	c = order2idx(dev, ent->order);
+	lbuf[sizeof(lbuf) - 1] = 0;
+
+	if (sscanf(lbuf, "%u", &var) != 1)
+		return -EINVAL;
+
+	if (var < ent->limit)
+		return -EINVAL;
+
+	if (var > ent->size) {
+		err = add_keys(dev, c, var - ent->size);
+		if (err)
+			return err;
+	} else if (var < ent->size) {
+		remove_keys(dev, c, ent->size - var);
+	}
+
+	return count;
+}
+
+static ssize_t size_read(struct file *filp, char __user *buf, size_t count,
+			 loff_t *pos)
+{
+	struct mlx5_cache_ent *ent = filp->private_data;
+	char lbuf[20];
+	int err;
+
+	if (*pos)
+		return 0;
+
+	err = snprintf(lbuf, sizeof(lbuf), "%d\n", ent->size);
+	if (err < 0)
+		return err;
+
+	if (copy_to_user(buf, lbuf, err))
+		return -EPERM;
+
+	*pos += err;
+
+	return err;
+}
+
+static const struct file_operations size_fops = {
+	.owner	= THIS_MODULE,
+	.open	= simple_open,
+	.write	= size_write,
+	.read	= size_read,
+};
+
+static ssize_t limit_write(struct file *filp, const char __user *buf,
+			   size_t count, loff_t *pos)
+{
+	struct mlx5_cache_ent *ent = filp->private_data;
+	struct mlx5_ib_dev *dev = ent->dev;
+	char lbuf[20];
+	u32 var;
+	int err;
+	int c;
+
+	if (copy_from_user(lbuf, buf, sizeof(lbuf)))
+		return -EPERM;
+
+	c = order2idx(dev, ent->order);
+	lbuf[sizeof(lbuf) - 1] = 0;
+
+	if (sscanf(lbuf, "%u", &var) != 1)
+		return -EINVAL;
+
+	if (var > ent->size)
+		return -EINVAL;
+
+	ent->limit = var;
+
+	if (ent->cur < ent->limit) {
+		err = add_keys(dev, c, 2 * ent->limit - ent->cur);
+		if (err)
+			return err;
+	}
+
+	return count;
+}
+
+static ssize_t limit_read(struct file *filp, char __user *buf, size_t count,
+			  loff_t *pos)
+{
+	struct mlx5_cache_ent *ent = filp->private_data;
+	char lbuf[20];
+	int err;
+
+	if (*pos)
+		return 0;
+
+	err = snprintf(lbuf, sizeof(lbuf), "%d\n", ent->limit);
+	if (err < 0)
+		return err;
+
+	if (copy_to_user(buf, lbuf, err))
+		return -EPERM;
+
+	*pos += err;
+
+	return err;
+}
+
+static const struct file_operations limit_fops = {
+	.owner	= THIS_MODULE,
+	.open	= simple_open,
+	.write	= limit_write,
+	.read	= limit_read,
+};
+
+static int someone_adding(struct mlx5_mr_cache *cache)
+{
+	int i;
+
+	for (i = 0; i < MAX_MR_CACHE_ENTRIES; i++) {
+		if (cache->ent[i].cur < cache->ent[i].limit)
+			return 1;
+	}
+
+	return 0;
+}
+
+static void __cache_work_func(struct mlx5_cache_ent *ent)
+{
+	struct mlx5_ib_dev *dev = ent->dev;
+	struct mlx5_mr_cache *cache = &dev->cache;
+	int i = order2idx(dev, ent->order);
+
+	if (cache->stopped)
+		return;
+
+	ent = &dev->cache.ent[i];
+	if (ent->cur < 2 * ent->limit) {
+		add_keys(dev, i, 1);
+		if (ent->cur < 2 * ent->limit)
+			queue_work(cache->wq, &ent->work);
+	} else if (ent->cur > 2 * ent->limit) {
+		if (!someone_adding(cache) &&
+		    time_after(jiffies, cache->last_add + 60 * HZ)) {
+			remove_keys(dev, i, 1);
+			if (ent->cur > ent->limit)
+				queue_work(cache->wq, &ent->work);
+		} else {
+			queue_delayed_work(cache->wq, &ent->dwork, 60 * HZ);
+		}
+	}
+}
+
+static void delayed_cache_work_func(struct work_struct *work)
+{
+	struct mlx5_cache_ent *ent;
+
+	ent = container_of(work, struct mlx5_cache_ent, dwork.work);
+	__cache_work_func(ent);
+}
+
+static void cache_work_func(struct work_struct *work)
+{
+	struct mlx5_cache_ent *ent;
+
+	ent = container_of(work, struct mlx5_cache_ent, work);
+	__cache_work_func(ent);
+}
+
+static struct mlx5_ib_mr *alloc_cached_mr(struct mlx5_ib_dev *dev, int order)
+{
+	struct mlx5_mr_cache *cache = &dev->cache;
+	struct mlx5_ib_mr *mr = NULL;
+	struct mlx5_cache_ent *ent;
+	int c;
+	int i;
+
+	c = order2idx(dev, order);
+	if (c < 0 || c >= MAX_MR_CACHE_ENTRIES) {
+		mlx5_ib_warn(dev, "order %d, cache index %d\n", order, c);
+		return NULL;
+	}
+
+	for (i = c; i < MAX_MR_CACHE_ENTRIES; i++) {
+		ent = &cache->ent[i];
+
+		mlx5_ib_dbg(dev, "order %d, cache index %d\n", ent->order, i);
+
+		spin_lock(&ent->lock);
+		if (!list_empty(&ent->head)) {
+			mr = list_first_entry(&ent->head, struct mlx5_ib_mr,
+					      list);
+			list_del(&mr->list);
+			ent->cur--;
+			spin_unlock(&ent->lock);
+			if (ent->cur < ent->limit)
+				queue_work(cache->wq, &ent->work);
+			break;
+		}
+		spin_unlock(&ent->lock);
+
+		queue_work(cache->wq, &ent->work);
+
+		if (mr)
+			break;
+	}
+
+	if (!mr)
+		cache->ent[c].miss++;
+
+	return mr;
+}
+
+static void free_cached_mr(struct mlx5_ib_dev *dev, struct mlx5_ib_mr *mr)
+{
+	struct mlx5_mr_cache *cache = &dev->cache;
+	struct mlx5_cache_ent *ent;
+	int shrink = 0;
+	int c;
+
+	c = order2idx(dev, mr->order);
+	if (c < 0 || c >= MAX_MR_CACHE_ENTRIES) {
+		mlx5_ib_warn(dev, "order %d, cache index %d\n", mr->order, c);
+		return;
+	}
+	ent = &cache->ent[c];
+	spin_lock(&ent->lock);
+	list_add_tail(&mr->list, &ent->head);
+	ent->cur++;
+	if (ent->cur > 2 * ent->limit)
+		shrink = 1;
+	spin_unlock(&ent->lock);
+
+	if (shrink)
+		queue_work(cache->wq, &ent->work);
+}
+
+static void clean_keys(struct mlx5_ib_dev *dev, int c)
+{
+	struct device *ddev = dev->ib_dev.dma_device;
+	struct mlx5_mr_cache *cache = &dev->cache;
+	struct mlx5_cache_ent *ent = &cache->ent[c];
+	struct mlx5_ib_mr *mr;
+	int size;
+	int err;
+
+	while (1) {
+		spin_lock(&ent->lock);
+		if (list_empty(&ent->head)) {
+			spin_unlock(&ent->lock);
+			return;
+		}
+		mr = list_first_entry(&ent->head, struct mlx5_ib_mr, list);
+		list_del(&mr->list);
+		ent->cur--;
+		ent->size--;
+		spin_unlock(&ent->lock);
+		err = mlx5_core_destroy_mkey(&dev->mdev, &mr->mmr);
+		if (err) {
+			mlx5_ib_warn(dev, "failed destroy mkey\n");
+		} else {
+			size = ALIGN(sizeof(u64) * (1 << mr->order), 0x40);
+			dma_unmap_single(ddev, mr->dma, size, DMA_TO_DEVICE);
+			kfree(mr->pas);
+			kfree(mr);
+		}
+	}
+}
+
+static int mlx5_mr_cache_debugfs_init(struct mlx5_ib_dev *dev)
+{
+	struct mlx5_mr_cache *cache = &dev->cache;
+	struct mlx5_cache_ent *ent;
+	int i;
+
+	if (!mlx5_debugfs_root)
+		return 0;
+
+	cache->root = debugfs_create_dir("mr_cache", dev->mdev.priv.dbg_root);
+	if (!cache->root)
+		return -ENOMEM;
+
+	for (i = 0; i < MAX_MR_CACHE_ENTRIES; i++) {
+		ent = &cache->ent[i];
+		sprintf(ent->name, "%d", ent->order);
+		ent->dir = debugfs_create_dir(ent->name,  cache->root);
+		if (!ent->dir)
+			return -ENOMEM;
+
+		ent->fsize = debugfs_create_file("size", 0600, ent->dir, ent,
+						 &size_fops);
+		if (!ent->fsize)
+			return -ENOMEM;
+
+		ent->flimit = debugfs_create_file("limit", 0600, ent->dir, ent,
+						  &limit_fops);
+		if (!ent->flimit)
+			return -ENOMEM;
+
+		ent->fcur = debugfs_create_u32("cur", 0400, ent->dir,
+					       &ent->cur);
+		if (!ent->fcur)
+			return -ENOMEM;
+
+		ent->fmiss = debugfs_create_u32("miss", 0600, ent->dir,
+						&ent->miss);
+		if (!ent->fmiss)
+			return -ENOMEM;
+	}
+
+	return 0;
+}
+
+static void mlx5_mr_cache_debugfs_cleanup(struct mlx5_ib_dev *dev)
+{
+	if (!mlx5_debugfs_root)
+		return;
+
+	debugfs_remove_recursive(dev->cache.root);
+}
+
+int mlx5_mr_cache_init(struct mlx5_ib_dev *dev)
+{
+	struct mlx5_mr_cache *cache = &dev->cache;
+	struct mlx5_cache_ent *ent;
+	int limit;
+	int size;
+	int err;
+	int i;
+
+	cache->wq = create_singlethread_workqueue("mkey_cache");
+	if (!cache->wq) {
+		mlx5_ib_warn(dev, "failed to create work queue\n");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < MAX_MR_CACHE_ENTRIES; i++) {
+		INIT_LIST_HEAD(&cache->ent[i].head);
+		spin_lock_init(&cache->ent[i].lock);
+
+		ent = &cache->ent[i];
+		INIT_LIST_HEAD(&ent->head);
+		spin_lock_init(&ent->lock);
+		ent->order = i + 2;
+		ent->dev = dev;
+
+		if (dev->mdev.profile->mask & MLX5_PROF_MASK_MR_CACHE) {
+			size = dev->mdev.profile->mr_cache[i].size;
+			limit = dev->mdev.profile->mr_cache[i].limit;
+		} else {
+			size = DEF_CACHE_SIZE;
+			limit = 0;
+		}
+		INIT_WORK(&ent->work, cache_work_func);
+		INIT_DELAYED_WORK(&ent->dwork, delayed_cache_work_func);
+		ent->limit = limit;
+		queue_work(cache->wq, &ent->work);
+	}
+
+	err = mlx5_mr_cache_debugfs_init(dev);
+	if (err)
+		mlx5_ib_warn(dev, "cache debugfs failure\n");
+
+	return 0;
+}
+
+int mlx5_mr_cache_cleanup(struct mlx5_ib_dev *dev)
+{
+	int i;
+
+	dev->cache.stopped = 1;
+	destroy_workqueue(dev->cache.wq);
+
+	mlx5_mr_cache_debugfs_cleanup(dev);
+
+	for (i = 0; i < MAX_MR_CACHE_ENTRIES; i++)
+		clean_keys(dev, i);
+
+	return 0;
+}
+
+struct ib_mr *mlx5_ib_get_dma_mr(struct ib_pd *pd, int acc)
+{
+	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+	struct mlx5_core_dev *mdev = &dev->mdev;
+	struct mlx5_create_mkey_mbox_in *in;
+	struct mlx5_mkey_seg *seg;
+	struct mlx5_ib_mr *mr;
+	int err;
+
+	mr = kzalloc(sizeof(*mr), GFP_KERNEL);
+	if (!mr)
+		return ERR_PTR(-ENOMEM);
+
+	in = kzalloc(sizeof(*in), GFP_KERNEL);
+	if (!in) {
+		err = -ENOMEM;
+		goto err_free;
+	}
+
+	seg = &in->seg;
+	seg->flags = convert_access(acc) | MLX5_ACCESS_MODE_PA;
+	seg->flags_pd = cpu_to_be32(to_mpd(pd)->pdn | MLX5_MKEY_LEN64);
+	seg->qpn_mkey7_0 = cpu_to_be32(0xffffff << 8);
+	seg->start_addr = 0;
+
+	err = mlx5_core_create_mkey(mdev, &mr->mmr, in, sizeof(*in));
+	if (err)
+		goto err_in;
+
+	kfree(in);
+	mr->ibmr.lkey = mr->mmr.key;
+	mr->ibmr.rkey = mr->mmr.key;
+	mr->umem = NULL;
+
+	return &mr->ibmr;
+
+err_in:
+	kfree(in);
+
+err_free:
+	kfree(mr);
+
+	return ERR_PTR(err);
+}
+
+static int get_octo_len(u64 addr, u64 len, int page_size)
+{
+	u64 offset;
+	int npages;
+
+	offset = addr & (page_size - 1);
+	npages = ALIGN(len + offset, page_size) >> ilog2(page_size);
+	return (npages + 1) / 2;
+}
+
+static int use_umr(int order)
+{
+	return order <= 17;
+}
+
+static void prep_umr_reg_wqe(struct ib_pd *pd, struct ib_send_wr *wr,
+			     struct ib_sge *sg, u64 dma, int n, u32 key,
+			     int page_shift, u64 virt_addr, u64 len,
+			     int access_flags)
+{
+	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+	struct ib_mr *mr = dev->umrc.mr;
+
+	sg->addr = dma;
+	sg->length = ALIGN(sizeof(u64) * n, 64);
+	sg->lkey = mr->lkey;
+
+	wr->next = NULL;
+	wr->send_flags = 0;
+	wr->sg_list = sg;
+	if (n)
+		wr->num_sge = 1;
+	else
+		wr->num_sge = 0;
+
+	wr->opcode = MLX5_IB_WR_UMR;
+	wr->wr.fast_reg.page_list_len = n;
+	wr->wr.fast_reg.page_shift = page_shift;
+	wr->wr.fast_reg.rkey = key;
+	wr->wr.fast_reg.iova_start = virt_addr;
+	wr->wr.fast_reg.length = len;
+	wr->wr.fast_reg.access_flags = access_flags;
+	wr->wr.fast_reg.page_list = (struct ib_fast_reg_page_list *)pd;
+}
+
+static void prep_umr_unreg_wqe(struct mlx5_ib_dev *dev,
+			       struct ib_send_wr *wr, u32 key)
+{
+	wr->send_flags = MLX5_IB_SEND_UMR_UNREG;
+	wr->opcode = MLX5_IB_WR_UMR;
+	wr->wr.fast_reg.rkey = key;
+}
+
+void mlx5_umr_cq_handler(struct ib_cq *cq, void *cq_context)
+{
+	struct mlx5_ib_mr *mr;
+	struct ib_wc wc;
+	int err;
+
+	while (1) {
+		err = ib_poll_cq(cq, 1, &wc);
+		if (err < 0) {
+			pr_warn("poll cq error %d\n", err);
+			return;
+		}
+		if (err == 0)
+			break;
+
+		mr = (struct mlx5_ib_mr *)(unsigned long)wc.wr_id;
+		mr->status = wc.status;
+		complete(&mr->done);
+	}
+	ib_req_notify_cq(cq, IB_CQ_NEXT_COMP);
+}
+
+static struct mlx5_ib_mr *reg_umr(struct ib_pd *pd, struct ib_umem *umem,
+				  u64 virt_addr, u64 len, int npages,
+				  int page_shift, int order, int access_flags)
+{
+	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+	struct umr_common *umrc = &dev->umrc;
+	struct ib_send_wr wr, *bad;
+	struct mlx5_ib_mr *mr;
+	struct ib_sge sg;
+	int err;
+	int i;
+
+	for (i = 0; i < 10; i++) {
+		mr = alloc_cached_mr(dev, order);
+		if (mr)
+			break;
+
+		err = add_keys(dev, order2idx(dev, order), 1);
+		if (err) {
+			mlx5_ib_warn(dev, "add_keys failed\n");
+			break;
+		}
+	}
+
+	if (!mr)
+		return ERR_PTR(-EAGAIN);
+
+	mlx5_ib_populate_pas(dev, umem, page_shift, mr_align(mr->pas, 0x40), 1);
+
+	memset(&wr, 0, sizeof(wr));
+	wr.wr_id = (u64)(unsigned long)mr;
+	prep_umr_reg_wqe(pd, &wr, &sg, mr->dma, npages, mr->mmr.key, page_shift, virt_addr, len, access_flags);
+
+	/* We serialize polls so one process does not kidnap another's
+	 * completion. This is not a problem since wr is completed in
+	 * around 1 usec
+	 */
+	down(&umrc->sem);
+	init_completion(&mr->done);
+	err = ib_post_send(umrc->qp, &wr, &bad);
+	if (err) {
+		mlx5_ib_warn(dev, "post send failed, err %d\n", err);
+		up(&umrc->sem);
+		goto error;
+	}
+	wait_for_completion(&mr->done);
+	up(&umrc->sem);
+
+	if (mr->status != IB_WC_SUCCESS) {
+		mlx5_ib_warn(dev, "reg umr failed\n");
+		err = -EFAULT;
+		goto error;
+	}
+
+	return mr;
+
+error:
+	free_cached_mr(dev, mr);
+	return ERR_PTR(err);
+}
+
+static struct mlx5_ib_mr *reg_create(struct ib_pd *pd, u64 virt_addr,
+				     u64 length, struct ib_umem *umem,
+				     int npages, int page_shift,
+				     int access_flags)
+{
+	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+	struct mlx5_create_mkey_mbox_in *in;
+	struct mlx5_ib_mr *mr;
+	int inlen;
+	int err;
+
+	mr = kzalloc(sizeof(*mr), GFP_KERNEL);
+	if (!mr)
+		return ERR_PTR(-ENOMEM);
+
+	inlen = sizeof(*in) + sizeof(*in->pas) * ((npages + 1) / 2) * 2;
+	in = mlx5_vzalloc(inlen);
+	if (!in) {
+		err = -ENOMEM;
+		goto err_1;
+	}
+	mlx5_ib_populate_pas(dev, umem, page_shift, in->pas, 0);
+
+	in->seg.flags = convert_access(access_flags) |
+		MLX5_ACCESS_MODE_MTT;
+	in->seg.flags_pd = cpu_to_be32(to_mpd(pd)->pdn);
+	in->seg.start_addr = cpu_to_be64(virt_addr);
+	in->seg.len = cpu_to_be64(length);
+	in->seg.bsfs_octo_size = 0;
+	in->seg.xlt_oct_size = cpu_to_be32(get_octo_len(virt_addr, length, 1 << page_shift));
+	in->seg.log2_page_size = page_shift;
+	in->seg.qpn_mkey7_0 = cpu_to_be32(0xffffff << 8);
+	in->xlat_oct_act_size = cpu_to_be32(get_octo_len(virt_addr, length, 1 << page_shift));
+	err = mlx5_core_create_mkey(&dev->mdev, &mr->mmr, in, inlen);
+	if (err) {
+		mlx5_ib_warn(dev, "create mkey failed\n");
+		goto err_2;
+	}
+	mr->umem = umem;
+	mlx5_vfree(in);
+
+	mlx5_ib_dbg(dev, "mkey = 0x%x\n", mr->mmr.key);
+
+	return mr;
+
+err_2:
+	mlx5_vfree(in);
+
+err_1:
+	kfree(mr);
+
+	return ERR_PTR(err);
+}
+
+struct ib_mr *mlx5_ib_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
+				  u64 virt_addr, int access_flags,
+				  struct ib_udata *udata)
+{
+	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+	struct mlx5_ib_mr *mr = NULL;
+	struct ib_umem *umem;
+	int page_shift;
+	int npages;
+	int ncont;
+	int order;
+	int err;
+
+	mlx5_ib_dbg(dev, "start 0x%llx, virt_addr 0x%llx, length 0x%llx\n",
+		    start, virt_addr, length);
+	umem = ib_umem_get(pd->uobject->context, start, length, access_flags,
+			   0);
+	if (IS_ERR(umem)) {
+		mlx5_ib_dbg(dev, "umem get failed\n");
+		return (void *)umem;
+	}
+
+	mlx5_ib_cont_pages(umem, start, &npages, &page_shift, &ncont, &order);
+	if (!npages) {
+		mlx5_ib_warn(dev, "avoid zero region\n");
+		err = -EINVAL;
+		goto error;
+	}
+
+	mlx5_ib_dbg(dev, "npages %d, ncont %d, order %d, page_shift %d\n",
+		    npages, ncont, order, page_shift);
+
+	if (use_umr(order)) {
+		mr = reg_umr(pd, umem, virt_addr, length, ncont, page_shift,
+			     order, access_flags);
+		if (PTR_ERR(mr) == -EAGAIN) {
+			mlx5_ib_dbg(dev, "cache empty for order %d", order);
+			mr = NULL;
+		}
+	}
+
+	if (!mr)
+		mr = reg_create(pd, virt_addr, length, umem, ncont, page_shift,
+				access_flags);
+
+	if (IS_ERR(mr)) {
+		err = PTR_ERR(mr);
+		goto error;
+	}
+
+	mlx5_ib_dbg(dev, "mkey 0x%x\n", mr->mmr.key);
+
+	mr->umem = umem;
+	mr->npages = npages;
+	spin_lock(&dev->mr_lock);
+	dev->mdev.priv.reg_pages += npages;
+	spin_unlock(&dev->mr_lock);
+	mr->ibmr.lkey = mr->mmr.key;
+	mr->ibmr.rkey = mr->mmr.key;
+
+	return &mr->ibmr;
+
+error:
+	ib_umem_release(umem);
+	return ERR_PTR(err);
+}
+
+static int unreg_umr(struct mlx5_ib_dev *dev, struct mlx5_ib_mr *mr)
+{
+	struct umr_common *umrc = &dev->umrc;
+	struct ib_send_wr wr, *bad;
+	int err;
+
+	memset(&wr, 0, sizeof(wr));
+	wr.wr_id = (u64)(unsigned long)mr;
+	prep_umr_unreg_wqe(dev, &wr, mr->mmr.key);
+
+	down(&umrc->sem);
+	init_completion(&mr->done);
+	err = ib_post_send(umrc->qp, &wr, &bad);
+	if (err) {
+		up(&umrc->sem);
+		mlx5_ib_dbg(dev, "err %d\n", err);
+		goto error;
+	}
+	wait_for_completion(&mr->done);
+	up(&umrc->sem);
+	if (mr->status != IB_WC_SUCCESS) {
+		mlx5_ib_warn(dev, "unreg umr failed\n");
+		err = -EFAULT;
+		goto error;
+	}
+	return 0;
+
+error:
+	return err;
+}
+
+int mlx5_ib_dereg_mr(struct ib_mr *ibmr)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibmr->device);
+	struct mlx5_ib_mr *mr = to_mmr(ibmr);
+	struct ib_umem *umem = mr->umem;
+	int npages = mr->npages;
+	int umred = mr->umred;
+	int err;
+
+	if (!umred) {
+		err = mlx5_core_destroy_mkey(&dev->mdev, &mr->mmr);
+		if (err) {
+			mlx5_ib_warn(dev, "failed to destroy mkey 0x%x (%d)\n",
+				     mr->mmr.key, err);
+			return err;
+		}
+	} else {
+		err = unreg_umr(dev, mr);
+		if (err) {
+			mlx5_ib_warn(dev, "failed unregister\n");
+			return err;
+		}
+		free_cached_mr(dev, mr);
+	}
+
+	if (umem) {
+		ib_umem_release(umem);
+		spin_lock(&dev->mr_lock);
+		dev->mdev.priv.reg_pages -= npages;
+		spin_unlock(&dev->mr_lock);
+	}
+
+	if (!umred)
+		kfree(mr);
+
+	return 0;
+}
+
+struct ib_mr *mlx5_ib_alloc_fast_reg_mr(struct ib_pd *pd,
+					int max_page_list_len)
+{
+	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+	struct mlx5_create_mkey_mbox_in *in;
+	struct mlx5_ib_mr *mr;
+	int err;
+
+	mr = kzalloc(sizeof(*mr), GFP_KERNEL);
+	if (!mr)
+		return ERR_PTR(-ENOMEM);
+
+	in = kzalloc(sizeof(*in), GFP_KERNEL);
+	if (!in) {
+		err = -ENOMEM;
+		goto err_free;
+	}
+
+	in->seg.status = 1 << 6; /* free */
+	in->seg.xlt_oct_size = cpu_to_be32((max_page_list_len + 1) / 2);
+	in->seg.qpn_mkey7_0 = cpu_to_be32(0xffffff << 8);
+	in->seg.flags = MLX5_PERM_UMR_EN | MLX5_ACCESS_MODE_MTT;
+	in->seg.flags_pd = cpu_to_be32(to_mpd(pd)->pdn);
+	/*
+	 * TBD not needed - issue 197292 */
+	in->seg.log2_page_size = PAGE_SHIFT;
+
+	err = mlx5_core_create_mkey(&dev->mdev, &mr->mmr, in, sizeof(*in));
+	kfree(in);
+	if (err)
+		goto err_free;
+
+	mr->ibmr.lkey = mr->mmr.key;
+	mr->ibmr.rkey = mr->mmr.key;
+	mr->umem = NULL;
+
+	return &mr->ibmr;
+
+err_free:
+	kfree(mr);
+	return ERR_PTR(err);
+}
+
+struct ib_fast_reg_page_list *mlx5_ib_alloc_fast_reg_page_list(struct ib_device *ibdev,
+							       int page_list_len)
+{
+	struct mlx5_ib_fast_reg_page_list *mfrpl;
+	int size = page_list_len * sizeof(u64);
+
+	mfrpl = kmalloc(sizeof(*mfrpl), GFP_KERNEL);
+	if (!mfrpl)
+		return ERR_PTR(-ENOMEM);
+
+	mfrpl->ibfrpl.page_list = kmalloc(size, GFP_KERNEL);
+	if (!mfrpl->ibfrpl.page_list)
+		goto err_free;
+
+	mfrpl->mapped_page_list = dma_alloc_coherent(ibdev->dma_device,
+						     size, &mfrpl->map,
+						     GFP_KERNEL);
+	if (!mfrpl->mapped_page_list)
+		goto err_free;
+
+	WARN_ON(mfrpl->map & 0x3f);
+
+	return &mfrpl->ibfrpl;
+
+err_free:
+	kfree(mfrpl->ibfrpl.page_list);
+	kfree(mfrpl);
+	return ERR_PTR(-ENOMEM);
+}
+
+void mlx5_ib_free_fast_reg_page_list(struct ib_fast_reg_page_list *page_list)
+{
+	struct mlx5_ib_fast_reg_page_list *mfrpl = to_mfrpl(page_list);
+	struct mlx5_ib_dev *dev = to_mdev(page_list->device);
+	int size = page_list->max_page_list_len * sizeof(u64);
+
+	dma_free_coherent(&dev->mdev.pdev->dev, size, mfrpl->mapped_page_list,
+			  mfrpl->map);
+	kfree(mfrpl->ibfrpl.page_list);
+	kfree(mfrpl);
+}
diff --git a/drivers/infiniband/hw/mlx5/qp.c b/drivers/infiniband/hw/mlx5/qp.c
new file mode 100644
index 0000000..16ac54c
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@ -0,0 +1,2524 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/module.h>
+#include <rdma/ib_umem.h>
+#include "mlx5_ib.h"
+#include "user.h"
+
+/* not supported currently */
+static int wq_signature;
+
+enum {
+	MLX5_IB_ACK_REQ_FREQ	= 8,
+};
+
+enum {
+	MLX5_IB_DEFAULT_SCHED_QUEUE	= 0x83,
+	MLX5_IB_DEFAULT_QP0_SCHED_QUEUE	= 0x3f,
+	MLX5_IB_LINK_TYPE_IB		= 0,
+	MLX5_IB_LINK_TYPE_ETH		= 1
+};
+
+enum {
+	MLX5_IB_SQ_STRIDE	= 6,
+	MLX5_IB_CACHE_LINE_SIZE	= 64,
+};
+
+static const u32 mlx5_ib_opcode[] = {
+	[IB_WR_SEND]				= MLX5_OPCODE_SEND,
+	[IB_WR_SEND_WITH_IMM]			= MLX5_OPCODE_SEND_IMM,
+	[IB_WR_RDMA_WRITE]			= MLX5_OPCODE_RDMA_WRITE,
+	[IB_WR_RDMA_WRITE_WITH_IMM]		= MLX5_OPCODE_RDMA_WRITE_IMM,
+	[IB_WR_RDMA_READ]			= MLX5_OPCODE_RDMA_READ,
+	[IB_WR_ATOMIC_CMP_AND_SWP]		= MLX5_OPCODE_ATOMIC_CS,
+	[IB_WR_ATOMIC_FETCH_AND_ADD]		= MLX5_OPCODE_ATOMIC_FA,
+	[IB_WR_SEND_WITH_INV]			= MLX5_OPCODE_SEND_INVAL,
+	[IB_WR_LOCAL_INV]			= MLX5_OPCODE_UMR,
+	[IB_WR_FAST_REG_MR]			= MLX5_OPCODE_UMR,
+	[IB_WR_MASKED_ATOMIC_CMP_AND_SWP]	= MLX5_OPCODE_ATOMIC_MASKED_CS,
+	[IB_WR_MASKED_ATOMIC_FETCH_AND_ADD]	= MLX5_OPCODE_ATOMIC_MASKED_FA,
+	[MLX5_IB_WR_UMR]			= MLX5_OPCODE_UMR,
+};
+
+struct umr_wr {
+	u64				virt_addr;
+	struct ib_pd		       *pd;
+	unsigned int			page_shift;
+	unsigned int			npages;
+	u32				length;
+	int				access_flags;
+	u32				mkey;
+};
+
+static int is_qp0(enum ib_qp_type qp_type)
+{
+	return qp_type == IB_QPT_SMI;
+}
+
+static int is_qp1(enum ib_qp_type qp_type)
+{
+	return qp_type == IB_QPT_GSI;
+}
+
+static int is_sqp(enum ib_qp_type qp_type)
+{
+	return is_qp0(qp_type) || is_qp1(qp_type);
+}
+
+static void *get_wqe(struct mlx5_ib_qp *qp, int offset)
+{
+	return mlx5_buf_offset(&qp->buf, offset);
+}
+
+static void *get_recv_wqe(struct mlx5_ib_qp *qp, int n)
+{
+	return get_wqe(qp, qp->rq.offset + (n << qp->rq.wqe_shift));
+}
+
+void *mlx5_get_send_wqe(struct mlx5_ib_qp *qp, int n)
+{
+	return get_wqe(qp, qp->sq.offset + (n << MLX5_IB_SQ_STRIDE));
+}
+
+static void mlx5_ib_qp_event(struct mlx5_core_qp *qp, int type)
+{
+	struct ib_qp *ibqp = &to_mibqp(qp)->ibqp;
+	struct ib_event event;
+
+	if (type == MLX5_EVENT_TYPE_PATH_MIG)
+		to_mibqp(qp)->port = to_mibqp(qp)->alt_port;
+
+	if (ibqp->event_handler) {
+		event.device     = ibqp->device;
+		event.element.qp = ibqp;
+		switch (type) {
+		case MLX5_EVENT_TYPE_PATH_MIG:
+			event.event = IB_EVENT_PATH_MIG;
+			break;
+		case MLX5_EVENT_TYPE_COMM_EST:
+			event.event = IB_EVENT_COMM_EST;
+			break;
+		case MLX5_EVENT_TYPE_SQ_DRAINED:
+			event.event = IB_EVENT_SQ_DRAINED;
+			break;
+		case MLX5_EVENT_TYPE_SRQ_LAST_WQE:
+			event.event = IB_EVENT_QP_LAST_WQE_REACHED;
+			break;
+		case MLX5_EVENT_TYPE_WQ_CATAS_ERROR:
+			event.event = IB_EVENT_QP_FATAL;
+			break;
+		case MLX5_EVENT_TYPE_PATH_MIG_FAILED:
+			event.event = IB_EVENT_PATH_MIG_ERR;
+			break;
+		case MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR:
+			event.event = IB_EVENT_QP_REQ_ERR;
+			break;
+		case MLX5_EVENT_TYPE_WQ_ACCESS_ERROR:
+			event.event = IB_EVENT_QP_ACCESS_ERR;
+			break;
+		default:
+			pr_warn("mlx5_ib: Unexpected event type %d on QP %06x\n", type, qp->qpn);
+			return;
+		}
+
+		ibqp->event_handler(&event, ibqp->qp_context);
+	}
+}
+
+static int set_rq_size(struct mlx5_ib_dev *dev, struct ib_qp_cap *cap,
+		       int has_rq, struct mlx5_ib_qp *qp, struct mlx5_ib_create_qp *ucmd)
+{
+	int wqe_size;
+	int wq_size;
+
+	/* Sanity check RQ size before proceeding */
+	if (cap->max_recv_wr  > dev->mdev.caps.max_wqes)
+		return -EINVAL;
+
+	if (!has_rq) {
+		qp->rq.max_gs = 0;
+		qp->rq.wqe_cnt = 0;
+		qp->rq.wqe_shift = 0;
+	} else {
+		if (ucmd) {
+			qp->rq.wqe_cnt = ucmd->rq_wqe_count;
+			qp->rq.wqe_shift = ucmd->rq_wqe_shift;
+			qp->rq.max_gs = (1 << qp->rq.wqe_shift) / sizeof(struct mlx5_wqe_data_seg) - qp->wq_sig;
+			qp->rq.max_post = qp->rq.wqe_cnt;
+		} else {
+			wqe_size = qp->wq_sig ? sizeof(struct mlx5_wqe_signature_seg) : 0;
+			wqe_size += cap->max_recv_sge * sizeof(struct mlx5_wqe_data_seg);
+			wqe_size = roundup_pow_of_two(wqe_size);
+			wq_size = roundup_pow_of_two(cap->max_recv_wr) * wqe_size;
+			wq_size = max_t(int, wq_size, MLX5_SEND_WQE_BB);
+			qp->rq.wqe_cnt = wq_size / wqe_size;
+			if (wqe_size > dev->mdev.caps.max_rq_desc_sz) {
+				mlx5_ib_dbg(dev, "wqe_size %d, max %d\n",
+					    wqe_size,
+					    dev->mdev.caps.max_rq_desc_sz);
+				return -EINVAL;
+			}
+			qp->rq.wqe_shift = ilog2(wqe_size);
+			qp->rq.max_gs = (1 << qp->rq.wqe_shift) / sizeof(struct mlx5_wqe_data_seg) - qp->wq_sig;
+			qp->rq.max_post = qp->rq.wqe_cnt;
+		}
+	}
+
+	return 0;
+}
+
+static int sq_overhead(enum ib_qp_type qp_type)
+{
+	int size;
+
+	switch (qp_type) {
+	case IB_QPT_XRC_INI:
+		size = sizeof(struct mlx5_wqe_xrc_seg);
+		/* fall through */
+	case IB_QPT_RC:
+		size += sizeof(struct mlx5_wqe_ctrl_seg) +
+			sizeof(struct mlx5_wqe_atomic_seg) +
+			sizeof(struct mlx5_wqe_raddr_seg);
+		break;
+
+	case IB_QPT_UC:
+		size = sizeof(struct mlx5_wqe_ctrl_seg) +
+			sizeof(struct mlx5_wqe_raddr_seg);
+		break;
+
+	case IB_QPT_UD:
+	case IB_QPT_SMI:
+	case IB_QPT_GSI:
+		size = sizeof(struct mlx5_wqe_ctrl_seg) +
+			sizeof(struct mlx5_wqe_datagram_seg);
+		break;
+
+	case MLX5_IB_QPT_REG_UMR:
+		size = sizeof(struct mlx5_wqe_ctrl_seg) +
+			sizeof(struct mlx5_wqe_umr_ctrl_seg) +
+			sizeof(struct mlx5_mkey_seg);
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+	return size;
+}
+
+static int calc_send_wqe(struct ib_qp_init_attr *attr)
+{
+	int inl_size = 0;
+	int size;
+
+	size = sq_overhead(attr->qp_type);
+	if (size < 0)
+		return size;
+
+	if (attr->cap.max_inline_data) {
+		inl_size = size + sizeof(struct mlx5_wqe_inline_seg) +
+			attr->cap.max_inline_data;
+	}
+
+	size += attr->cap.max_send_sge * sizeof(struct mlx5_wqe_data_seg);
+
+	return ALIGN(max_t(int, inl_size, size), MLX5_SEND_WQE_BB);
+}
+
+static int calc_sq_size(struct mlx5_ib_dev *dev, struct ib_qp_init_attr *attr,
+			struct mlx5_ib_qp *qp)
+{
+	int wqe_size;
+	int wq_size;
+
+	if (!attr->cap.max_send_wr)
+		return 0;
+
+	wqe_size = calc_send_wqe(attr);
+	mlx5_ib_dbg(dev, "wqe_size %d\n", wqe_size);
+	if (wqe_size < 0)
+		return wqe_size;
+
+	if (wqe_size > dev->mdev.caps.max_sq_desc_sz) {
+		mlx5_ib_dbg(dev, "\n");
+		return -EINVAL;
+	}
+
+	qp->max_inline_data = wqe_size - sq_overhead(attr->qp_type) -
+		sizeof(struct mlx5_wqe_inline_seg);
+	attr->cap.max_inline_data = qp->max_inline_data;
+
+	wq_size = roundup_pow_of_two(attr->cap.max_send_wr * wqe_size);
+	qp->sq.wqe_cnt = wq_size / MLX5_SEND_WQE_BB;
+	qp->sq.wqe_shift = ilog2(MLX5_SEND_WQE_BB);
+	qp->sq.max_gs = attr->cap.max_send_sge;
+	qp->sq.max_post = 1 << ilog2(wq_size / wqe_size);
+
+	return wq_size;
+}
+
+static int set_user_buf_size(struct mlx5_ib_dev *dev,
+			    struct mlx5_ib_qp *qp,
+			    struct mlx5_ib_create_qp *ucmd)
+{
+	int desc_sz = 1 << qp->sq.wqe_shift;
+
+	if (desc_sz > dev->mdev.caps.max_sq_desc_sz) {
+		mlx5_ib_warn(dev, "desc_sz %d, max_sq_desc_sz %d\n",
+			     desc_sz, dev->mdev.caps.max_sq_desc_sz);
+		return -EINVAL;
+	}
+
+	if (ucmd->sq_wqe_count && ((1 << ilog2(ucmd->sq_wqe_count)) != ucmd->sq_wqe_count)) {
+		mlx5_ib_warn(dev, "sq_wqe_count %d, sq_wqe_count %d\n",
+			     ucmd->sq_wqe_count, ucmd->sq_wqe_count);
+		return -EINVAL;
+	}
+
+	qp->sq.wqe_cnt = ucmd->sq_wqe_count;
+
+	if (qp->sq.wqe_cnt > dev->mdev.caps.max_wqes) {
+		mlx5_ib_warn(dev, "wqe_cnt %d, max_wqes %d\n",
+			     qp->sq.wqe_cnt, dev->mdev.caps.max_wqes);
+		return -EINVAL;
+	}
+
+	qp->buf_size = (qp->rq.wqe_cnt << qp->rq.wqe_shift) +
+		(qp->sq.wqe_cnt << 6);
+
+	return 0;
+}
+
+static int qp_has_rq(struct ib_qp_init_attr *attr)
+{
+	if (attr->qp_type == IB_QPT_XRC_INI ||
+	    attr->qp_type == IB_QPT_XRC_TGT || attr->srq ||
+	    attr->qp_type == MLX5_IB_QPT_REG_UMR ||
+	    !attr->cap.max_recv_wr)
+		return 0;
+
+	return 1;
+}
+
+static int alloc_high_class_uuar(struct mlx5_uuar_info *uuari)
+{
+	int nuuars = uuari->num_uars * MLX5_BF_REGS_PER_PAGE;
+	int start_uuar;
+	int i;
+
+	start_uuar = nuuars - uuari->num_low_latency_uuars;
+	for (i = start_uuar; i < nuuars; i++) {
+		if (!test_bit(i, uuari->bitmap)) {
+			set_bit(i, uuari->bitmap);
+			uuari->count[i]++;
+			return i;
+		}
+	}
+
+	return -ENOMEM;
+}
+
+static int alloc_med_class_uuar(struct mlx5_uuar_info *uuari)
+{
+	int nuuars = uuari->num_uars * MLX5_BF_REGS_PER_PAGE;
+	int minidx = 1;
+	int uuarn;
+	int end;
+	int i;
+
+	end = nuuars - uuari->num_low_latency_uuars;
+
+	for (i = 1; i < end; i++) {
+		uuarn = i & 3;
+		if (uuarn == 2 || uuarn == 3)
+			continue;
+
+		if (uuari->count[i] < uuari->count[minidx])
+			minidx = i;
+	}
+
+	uuari->count[minidx]++;
+	return minidx;
+}
+
+static int alloc_uuar(struct mlx5_uuar_info *uuari,
+		      enum mlx5_ib_latency_class lat)
+{
+	int uuarn = -EINVAL;
+
+	mutex_lock(&uuari->lock);
+	switch (lat) {
+	case MLX5_IB_LATENCY_CLASS_LOW:
+		uuarn = 0;
+		uuari->count[uuarn]++;
+		break;
+
+	case MLX5_IB_LATENCY_CLASS_MEDIUM:
+		uuarn = alloc_med_class_uuar(uuari);
+		break;
+
+	case MLX5_IB_LATENCY_CLASS_HIGH:
+		uuarn = alloc_high_class_uuar(uuari);
+		break;
+
+	case MLX5_IB_LATENCY_CLASS_FAST_PATH:
+		uuarn = 2;
+		break;
+	}
+	mutex_unlock(&uuari->lock);
+
+	return uuarn;
+}
+
+static void free_med_class_uuar(struct mlx5_uuar_info *uuari, int uuarn)
+{
+	clear_bit(uuarn, uuari->bitmap);
+	--uuari->count[uuarn];
+}
+
+static void free_high_class_uuar(struct mlx5_uuar_info *uuari, int uuarn)
+{
+	clear_bit(uuarn, uuari->bitmap);
+	--uuari->count[uuarn];
+}
+
+static void free_uuar(struct mlx5_uuar_info *uuari, int uuarn)
+{
+	int nuuars = uuari->num_uars * MLX5_BF_REGS_PER_PAGE;
+	int high_uuar = nuuars - uuari->num_low_latency_uuars;
+
+	mutex_lock(&uuari->lock);
+	if (uuarn == 0) {
+		--uuari->count[uuarn];
+		goto out;
+	}
+
+	if (uuarn < high_uuar) {
+		free_med_class_uuar(uuari, uuarn);
+		goto out;
+	}
+
+	free_high_class_uuar(uuari, uuarn);
+
+out:
+	mutex_unlock(&uuari->lock);
+}
+
+static enum mlx5_qp_state to_mlx5_state(enum ib_qp_state state)
+{
+	switch (state) {
+	case IB_QPS_RESET:	return MLX5_QP_STATE_RST;
+	case IB_QPS_INIT:	return MLX5_QP_STATE_INIT;
+	case IB_QPS_RTR:	return MLX5_QP_STATE_RTR;
+	case IB_QPS_RTS:	return MLX5_QP_STATE_RTS;
+	case IB_QPS_SQD:	return MLX5_QP_STATE_SQD;
+	case IB_QPS_SQE:	return MLX5_QP_STATE_SQER;
+	case IB_QPS_ERR:	return MLX5_QP_STATE_ERR;
+	default:		return -1;
+	}
+}
+
+static int to_mlx5_st(enum ib_qp_type type)
+{
+	switch (type) {
+	case IB_QPT_RC:			return MLX5_QP_ST_RC;
+	case IB_QPT_UC:			return MLX5_QP_ST_UC;
+	case IB_QPT_UD:			return MLX5_QP_ST_UD;
+	case MLX5_IB_QPT_REG_UMR:	return MLX5_QP_ST_REG_UMR;
+	case IB_QPT_XRC_INI:
+	case IB_QPT_XRC_TGT:		return MLX5_QP_ST_XRC;
+	case IB_QPT_SMI:		return MLX5_QP_ST_QP0;
+	case IB_QPT_GSI:		return MLX5_QP_ST_QP1;
+	case IB_QPT_RAW_IPV6:		return MLX5_QP_ST_RAW_IPV6;
+	case IB_QPT_RAW_ETHERTYPE:	return MLX5_QP_ST_RAW_ETHERTYPE;
+	case IB_QPT_RAW_PACKET:
+	case IB_QPT_MAX:
+	default:		return -EINVAL;
+	}
+}
+
+static int uuarn_to_uar_index(struct mlx5_uuar_info *uuari, int uuarn)
+{
+	return uuari->uars[uuarn / MLX5_BF_REGS_PER_PAGE].index;
+}
+
+static int create_user_qp(struct mlx5_ib_dev *dev, struct ib_pd *pd,
+			  struct mlx5_ib_qp *qp, struct ib_udata *udata,
+			  struct mlx5_create_qp_mbox_in **in,
+			  struct mlx5_ib_create_qp_resp *resp, int *inlen)
+{
+	struct mlx5_ib_ucontext *context;
+	struct mlx5_ib_create_qp ucmd;
+	int page_shift;
+	int uar_index;
+	int npages;
+	u32 offset;
+	int uuarn;
+	int ncont;
+	int err;
+
+	err = ib_copy_from_udata(&ucmd, udata, sizeof(ucmd));
+	if (err) {
+		mlx5_ib_dbg(dev, "copy failed\n");
+		return err;
+	}
+
+	context = to_mucontext(pd->uobject->context);
+	/*
+	 * TBD: should come from the verbs when we have the API
+	 */
+	uuarn = alloc_uuar(&context->uuari, MLX5_IB_LATENCY_CLASS_HIGH);
+	if (uuarn < 0) {
+		mlx5_ib_dbg(dev, "failed to allocate low latency UUAR\n");
+		mlx5_ib_dbg(dev, "reverting to high latency\n");
+		uuarn = alloc_uuar(&context->uuari, MLX5_IB_LATENCY_CLASS_LOW);
+		if (uuarn < 0) {
+			mlx5_ib_dbg(dev, "uuar allocation failed\n");
+			return uuarn;
+		}
+	}
+
+	uar_index = uuarn_to_uar_index(&context->uuari, uuarn);
+	mlx5_ib_dbg(dev, "uuarn 0x%x, uar_index 0x%x\n", uuarn, uar_index);
+
+	err = set_user_buf_size(dev, qp, &ucmd);
+	if (err)
+		goto err_uuar;
+
+	qp->umem = ib_umem_get(pd->uobject->context, ucmd.buf_addr,
+			       qp->buf_size, 0, 0);
+	if (IS_ERR(qp->umem)) {
+		mlx5_ib_dbg(dev, "umem_get failed\n");
+		err = PTR_ERR(qp->umem);
+		goto err_uuar;
+	}
+
+	mlx5_ib_cont_pages(qp->umem, ucmd.buf_addr, &npages, &page_shift,
+			   &ncont, NULL);
+	err = mlx5_ib_get_buf_offset(ucmd.buf_addr, page_shift, &offset);
+	if (err) {
+		mlx5_ib_warn(dev, "bad offset\n");
+		goto err_umem;
+	}
+	mlx5_ib_dbg(dev, "addr 0x%llx, size %d, npages %d, page_shift %d, ncont %d, offset %d\n",
+		    ucmd.buf_addr, qp->buf_size, npages, page_shift, ncont, offset);
+
+	*inlen = sizeof(**in) + sizeof(*(*in)->pas) * ncont;
+	*in = mlx5_vzalloc(*inlen);
+	if (!*in) {
+		err = -ENOMEM;
+		goto err_umem;
+	}
+	mlx5_ib_populate_pas(dev, qp->umem, page_shift, (*in)->pas, 0);
+	(*in)->ctx.log_pg_sz_remote_qpn =
+		cpu_to_be32((page_shift - PAGE_SHIFT) << 24);
+	(*in)->ctx.params2 = cpu_to_be32(offset << 6);
+
+	(*in)->ctx.qp_counter_set_usr_page = cpu_to_be32(uar_index);
+	resp->uuar_index = uuarn;
+	qp->uuarn = uuarn;
+
+	err = mlx5_ib_db_map_user(context, ucmd.db_addr, &qp->db);
+	if (err) {
+		mlx5_ib_dbg(dev, "map failed\n");
+		goto err_free;
+	}
+
+	err = ib_copy_to_udata(udata, resp, sizeof(*resp));
+	if (err) {
+		mlx5_ib_dbg(dev, "copy failed\n");
+		goto err_unmap;
+	}
+	qp->create_type = MLX5_QP_USER;
+
+	return 0;
+
+err_unmap:
+	mlx5_ib_db_unmap_user(context, &qp->db);
+
+err_free:
+	mlx5_vfree(*in);
+
+err_umem:
+	ib_umem_release(qp->umem);
+
+err_uuar:
+	free_uuar(&context->uuari, uuarn);
+	return err;
+}
+
+static void destroy_qp_user(struct ib_pd *pd, struct mlx5_ib_qp *qp)
+{
+	struct mlx5_ib_ucontext *context;
+
+	context = to_mucontext(pd->uobject->context);
+	mlx5_ib_db_unmap_user(context, &qp->db);
+	ib_umem_release(qp->umem);
+	free_uuar(&context->uuari, qp->uuarn);
+}
+
+static int create_kernel_qp(struct mlx5_ib_dev *dev,
+			    struct ib_qp_init_attr *init_attr,
+			    struct mlx5_ib_qp *qp,
+			    struct mlx5_create_qp_mbox_in **in, int *inlen)
+{
+	enum mlx5_ib_latency_class lc = MLX5_IB_LATENCY_CLASS_LOW;
+	struct mlx5_uuar_info *uuari;
+	int uar_index;
+	int uuarn;
+	int err;
+
+	uuari = &dev->mdev.priv.uuari;
+	if (init_attr->create_flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK)
+		qp->flags |= MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK;
+
+	if (init_attr->qp_type == MLX5_IB_QPT_REG_UMR)
+		lc = MLX5_IB_LATENCY_CLASS_FAST_PATH;
+
+	uuarn = alloc_uuar(uuari, lc);
+	if (uuarn < 0) {
+		mlx5_ib_dbg(dev, "\n");
+		return -ENOMEM;
+	}
+
+	qp->bf = &uuari->bfs[uuarn];
+	uar_index = qp->bf->uar->index;
+
+	err = calc_sq_size(dev, init_attr, qp);
+	if (err < 0) {
+		mlx5_ib_dbg(dev, "err %d\n", err);
+		goto err_uuar;
+	}
+
+	qp->rq.offset = 0;
+	qp->sq.offset = qp->rq.wqe_cnt << qp->rq.wqe_shift;
+	qp->buf_size = err + (qp->rq.wqe_cnt << qp->rq.wqe_shift);
+
+	err = mlx5_buf_alloc(&dev->mdev, qp->buf_size, PAGE_SIZE * 2, &qp->buf);
+	if (err) {
+		mlx5_ib_dbg(dev, "err %d\n", err);
+		goto err_uuar;
+	}
+
+	qp->sq.qend = mlx5_get_send_wqe(qp, qp->sq.wqe_cnt);
+	*inlen = sizeof(**in) + sizeof(*(*in)->pas) * qp->buf.npages;
+	*in = mlx5_vzalloc(*inlen);
+	if (!*in) {
+		err = -ENOMEM;
+		goto err_buf;
+	}
+	(*in)->ctx.qp_counter_set_usr_page = cpu_to_be32(uar_index);
+	(*in)->ctx.log_pg_sz_remote_qpn = cpu_to_be32((qp->buf.page_shift - PAGE_SHIFT) << 24);
+	/* Set "fast registration enabled" for all kernel QPs */
+	(*in)->ctx.params1 |= cpu_to_be32(1 << 11);
+	(*in)->ctx.sq_crq_size |= cpu_to_be16(1 << 4);
+
+	mlx5_fill_page_array(&qp->buf, (*in)->pas);
+
+	err = mlx5_db_alloc(&dev->mdev, &qp->db);
+	if (err) {
+		mlx5_ib_dbg(dev, "err %d\n", err);
+		goto err_free;
+	}
+
+	qp->db.db[0] = 0;
+	qp->db.db[1] = 0;
+
+	qp->sq.wrid = kmalloc(qp->sq.wqe_cnt * sizeof(*qp->sq.wrid), GFP_KERNEL);
+	qp->sq.wr_data = kmalloc(qp->sq.wqe_cnt * sizeof(*qp->sq.wr_data), GFP_KERNEL);
+	qp->rq.wrid = kmalloc(qp->rq.wqe_cnt * sizeof(*qp->rq.wrid), GFP_KERNEL);
+	qp->sq.w_list = kmalloc(qp->sq.wqe_cnt * sizeof(*qp->sq.w_list), GFP_KERNEL);
+	qp->sq.wqe_head = kmalloc(qp->sq.wqe_cnt * sizeof(*qp->sq.wqe_head), GFP_KERNEL);
+
+	if (!qp->sq.wrid || !qp->sq.wr_data || !qp->rq.wrid ||
+	    !qp->sq.w_list || !qp->sq.wqe_head) {
+		err = -ENOMEM;
+		goto err_wrid;
+	}
+	qp->create_type = MLX5_QP_KERNEL;
+
+	return 0;
+
+err_wrid:
+	mlx5_db_free(&dev->mdev, &qp->db);
+	kfree(qp->sq.wqe_head);
+	kfree(qp->sq.w_list);
+	kfree(qp->sq.wrid);
+	kfree(qp->sq.wr_data);
+	kfree(qp->rq.wrid);
+
+err_free:
+	mlx5_vfree(*in);
+
+err_buf:
+	mlx5_buf_free(&dev->mdev, &qp->buf);
+
+err_uuar:
+	free_uuar(&dev->mdev.priv.uuari, uuarn);
+	return err;
+}
+
+static void destroy_qp_kernel(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp)
+{
+	mlx5_db_free(&dev->mdev, &qp->db);
+	kfree(qp->sq.wqe_head);
+	kfree(qp->sq.w_list);
+	kfree(qp->sq.wrid);
+	kfree(qp->sq.wr_data);
+	kfree(qp->rq.wrid);
+	mlx5_buf_free(&dev->mdev, &qp->buf);
+	free_uuar(&dev->mdev.priv.uuari, qp->bf->uuarn);
+}
+
+static __be32 get_rx_type(struct mlx5_ib_qp *qp, struct ib_qp_init_attr *attr)
+{
+	if (attr->srq || (attr->qp_type == IB_QPT_XRC_TGT) ||
+	    (attr->qp_type == IB_QPT_XRC_INI))
+		return cpu_to_be32(MLX5_SRQ_RQ);
+	else if (!qp->has_rq)
+		return cpu_to_be32(MLX5_ZERO_LEN_RQ);
+	else
+		return cpu_to_be32(MLX5_NON_ZERO_RQ);
+}
+
+static int is_connected(enum ib_qp_type qp_type)
+{
+	if (qp_type == IB_QPT_RC || qp_type == IB_QPT_UC)
+		return 1;
+
+	return 0;
+}
+
+static int create_qp_common(struct mlx5_ib_dev *dev, struct ib_pd *pd,
+			    struct ib_qp_init_attr *init_attr,
+			    struct ib_udata *udata, struct mlx5_ib_qp *qp)
+{
+	struct mlx5_ib_resources *devr = &dev->devr;
+	struct mlx5_ib_create_qp_resp resp;
+	struct mlx5_create_qp_mbox_in *in;
+	struct mlx5_ib_create_qp ucmd;
+	int inlen = sizeof(*in);
+	int err;
+
+	mutex_init(&qp->mutex);
+	spin_lock_init(&qp->sq.lock);
+	spin_lock_init(&qp->rq.lock);
+
+	if (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR)
+		qp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;
+
+	if (pd && pd->uobject) {
+		if (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd))) {
+			mlx5_ib_dbg(dev, "copy failed\n");
+			return -EFAULT;
+		}
+
+		qp->wq_sig = !!(ucmd.flags & MLX5_QP_FLAG_SIGNATURE);
+		qp->scat_cqe = !!(ucmd.flags & MLX5_QP_FLAG_SCATTER_CQE);
+	} else {
+		qp->wq_sig = !!wq_signature;
+	}
+
+	qp->has_rq = qp_has_rq(init_attr);
+	err = set_rq_size(dev, &init_attr->cap, qp->has_rq,
+			  qp, (pd && pd->uobject) ? &ucmd : NULL);
+	if (err) {
+		mlx5_ib_dbg(dev, "err %d\n", err);
+		return err;
+	}
+
+	if (pd) {
+		if (pd->uobject) {
+			mlx5_ib_dbg(dev, "requested sq_wqe_count (%d)\n", ucmd.sq_wqe_count);
+			if (ucmd.rq_wqe_shift != qp->rq.wqe_shift ||
+			    ucmd.rq_wqe_count != qp->rq.wqe_cnt) {
+				mlx5_ib_dbg(dev, "invalid rq params\n");
+				return -EINVAL;
+			}
+			if (ucmd.sq_wqe_count > dev->mdev.caps.max_wqes) {
+				mlx5_ib_dbg(dev, "requested sq_wqe_count (%d) > max allowed (%d)\n",
+					    ucmd.sq_wqe_count, dev->mdev.caps.max_wqes);
+				return -EINVAL;
+			}
+			err = create_user_qp(dev, pd, qp, udata, &in, &resp, &inlen);
+			if (err)
+				mlx5_ib_dbg(dev, "err %d\n", err);
+		} else {
+			err = create_kernel_qp(dev, init_attr, qp, &in, &inlen);
+			if (err)
+				mlx5_ib_dbg(dev, "err %d\n", err);
+			else
+				qp->pa_lkey = to_mpd(pd)->pa_lkey;
+		}
+
+		if (err)
+			return err;
+	} else {
+		in = mlx5_vzalloc(sizeof(*in));
+		if (!in)
+			return -ENOMEM;
+
+		qp->create_type = MLX5_QP_EMPTY;
+	}
+
+	if (is_sqp(init_attr->qp_type))
+		qp->port = init_attr->port_num;
+
+	in->ctx.flags = cpu_to_be32(to_mlx5_st(init_attr->qp_type) << 16 |
+				    MLX5_QP_PM_MIGRATED << 11);
+
+	if (init_attr->qp_type != MLX5_IB_QPT_REG_UMR)
+		in->ctx.flags_pd = cpu_to_be32(to_mpd(pd ? pd : devr->p0)->pdn);
+	else
+		in->ctx.flags_pd = cpu_to_be32(MLX5_QP_LAT_SENSITIVE);
+
+	if (qp->wq_sig)
+		in->ctx.flags_pd |= cpu_to_be32(MLX5_QP_ENABLE_SIG);
+
+	if (qp->scat_cqe && is_connected(init_attr->qp_type)) {
+		int rcqe_sz;
+		int scqe_sz;
+
+		rcqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->recv_cq);
+		scqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->send_cq);
+
+		if (rcqe_sz == 128)
+			in->ctx.cs_res = MLX5_RES_SCAT_DATA64_CQE;
+		else
+			in->ctx.cs_res = MLX5_RES_SCAT_DATA32_CQE;
+
+		if (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR) {
+			if (scqe_sz == 128)
+				in->ctx.cs_req = MLX5_REQ_SCAT_DATA64_CQE;
+			else
+				in->ctx.cs_req = MLX5_REQ_SCAT_DATA32_CQE;
+		}
+	}
+
+	if (qp->rq.wqe_cnt) {
+		in->ctx.rq_size_stride = (qp->rq.wqe_shift - 4);
+		in->ctx.rq_size_stride |= ilog2(qp->rq.wqe_cnt) << 3;
+	}
+
+	in->ctx.rq_type_srqn = get_rx_type(qp, init_attr);
+
+	if (qp->sq.wqe_cnt)
+		in->ctx.sq_crq_size |= cpu_to_be16(ilog2(qp->sq.wqe_cnt) << 11);
+	else
+		in->ctx.sq_crq_size |= cpu_to_be16(0x8000);
+
+	/* Set default resources */
+	switch (init_attr->qp_type) {
+	case IB_QPT_XRC_TGT:
+		in->ctx.cqn_recv = cpu_to_be32(to_mcq(devr->c0)->mcq.cqn);
+		in->ctx.cqn_send = cpu_to_be32(to_mcq(devr->c0)->mcq.cqn);
+		in->ctx.rq_type_srqn |= cpu_to_be32(to_msrq(devr->s0)->msrq.srqn);
+		in->ctx.xrcd = cpu_to_be32(to_mxrcd(init_attr->xrcd)->xrcdn);
+		break;
+	case IB_QPT_XRC_INI:
+		in->ctx.cqn_recv = cpu_to_be32(to_mcq(devr->c0)->mcq.cqn);
+		in->ctx.xrcd = cpu_to_be32(to_mxrcd(devr->x1)->xrcdn);
+		in->ctx.rq_type_srqn |= cpu_to_be32(to_msrq(devr->s0)->msrq.srqn);
+		break;
+	default:
+		if (init_attr->srq) {
+			in->ctx.xrcd = cpu_to_be32(to_mxrcd(devr->x0)->xrcdn);
+			in->ctx.rq_type_srqn |= cpu_to_be32(to_msrq(init_attr->srq)->msrq.srqn);
+		} else {
+			in->ctx.xrcd = cpu_to_be32(to_mxrcd(devr->x1)->xrcdn);
+			in->ctx.rq_type_srqn |= cpu_to_be32(to_msrq(devr->s0)->msrq.srqn);
+		}
+	}
+
+	if (init_attr->send_cq)
+		in->ctx.cqn_send = cpu_to_be32(to_mcq(init_attr->send_cq)->mcq.cqn);
+
+	if (init_attr->recv_cq)
+		in->ctx.cqn_recv = cpu_to_be32(to_mcq(init_attr->recv_cq)->mcq.cqn);
+
+	in->ctx.db_rec_addr = cpu_to_be64(qp->db.dma);
+
+	err = mlx5_core_create_qp(&dev->mdev, &qp->mqp, in, inlen);
+	if (err) {
+		mlx5_ib_dbg(dev, "create qp failed\n");
+		goto err_create;
+	}
+
+	mlx5_vfree(in);
+	/* Hardware wants QPN written in big-endian order (after
+	 * shifting) for send doorbell.  Precompute this value to save
+	 * a little bit when posting sends.
+	 */
+	qp->doorbell_qpn = swab32(qp->mqp.qpn << 8);
+
+	qp->mqp.event = mlx5_ib_qp_event;
+
+	return 0;
+
+err_create:
+	if (qp->create_type == MLX5_QP_USER)
+		destroy_qp_user(pd, qp);
+	else if (qp->create_type == MLX5_QP_KERNEL)
+		destroy_qp_kernel(dev, qp);
+
+	mlx5_vfree(in);
+	return err;
+}
+
+static void mlx5_ib_lock_cqs(struct mlx5_ib_cq *send_cq, struct mlx5_ib_cq *recv_cq)
+	__acquires(&send_cq->lock) __acquires(&recv_cq->lock)
+{
+	if (send_cq) {
+		if (recv_cq) {
+			if (send_cq->mcq.cqn < recv_cq->mcq.cqn)  {
+				spin_lock_irq(&send_cq->lock);
+				spin_lock_nested(&recv_cq->lock,
+						 SINGLE_DEPTH_NESTING);
+			} else if (send_cq->mcq.cqn == recv_cq->mcq.cqn) {
+				spin_lock_irq(&send_cq->lock);
+				__acquire(&recv_cq->lock);
+			} else {
+				spin_lock_irq(&recv_cq->lock);
+				spin_lock_nested(&send_cq->lock,
+						 SINGLE_DEPTH_NESTING);
+			}
+		} else {
+			spin_lock_irq(&send_cq->lock);
+		}
+	} else if (recv_cq) {
+		spin_lock_irq(&recv_cq->lock);
+	}
+}
+
+static void mlx5_ib_unlock_cqs(struct mlx5_ib_cq *send_cq, struct mlx5_ib_cq *recv_cq)
+	__releases(&send_cq->lock) __releases(&recv_cq->lock)
+{
+	if (send_cq) {
+		if (recv_cq) {
+			if (send_cq->mcq.cqn < recv_cq->mcq.cqn)  {
+				spin_unlock(&recv_cq->lock);
+				spin_unlock_irq(&send_cq->lock);
+			} else if (send_cq->mcq.cqn == recv_cq->mcq.cqn) {
+				__release(&recv_cq->lock);
+				spin_unlock_irq(&send_cq->lock);
+			} else {
+				spin_unlock(&send_cq->lock);
+				spin_unlock_irq(&recv_cq->lock);
+			}
+		} else {
+			spin_unlock_irq(&send_cq->lock);
+		}
+	} else if (recv_cq) {
+		spin_unlock_irq(&recv_cq->lock);
+	}
+}
+
+static struct mlx5_ib_pd *get_pd(struct mlx5_ib_qp *qp)
+{
+	return to_mpd(qp->ibqp.pd);
+}
+
+static void get_cqs(struct mlx5_ib_qp *qp,
+		    struct mlx5_ib_cq **send_cq, struct mlx5_ib_cq **recv_cq)
+{
+	switch (qp->ibqp.qp_type) {
+	case IB_QPT_XRC_TGT:
+		*send_cq = NULL;
+		*recv_cq = NULL;
+		break;
+	case MLX5_IB_QPT_REG_UMR:
+	case IB_QPT_XRC_INI:
+		*send_cq = to_mcq(qp->ibqp.send_cq);
+		*recv_cq = NULL;
+		break;
+
+	case IB_QPT_SMI:
+	case IB_QPT_GSI:
+	case IB_QPT_RC:
+	case IB_QPT_UC:
+	case IB_QPT_UD:
+	case IB_QPT_RAW_IPV6:
+	case IB_QPT_RAW_ETHERTYPE:
+		*send_cq = to_mcq(qp->ibqp.send_cq);
+		*recv_cq = to_mcq(qp->ibqp.recv_cq);
+		break;
+
+	case IB_QPT_RAW_PACKET:
+	case IB_QPT_MAX:
+	default:
+		*send_cq = NULL;
+		*recv_cq = NULL;
+		break;
+	}
+}
+
+static void destroy_qp_common(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp)
+{
+	struct mlx5_ib_cq *send_cq, *recv_cq;
+	struct mlx5_modify_qp_mbox_in *in;
+	int err;
+
+	in = kzalloc(sizeof(*in), GFP_KERNEL);
+	if (!in)
+		return;
+	if (qp->state != IB_QPS_RESET)
+		if (mlx5_core_qp_modify(&dev->mdev, to_mlx5_state(qp->state),
+					MLX5_QP_STATE_RST, in, sizeof(*in), &qp->mqp))
+			mlx5_ib_warn(dev, "mlx5_ib: modify QP %06x to RESET failed\n",
+				     qp->mqp.qpn);
+
+	get_cqs(qp, &send_cq, &recv_cq);
+
+	if (qp->create_type == MLX5_QP_KERNEL) {
+		mlx5_ib_lock_cqs(send_cq, recv_cq);
+		__mlx5_ib_cq_clean(recv_cq, qp->mqp.qpn,
+				   qp->ibqp.srq ? to_msrq(qp->ibqp.srq) : NULL);
+		if (send_cq != recv_cq)
+			__mlx5_ib_cq_clean(send_cq, qp->mqp.qpn, NULL);
+		mlx5_ib_unlock_cqs(send_cq, recv_cq);
+	}
+
+	err = mlx5_core_destroy_qp(&dev->mdev, &qp->mqp);
+	if (err)
+		mlx5_ib_warn(dev, "failed to destroy QP 0x%x\n", qp->mqp.qpn);
+	kfree(in);
+
+
+	if (qp->create_type == MLX5_QP_KERNEL)
+		destroy_qp_kernel(dev, qp);
+	else if (qp->create_type == MLX5_QP_USER)
+		destroy_qp_user(&get_pd(qp)->ibpd, qp);
+}
+
+static const char *ib_qp_type_str(enum ib_qp_type type)
+{
+	switch (type) {
+	case IB_QPT_SMI:
+		return "IB_QPT_SMI";
+	case IB_QPT_GSI:
+		return "IB_QPT_GSI";
+	case IB_QPT_RC:
+		return "IB_QPT_RC";
+	case IB_QPT_UC:
+		return "IB_QPT_UC";
+	case IB_QPT_UD:
+		return "IB_QPT_UD";
+	case IB_QPT_RAW_IPV6:
+		return "IB_QPT_RAW_IPV6";
+	case IB_QPT_RAW_ETHERTYPE:
+		return "IB_QPT_RAW_ETHERTYPE";
+	case IB_QPT_XRC_INI:
+		return "IB_QPT_XRC_INI";
+	case IB_QPT_XRC_TGT:
+		return "IB_QPT_XRC_TGT";
+	case IB_QPT_RAW_PACKET:
+		return "IB_QPT_RAW_PACKET";
+	case MLX5_IB_QPT_REG_UMR:
+		return "MLX5_IB_QPT_REG_UMR";
+	case IB_QPT_MAX:
+	default:
+		return "Invalid QP type";
+	}
+}
+
+struct ib_qp *mlx5_ib_create_qp(struct ib_pd *pd,
+				struct ib_qp_init_attr *init_attr,
+				struct ib_udata *udata)
+{
+	struct mlx5_ib_dev *dev;
+	struct mlx5_ib_qp *qp;
+	u16 xrcdn = 0;
+	int err;
+
+	if (pd) {
+		dev = to_mdev(pd->device);
+	} else {
+		/* being cautious here */
+		if (init_attr->qp_type != IB_QPT_XRC_TGT &&
+		    init_attr->qp_type != MLX5_IB_QPT_REG_UMR) {
+			pr_warn("%s: no PD for transport %s\n", __func__,
+				ib_qp_type_str(init_attr->qp_type));
+			return ERR_PTR(-EINVAL);
+		}
+		dev = to_mdev(to_mxrcd(init_attr->xrcd)->ibxrcd.device);
+	}
+
+	switch (init_attr->qp_type) {
+	case IB_QPT_XRC_TGT:
+	case IB_QPT_XRC_INI:
+		if (!(dev->mdev.caps.flags & MLX5_DEV_CAP_FLAG_XRC)) {
+			mlx5_ib_dbg(dev, "XRC not supported\n");
+			return ERR_PTR(-ENOSYS);
+		}
+		init_attr->recv_cq = NULL;
+		if (init_attr->qp_type == IB_QPT_XRC_TGT) {
+			xrcdn = to_mxrcd(init_attr->xrcd)->xrcdn;
+			init_attr->send_cq = NULL;
+		}
+
+		/* fall through */
+	case IB_QPT_RC:
+	case IB_QPT_UC:
+	case IB_QPT_UD:
+	case IB_QPT_SMI:
+	case IB_QPT_GSI:
+	case MLX5_IB_QPT_REG_UMR:
+		qp = kzalloc(sizeof(*qp), GFP_KERNEL);
+		if (!qp)
+			return ERR_PTR(-ENOMEM);
+
+		err = create_qp_common(dev, pd, init_attr, udata, qp);
+		if (err) {
+			mlx5_ib_dbg(dev, "create_qp_common failed\n");
+			kfree(qp);
+			return ERR_PTR(err);
+		}
+
+		if (is_qp0(init_attr->qp_type))
+			qp->ibqp.qp_num = 0;
+		else if (is_qp1(init_attr->qp_type))
+			qp->ibqp.qp_num = 1;
+		else
+			qp->ibqp.qp_num = qp->mqp.qpn;
+
+		mlx5_ib_dbg(dev, "ib qpnum 0x%x, mlx qpn 0x%x, rcqn 0x%x, scqn 0x%x\n",
+			    qp->ibqp.qp_num, qp->mqp.qpn, to_mcq(init_attr->recv_cq)->mcq.cqn,
+			    to_mcq(init_attr->send_cq)->mcq.cqn);
+
+		qp->xrcdn = xrcdn;
+
+		break;
+
+	case IB_QPT_RAW_IPV6:
+	case IB_QPT_RAW_ETHERTYPE:
+	case IB_QPT_RAW_PACKET:
+	case IB_QPT_MAX:
+	default:
+		mlx5_ib_dbg(dev, "unsupported qp type %d\n",
+			    init_attr->qp_type);
+		/* Don't support raw QPs */
+		return ERR_PTR(-EINVAL);
+	}
+
+	return &qp->ibqp;
+}
+
+int mlx5_ib_destroy_qp(struct ib_qp *qp)
+{
+	struct mlx5_ib_dev *dev = to_mdev(qp->device);
+	struct mlx5_ib_qp *mqp = to_mqp(qp);
+
+	destroy_qp_common(dev, mqp);
+
+	kfree(mqp);
+
+	return 0;
+}
+
+static __be32 to_mlx5_access_flags(struct mlx5_ib_qp *qp, const struct ib_qp_attr *attr,
+				   int attr_mask)
+{
+	u32 hw_access_flags = 0;
+	u8 dest_rd_atomic;
+	u32 access_flags;
+
+	if (attr_mask & IB_QP_MAX_DEST_RD_ATOMIC)
+		dest_rd_atomic = attr->max_dest_rd_atomic;
+	else
+		dest_rd_atomic = qp->resp_depth;
+
+	if (attr_mask & IB_QP_ACCESS_FLAGS)
+		access_flags = attr->qp_access_flags;
+	else
+		access_flags = qp->atomic_rd_en;
+
+	if (!dest_rd_atomic)
+		access_flags &= IB_ACCESS_REMOTE_WRITE;
+
+	if (access_flags & IB_ACCESS_REMOTE_READ)
+		hw_access_flags |= MLX5_QP_BIT_RRE;
+	if (access_flags & IB_ACCESS_REMOTE_ATOMIC)
+		hw_access_flags |= (MLX5_QP_BIT_RAE | MLX5_ATOMIC_MODE_CX);
+	if (access_flags & IB_ACCESS_REMOTE_WRITE)
+		hw_access_flags |= MLX5_QP_BIT_RWE;
+
+	return cpu_to_be32(hw_access_flags);
+}
+
+enum {
+	MLX5_PATH_FLAG_FL	= 1 << 0,
+	MLX5_PATH_FLAG_FREE_AR	= 1 << 1,
+	MLX5_PATH_FLAG_COUNTER	= 1 << 2,
+};
+
+static int ib_rate_to_mlx5(struct mlx5_ib_dev *dev, u8 rate)
+{
+	if (rate == IB_RATE_PORT_CURRENT) {
+		return 0;
+	} else if (rate < IB_RATE_2_5_GBPS || rate > IB_RATE_300_GBPS) {
+		return -EINVAL;
+	} else {
+		while (rate != IB_RATE_2_5_GBPS &&
+		       !(1 << (rate + MLX5_STAT_RATE_OFFSET) &
+			 dev->mdev.caps.stat_rate_support))
+			--rate;
+	}
+
+	return rate + MLX5_STAT_RATE_OFFSET;
+}
+
+static int mlx5_set_path(struct mlx5_ib_dev *dev, const struct ib_ah_attr *ah,
+			 struct mlx5_qp_path *path, u8 port, int attr_mask,
+			 u32 path_flags, const struct ib_qp_attr *attr)
+{
+	int err;
+
+	path->fl = (path_flags & MLX5_PATH_FLAG_FL) ? 0x80 : 0;
+	path->free_ar = (path_flags & MLX5_PATH_FLAG_FREE_AR) ? 0x80 : 0;
+
+	if (attr_mask & IB_QP_PKEY_INDEX)
+		path->pkey_index = attr->pkey_index;
+
+	path->grh_mlid	= ah->src_path_bits & 0x7f;
+	path->rlid	= cpu_to_be16(ah->dlid);
+
+	if (ah->ah_flags & IB_AH_GRH) {
+		path->grh_mlid |= 1 << 7;
+		path->mgid_index = ah->grh.sgid_index;
+		path->hop_limit  = ah->grh.hop_limit;
+		path->tclass_flowlabel =
+			cpu_to_be32((ah->grh.traffic_class << 20) |
+				    (ah->grh.flow_label));
+		memcpy(path->rgid, ah->grh.dgid.raw, 16);
+	}
+
+	err = ib_rate_to_mlx5(dev, ah->static_rate);
+	if (err < 0)
+		return err;
+	path->static_rate = err;
+	path->port = port;
+
+	if (ah->ah_flags & IB_AH_GRH) {
+		if (ah->grh.sgid_index >= dev->mdev.caps.port[port - 1].gid_table_len) {
+			pr_err(KERN_ERR "sgid_index (%u) too large. max is %d\n",
+			       ah->grh.sgid_index, dev->mdev.caps.port[port - 1].gid_table_len);
+			return -EINVAL;
+		}
+
+		path->grh_mlid |= 1 << 7;
+		path->mgid_index = ah->grh.sgid_index;
+		path->hop_limit  = ah->grh.hop_limit;
+		path->tclass_flowlabel =
+			cpu_to_be32((ah->grh.traffic_class << 20) |
+				    (ah->grh.flow_label));
+		memcpy(path->rgid, ah->grh.dgid.raw, 16);
+	}
+
+	if (attr_mask & IB_QP_TIMEOUT)
+		path->ackto_lt = attr->timeout << 3;
+
+	path->sl = ah->sl & 0xf;
+
+	return 0;
+}
+
+static enum mlx5_qp_optpar opt_mask[MLX5_QP_NUM_STATE][MLX5_QP_NUM_STATE][MLX5_QP_ST_MAX] = {
+	[MLX5_QP_STATE_INIT] = {
+		[MLX5_QP_STATE_INIT] = {
+			[MLX5_QP_ST_RC] = MLX5_QP_OPTPAR_RRE		|
+					  MLX5_QP_OPTPAR_RAE		|
+					  MLX5_QP_OPTPAR_RWE		|
+					  MLX5_QP_OPTPAR_PKEY_INDEX	|
+					  MLX5_QP_OPTPAR_PRI_PORT,
+			[MLX5_QP_ST_UC] = MLX5_QP_OPTPAR_RWE		|
+					  MLX5_QP_OPTPAR_PKEY_INDEX	|
+					  MLX5_QP_OPTPAR_PRI_PORT,
+			[MLX5_QP_ST_UD] = MLX5_QP_OPTPAR_PKEY_INDEX	|
+					  MLX5_QP_OPTPAR_Q_KEY		|
+					  MLX5_QP_OPTPAR_PRI_PORT,
+		},
+		[MLX5_QP_STATE_RTR] = {
+			[MLX5_QP_ST_RC] = MLX5_QP_OPTPAR_ALT_ADDR_PATH  |
+					  MLX5_QP_OPTPAR_RRE            |
+					  MLX5_QP_OPTPAR_RAE            |
+					  MLX5_QP_OPTPAR_RWE            |
+					  MLX5_QP_OPTPAR_PKEY_INDEX,
+			[MLX5_QP_ST_UC] = MLX5_QP_OPTPAR_ALT_ADDR_PATH  |
+					  MLX5_QP_OPTPAR_RWE            |
+					  MLX5_QP_OPTPAR_PKEY_INDEX,
+			[MLX5_QP_ST_UD] = MLX5_QP_OPTPAR_PKEY_INDEX     |
+					  MLX5_QP_OPTPAR_Q_KEY,
+			[MLX5_QP_ST_MLX] = MLX5_QP_OPTPAR_PKEY_INDEX	|
+					   MLX5_QP_OPTPAR_Q_KEY,
+		},
+	},
+	[MLX5_QP_STATE_RTR] = {
+		[MLX5_QP_STATE_RTS] = {
+			[MLX5_QP_ST_RC] = MLX5_QP_OPTPAR_ALT_ADDR_PATH	|
+					  MLX5_QP_OPTPAR_RRE		|
+					  MLX5_QP_OPTPAR_RAE		|
+					  MLX5_QP_OPTPAR_RWE		|
+					  MLX5_QP_OPTPAR_PM_STATE	|
+					  MLX5_QP_OPTPAR_RNR_TIMEOUT,
+			[MLX5_QP_ST_UC] = MLX5_QP_OPTPAR_ALT_ADDR_PATH	|
+					  MLX5_QP_OPTPAR_RWE		|
+					  MLX5_QP_OPTPAR_PM_STATE,
+			[MLX5_QP_ST_UD] = MLX5_QP_OPTPAR_Q_KEY,
+		},
+	},
+	[MLX5_QP_STATE_RTS] = {
+		[MLX5_QP_STATE_RTS] = {
+			[MLX5_QP_ST_RC] = MLX5_QP_OPTPAR_RRE		|
+					  MLX5_QP_OPTPAR_RAE		|
+					  MLX5_QP_OPTPAR_RWE		|
+					  MLX5_QP_OPTPAR_RNR_TIMEOUT	|
+					  MLX5_QP_OPTPAR_PM_STATE,
+			[MLX5_QP_ST_UC] = MLX5_QP_OPTPAR_RWE		|
+					  MLX5_QP_OPTPAR_PM_STATE,
+			[MLX5_QP_ST_UD] = MLX5_QP_OPTPAR_Q_KEY		|
+					  MLX5_QP_OPTPAR_SRQN		|
+					  MLX5_QP_OPTPAR_CQN_RCV,
+		},
+	},
+	[MLX5_QP_STATE_SQER] = {
+		[MLX5_QP_STATE_RTS] = {
+			[MLX5_QP_ST_UD]	 = MLX5_QP_OPTPAR_Q_KEY,
+			[MLX5_QP_ST_MLX] = MLX5_QP_OPTPAR_Q_KEY,
+		},
+	},
+};
+
+static int ib_nr_to_mlx5_nr(int ib_mask)
+{
+	switch (ib_mask) {
+	case IB_QP_STATE:
+		return 0;
+	case IB_QP_CUR_STATE:
+		return 0;
+	case IB_QP_EN_SQD_ASYNC_NOTIFY:
+		return 0;
+	case IB_QP_ACCESS_FLAGS:
+		return MLX5_QP_OPTPAR_RWE | MLX5_QP_OPTPAR_RRE |
+			MLX5_QP_OPTPAR_RAE;
+	case IB_QP_PKEY_INDEX:
+		return MLX5_QP_OPTPAR_PKEY_INDEX;
+	case IB_QP_PORT:
+		return MLX5_QP_OPTPAR_PRI_PORT;
+	case IB_QP_QKEY:
+		return MLX5_QP_OPTPAR_Q_KEY;
+	case IB_QP_AV:
+		return MLX5_QP_OPTPAR_PRIMARY_ADDR_PATH |
+			MLX5_QP_OPTPAR_PRI_PORT;
+	case IB_QP_PATH_MTU:
+		return 0;
+	case IB_QP_TIMEOUT:
+		return MLX5_QP_OPTPAR_ACK_TIMEOUT;
+	case IB_QP_RETRY_CNT:
+		return MLX5_QP_OPTPAR_RETRY_COUNT;
+	case IB_QP_RNR_RETRY:
+		return MLX5_QP_OPTPAR_RNR_RETRY;
+	case IB_QP_RQ_PSN:
+		return 0;
+	case IB_QP_MAX_QP_RD_ATOMIC:
+		return MLX5_QP_OPTPAR_SRA_MAX;
+	case IB_QP_ALT_PATH:
+		return MLX5_QP_OPTPAR_ALT_ADDR_PATH;
+	case IB_QP_MIN_RNR_TIMER:
+		return MLX5_QP_OPTPAR_RNR_TIMEOUT;
+	case IB_QP_SQ_PSN:
+		return 0;
+	case IB_QP_MAX_DEST_RD_ATOMIC:
+		return MLX5_QP_OPTPAR_RRA_MAX | MLX5_QP_OPTPAR_RWE |
+			MLX5_QP_OPTPAR_RRE | MLX5_QP_OPTPAR_RAE;
+	case IB_QP_PATH_MIG_STATE:
+		return MLX5_QP_OPTPAR_PM_STATE;
+	case IB_QP_CAP:
+		return 0;
+	case IB_QP_DEST_QPN:
+		return 0;
+	}
+	return 0;
+}
+
+static int ib_mask_to_mlx5_opt(int ib_mask)
+{
+	int result = 0;
+	int i;
+
+	for (i = 0; i < 8 * sizeof(int); i++) {
+		if ((1 << i) & ib_mask)
+			result |= ib_nr_to_mlx5_nr(1 << i);
+	}
+
+	return result;
+}
+
+static int __mlx5_ib_modify_qp(struct ib_qp *ibqp,
+			       const struct ib_qp_attr *attr, int attr_mask,
+			       enum ib_qp_state cur_state, enum ib_qp_state new_state)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibqp->device);
+	struct mlx5_ib_qp *qp = to_mqp(ibqp);
+	struct mlx5_ib_cq *send_cq, *recv_cq;
+	struct mlx5_qp_context *context;
+	struct mlx5_modify_qp_mbox_in *in;
+	struct mlx5_ib_pd *pd;
+	enum mlx5_qp_state mlx5_cur, mlx5_new;
+	enum mlx5_qp_optpar optpar;
+	int sqd_event;
+	int mlx5_st;
+	int err;
+
+	in = kzalloc(sizeof(*in), GFP_KERNEL);
+	if (!in)
+		return -ENOMEM;
+
+	context = &in->ctx;
+	err = to_mlx5_st(ibqp->qp_type);
+	if (err < 0)
+		goto out;
+
+	context->flags = cpu_to_be32(err << 16);
+
+	if (!(attr_mask & IB_QP_PATH_MIG_STATE)) {
+		context->flags |= cpu_to_be32(MLX5_QP_PM_MIGRATED << 11);
+	} else {
+		switch (attr->path_mig_state) {
+		case IB_MIG_MIGRATED:
+			context->flags |= cpu_to_be32(MLX5_QP_PM_MIGRATED << 11);
+			break;
+		case IB_MIG_REARM:
+			context->flags |= cpu_to_be32(MLX5_QP_PM_REARM << 11);
+			break;
+		case IB_MIG_ARMED:
+			context->flags |= cpu_to_be32(MLX5_QP_PM_ARMED << 11);
+			break;
+		}
+	}
+
+	if (ibqp->qp_type == IB_QPT_GSI || ibqp->qp_type == IB_QPT_SMI) {
+		context->mtu_msgmax = (IB_MTU_256 << 5) | 8;
+	} else if (ibqp->qp_type == IB_QPT_UD ||
+		   ibqp->qp_type == MLX5_IB_QPT_REG_UMR) {
+		context->mtu_msgmax = (IB_MTU_4096 << 5) | 12;
+	} else if (attr_mask & IB_QP_PATH_MTU) {
+		if (attr->path_mtu < IB_MTU_256 ||
+		    attr->path_mtu > IB_MTU_4096) {
+			mlx5_ib_warn(dev, "invalid mtu %d\n", attr->path_mtu);
+			err = -EINVAL;
+			goto out;
+		}
+		context->mtu_msgmax = (attr->path_mtu << 5) | dev->mdev.caps.log_max_msg;
+	}
+
+	if (attr_mask & IB_QP_DEST_QPN)
+		context->log_pg_sz_remote_qpn = cpu_to_be32(attr->dest_qp_num);
+
+	if (attr_mask & IB_QP_PKEY_INDEX)
+		context->pri_path.pkey_index = attr->pkey_index;
+
+	/* todo implement counter_index functionality */
+
+	if (is_sqp(ibqp->qp_type))
+		context->pri_path.port = qp->port;
+
+	if (attr_mask & IB_QP_PORT)
+		context->pri_path.port = attr->port_num;
+
+	if (attr_mask & IB_QP_AV) {
+		err = mlx5_set_path(dev, &attr->ah_attr, &context->pri_path,
+				    attr_mask & IB_QP_PORT ? attr->port_num : qp->port,
+				    attr_mask, 0, attr);
+		if (err)
+			goto out;
+	}
+
+	if (attr_mask & IB_QP_TIMEOUT)
+		context->pri_path.ackto_lt |= attr->timeout << 3;
+
+	if (attr_mask & IB_QP_ALT_PATH) {
+		err = mlx5_set_path(dev, &attr->alt_ah_attr, &context->alt_path,
+				    attr->alt_port_num, attr_mask, 0, attr);
+		if (err)
+			goto out;
+	}
+
+	pd = get_pd(qp);
+	get_cqs(qp, &send_cq, &recv_cq);
+
+	context->flags_pd = cpu_to_be32(pd ? pd->pdn : to_mpd(dev->devr.p0)->pdn);
+	context->cqn_send = send_cq ? cpu_to_be32(send_cq->mcq.cqn) : 0;
+	context->cqn_recv = recv_cq ? cpu_to_be32(recv_cq->mcq.cqn) : 0;
+	context->params1  = cpu_to_be32(MLX5_IB_ACK_REQ_FREQ << 28);
+
+	if (attr_mask & IB_QP_RNR_RETRY)
+		context->params1 |= cpu_to_be32(attr->rnr_retry << 13);
+
+	if (attr_mask & IB_QP_RETRY_CNT)
+		context->params1 |= cpu_to_be32(attr->retry_cnt << 16);
+
+	if (attr_mask & IB_QP_MAX_QP_RD_ATOMIC) {
+		if (attr->max_rd_atomic)
+			context->params1 |=
+				cpu_to_be32(fls(attr->max_rd_atomic - 1) << 21);
+	}
+
+	if (attr_mask & IB_QP_SQ_PSN)
+		context->next_send_psn = cpu_to_be32(attr->sq_psn);
+
+	if (attr_mask & IB_QP_MAX_DEST_RD_ATOMIC) {
+		if (attr->max_dest_rd_atomic)
+			context->params2 |=
+				cpu_to_be32(fls(attr->max_dest_rd_atomic - 1) << 21);
+	}
+
+	if (attr_mask & (IB_QP_ACCESS_FLAGS | IB_QP_MAX_DEST_RD_ATOMIC))
+		context->params2 |= to_mlx5_access_flags(qp, attr, attr_mask);
+
+	if (attr_mask & IB_QP_MIN_RNR_TIMER)
+		context->rnr_nextrecvpsn |= cpu_to_be32(attr->min_rnr_timer << 24);
+
+	if (attr_mask & IB_QP_RQ_PSN)
+		context->rnr_nextrecvpsn |= cpu_to_be32(attr->rq_psn);
+
+	if (attr_mask & IB_QP_QKEY)
+		context->qkey = cpu_to_be32(attr->qkey);
+
+	if (qp->rq.wqe_cnt && cur_state == IB_QPS_RESET && new_state == IB_QPS_INIT)
+		context->db_rec_addr = cpu_to_be64(qp->db.dma);
+
+	if (cur_state == IB_QPS_RTS && new_state == IB_QPS_SQD	&&
+	    attr_mask & IB_QP_EN_SQD_ASYNC_NOTIFY && attr->en_sqd_async_notify)
+		sqd_event = 1;
+	else
+		sqd_event = 0;
+
+	if (!ibqp->uobject && cur_state == IB_QPS_RESET && new_state == IB_QPS_INIT)
+		context->sq_crq_size |= cpu_to_be16(1 << 4);
+
+
+	mlx5_cur = to_mlx5_state(cur_state);
+	mlx5_new = to_mlx5_state(new_state);
+	mlx5_st = to_mlx5_st(ibqp->qp_type);
+	if (mlx5_cur < 0 || mlx5_new < 0 || mlx5_st < 0)
+		goto out;
+
+	optpar = ib_mask_to_mlx5_opt(attr_mask);
+	optpar &= opt_mask[mlx5_cur][mlx5_new][mlx5_st];
+	in->optparam = cpu_to_be32(optpar);
+	err = mlx5_core_qp_modify(&dev->mdev, to_mlx5_state(cur_state),
+				  to_mlx5_state(new_state), in, sqd_event,
+				  &qp->mqp);
+	if (err)
+		goto out;
+
+	qp->state = new_state;
+
+	if (attr_mask & IB_QP_ACCESS_FLAGS)
+		qp->atomic_rd_en = attr->qp_access_flags;
+	if (attr_mask & IB_QP_MAX_DEST_RD_ATOMIC)
+		qp->resp_depth = attr->max_dest_rd_atomic;
+	if (attr_mask & IB_QP_PORT)
+		qp->port = attr->port_num;
+	if (attr_mask & IB_QP_ALT_PATH)
+		qp->alt_port = attr->alt_port_num;
+
+	/*
+	 * If we moved a kernel QP to RESET, clean up all old CQ
+	 * entries and reinitialize the QP.
+	 */
+	if (new_state == IB_QPS_RESET && !ibqp->uobject) {
+		mlx5_ib_cq_clean(recv_cq, qp->mqp.qpn,
+				 ibqp->srq ? to_msrq(ibqp->srq) : NULL);
+		if (send_cq != recv_cq)
+			mlx5_ib_cq_clean(send_cq, qp->mqp.qpn, NULL);
+
+		qp->rq.head = 0;
+		qp->rq.tail = 0;
+		qp->sq.head = 0;
+		qp->sq.tail = 0;
+		qp->sq.cur_post = 0;
+		qp->sq.last_poll = 0;
+		qp->db.db[MLX5_RCV_DBR] = 0;
+		qp->db.db[MLX5_SND_DBR] = 0;
+	}
+
+out:
+	kfree(in);
+	return err;
+}
+
+int mlx5_ib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
+		      int attr_mask, struct ib_udata *udata)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibqp->device);
+	struct mlx5_ib_qp *qp = to_mqp(ibqp);
+	enum ib_qp_state cur_state, new_state;
+	int err = -EINVAL;
+	int port;
+
+	mutex_lock(&qp->mutex);
+
+	cur_state = attr_mask & IB_QP_CUR_STATE ? attr->cur_qp_state : qp->state;
+	new_state = attr_mask & IB_QP_STATE ? attr->qp_state : cur_state;
+
+	if (ibqp->qp_type != MLX5_IB_QPT_REG_UMR &&
+	    !ib_modify_qp_is_ok(cur_state, new_state, ibqp->qp_type, attr_mask))
+		goto out;
+
+	if ((attr_mask & IB_QP_PORT) &&
+	    (attr->port_num == 0 || attr->port_num > dev->mdev.caps.num_ports))
+		goto out;
+
+	if (attr_mask & IB_QP_PKEY_INDEX) {
+		port = attr_mask & IB_QP_PORT ? attr->port_num : qp->port;
+		if (attr->pkey_index >= dev->mdev.caps.port[port - 1].pkey_table_len)
+			goto out;
+	}
+
+	if (attr_mask & IB_QP_MAX_QP_RD_ATOMIC &&
+	    attr->max_rd_atomic > dev->mdev.caps.max_ra_res_qp)
+		goto out;
+
+	if (attr_mask & IB_QP_MAX_DEST_RD_ATOMIC &&
+	    attr->max_dest_rd_atomic > dev->mdev.caps.max_ra_req_qp)
+		goto out;
+
+	if (cur_state == new_state && cur_state == IB_QPS_RESET) {
+		err = 0;
+		goto out;
+	}
+
+	err = __mlx5_ib_modify_qp(ibqp, attr, attr_mask, cur_state, new_state);
+
+out:
+	mutex_unlock(&qp->mutex);
+	return err;
+}
+
+static int mlx5_wq_overflow(struct mlx5_ib_wq *wq, int nreq, struct ib_cq *ib_cq)
+{
+	struct mlx5_ib_cq *cq;
+	unsigned cur;
+
+	cur = wq->head - wq->tail;
+	if (likely(cur + nreq < wq->max_post))
+		return 0;
+
+	cq = to_mcq(ib_cq);
+	spin_lock(&cq->lock);
+	cur = wq->head - wq->tail;
+	spin_unlock(&cq->lock);
+
+	return cur + nreq >= wq->max_post;
+}
+
+static __always_inline void set_raddr_seg(struct mlx5_wqe_raddr_seg *rseg,
+					  u64 remote_addr, u32 rkey)
+{
+	rseg->raddr    = cpu_to_be64(remote_addr);
+	rseg->rkey     = cpu_to_be32(rkey);
+	rseg->reserved = 0;
+}
+
+static void set_atomic_seg(struct mlx5_wqe_atomic_seg *aseg, struct ib_send_wr *wr)
+{
+	if (wr->opcode == IB_WR_ATOMIC_CMP_AND_SWP) {
+		aseg->swap_add = cpu_to_be64(wr->wr.atomic.swap);
+		aseg->compare  = cpu_to_be64(wr->wr.atomic.compare_add);
+	} else if (wr->opcode == IB_WR_MASKED_ATOMIC_FETCH_AND_ADD) {
+		aseg->swap_add = cpu_to_be64(wr->wr.atomic.compare_add);
+		aseg->compare  = cpu_to_be64(wr->wr.atomic.compare_add_mask);
+	} else {
+		aseg->swap_add = cpu_to_be64(wr->wr.atomic.compare_add);
+		aseg->compare  = 0;
+	}
+}
+
+static void set_masked_atomic_seg(struct mlx5_wqe_masked_atomic_seg *aseg,
+				  struct ib_send_wr *wr)
+{
+	aseg->swap_add		= cpu_to_be64(wr->wr.atomic.swap);
+	aseg->swap_add_mask	= cpu_to_be64(wr->wr.atomic.swap_mask);
+	aseg->compare		= cpu_to_be64(wr->wr.atomic.compare_add);
+	aseg->compare_mask	= cpu_to_be64(wr->wr.atomic.compare_add_mask);
+}
+
+static void set_datagram_seg(struct mlx5_wqe_datagram_seg *dseg,
+			     struct ib_send_wr *wr)
+{
+	memcpy(&dseg->av, &to_mah(wr->wr.ud.ah)->av, sizeof(struct mlx5_av));
+	dseg->av.dqp_dct = cpu_to_be32(wr->wr.ud.remote_qpn | MLX5_EXTENDED_UD_AV);
+	dseg->av.key.qkey.qkey = cpu_to_be32(wr->wr.ud.remote_qkey);
+}
+
+static void set_data_ptr_seg(struct mlx5_wqe_data_seg *dseg, struct ib_sge *sg)
+{
+	dseg->byte_count = cpu_to_be32(sg->length);
+	dseg->lkey       = cpu_to_be32(sg->lkey);
+	dseg->addr       = cpu_to_be64(sg->addr);
+}
+
+static __be16 get_klm_octo(int npages)
+{
+	return cpu_to_be16(ALIGN(npages, 8) / 2);
+}
+
+static __be64 frwr_mkey_mask(void)
+{
+	u64 result;
+
+	result = MLX5_MKEY_MASK_LEN		|
+		MLX5_MKEY_MASK_PAGE_SIZE	|
+		MLX5_MKEY_MASK_START_ADDR	|
+		MLX5_MKEY_MASK_EN_RINVAL	|
+		MLX5_MKEY_MASK_KEY		|
+		MLX5_MKEY_MASK_LR		|
+		MLX5_MKEY_MASK_LW		|
+		MLX5_MKEY_MASK_RR		|
+		MLX5_MKEY_MASK_RW		|
+		MLX5_MKEY_MASK_A		|
+		MLX5_MKEY_MASK_SMALL_FENCE	|
+		MLX5_MKEY_MASK_FREE;
+
+	return cpu_to_be64(result);
+}
+
+static void set_frwr_umr_segment(struct mlx5_wqe_umr_ctrl_seg *umr,
+				 struct ib_send_wr *wr, int li)
+{
+	memset(umr, 0, sizeof(*umr));
+
+	if (li) {
+		umr->mkey_mask = cpu_to_be64(MLX5_MKEY_MASK_FREE);
+		umr->flags = 1 << 7;
+		return;
+	}
+
+	umr->flags = (1 << 5); /* fail if not free */
+	umr->klm_octowords = get_klm_octo(wr->wr.fast_reg.page_list_len);
+	umr->mkey_mask = frwr_mkey_mask();
+}
+
+static void set_reg_umr_segment(struct mlx5_wqe_umr_ctrl_seg *umr,
+				struct ib_send_wr *wr)
+{
+	struct umr_wr *umrwr = (struct umr_wr *)&wr->wr.fast_reg;
+	u64 mask;
+
+	memset(umr, 0, sizeof(*umr));
+
+	if (!(wr->send_flags & MLX5_IB_SEND_UMR_UNREG)) {
+		umr->flags = 1 << 5; /* fail if not free */
+		umr->klm_octowords = get_klm_octo(umrwr->npages);
+		mask =  MLX5_MKEY_MASK_LEN		|
+			MLX5_MKEY_MASK_PAGE_SIZE	|
+			MLX5_MKEY_MASK_START_ADDR	|
+			MLX5_MKEY_MASK_PD		|
+			MLX5_MKEY_MASK_LR		|
+			MLX5_MKEY_MASK_LW		|
+			MLX5_MKEY_MASK_RR		|
+			MLX5_MKEY_MASK_RW		|
+			MLX5_MKEY_MASK_A		|
+			MLX5_MKEY_MASK_FREE;
+		umr->mkey_mask = cpu_to_be64(mask);
+	} else {
+		umr->flags = 2 << 5; /* fail if free */
+		mask = MLX5_MKEY_MASK_FREE;
+		umr->mkey_mask = cpu_to_be64(mask);
+	}
+
+	if (!wr->num_sge)
+		umr->flags |= (1 << 7); /* inline */
+}
+
+static u8 get_umr_flags(int acc)
+{
+	return (acc & IB_ACCESS_REMOTE_ATOMIC ? MLX5_PERM_ATOMIC       : 0) |
+	       (acc & IB_ACCESS_REMOTE_WRITE  ? MLX5_PERM_REMOTE_WRITE : 0) |
+	       (acc & IB_ACCESS_REMOTE_READ   ? MLX5_PERM_REMOTE_READ  : 0) |
+	       (acc & IB_ACCESS_LOCAL_WRITE   ? MLX5_PERM_LOCAL_WRITE  : 0) |
+		MLX5_PERM_LOCAL_READ | MLX5_PERM_UMR_EN | MLX5_ACCESS_MODE_MTT;
+}
+
+static void set_mkey_segment(struct mlx5_mkey_seg *seg, struct ib_send_wr *wr,
+			     int li, int *writ)
+{
+	memset(seg, 0, sizeof(*seg));
+	if (li) {
+		seg->status = 1 << 6;
+		return;
+	}
+
+	seg->flags = get_umr_flags(wr->wr.fast_reg.access_flags);
+	*writ = seg->flags & (MLX5_PERM_LOCAL_WRITE | IB_ACCESS_REMOTE_WRITE);
+	seg->qpn_mkey7_0 = cpu_to_be32((wr->wr.fast_reg.rkey & 0xff) | 0xffffff00);
+	seg->flags_pd = cpu_to_be32(MLX5_MKEY_REMOTE_INVAL);
+	seg->start_addr = cpu_to_be64(wr->wr.fast_reg.iova_start);
+	seg->len = cpu_to_be64(wr->wr.fast_reg.length);
+	seg->xlt_oct_size = cpu_to_be32((wr->wr.fast_reg.page_list_len + 1) / 2);
+	seg->log2_page_size = wr->wr.fast_reg.page_shift;
+}
+
+static void set_reg_mkey_segment(struct mlx5_mkey_seg *seg, struct ib_send_wr *wr)
+{
+	memset(seg, 0, sizeof(*seg));
+	if (wr->send_flags & MLX5_IB_SEND_UMR_UNREG) {
+		seg->status = 1 << 6;
+		return;
+	}
+
+	seg->flags = convert_access(wr->wr.fast_reg.access_flags);
+	seg->flags_pd = cpu_to_be32(to_mpd((struct ib_pd *)wr->wr.fast_reg.page_list)->pdn);
+	seg->start_addr = cpu_to_be64(wr->wr.fast_reg.iova_start);
+	seg->len = cpu_to_be64(wr->wr.fast_reg.length);
+	seg->log2_page_size = wr->wr.fast_reg.page_shift;
+	seg->qpn_mkey7_0 = cpu_to_be32(0xffffff << 8);
+}
+
+static void set_frwr_pages(struct mlx5_wqe_data_seg *dseg,
+			   struct ib_send_wr *wr,
+			   struct mlx5_core_dev *mdev,
+			   struct mlx5_ib_pd *pd,
+			   int writ)
+{
+	struct mlx5_ib_fast_reg_page_list *mfrpl = to_mfrpl(wr->wr.fast_reg.page_list);
+	u64 *page_list = wr->wr.fast_reg.page_list->page_list;
+	u64 perm = MLX5_EN_RD | (writ ? MLX5_EN_WR : 0);
+	int i;
+
+	for (i = 0; i < wr->wr.fast_reg.page_list_len; i++)
+		mfrpl->mapped_page_list[i] = cpu_to_be64(page_list[i] | perm);
+	dseg->addr = cpu_to_be64(mfrpl->map);
+	dseg->byte_count = cpu_to_be32(ALIGN(sizeof(u64) * wr->wr.fast_reg.page_list_len, 64));
+	dseg->lkey = cpu_to_be32(pd->pa_lkey);
+}
+
+static __be32 send_ieth(struct ib_send_wr *wr)
+{
+	switch (wr->opcode) {
+	case IB_WR_SEND_WITH_IMM:
+	case IB_WR_RDMA_WRITE_WITH_IMM:
+		return wr->ex.imm_data;
+
+	case IB_WR_SEND_WITH_INV:
+		return cpu_to_be32(wr->ex.invalidate_rkey);
+
+	default:
+		return 0;
+	}
+}
+
+static u8 calc_sig(void *wqe, int size)
+{
+	u8 *p = wqe;
+	u8 res = 0;
+	int i;
+
+	for (i = 0; i < size; i++)
+		res ^= p[i];
+
+	return ~res;
+}
+
+static u8 wq_sig(void *wqe)
+{
+	return calc_sig(wqe, (*((u8 *)wqe + 8) & 0x3f) << 4);
+}
+
+static int set_data_inl_seg(struct mlx5_ib_qp *qp, struct ib_send_wr *wr,
+			    void *wqe, int *sz)
+{
+	struct mlx5_wqe_inline_seg *seg;
+	void *qend = qp->sq.qend;
+	void *addr;
+	int inl = 0;
+	int copy;
+	int len;
+	int i;
+
+	seg = wqe;
+	wqe += sizeof(*seg);
+	for (i = 0; i < wr->num_sge; i++) {
+		addr = (void *)(unsigned long)(wr->sg_list[i].addr);
+		len  = wr->sg_list[i].length;
+		inl += len;
+
+		if (unlikely(inl > qp->max_inline_data))
+			return -ENOMEM;
+
+		if (unlikely(wqe + len > qend)) {
+			copy = qend - wqe;
+			memcpy(wqe, addr, copy);
+			addr += copy;
+			len -= copy;
+			wqe = mlx5_get_send_wqe(qp, 0);
+		}
+		memcpy(wqe, addr, len);
+		wqe += len;
+	}
+
+	seg->byte_count = cpu_to_be32(inl | MLX5_INLINE_SEG);
+
+	*sz = ALIGN(inl + sizeof(seg->byte_count), 16) / 16;
+
+	return 0;
+}
+
+static int set_frwr_li_wr(void **seg, struct ib_send_wr *wr, int *size,
+			  struct mlx5_core_dev *mdev, struct mlx5_ib_pd *pd, struct mlx5_ib_qp *qp)
+{
+	int writ = 0;
+	int li;
+
+	li = wr->opcode == IB_WR_LOCAL_INV ? 1 : 0;
+	if (unlikely(wr->send_flags & IB_SEND_INLINE))
+		return -EINVAL;
+
+	set_frwr_umr_segment(*seg, wr, li);
+	*seg += sizeof(struct mlx5_wqe_umr_ctrl_seg);
+	*size += sizeof(struct mlx5_wqe_umr_ctrl_seg) / 16;
+	if (unlikely((*seg == qp->sq.qend)))
+		*seg = mlx5_get_send_wqe(qp, 0);
+	set_mkey_segment(*seg, wr, li, &writ);
+	*seg += sizeof(struct mlx5_mkey_seg);
+	*size += sizeof(struct mlx5_mkey_seg) / 16;
+	if (unlikely((*seg == qp->sq.qend)))
+		*seg = mlx5_get_send_wqe(qp, 0);
+	if (!li) {
+		set_frwr_pages(*seg, wr, mdev, pd, writ);
+		*seg += sizeof(struct mlx5_wqe_data_seg);
+		*size += (sizeof(struct mlx5_wqe_data_seg) / 16);
+	}
+	return 0;
+}
+
+static void dump_wqe(struct mlx5_ib_qp *qp, int idx, int size_16)
+{
+	__be32 *p = NULL;
+	int tidx = idx;
+	int i, j;
+
+	pr_debug("dump wqe at %p\n", mlx5_get_send_wqe(qp, tidx));
+	for (i = 0, j = 0; i < size_16 * 4; i += 4, j += 4) {
+		if ((i & 0xf) == 0) {
+			void *buf = mlx5_get_send_wqe(qp, tidx);
+			tidx = (tidx + 1) & (qp->sq.wqe_cnt - 1);
+			p = buf;
+			j = 0;
+		}
+		pr_debug("%08x %08x %08x %08x\n", be32_to_cpu(p[j]),
+			 be32_to_cpu(p[j + 1]), be32_to_cpu(p[j + 2]),
+			 be32_to_cpu(p[j + 3]));
+	}
+}
+
+static void mlx5_bf_copy(u64 __iomem *dst, u64 *src,
+			 unsigned bytecnt, struct mlx5_ib_qp *qp)
+{
+	while (bytecnt > 0) {
+		__iowrite64_copy(dst++, src++, 8);
+		__iowrite64_copy(dst++, src++, 8);
+		__iowrite64_copy(dst++, src++, 8);
+		__iowrite64_copy(dst++, src++, 8);
+		__iowrite64_copy(dst++, src++, 8);
+		__iowrite64_copy(dst++, src++, 8);
+		__iowrite64_copy(dst++, src++, 8);
+		__iowrite64_copy(dst++, src++, 8);
+		bytecnt -= 64;
+		if (unlikely(src == qp->sq.qend))
+			src = mlx5_get_send_wqe(qp, 0);
+	}
+}
+
+static u8 get_fence(u8 fence, struct ib_send_wr *wr)
+{
+	if (unlikely(wr->opcode == IB_WR_LOCAL_INV &&
+		     wr->send_flags & IB_SEND_FENCE))
+		return MLX5_FENCE_MODE_STRONG_ORDERING;
+
+	if (unlikely(fence)) {
+		if (wr->send_flags & IB_SEND_FENCE)
+			return MLX5_FENCE_MODE_SMALL_AND_FENCE;
+		else
+			return fence;
+
+	} else {
+		return 0;
+	}
+}
+
+int mlx5_ib_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
+		      struct ib_send_wr **bad_wr)
+{
+	struct mlx5_wqe_ctrl_seg *ctrl = NULL;  /* compiler warning */
+	struct mlx5_ib_dev *dev = to_mdev(ibqp->device);
+	struct mlx5_core_dev *mdev = &dev->mdev;
+	struct mlx5_ib_qp *qp = to_mqp(ibqp);
+	struct mlx5_wqe_data_seg *dpseg;
+	struct mlx5_wqe_xrc_seg *xrc;
+	struct mlx5_bf *bf = qp->bf;
+	int uninitialized_var(size);
+	void *qend = qp->sq.qend;
+	unsigned long flags;
+	u32 mlx5_opcode;
+	unsigned idx;
+	int err = 0;
+	int inl = 0;
+	int num_sge;
+	void *seg;
+	int nreq;
+	int i;
+	u8 next_fence = 0;
+	u8 opmod = 0;
+	u8 fence;
+
+	spin_lock_irqsave(&qp->sq.lock, flags);
+
+	for (nreq = 0; wr; nreq++, wr = wr->next) {
+		if (unlikely(wr->opcode >= sizeof(mlx5_ib_opcode) / sizeof(mlx5_ib_opcode[0]))) {
+			mlx5_ib_warn(dev, "\n");
+			err = -EINVAL;
+			*bad_wr = wr;
+			goto out;
+		}
+
+		if (unlikely(mlx5_wq_overflow(&qp->sq, nreq, qp->ibqp.send_cq))) {
+			mlx5_ib_warn(dev, "\n");
+			err = -ENOMEM;
+			*bad_wr = wr;
+			goto out;
+		}
+
+		fence = qp->fm_cache;
+		num_sge = wr->num_sge;
+		if (unlikely(num_sge > qp->sq.max_gs)) {
+			mlx5_ib_warn(dev, "\n");
+			err = -ENOMEM;
+			*bad_wr = wr;
+			goto out;
+		}
+
+		idx = qp->sq.cur_post & (qp->sq.wqe_cnt - 1);
+		seg = mlx5_get_send_wqe(qp, idx);
+		ctrl = seg;
+		*(uint32_t *)(seg + 8) = 0;
+		ctrl->imm = send_ieth(wr);
+		ctrl->fm_ce_se = qp->sq_signal_bits |
+			(wr->send_flags & IB_SEND_SIGNALED ?
+			 MLX5_WQE_CTRL_CQ_UPDATE : 0) |
+			(wr->send_flags & IB_SEND_SOLICITED ?
+			 MLX5_WQE_CTRL_SOLICITED : 0);
+
+		seg += sizeof(*ctrl);
+		size = sizeof(*ctrl) / 16;
+
+		switch (ibqp->qp_type) {
+		case IB_QPT_XRC_INI:
+			xrc = seg;
+			xrc->xrc_srqn = htonl(wr->xrc_remote_srq_num);
+			seg += sizeof(*xrc);
+			size += sizeof(*xrc) / 16;
+			/* fall through */
+		case IB_QPT_RC:
+			switch (wr->opcode) {
+			case IB_WR_RDMA_READ:
+			case IB_WR_RDMA_WRITE:
+			case IB_WR_RDMA_WRITE_WITH_IMM:
+				set_raddr_seg(seg, wr->wr.rdma.remote_addr,
+					      wr->wr.rdma.rkey);
+				seg  += sizeof(struct mlx5_wqe_raddr_seg);
+				size += sizeof(struct mlx5_wqe_raddr_seg) / 16;
+				break;
+
+			case IB_WR_ATOMIC_CMP_AND_SWP:
+			case IB_WR_ATOMIC_FETCH_AND_ADD:
+				set_raddr_seg(seg, wr->wr.atomic.remote_addr,
+					      wr->wr.atomic.rkey);
+				seg  += sizeof(struct mlx5_wqe_raddr_seg);
+
+				set_atomic_seg(seg, wr);
+				seg  += sizeof(struct mlx5_wqe_atomic_seg);
+
+				size += (sizeof(struct mlx5_wqe_raddr_seg) +
+					 sizeof(struct mlx5_wqe_atomic_seg)) / 16;
+				break;
+
+			case IB_WR_MASKED_ATOMIC_CMP_AND_SWP:
+				set_raddr_seg(seg, wr->wr.atomic.remote_addr,
+					      wr->wr.atomic.rkey);
+				seg  += sizeof(struct mlx5_wqe_raddr_seg);
+
+				set_masked_atomic_seg(seg, wr);
+				seg  += sizeof(struct mlx5_wqe_masked_atomic_seg);
+
+				size += (sizeof(struct mlx5_wqe_raddr_seg) +
+					 sizeof(struct mlx5_wqe_masked_atomic_seg)) / 16;
+				break;
+
+			case IB_WR_LOCAL_INV:
+				next_fence = MLX5_FENCE_MODE_INITIATOR_SMALL;
+				qp->sq.wr_data[idx] = IB_WR_LOCAL_INV;
+				ctrl->imm = cpu_to_be32(wr->ex.invalidate_rkey);
+				err = set_frwr_li_wr(&seg, wr, &size, mdev, to_mpd(ibqp->pd), qp);
+				if (err) {
+					mlx5_ib_warn(dev, "\n");
+					*bad_wr = wr;
+					goto out;
+				}
+				num_sge = 0;
+				break;
+
+			case IB_WR_FAST_REG_MR:
+				next_fence = MLX5_FENCE_MODE_INITIATOR_SMALL;
+				qp->sq.wr_data[idx] = IB_WR_FAST_REG_MR;
+				ctrl->imm = cpu_to_be32(wr->wr.fast_reg.rkey);
+				err = set_frwr_li_wr(&seg, wr, &size, mdev, to_mpd(ibqp->pd), qp);
+				if (err) {
+					mlx5_ib_warn(dev, "\n");
+					*bad_wr = wr;
+					goto out;
+				}
+				num_sge = 0;
+				break;
+
+			default:
+				break;
+			}
+			break;
+
+		case IB_QPT_UC:
+			switch (wr->opcode) {
+			case IB_WR_RDMA_WRITE:
+			case IB_WR_RDMA_WRITE_WITH_IMM:
+				set_raddr_seg(seg, wr->wr.rdma.remote_addr,
+					      wr->wr.rdma.rkey);
+				seg  += sizeof(struct mlx5_wqe_raddr_seg);
+				size += sizeof(struct mlx5_wqe_raddr_seg) / 16;
+				break;
+
+			default:
+				break;
+			}
+			break;
+
+		case IB_QPT_UD:
+		case IB_QPT_SMI:
+		case IB_QPT_GSI:
+			set_datagram_seg(seg, wr);
+			seg  += sizeof(struct mlx5_wqe_datagram_seg);
+			size += sizeof(struct mlx5_wqe_datagram_seg) / 16;
+			if (unlikely((seg == qend)))
+				seg = mlx5_get_send_wqe(qp, 0);
+			break;
+
+		case MLX5_IB_QPT_REG_UMR:
+			if (wr->opcode != MLX5_IB_WR_UMR) {
+				err = -EINVAL;
+				mlx5_ib_warn(dev, "bad opcode\n");
+				goto out;
+			}
+			qp->sq.wr_data[idx] = MLX5_IB_WR_UMR;
+			ctrl->imm = cpu_to_be32(wr->wr.fast_reg.rkey);
+			set_reg_umr_segment(seg, wr);
+			seg += sizeof(struct mlx5_wqe_umr_ctrl_seg);
+			size += sizeof(struct mlx5_wqe_umr_ctrl_seg) / 16;
+			if (unlikely((seg == qend)))
+				seg = mlx5_get_send_wqe(qp, 0);
+			set_reg_mkey_segment(seg, wr);
+			seg += sizeof(struct mlx5_mkey_seg);
+			size += sizeof(struct mlx5_mkey_seg) / 16;
+			if (unlikely((seg == qend)))
+				seg = mlx5_get_send_wqe(qp, 0);
+			break;
+
+		default:
+			break;
+		}
+
+		if (wr->send_flags & IB_SEND_INLINE && num_sge) {
+			int uninitialized_var(sz);
+
+			err = set_data_inl_seg(qp, wr, seg, &sz);
+			if (unlikely(err)) {
+				mlx5_ib_warn(dev, "\n");
+				*bad_wr = wr;
+				goto out;
+			}
+			inl = 1;
+			size += sz;
+		} else {
+			dpseg = seg;
+			for (i = 0; i < num_sge; i++) {
+				if (unlikely(dpseg == qend)) {
+					seg = mlx5_get_send_wqe(qp, 0);
+					dpseg = seg;
+				}
+				if (likely(wr->sg_list[i].length)) {
+					set_data_ptr_seg(dpseg, wr->sg_list + i);
+					size += sizeof(struct mlx5_wqe_data_seg) / 16;
+					dpseg++;
+				}
+			}
+		}
+
+		mlx5_opcode = mlx5_ib_opcode[wr->opcode];
+		ctrl->opmod_idx_opcode = cpu_to_be32(((u32)(qp->sq.cur_post) << 8)	|
+						     mlx5_opcode			|
+						     ((u32)opmod << 24));
+		ctrl->qpn_ds = cpu_to_be32(size | (qp->mqp.qpn << 8));
+		ctrl->fm_ce_se |= get_fence(fence, wr);
+		qp->fm_cache = next_fence;
+		if (unlikely(qp->wq_sig))
+			ctrl->signature = wq_sig(ctrl);
+
+		qp->sq.wrid[idx] = wr->wr_id;
+		qp->sq.w_list[idx].opcode = mlx5_opcode;
+		qp->sq.wqe_head[idx] = qp->sq.head + nreq;
+		qp->sq.cur_post += DIV_ROUND_UP(size * 16, MLX5_SEND_WQE_BB);
+		qp->sq.w_list[idx].next = qp->sq.cur_post;
+
+		if (0)
+			dump_wqe(qp, idx, size);
+	}
+
+out:
+	if (likely(nreq)) {
+		qp->sq.head += nreq;
+
+		/* Make sure that descriptors are written before
+		 * updating doorbell record and ringing the doorbell
+		 */
+		wmb();
+
+		qp->db.db[MLX5_SND_DBR] = cpu_to_be32(qp->sq.cur_post);
+
+		if (bf->need_lock)
+			spin_lock(&bf->lock);
+
+		/* TBD enable WC */
+		if (0 && nreq == 1 && bf->uuarn && inl && size > 1 && size <= bf->buf_size / 16) {
+			mlx5_bf_copy(bf->reg + bf->offset, (u64 *)ctrl, ALIGN(size * 16, 64), qp);
+			/* wc_wmb(); */
+		} else {
+			mlx5_write64((__be32 *)ctrl, bf->regreg + bf->offset,
+				     MLX5_GET_DOORBELL_LOCK(&bf->lock32));
+			/* Make sure doorbells don't leak out of SQ spinlock
+			 * and reach the HCA out of order.
+			 */
+			mmiowb();
+		}
+		bf->offset ^= bf->buf_size;
+		if (bf->need_lock)
+			spin_unlock(&bf->lock);
+	}
+
+	spin_unlock_irqrestore(&qp->sq.lock, flags);
+
+	return err;
+}
+
+static void set_sig_seg(struct mlx5_rwqe_sig *sig, int size)
+{
+	sig->signature = calc_sig(sig, size);
+}
+
+int mlx5_ib_post_recv(struct ib_qp *ibqp, struct ib_recv_wr *wr,
+		      struct ib_recv_wr **bad_wr)
+{
+	struct mlx5_ib_qp *qp = to_mqp(ibqp);
+	struct mlx5_wqe_data_seg *scat;
+	struct mlx5_rwqe_sig *sig;
+	unsigned long flags;
+	int err = 0;
+	int nreq;
+	int ind;
+	int i;
+
+	spin_lock_irqsave(&qp->rq.lock, flags);
+
+	ind = qp->rq.head & (qp->rq.wqe_cnt - 1);
+
+	for (nreq = 0; wr; nreq++, wr = wr->next) {
+		if (mlx5_wq_overflow(&qp->rq, nreq, qp->ibqp.recv_cq)) {
+			err = -ENOMEM;
+			*bad_wr = wr;
+			goto out;
+		}
+
+		if (unlikely(wr->num_sge > qp->rq.max_gs)) {
+			err = -EINVAL;
+			*bad_wr = wr;
+			goto out;
+		}
+
+		scat = get_recv_wqe(qp, ind);
+		if (qp->wq_sig)
+			scat++;
+
+		for (i = 0; i < wr->num_sge; i++)
+			set_data_ptr_seg(scat + i, wr->sg_list + i);
+
+		if (i < qp->rq.max_gs) {
+			scat[i].byte_count = 0;
+			scat[i].lkey       = cpu_to_be32(MLX5_INVALID_LKEY);
+			scat[i].addr       = 0;
+		}
+
+		if (qp->wq_sig) {
+			sig = (struct mlx5_rwqe_sig *)scat;
+			set_sig_seg(sig, (qp->rq.max_gs + 1) << 2);
+		}
+
+		qp->rq.wrid[ind] = wr->wr_id;
+
+		ind = (ind + 1) & (qp->rq.wqe_cnt - 1);
+	}
+
+out:
+	if (likely(nreq)) {
+		qp->rq.head += nreq;
+
+		/* Make sure that descriptors are written before
+		 * doorbell record.
+		 */
+		wmb();
+
+		*qp->db.db = cpu_to_be32(qp->rq.head & 0xffff);
+	}
+
+	spin_unlock_irqrestore(&qp->rq.lock, flags);
+
+	return err;
+}
+
+static inline enum ib_qp_state to_ib_qp_state(enum mlx5_qp_state mlx5_state)
+{
+	switch (mlx5_state) {
+	case MLX5_QP_STATE_RST:      return IB_QPS_RESET;
+	case MLX5_QP_STATE_INIT:     return IB_QPS_INIT;
+	case MLX5_QP_STATE_RTR:      return IB_QPS_RTR;
+	case MLX5_QP_STATE_RTS:      return IB_QPS_RTS;
+	case MLX5_QP_STATE_SQ_DRAINING:
+	case MLX5_QP_STATE_SQD:      return IB_QPS_SQD;
+	case MLX5_QP_STATE_SQER:     return IB_QPS_SQE;
+	case MLX5_QP_STATE_ERR:      return IB_QPS_ERR;
+	default:		     return -1;
+	}
+}
+
+static inline enum ib_mig_state to_ib_mig_state(int mlx5_mig_state)
+{
+	switch (mlx5_mig_state) {
+	case MLX5_QP_PM_ARMED:		return IB_MIG_ARMED;
+	case MLX5_QP_PM_REARM:		return IB_MIG_REARM;
+	case MLX5_QP_PM_MIGRATED:	return IB_MIG_MIGRATED;
+	default: return -1;
+	}
+}
+
+static int to_ib_qp_access_flags(int mlx5_flags)
+{
+	int ib_flags = 0;
+
+	if (mlx5_flags & MLX5_QP_BIT_RRE)
+		ib_flags |= IB_ACCESS_REMOTE_READ;
+	if (mlx5_flags & MLX5_QP_BIT_RWE)
+		ib_flags |= IB_ACCESS_REMOTE_WRITE;
+	if (mlx5_flags & MLX5_QP_BIT_RAE)
+		ib_flags |= IB_ACCESS_REMOTE_ATOMIC;
+
+	return ib_flags;
+}
+
+static void to_ib_ah_attr(struct mlx5_ib_dev *ibdev, struct ib_ah_attr *ib_ah_attr,
+				struct mlx5_qp_path *path)
+{
+	struct mlx5_core_dev *dev = &ibdev->mdev;
+
+	memset(ib_ah_attr, 0, sizeof(*ib_ah_attr));
+	ib_ah_attr->port_num	  = path->port;
+
+	if (ib_ah_attr->port_num == 0 || ib_ah_attr->port_num > dev->caps.num_ports)
+		return;
+
+	ib_ah_attr->sl = path->sl & 0xf;
+
+	ib_ah_attr->dlid	  = be16_to_cpu(path->rlid);
+	ib_ah_attr->src_path_bits = path->grh_mlid & 0x7f;
+	ib_ah_attr->static_rate   = path->static_rate ? path->static_rate - 5 : 0;
+	ib_ah_attr->ah_flags      = (path->grh_mlid & (1 << 7)) ? IB_AH_GRH : 0;
+	if (ib_ah_attr->ah_flags) {
+		ib_ah_attr->grh.sgid_index = path->mgid_index;
+		ib_ah_attr->grh.hop_limit  = path->hop_limit;
+		ib_ah_attr->grh.traffic_class =
+			(be32_to_cpu(path->tclass_flowlabel) >> 20) & 0xff;
+		ib_ah_attr->grh.flow_label =
+			be32_to_cpu(path->tclass_flowlabel) & 0xfffff;
+		memcpy(ib_ah_attr->grh.dgid.raw,
+		       path->rgid, sizeof(ib_ah_attr->grh.dgid.raw));
+	}
+}
+
+int mlx5_ib_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *qp_attr, int qp_attr_mask,
+		     struct ib_qp_init_attr *qp_init_attr)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibqp->device);
+	struct mlx5_ib_qp *qp = to_mqp(ibqp);
+	struct mlx5_query_qp_mbox_out *outb;
+	struct mlx5_qp_context *context;
+	int mlx5_state;
+	int err = 0;
+
+	mutex_lock(&qp->mutex);
+	outb = kzalloc(sizeof(*outb), GFP_KERNEL);
+	if (!outb) {
+		err = -ENOMEM;
+		goto out;
+	}
+	context = &outb->ctx;
+	err = mlx5_core_qp_query(&dev->mdev, &qp->mqp, outb, sizeof(*outb));
+	if (err)
+		goto out_free;
+
+	mlx5_state = be32_to_cpu(context->flags) >> 28;
+
+	qp->state		     = to_ib_qp_state(mlx5_state);
+	qp_attr->qp_state	     = qp->state;
+	qp_attr->path_mtu	     = context->mtu_msgmax >> 5;
+	qp_attr->path_mig_state	     =
+		to_ib_mig_state((be32_to_cpu(context->flags) >> 11) & 0x3);
+	qp_attr->qkey		     = be32_to_cpu(context->qkey);
+	qp_attr->rq_psn		     = be32_to_cpu(context->rnr_nextrecvpsn) & 0xffffff;
+	qp_attr->sq_psn		     = be32_to_cpu(context->next_send_psn) & 0xffffff;
+	qp_attr->dest_qp_num	     = be32_to_cpu(context->log_pg_sz_remote_qpn) & 0xffffff;
+	qp_attr->qp_access_flags     =
+		to_ib_qp_access_flags(be32_to_cpu(context->params2));
+
+	if (qp->ibqp.qp_type == IB_QPT_RC || qp->ibqp.qp_type == IB_QPT_UC) {
+		to_ib_ah_attr(dev, &qp_attr->ah_attr, &context->pri_path);
+		to_ib_ah_attr(dev, &qp_attr->alt_ah_attr, &context->alt_path);
+		qp_attr->alt_pkey_index = context->alt_path.pkey_index & 0x7f;
+		qp_attr->alt_port_num	= qp_attr->alt_ah_attr.port_num;
+	}
+
+	qp_attr->pkey_index = context->pri_path.pkey_index & 0x7f;
+	qp_attr->port_num = context->pri_path.port;
+
+	/* qp_attr->en_sqd_async_notify is only applicable in modify qp */
+	qp_attr->sq_draining = mlx5_state == MLX5_QP_STATE_SQ_DRAINING;
+
+	qp_attr->max_rd_atomic = 1 << ((be32_to_cpu(context->params1) >> 21) & 0x7);
+
+	qp_attr->max_dest_rd_atomic =
+		1 << ((be32_to_cpu(context->params2) >> 21) & 0x7);
+	qp_attr->min_rnr_timer	    =
+		(be32_to_cpu(context->rnr_nextrecvpsn) >> 24) & 0x1f;
+	qp_attr->timeout	    = context->pri_path.ackto_lt >> 3;
+	qp_attr->retry_cnt	    = (be32_to_cpu(context->params1) >> 16) & 0x7;
+	qp_attr->rnr_retry	    = (be32_to_cpu(context->params1) >> 13) & 0x7;
+	qp_attr->alt_timeout	    = context->alt_path.ackto_lt >> 3;
+	qp_attr->cur_qp_state	     = qp_attr->qp_state;
+	qp_attr->cap.max_recv_wr     = qp->rq.wqe_cnt;
+	qp_attr->cap.max_recv_sge    = qp->rq.max_gs;
+
+	if (!ibqp->uobject) {
+		qp_attr->cap.max_send_wr  = qp->sq.wqe_cnt;
+		qp_attr->cap.max_send_sge = qp->sq.max_gs;
+	} else {
+		qp_attr->cap.max_send_wr  = 0;
+		qp_attr->cap.max_send_sge = 0;
+	}
+
+	/* We don't support inline sends for kernel QPs (yet), and we
+	 * don't know what userspace's value should be.
+	 */
+	qp_attr->cap.max_inline_data = 0;
+
+	qp_init_attr->cap	     = qp_attr->cap;
+
+	qp_init_attr->create_flags = 0;
+	if (qp->flags & MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK)
+		qp_init_attr->create_flags |= IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK;
+
+	qp_init_attr->sq_sig_type = qp->sq_signal_bits & MLX5_WQE_CTRL_CQ_UPDATE ?
+		IB_SIGNAL_ALL_WR : IB_SIGNAL_REQ_WR;
+
+out_free:
+	kfree(outb);
+
+out:
+	mutex_unlock(&qp->mutex);
+	return err;
+}
+
+struct ib_xrcd *mlx5_ib_alloc_xrcd(struct ib_device *ibdev,
+					  struct ib_ucontext *context,
+					  struct ib_udata *udata)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+	struct mlx5_ib_xrcd *xrcd;
+	int err;
+
+	if (!(dev->mdev.caps.flags & MLX5_DEV_CAP_FLAG_XRC))
+		return ERR_PTR(-ENOSYS);
+
+	xrcd = kmalloc(sizeof(*xrcd), GFP_KERNEL);
+	if (!xrcd)
+		return ERR_PTR(-ENOMEM);
+
+	err = mlx5_core_xrcd_alloc(&dev->mdev, &xrcd->xrcdn);
+	if (err) {
+		kfree(xrcd);
+		return ERR_PTR(-ENOMEM);
+	}
+
+	return &xrcd->ibxrcd;
+}
+
+int mlx5_ib_dealloc_xrcd(struct ib_xrcd *xrcd)
+{
+	struct mlx5_ib_dev *dev = to_mdev(xrcd->device);
+	u32 xrcdn = to_mxrcd(xrcd)->xrcdn;
+	int err;
+
+	err = mlx5_core_xrcd_dealloc(&dev->mdev, xrcdn);
+	if (err) {
+		mlx5_ib_warn(dev, "failed to dealloc xrcdn 0x%x\n", xrcdn);
+		return err;
+	}
+
+	kfree(xrcd);
+
+	return 0;
+}
diff --git a/drivers/infiniband/hw/mlx5/srq.c b/drivers/infiniband/hw/mlx5/srq.c
new file mode 100644
index 0000000..84d297a
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/srq.c
@@ -0,0 +1,473 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/module.h>
+#include <linux/mlx5/qp.h>
+#include <linux/mlx5/srq.h>
+#include <linux/slab.h>
+#include <rdma/ib_umem.h>
+
+#include "mlx5_ib.h"
+#include "user.h"
+
+/* not supported currently */
+static int srq_signature;
+
+static void *get_wqe(struct mlx5_ib_srq *srq, int n)
+{
+	return mlx5_buf_offset(&srq->buf, n << srq->msrq.wqe_shift);
+}
+
+static void mlx5_ib_srq_event(struct mlx5_core_srq *srq, enum mlx5_event type)
+{
+	struct ib_event event;
+	struct ib_srq *ibsrq = &to_mibsrq(srq)->ibsrq;
+
+	if (ibsrq->event_handler) {
+		event.device      = ibsrq->device;
+		event.element.srq = ibsrq;
+		switch (type) {
+		case MLX5_EVENT_TYPE_SRQ_RQ_LIMIT:
+			event.event = IB_EVENT_SRQ_LIMIT_REACHED;
+			break;
+		case MLX5_EVENT_TYPE_SRQ_CATAS_ERROR:
+			event.event = IB_EVENT_SRQ_ERR;
+			break;
+		default:
+			pr_warn("mlx5_ib: Unexpected event type %d on SRQ %06x\n",
+				type, srq->srqn);
+			return;
+		}
+
+		ibsrq->event_handler(&event, ibsrq->srq_context);
+	}
+}
+
+static int create_srq_user(struct ib_pd *pd, struct mlx5_ib_srq *srq,
+			   struct mlx5_create_srq_mbox_in **in,
+			   struct ib_udata *udata, int buf_size, int *inlen)
+{
+	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+	struct mlx5_ib_create_srq ucmd;
+	int err;
+	int npages;
+	int page_shift;
+	int ncont;
+	u32 offset;
+
+	if (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd))) {
+		mlx5_ib_dbg(dev, "failed copy udata\n");
+		return -EFAULT;
+	}
+	srq->wq_sig = !!(ucmd.flags & MLX5_SRQ_FLAG_SIGNATURE);
+
+	srq->umem = ib_umem_get(pd->uobject->context, ucmd.buf_addr, buf_size,
+				0, 0);
+	if (IS_ERR(srq->umem)) {
+		mlx5_ib_dbg(dev, "failed umem get, size %d\n", buf_size);
+		err = PTR_ERR(srq->umem);
+		return err;
+	}
+
+	mlx5_ib_cont_pages(srq->umem, ucmd.buf_addr, &npages,
+			   &page_shift, &ncont, NULL);
+	err = mlx5_ib_get_buf_offset(ucmd.buf_addr, page_shift,
+				     &offset);
+	if (err) {
+		mlx5_ib_warn(dev, "bad offset\n");
+		goto err_umem;
+	}
+
+	*inlen = sizeof(**in) + sizeof(*(*in)->pas) * ncont;
+	*in = mlx5_vzalloc(*inlen);
+	if (!(*in)) {
+		err = -ENOMEM;
+		goto err_umem;
+	}
+
+	mlx5_ib_populate_pas(dev, srq->umem, page_shift, (*in)->pas, 0);
+
+	err = mlx5_ib_db_map_user(to_mucontext(pd->uobject->context),
+				  ucmd.db_addr, &srq->db);
+	if (err) {
+		mlx5_ib_dbg(dev, "map doorbell failed\n");
+		goto err_in;
+	}
+
+	(*in)->ctx.log_pg_sz = page_shift - PAGE_SHIFT;
+	(*in)->ctx.pgoff_cqn = cpu_to_be32(offset << 26);
+
+	return 0;
+
+err_in:
+	mlx5_vfree(*in);
+
+err_umem:
+	ib_umem_release(srq->umem);
+
+	return err;
+}
+
+static int create_srq_kernel(struct mlx5_ib_dev *dev, struct mlx5_ib_srq *srq,
+			     struct mlx5_create_srq_mbox_in **in, int buf_size,
+			     int *inlen)
+{
+	int err;
+	int i;
+	struct mlx5_wqe_srq_next_seg *next;
+	int page_shift;
+	int npages;
+
+	err = mlx5_db_alloc(&dev->mdev, &srq->db);
+	if (err) {
+		mlx5_ib_warn(dev, "alloc dbell rec failed\n");
+		return err;
+	}
+
+	*srq->db.db = 0;
+
+	if (mlx5_buf_alloc(&dev->mdev, buf_size, PAGE_SIZE * 2, &srq->buf)) {
+		mlx5_ib_dbg(dev, "buf alloc failed\n");
+		err = -ENOMEM;
+		goto err_db;
+	}
+	page_shift = srq->buf.page_shift;
+
+	srq->head    = 0;
+	srq->tail    = srq->msrq.max - 1;
+	srq->wqe_ctr = 0;
+
+	for (i = 0; i < srq->msrq.max; i++) {
+		next = get_wqe(srq, i);
+		next->next_wqe_index =
+			cpu_to_be16((i + 1) & (srq->msrq.max - 1));
+	}
+
+	npages = DIV_ROUND_UP(srq->buf.npages, 1 << (page_shift - PAGE_SHIFT));
+	mlx5_ib_dbg(dev, "buf_size %d, page_shift %d, npages %d, calc npages %d\n",
+		    buf_size, page_shift, srq->buf.npages, npages);
+	*inlen = sizeof(**in) + sizeof(*(*in)->pas) * npages;
+	*in = mlx5_vzalloc(*inlen);
+	if (!*in) {
+		err = -ENOMEM;
+		goto err_buf;
+	}
+	mlx5_fill_page_array(&srq->buf, (*in)->pas);
+
+	srq->wrid = kmalloc(srq->msrq.max * sizeof(u64), GFP_KERNEL);
+	if (!srq->wrid) {
+		mlx5_ib_dbg(dev, "kmalloc failed %lu\n",
+			    (unsigned long)(srq->msrq.max * sizeof(u64)));
+		err = -ENOMEM;
+		goto err_in;
+	}
+	srq->wq_sig = !!srq_signature;
+
+	(*in)->ctx.log_pg_sz = page_shift - PAGE_SHIFT;
+
+	return 0;
+
+err_in:
+	mlx5_vfree(*in);
+
+err_buf:
+	mlx5_buf_free(&dev->mdev, &srq->buf);
+
+err_db:
+	mlx5_db_free(&dev->mdev, &srq->db);
+	return err;
+}
+
+static void destroy_srq_user(struct ib_pd *pd, struct mlx5_ib_srq *srq)
+{
+	mlx5_ib_db_unmap_user(to_mucontext(pd->uobject->context), &srq->db);
+	ib_umem_release(srq->umem);
+}
+
+
+static void destroy_srq_kernel(struct mlx5_ib_dev *dev, struct mlx5_ib_srq *srq)
+{
+	kfree(srq->wrid);
+	mlx5_buf_free(&dev->mdev, &srq->buf);
+	mlx5_db_free(&dev->mdev, &srq->db);
+}
+
+struct ib_srq *mlx5_ib_create_srq(struct ib_pd *pd,
+				  struct ib_srq_init_attr *init_attr,
+				  struct ib_udata *udata)
+{
+	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+	struct mlx5_ib_srq *srq;
+	int desc_size;
+	int buf_size;
+	int err;
+	struct mlx5_create_srq_mbox_in *uninitialized_var(in);
+	int uninitialized_var(inlen);
+	int is_xrc;
+	u32 flgs, xrcdn;
+
+	/* Sanity check SRQ size before proceeding */
+	if (init_attr->attr.max_wr >= dev->mdev.caps.max_srq_wqes) {
+		mlx5_ib_dbg(dev, "max_wr %d, cap %d\n",
+			    init_attr->attr.max_wr,
+			    dev->mdev.caps.max_srq_wqes);
+		return ERR_PTR(-EINVAL);
+	}
+
+	srq = kmalloc(sizeof(*srq), GFP_KERNEL);
+	if (!srq)
+		return ERR_PTR(-ENOMEM);
+
+	mutex_init(&srq->mutex);
+	spin_lock_init(&srq->lock);
+	srq->msrq.max    = roundup_pow_of_two(init_attr->attr.max_wr + 1);
+	srq->msrq.max_gs = init_attr->attr.max_sge;
+
+	desc_size = sizeof(struct mlx5_wqe_srq_next_seg) +
+		    srq->msrq.max_gs * sizeof(struct mlx5_wqe_data_seg);
+	desc_size = roundup_pow_of_two(desc_size);
+	desc_size = max_t(int, 32, desc_size);
+	srq->msrq.max_avail_gather = (desc_size - sizeof(struct mlx5_wqe_srq_next_seg)) /
+		sizeof(struct mlx5_wqe_data_seg);
+	srq->msrq.wqe_shift = ilog2(desc_size);
+	buf_size = srq->msrq.max * desc_size;
+	mlx5_ib_dbg(dev, "desc_size 0x%x, req wr 0x%x, srq size 0x%x, max_gs 0x%x, max_avail_gather 0x%x\n",
+		    desc_size, init_attr->attr.max_wr, srq->msrq.max, srq->msrq.max_gs,
+		    srq->msrq.max_avail_gather);
+
+	if (pd->uobject)
+		err = create_srq_user(pd, srq, &in, udata, buf_size, &inlen);
+	else
+		err = create_srq_kernel(dev, srq, &in, buf_size, &inlen);
+
+	if (err) {
+		mlx5_ib_warn(dev, "create srq %s failed, err %d\n",
+			     pd->uobject ? "user" : "kernel", err);
+		goto err_srq;
+	}
+
+	is_xrc = (init_attr->srq_type == IB_SRQT_XRC);
+	in->ctx.state_log_sz = ilog2(srq->msrq.max);
+	flgs = ((srq->msrq.wqe_shift - 4) | (is_xrc << 5) | (srq->wq_sig << 7)) << 24;
+	xrcdn = 0;
+	if (is_xrc) {
+		xrcdn = to_mxrcd(init_attr->ext.xrc.xrcd)->xrcdn;
+		in->ctx.pgoff_cqn |= cpu_to_be32(to_mcq(init_attr->ext.xrc.cq)->mcq.cqn);
+	} else if (init_attr->srq_type == IB_SRQT_BASIC) {
+		xrcdn = to_mxrcd(dev->devr.x0)->xrcdn;
+		in->ctx.pgoff_cqn |= cpu_to_be32(to_mcq(dev->devr.c0)->mcq.cqn);
+	}
+
+	in->ctx.flags_xrcd = cpu_to_be32((flgs & 0xFF000000) | (xrcdn & 0xFFFFFF));
+
+	in->ctx.pd = cpu_to_be32(to_mpd(pd)->pdn);
+	in->ctx.db_record = cpu_to_be64(srq->db.dma);
+	err = mlx5_core_create_srq(&dev->mdev, &srq->msrq, in, inlen);
+	mlx5_vfree(in);
+	if (err) {
+		mlx5_ib_dbg(dev, "create SRQ failed, err %d\n", err);
+		goto err_srq;
+	}
+
+	mlx5_ib_dbg(dev, "create SRQ with srqn 0x%x\n", srq->msrq.srqn);
+
+	srq->msrq.event = mlx5_ib_srq_event;
+	srq->ibsrq.ext.xrc.srq_num = srq->msrq.srqn;
+
+	if (pd->uobject)
+		if (ib_copy_to_udata(udata, &srq->msrq.srqn, sizeof(__u32))) {
+			mlx5_ib_dbg(dev, "copy to user failed\n");
+			err = -EFAULT;
+			goto err_core;
+		}
+
+	init_attr->attr.max_wr = srq->msrq.max - 1;
+
+	return &srq->ibsrq;
+
+err_core:
+	mlx5_core_destroy_srq(&dev->mdev, &srq->msrq);
+	if (pd->uobject)
+		destroy_srq_user(pd, srq);
+	else
+		destroy_srq_kernel(dev, srq);
+
+err_srq:
+	kfree(srq);
+
+	return ERR_PTR(err);
+}
+
+int mlx5_ib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
+		       enum ib_srq_attr_mask attr_mask, struct ib_udata *udata)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibsrq->device);
+	struct mlx5_ib_srq *srq = to_msrq(ibsrq);
+	int ret;
+
+	/* We don't support resizing SRQs yet */
+	if (attr_mask & IB_SRQ_MAX_WR)
+		return -EINVAL;
+
+	if (attr_mask & IB_SRQ_LIMIT) {
+		if (attr->srq_limit >= srq->msrq.max)
+			return -EINVAL;
+
+		mutex_lock(&srq->mutex);
+		ret = mlx5_core_arm_srq(&dev->mdev, &srq->msrq, attr->srq_limit, 1);
+		mutex_unlock(&srq->mutex);
+
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+int mlx5_ib_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *srq_attr)
+{
+	struct mlx5_ib_dev *dev = to_mdev(ibsrq->device);
+	struct mlx5_ib_srq *srq = to_msrq(ibsrq);
+	int ret;
+	struct mlx5_query_srq_mbox_out *out;
+
+	out = kzalloc(sizeof(*out), GFP_KERNEL);
+	if (!out)
+		return -ENOMEM;
+
+	ret = mlx5_core_query_srq(&dev->mdev, &srq->msrq, out);
+	if (ret)
+		goto out_box;
+
+	srq_attr->srq_limit = be16_to_cpu(out->ctx.lwm);
+	srq_attr->max_wr    = srq->msrq.max - 1;
+	srq_attr->max_sge   = srq->msrq.max_gs;
+
+out_box:
+	kfree(out);
+	return ret;
+}
+
+int mlx5_ib_destroy_srq(struct ib_srq *srq)
+{
+	struct mlx5_ib_dev *dev = to_mdev(srq->device);
+	struct mlx5_ib_srq *msrq = to_msrq(srq);
+
+	mlx5_core_destroy_srq(&dev->mdev, &msrq->msrq);
+
+	if (srq->uobject) {
+		mlx5_ib_db_unmap_user(to_mucontext(srq->uobject->context), &msrq->db);
+		ib_umem_release(msrq->umem);
+	} else {
+		kfree(msrq->wrid);
+		mlx5_buf_free(&dev->mdev, &msrq->buf);
+		mlx5_db_free(&dev->mdev, &msrq->db);
+	}
+
+	kfree(srq);
+	return 0;
+}
+
+void mlx5_ib_free_srq_wqe(struct mlx5_ib_srq *srq, int wqe_index)
+{
+	struct mlx5_wqe_srq_next_seg *next;
+
+	/* always called with interrupts disabled. */
+	spin_lock(&srq->lock);
+
+	next = get_wqe(srq, srq->tail);
+	next->next_wqe_index = cpu_to_be16(wqe_index);
+	srq->tail = wqe_index;
+
+	spin_unlock(&srq->lock);
+}
+
+int mlx5_ib_post_srq_recv(struct ib_srq *ibsrq, struct ib_recv_wr *wr,
+			  struct ib_recv_wr **bad_wr)
+{
+	struct mlx5_ib_srq *srq = to_msrq(ibsrq);
+	struct mlx5_wqe_srq_next_seg *next;
+	struct mlx5_wqe_data_seg *scat;
+	unsigned long flags;
+	int err = 0;
+	int nreq;
+	int i;
+
+	spin_lock_irqsave(&srq->lock, flags);
+
+	for (nreq = 0; wr; nreq++, wr = wr->next) {
+		if (unlikely(wr->num_sge > srq->msrq.max_gs)) {
+			err = -EINVAL;
+			*bad_wr = wr;
+			break;
+		}
+
+		if (unlikely(srq->head == srq->tail)) {
+			err = -ENOMEM;
+			*bad_wr = wr;
+			break;
+		}
+
+		srq->wrid[srq->head] = wr->wr_id;
+
+		next      = get_wqe(srq, srq->head);
+		srq->head = be16_to_cpu(next->next_wqe_index);
+		scat      = (struct mlx5_wqe_data_seg *)(next + 1);
+
+		for (i = 0; i < wr->num_sge; i++) {
+			scat[i].byte_count = cpu_to_be32(wr->sg_list[i].length);
+			scat[i].lkey       = cpu_to_be32(wr->sg_list[i].lkey);
+			scat[i].addr       = cpu_to_be64(wr->sg_list[i].addr);
+		}
+
+		if (i < srq->msrq.max_avail_gather) {
+			scat[i].byte_count = 0;
+			scat[i].lkey       = cpu_to_be32(MLX5_INVALID_LKEY);
+			scat[i].addr       = 0;
+		}
+	}
+
+	if (likely(nreq)) {
+		srq->wqe_ctr += nreq;
+
+		/* Make sure that descriptors are written before
+		 * doorbell record.
+		 */
+		wmb();
+
+		*srq->db.db = cpu_to_be32(srq->wqe_ctr);
+	}
+
+	spin_unlock_irqrestore(&srq->lock, flags);
+
+	return err;
+}
diff --git a/drivers/infiniband/hw/mlx5/user.h b/drivers/infiniband/hw/mlx5/user.h
new file mode 100644
index 0000000..a886de3
--- /dev/null
+++ b/drivers/infiniband/hw/mlx5/user.h
@@ -0,0 +1,121 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_IB_USER_H
+#define MLX5_IB_USER_H
+
+#include <linux/types.h>
+
+enum {
+	MLX5_QP_FLAG_SIGNATURE		= 1 << 0,
+	MLX5_QP_FLAG_SCATTER_CQE	= 1 << 1,
+};
+
+enum {
+	MLX5_SRQ_FLAG_SIGNATURE		= 1 << 0,
+};
+
+
+/* Increment this value if any changes that break userspace ABI
+ * compatibility are made.
+ */
+#define MLX5_IB_UVERBS_ABI_VERSION	1
+
+/* Make sure that all structs defined in this file remain laid out so
+ * that they pack the same way on 32-bit and 64-bit architectures (to
+ * avoid incompatibility between 32-bit userspace and 64-bit kernels).
+ * In particular do not use pointer types -- pass pointers in __u64
+ * instead.
+ */
+
+struct mlx5_ib_alloc_ucontext_req {
+	__u32	total_num_uuars;
+	__u32	num_low_latency_uuars;
+};
+
+struct mlx5_ib_alloc_ucontext_resp {
+	__u32	qp_tab_size;
+	__u32	bf_reg_size;
+	__u32	tot_uuars;
+	__u32	cache_line_size;
+	__u16	max_sq_desc_sz;
+	__u16	max_rq_desc_sz;
+	__u32	max_send_wqebb;
+	__u32	max_recv_wr;
+	__u32	max_srq_recv_wr;
+	__u16	num_ports;
+	__u16	reserved;
+};
+
+struct mlx5_ib_alloc_pd_resp {
+	__u32	pdn;
+};
+
+struct mlx5_ib_create_cq {
+	__u64	buf_addr;
+	__u64	db_addr;
+	__u32	cqe_size;
+};
+
+struct mlx5_ib_create_cq_resp {
+	__u32	cqn;
+	__u32	reserved;
+};
+
+struct mlx5_ib_resize_cq {
+	__u64	buf_addr;
+};
+
+struct mlx5_ib_create_srq {
+	__u64	buf_addr;
+	__u64	db_addr;
+	__u32	flags;
+};
+
+struct mlx5_ib_create_srq_resp {
+	__u32	srqn;
+	__u32	reserved;
+};
+
+struct mlx5_ib_create_qp {
+	__u64	buf_addr;
+	__u64	db_addr;
+	__u32	sq_wqe_count;
+	__u32	rq_wqe_count;
+	__u32	rq_wqe_shift;
+	__u32	flags;
+};
+
+struct mlx5_ib_create_qp_resp {
+	__u32	uuar_index;
+};
+#endif /* MLX5_IB_USER_H */
diff --git a/drivers/net/ethernet/mellanox/Kconfig b/drivers/net/ethernet/mellanox/Kconfig
index bcdbc14..8cf7563 100644
--- a/drivers/net/ethernet/mellanox/Kconfig
+++ b/drivers/net/ethernet/mellanox/Kconfig
@@ -19,5 +19,6 @@ config NET_VENDOR_MELLANOX
 if NET_VENDOR_MELLANOX
 
 source "drivers/net/ethernet/mellanox/mlx4/Kconfig"
+source "drivers/net/ethernet/mellanox/mlx5/core/Kconfig"
 
 endif # NET_VENDOR_MELLANOX
diff --git a/drivers/net/ethernet/mellanox/Makefile b/drivers/net/ethernet/mellanox/Makefile
index 37afb96..38fe32e 100644
--- a/drivers/net/ethernet/mellanox/Makefile
+++ b/drivers/net/ethernet/mellanox/Makefile
@@ -3,3 +3,4 @@
 #
 
 obj-$(CONFIG_MLX4_CORE) += mlx4/
+obj-$(CONFIG_MLX5_CORE) += mlx5/core/
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/Kconfig b/drivers/net/ethernet/mellanox/mlx5/core/Kconfig
new file mode 100644
index 0000000..2196282
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/Kconfig
@@ -0,0 +1,18 @@
+#
+# Mellanox driver configuration
+#
+
+config MLX5_CORE
+	tristate
+	depends on PCI && X86
+	default n
+
+config MLX5_DEBUG
+	bool "Verbose debugging output" if (MLX5_CORE && EXPERT)
+	depends on MLX5_CORE
+	default y
+	---help---
+	  This option causes debugging code to be compiled into the
+	  mlx5_core driver.  The output can be turned on via the
+	  debug_mask module parameter (which can also be set after
+	  the driver is loaded through sysfs).
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/Makefile b/drivers/net/ethernet/mellanox/mlx5/core/Makefile
new file mode 100644
index 0000000..105780b
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/Makefile
@@ -0,0 +1,5 @@
+obj-$(CONFIG_MLX5_CORE)		+= mlx5_core.o
+
+mlx5_core-y :=	main.o cmd.o debugfs.o fw.o eq.o uar.o pagealloc.o \
+		health.o mcg.o cq.o srq.o alloc.o qp.o port.o mr.o pd.o   \
+		mad.o
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/alloc.c b/drivers/net/ethernet/mellanox/mlx5/core/alloc.c
new file mode 100644
index 0000000..b215742
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/alloc.c
@@ -0,0 +1,238 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/errno.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/export.h>
+#include <linux/bitmap.h>
+#include <linux/dma-mapping.h>
+#include <linux/vmalloc.h>
+#include <linux/mlx5/driver.h>
+
+#include "mlx5_core.h"
+
+/* Handling for queue buffers -- we allocate a bunch of memory and
+ * register it in a memory region at HCA virtual address 0.  If the
+ * requested size is > max_direct, we split the allocation into
+ * multiple pages, so we don't require too much contiguous memory.
+ */
+
+int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, int max_direct,
+		   struct mlx5_buf *buf)
+{
+	dma_addr_t t;
+
+	buf->size = size;
+	if (size <= max_direct) {
+		buf->nbufs        = 1;
+		buf->npages       = 1;
+		buf->page_shift   = get_order(size) + PAGE_SHIFT;
+		buf->direct.buf   = dma_zalloc_coherent(&dev->pdev->dev,
+							size, &t, GFP_KERNEL);
+		if (!buf->direct.buf)
+			return -ENOMEM;
+
+		buf->direct.map = t;
+
+		while (t & ((1 << buf->page_shift) - 1)) {
+			--buf->page_shift;
+			buf->npages *= 2;
+		}
+	} else {
+		int i;
+
+		buf->direct.buf  = NULL;
+		buf->nbufs       = (size + PAGE_SIZE - 1) / PAGE_SIZE;
+		buf->npages      = buf->nbufs;
+		buf->page_shift  = PAGE_SHIFT;
+		buf->page_list   = kcalloc(buf->nbufs, sizeof(*buf->page_list),
+					   GFP_KERNEL);
+		if (!buf->page_list)
+			return -ENOMEM;
+
+		for (i = 0; i < buf->nbufs; i++) {
+			buf->page_list[i].buf =
+				dma_zalloc_coherent(&dev->pdev->dev, PAGE_SIZE,
+						    &t, GFP_KERNEL);
+			if (!buf->page_list[i].buf)
+				goto err_free;
+
+			buf->page_list[i].map = t;
+		}
+
+		if (BITS_PER_LONG == 64) {
+			struct page **pages;
+			pages = kmalloc(sizeof(*pages) * buf->nbufs, GFP_KERNEL);
+			if (!pages)
+				goto err_free;
+			for (i = 0; i < buf->nbufs; i++)
+				pages[i] = virt_to_page(buf->page_list[i].buf);
+			buf->direct.buf = vmap(pages, buf->nbufs, VM_MAP, PAGE_KERNEL);
+			kfree(pages);
+			if (!buf->direct.buf)
+				goto err_free;
+		}
+	}
+
+	return 0;
+
+err_free:
+	mlx5_buf_free(dev, buf);
+
+	return -ENOMEM;
+}
+EXPORT_SYMBOL_GPL(mlx5_buf_alloc);
+
+void mlx5_buf_free(struct mlx5_core_dev *dev, struct mlx5_buf *buf)
+{
+	int i;
+
+	if (buf->nbufs == 1)
+		dma_free_coherent(&dev->pdev->dev, buf->size, buf->direct.buf,
+				  buf->direct.map);
+	else {
+		if (BITS_PER_LONG == 64 && buf->direct.buf)
+			vunmap(buf->direct.buf);
+
+		for (i = 0; i < buf->nbufs; i++)
+			if (buf->page_list[i].buf)
+				dma_free_coherent(&dev->pdev->dev, PAGE_SIZE,
+						  buf->page_list[i].buf,
+						  buf->page_list[i].map);
+		kfree(buf->page_list);
+	}
+}
+EXPORT_SYMBOL_GPL(mlx5_buf_free);
+
+static struct mlx5_db_pgdir *mlx5_alloc_db_pgdir(struct device *dma_device)
+{
+	struct mlx5_db_pgdir *pgdir;
+
+	pgdir = kzalloc(sizeof(*pgdir), GFP_KERNEL);
+	if (!pgdir)
+		return NULL;
+
+	bitmap_fill(pgdir->bitmap, MLX5_DB_PER_PAGE);
+	pgdir->db_page = dma_alloc_coherent(dma_device, PAGE_SIZE,
+					    &pgdir->db_dma, GFP_KERNEL);
+	if (!pgdir->db_page) {
+		kfree(pgdir);
+		return NULL;
+	}
+
+	return pgdir;
+}
+
+static int mlx5_alloc_db_from_pgdir(struct mlx5_db_pgdir *pgdir,
+				    struct mlx5_db *db)
+{
+	int offset;
+	int i;
+
+	i = find_first_bit(pgdir->bitmap, MLX5_DB_PER_PAGE);
+	if (i >= MLX5_DB_PER_PAGE)
+		return -ENOMEM;
+
+	__clear_bit(i, pgdir->bitmap);
+
+	db->u.pgdir = pgdir;
+	db->index   = i;
+	offset = db->index * L1_CACHE_BYTES;
+	db->db      = pgdir->db_page + offset / sizeof(*pgdir->db_page);
+	db->dma     = pgdir->db_dma  + offset;
+
+	return 0;
+}
+
+int mlx5_db_alloc(struct mlx5_core_dev *dev, struct mlx5_db *db)
+{
+	struct mlx5_db_pgdir *pgdir;
+	int ret = 0;
+
+	mutex_lock(&dev->priv.pgdir_mutex);
+
+	list_for_each_entry(pgdir, &dev->priv.pgdir_list, list)
+		if (!mlx5_alloc_db_from_pgdir(pgdir, db))
+			goto out;
+
+	pgdir = mlx5_alloc_db_pgdir(&(dev->pdev->dev));
+	if (!pgdir) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	list_add(&pgdir->list, &dev->priv.pgdir_list);
+
+	/* This should never fail -- we just allocated an empty page: */
+	WARN_ON(mlx5_alloc_db_from_pgdir(pgdir, db));
+
+out:
+	mutex_unlock(&dev->priv.pgdir_mutex);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(mlx5_db_alloc);
+
+void mlx5_db_free(struct mlx5_core_dev *dev, struct mlx5_db *db)
+{
+	mutex_lock(&dev->priv.pgdir_mutex);
+
+	__set_bit(db->index, db->u.pgdir->bitmap);
+
+	if (bitmap_full(db->u.pgdir->bitmap, MLX5_DB_PER_PAGE)) {
+		dma_free_coherent(&(dev->pdev->dev), PAGE_SIZE,
+				  db->u.pgdir->db_page, db->u.pgdir->db_dma);
+		list_del(&db->u.pgdir->list);
+		kfree(db->u.pgdir);
+	}
+
+	mutex_unlock(&dev->priv.pgdir_mutex);
+}
+EXPORT_SYMBOL_GPL(mlx5_db_free);
+
+
+void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas)
+{
+	u64 addr;
+	int i;
+
+	for (i = 0; i < buf->npages; i++) {
+		if (buf->nbufs == 1)
+			addr = buf->direct.map + (i << buf->page_shift);
+		else
+			addr = buf->page_list[i].map;
+
+		pas[i] = cpu_to_be64(addr);
+	}
+}
+EXPORT_SYMBOL_GPL(mlx5_fill_page_array);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/cmd.c b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c
new file mode 100644
index 0000000..c1c0eef
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c
@@ -0,0 +1,1515 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <asm-generic/kmap_types.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/pci.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+#include <linux/random.h>
+#include <linux/io-mapping.h>
+#include <linux/mlx5/driver.h>
+#include <linux/debugfs.h>
+
+#include "mlx5_core.h"
+
+enum {
+	CMD_IF_REV = 3,
+};
+
+enum {
+	CMD_MODE_POLLING,
+	CMD_MODE_EVENTS
+};
+
+enum {
+	NUM_LONG_LISTS	  = 2,
+	NUM_MED_LISTS	  = 64,
+	LONG_LIST_SIZE	  = (2ULL * 1024 * 1024 * 1024 / PAGE_SIZE) * 8 + 16 +
+				MLX5_CMD_DATA_BLOCK_SIZE,
+	MED_LIST_SIZE	  = 16 + MLX5_CMD_DATA_BLOCK_SIZE,
+};
+
+enum {
+	MLX5_CMD_DELIVERY_STAT_OK			= 0x0,
+	MLX5_CMD_DELIVERY_STAT_SIGNAT_ERR		= 0x1,
+	MLX5_CMD_DELIVERY_STAT_TOK_ERR			= 0x2,
+	MLX5_CMD_DELIVERY_STAT_BAD_BLK_NUM_ERR		= 0x3,
+	MLX5_CMD_DELIVERY_STAT_OUT_PTR_ALIGN_ERR	= 0x4,
+	MLX5_CMD_DELIVERY_STAT_IN_PTR_ALIGN_ERR		= 0x5,
+	MLX5_CMD_DELIVERY_STAT_FW_ERR			= 0x6,
+	MLX5_CMD_DELIVERY_STAT_IN_LENGTH_ERR		= 0x7,
+	MLX5_CMD_DELIVERY_STAT_OUT_LENGTH_ERR		= 0x8,
+	MLX5_CMD_DELIVERY_STAT_RES_FLD_NOT_CLR_ERR	= 0x9,
+	MLX5_CMD_DELIVERY_STAT_CMD_DESCR_ERR		= 0x10,
+};
+
+enum {
+	MLX5_CMD_STAT_OK			= 0x0,
+	MLX5_CMD_STAT_INT_ERR			= 0x1,
+	MLX5_CMD_STAT_BAD_OP_ERR		= 0x2,
+	MLX5_CMD_STAT_BAD_PARAM_ERR		= 0x3,
+	MLX5_CMD_STAT_BAD_SYS_STATE_ERR		= 0x4,
+	MLX5_CMD_STAT_BAD_RES_ERR		= 0x5,
+	MLX5_CMD_STAT_RES_BUSY			= 0x6,
+	MLX5_CMD_STAT_LIM_ERR			= 0x8,
+	MLX5_CMD_STAT_BAD_RES_STATE_ERR		= 0x9,
+	MLX5_CMD_STAT_IX_ERR			= 0xa,
+	MLX5_CMD_STAT_NO_RES_ERR		= 0xf,
+	MLX5_CMD_STAT_BAD_INP_LEN_ERR		= 0x50,
+	MLX5_CMD_STAT_BAD_OUTP_LEN_ERR		= 0x51,
+	MLX5_CMD_STAT_BAD_QP_STATE_ERR		= 0x10,
+	MLX5_CMD_STAT_BAD_PKT_ERR		= 0x30,
+	MLX5_CMD_STAT_BAD_SIZE_OUTS_CQES_ERR	= 0x40,
+};
+
+static struct mlx5_cmd_work_ent *alloc_cmd(struct mlx5_cmd *cmd,
+					   struct mlx5_cmd_msg *in,
+					   struct mlx5_cmd_msg *out,
+					   mlx5_cmd_cbk_t cbk,
+					   void *context, int page_queue)
+{
+	gfp_t alloc_flags = cbk ? GFP_ATOMIC : GFP_KERNEL;
+	struct mlx5_cmd_work_ent *ent;
+
+	ent = kzalloc(sizeof(*ent), alloc_flags);
+	if (!ent)
+		return ERR_PTR(-ENOMEM);
+
+	ent->in		= in;
+	ent->out	= out;
+	ent->callback	= cbk;
+	ent->context	= context;
+	ent->cmd	= cmd;
+	ent->page_queue = page_queue;
+
+	return ent;
+}
+
+static u8 alloc_token(struct mlx5_cmd *cmd)
+{
+	u8 token;
+
+	spin_lock(&cmd->token_lock);
+	token = cmd->token++ % 255 + 1;
+	spin_unlock(&cmd->token_lock);
+
+	return token;
+}
+
+static int alloc_ent(struct mlx5_cmd *cmd)
+{
+	unsigned long flags;
+	int ret;
+
+	spin_lock_irqsave(&cmd->alloc_lock, flags);
+	ret = find_first_bit(&cmd->bitmask, cmd->max_reg_cmds);
+	if (ret < cmd->max_reg_cmds)
+		clear_bit(ret, &cmd->bitmask);
+	spin_unlock_irqrestore(&cmd->alloc_lock, flags);
+
+	return ret < cmd->max_reg_cmds ? ret : -ENOMEM;
+}
+
+static void free_ent(struct mlx5_cmd *cmd, int idx)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&cmd->alloc_lock, flags);
+	set_bit(idx, &cmd->bitmask);
+	spin_unlock_irqrestore(&cmd->alloc_lock, flags);
+}
+
+static struct mlx5_cmd_layout *get_inst(struct mlx5_cmd *cmd, int idx)
+{
+	return cmd->cmd_buf + (idx << cmd->log_stride);
+}
+
+static u8 xor8_buf(void *buf, int len)
+{
+	u8 *ptr = buf;
+	u8 sum = 0;
+	int i;
+
+	for (i = 0; i < len; i++)
+		sum ^= ptr[i];
+
+	return sum;
+}
+
+static int verify_block_sig(struct mlx5_cmd_prot_block *block)
+{
+	if (xor8_buf(block->rsvd0, sizeof(*block) - sizeof(block->data) - 1) != 0xff)
+		return -EINVAL;
+
+	if (xor8_buf(block, sizeof(*block)) != 0xff)
+		return -EINVAL;
+
+	return 0;
+}
+
+static void calc_block_sig(struct mlx5_cmd_prot_block *block, u8 token)
+{
+	block->token = token;
+	block->ctrl_sig = ~xor8_buf(block->rsvd0, sizeof(*block) - sizeof(block->data) - 2);
+	block->sig = ~xor8_buf(block, sizeof(*block) - 1);
+}
+
+static void calc_chain_sig(struct mlx5_cmd_msg *msg, u8 token)
+{
+	struct mlx5_cmd_mailbox *next = msg->next;
+
+	while (next) {
+		calc_block_sig(next->buf, token);
+		next = next->next;
+	}
+}
+
+static void set_signature(struct mlx5_cmd_work_ent *ent)
+{
+	ent->lay->sig = ~xor8_buf(ent->lay, sizeof(*ent->lay));
+	calc_chain_sig(ent->in, ent->token);
+	calc_chain_sig(ent->out, ent->token);
+}
+
+static void poll_timeout(struct mlx5_cmd_work_ent *ent)
+{
+	unsigned long poll_end = jiffies + msecs_to_jiffies(MLX5_CMD_TIMEOUT_MSEC + 1000);
+	u8 own;
+
+	do {
+		own = ent->lay->status_own;
+		if (!(own & CMD_OWNER_HW)) {
+			ent->ret = 0;
+			return;
+		}
+		usleep_range(5000, 10000);
+	} while (time_before(jiffies, poll_end));
+
+	ent->ret = -ETIMEDOUT;
+}
+
+static void free_cmd(struct mlx5_cmd_work_ent *ent)
+{
+	kfree(ent);
+}
+
+
+static int verify_signature(struct mlx5_cmd_work_ent *ent)
+{
+	struct mlx5_cmd_mailbox *next = ent->out->next;
+	int err;
+	u8 sig;
+
+	sig = xor8_buf(ent->lay, sizeof(*ent->lay));
+	if (sig != 0xff)
+		return -EINVAL;
+
+	while (next) {
+		err = verify_block_sig(next->buf);
+		if (err)
+			return err;
+
+		next = next->next;
+	}
+
+	return 0;
+}
+
+static void dump_buf(void *buf, int size, int data_only, int offset)
+{
+	__be32 *p = buf;
+	int i;
+
+	for (i = 0; i < size; i += 16) {
+		pr_debug("%03x: %08x %08x %08x %08x\n", offset, be32_to_cpu(p[0]),
+			 be32_to_cpu(p[1]), be32_to_cpu(p[2]),
+			 be32_to_cpu(p[3]));
+		p += 4;
+		offset += 16;
+	}
+	if (!data_only)
+		pr_debug("\n");
+}
+
+const char *mlx5_command_str(int command)
+{
+	switch (command) {
+	case MLX5_CMD_OP_QUERY_HCA_CAP:
+		return "QUERY_HCA_CAP";
+
+	case MLX5_CMD_OP_SET_HCA_CAP:
+		return "SET_HCA_CAP";
+
+	case MLX5_CMD_OP_QUERY_ADAPTER:
+		return "QUERY_ADAPTER";
+
+	case MLX5_CMD_OP_INIT_HCA:
+		return "INIT_HCA";
+
+	case MLX5_CMD_OP_TEARDOWN_HCA:
+		return "TEARDOWN_HCA";
+
+	case MLX5_CMD_OP_QUERY_PAGES:
+		return "QUERY_PAGES";
+
+	case MLX5_CMD_OP_MANAGE_PAGES:
+		return "MANAGE_PAGES";
+
+	case MLX5_CMD_OP_CREATE_MKEY:
+		return "CREATE_MKEY";
+
+	case MLX5_CMD_OP_QUERY_MKEY:
+		return "QUERY_MKEY";
+
+	case MLX5_CMD_OP_DESTROY_MKEY:
+		return "DESTROY_MKEY";
+
+	case MLX5_CMD_OP_QUERY_SPECIAL_CONTEXTS:
+		return "QUERY_SPECIAL_CONTEXTS";
+
+	case MLX5_CMD_OP_CREATE_EQ:
+		return "CREATE_EQ";
+
+	case MLX5_CMD_OP_DESTROY_EQ:
+		return "DESTROY_EQ";
+
+	case MLX5_CMD_OP_QUERY_EQ:
+		return "QUERY_EQ";
+
+	case MLX5_CMD_OP_CREATE_CQ:
+		return "CREATE_CQ";
+
+	case MLX5_CMD_OP_DESTROY_CQ:
+		return "DESTROY_CQ";
+
+	case MLX5_CMD_OP_QUERY_CQ:
+		return "QUERY_CQ";
+
+	case MLX5_CMD_OP_MODIFY_CQ:
+		return "MODIFY_CQ";
+
+	case MLX5_CMD_OP_CREATE_QP:
+		return "CREATE_QP";
+
+	case MLX5_CMD_OP_DESTROY_QP:
+		return "DESTROY_QP";
+
+	case MLX5_CMD_OP_RST2INIT_QP:
+		return "RST2INIT_QP";
+
+	case MLX5_CMD_OP_INIT2RTR_QP:
+		return "INIT2RTR_QP";
+
+	case MLX5_CMD_OP_RTR2RTS_QP:
+		return "RTR2RTS_QP";
+
+	case MLX5_CMD_OP_RTS2RTS_QP:
+		return "RTS2RTS_QP";
+
+	case MLX5_CMD_OP_SQERR2RTS_QP:
+		return "SQERR2RTS_QP";
+
+	case MLX5_CMD_OP_2ERR_QP:
+		return "2ERR_QP";
+
+	case MLX5_CMD_OP_RTS2SQD_QP:
+		return "RTS2SQD_QP";
+
+	case MLX5_CMD_OP_SQD2RTS_QP:
+		return "SQD2RTS_QP";
+
+	case MLX5_CMD_OP_2RST_QP:
+		return "2RST_QP";
+
+	case MLX5_CMD_OP_QUERY_QP:
+		return "QUERY_QP";
+
+	case MLX5_CMD_OP_CONF_SQP:
+		return "CONF_SQP";
+
+	case MLX5_CMD_OP_MAD_IFC:
+		return "MAD_IFC";
+
+	case MLX5_CMD_OP_INIT2INIT_QP:
+		return "INIT2INIT_QP";
+
+	case MLX5_CMD_OP_SUSPEND_QP:
+		return "SUSPEND_QP";
+
+	case MLX5_CMD_OP_UNSUSPEND_QP:
+		return "UNSUSPEND_QP";
+
+	case MLX5_CMD_OP_SQD2SQD_QP:
+		return "SQD2SQD_QP";
+
+	case MLX5_CMD_OP_ALLOC_QP_COUNTER_SET:
+		return "ALLOC_QP_COUNTER_SET";
+
+	case MLX5_CMD_OP_DEALLOC_QP_COUNTER_SET:
+		return "DEALLOC_QP_COUNTER_SET";
+
+	case MLX5_CMD_OP_QUERY_QP_COUNTER_SET:
+		return "QUERY_QP_COUNTER_SET";
+
+	case MLX5_CMD_OP_CREATE_PSV:
+		return "CREATE_PSV";
+
+	case MLX5_CMD_OP_DESTROY_PSV:
+		return "DESTROY_PSV";
+
+	case MLX5_CMD_OP_QUERY_PSV:
+		return "QUERY_PSV";
+
+	case MLX5_CMD_OP_QUERY_SIG_RULE_TABLE:
+		return "QUERY_SIG_RULE_TABLE";
+
+	case MLX5_CMD_OP_QUERY_BLOCK_SIZE_TABLE:
+		return "QUERY_BLOCK_SIZE_TABLE";
+
+	case MLX5_CMD_OP_CREATE_SRQ:
+		return "CREATE_SRQ";
+
+	case MLX5_CMD_OP_DESTROY_SRQ:
+		return "DESTROY_SRQ";
+
+	case MLX5_CMD_OP_QUERY_SRQ:
+		return "QUERY_SRQ";
+
+	case MLX5_CMD_OP_ARM_RQ:
+		return "ARM_RQ";
+
+	case MLX5_CMD_OP_RESIZE_SRQ:
+		return "RESIZE_SRQ";
+
+	case MLX5_CMD_OP_ALLOC_PD:
+		return "ALLOC_PD";
+
+	case MLX5_CMD_OP_DEALLOC_PD:
+		return "DEALLOC_PD";
+
+	case MLX5_CMD_OP_ALLOC_UAR:
+		return "ALLOC_UAR";
+
+	case MLX5_CMD_OP_DEALLOC_UAR:
+		return "DEALLOC_UAR";
+
+	case MLX5_CMD_OP_ATTACH_TO_MCG:
+		return "ATTACH_TO_MCG";
+
+	case MLX5_CMD_OP_DETACH_FROM_MCG:
+		return "DETACH_FROM_MCG";
+
+	case MLX5_CMD_OP_ALLOC_XRCD:
+		return "ALLOC_XRCD";
+
+	case MLX5_CMD_OP_DEALLOC_XRCD:
+		return "DEALLOC_XRCD";
+
+	case MLX5_CMD_OP_ACCESS_REG:
+		return "MLX5_CMD_OP_ACCESS_REG";
+
+	default: return "unknown command opcode";
+	}
+}
+
+static void dump_command(struct mlx5_core_dev *dev,
+			 struct mlx5_cmd_work_ent *ent, int input)
+{
+	u16 op = be16_to_cpu(((struct mlx5_inbox_hdr *)(ent->lay->in))->opcode);
+	struct mlx5_cmd_msg *msg = input ? ent->in : ent->out;
+	struct mlx5_cmd_mailbox *next = msg->next;
+	int data_only;
+	int offset = 0;
+	int dump_len;
+
+	data_only = !!(mlx5_core_debug_mask & (1 << MLX5_CMD_DATA));
+
+	if (data_only)
+		mlx5_core_dbg_mask(dev, 1 << MLX5_CMD_DATA,
+				   "dump command data %s(0x%x) %s\n",
+				   mlx5_command_str(op), op,
+				   input ? "INPUT" : "OUTPUT");
+	else
+		mlx5_core_dbg(dev, "dump command %s(0x%x) %s\n",
+			      mlx5_command_str(op), op,
+			      input ? "INPUT" : "OUTPUT");
+
+	if (data_only) {
+		if (input) {
+			dump_buf(ent->lay->in, sizeof(ent->lay->in), 1, offset);
+			offset += sizeof(ent->lay->in);
+		} else {
+			dump_buf(ent->lay->out, sizeof(ent->lay->out), 1, offset);
+			offset += sizeof(ent->lay->out);
+		}
+	} else {
+		dump_buf(ent->lay, sizeof(*ent->lay), 0, offset);
+		offset += sizeof(*ent->lay);
+	}
+
+	while (next && offset < msg->len) {
+		if (data_only) {
+			dump_len = min_t(int, MLX5_CMD_DATA_BLOCK_SIZE, msg->len - offset);
+			dump_buf(next->buf, dump_len, 1, offset);
+			offset += MLX5_CMD_DATA_BLOCK_SIZE;
+		} else {
+			mlx5_core_dbg(dev, "command block:\n");
+			dump_buf(next->buf, sizeof(struct mlx5_cmd_prot_block), 0, offset);
+			offset += sizeof(struct mlx5_cmd_prot_block);
+		}
+		next = next->next;
+	}
+
+	if (data_only)
+		pr_debug("\n");
+}
+
+static void cmd_work_handler(struct work_struct *work)
+{
+	struct mlx5_cmd_work_ent *ent = container_of(work, struct mlx5_cmd_work_ent, work);
+	struct mlx5_cmd *cmd = ent->cmd;
+	struct mlx5_core_dev *dev = container_of(cmd, struct mlx5_core_dev, cmd);
+	struct mlx5_cmd_layout *lay;
+	struct semaphore *sem;
+
+	sem = ent->page_queue ? &cmd->pages_sem : &cmd->sem;
+	down(sem);
+	if (!ent->page_queue) {
+		ent->idx = alloc_ent(cmd);
+		if (ent->idx < 0) {
+			mlx5_core_err(dev, "failed to allocate command entry\n");
+			up(sem);
+			return;
+		}
+	} else {
+		ent->idx = cmd->max_reg_cmds;
+	}
+
+	ent->token = alloc_token(cmd);
+	cmd->ent_arr[ent->idx] = ent;
+	lay = get_inst(cmd, ent->idx);
+	ent->lay = lay;
+	memset(lay, 0, sizeof(*lay));
+	memcpy(lay->in, ent->in->first.data, sizeof(lay->in));
+	if (ent->in->next)
+		lay->in_ptr = cpu_to_be64(ent->in->next->dma);
+	lay->inlen = cpu_to_be32(ent->in->len);
+	if (ent->out->next)
+		lay->out_ptr = cpu_to_be64(ent->out->next->dma);
+	lay->outlen = cpu_to_be32(ent->out->len);
+	lay->type = MLX5_PCI_CMD_XPORT;
+	lay->token = ent->token;
+	lay->status_own = CMD_OWNER_HW;
+	if (!cmd->checksum_disabled)
+		set_signature(ent);
+	dump_command(dev, ent, 1);
+	ktime_get_ts(&ent->ts1);
+
+	/* ring doorbell after the descriptor is valid */
+	wmb();
+	iowrite32be(1 << ent->idx, &dev->iseg->cmd_dbell);
+	mlx5_core_dbg(dev, "write 0x%x to command doorbell\n", 1 << ent->idx);
+	mmiowb();
+	if (cmd->mode == CMD_MODE_POLLING) {
+		poll_timeout(ent);
+		/* make sure we read the descriptor after ownership is SW */
+		rmb();
+		mlx5_cmd_comp_handler(dev, 1UL << ent->idx);
+	}
+}
+
+static const char *deliv_status_to_str(u8 status)
+{
+	switch (status) {
+	case MLX5_CMD_DELIVERY_STAT_OK:
+		return "no errors";
+	case MLX5_CMD_DELIVERY_STAT_SIGNAT_ERR:
+		return "signature error";
+	case MLX5_CMD_DELIVERY_STAT_TOK_ERR:
+		return "token error";
+	case MLX5_CMD_DELIVERY_STAT_BAD_BLK_NUM_ERR:
+		return "bad block number";
+	case MLX5_CMD_DELIVERY_STAT_OUT_PTR_ALIGN_ERR:
+		return "output pointer not aligned to block size";
+	case MLX5_CMD_DELIVERY_STAT_IN_PTR_ALIGN_ERR:
+		return "input pointer not aligned to block size";
+	case MLX5_CMD_DELIVERY_STAT_FW_ERR:
+		return "firmware internal error";
+	case MLX5_CMD_DELIVERY_STAT_IN_LENGTH_ERR:
+		return "command input length error";
+	case MLX5_CMD_DELIVERY_STAT_OUT_LENGTH_ERR:
+		return "command ouput length error";
+	case MLX5_CMD_DELIVERY_STAT_RES_FLD_NOT_CLR_ERR:
+		return "reserved fields not cleared";
+	case MLX5_CMD_DELIVERY_STAT_CMD_DESCR_ERR:
+		return "bad command descriptor type";
+	default:
+		return "unknown status code";
+	}
+}
+
+static u16 msg_to_opcode(struct mlx5_cmd_msg *in)
+{
+	struct mlx5_inbox_hdr *hdr = (struct mlx5_inbox_hdr *)(in->first.data);
+
+	return be16_to_cpu(hdr->opcode);
+}
+
+static int wait_func(struct mlx5_core_dev *dev, struct mlx5_cmd_work_ent *ent)
+{
+	unsigned long timeout = msecs_to_jiffies(MLX5_CMD_TIMEOUT_MSEC);
+	struct mlx5_cmd *cmd = &dev->cmd;
+	int err;
+
+	if (cmd->mode == CMD_MODE_POLLING) {
+		wait_for_completion(&ent->done);
+		err = ent->ret;
+	} else {
+		if (!wait_for_completion_timeout(&ent->done, timeout))
+			err = -ETIMEDOUT;
+		else
+			err = 0;
+	}
+	if (err == -ETIMEDOUT) {
+		mlx5_core_warn(dev, "%s(0x%x) timeout. Will cause a leak of a command resource\n",
+			       mlx5_command_str(msg_to_opcode(ent->in)),
+			       msg_to_opcode(ent->in));
+	}
+	mlx5_core_dbg(dev, "err %d, delivery status %s(%d)\n", err,
+		      deliv_status_to_str(ent->status), ent->status);
+
+	return err;
+}
+
+/*  Notes:
+ *    1. Callback functions may not sleep
+ *    2. page queue commands do not support asynchrous completion
+ */
+static int mlx5_cmd_invoke(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *in,
+			   struct mlx5_cmd_msg *out, mlx5_cmd_cbk_t callback,
+			   void *context, int page_queue, u8 *status)
+{
+	struct mlx5_cmd *cmd = &dev->cmd;
+	struct mlx5_cmd_work_ent *ent;
+	ktime_t t1, t2, delta;
+	struct mlx5_cmd_stats *stats;
+	int err = 0;
+	s64 ds;
+	u16 op;
+
+	if (callback && page_queue)
+		return -EINVAL;
+
+	ent = alloc_cmd(cmd, in, out, callback, context, page_queue);
+	if (IS_ERR(ent))
+		return PTR_ERR(ent);
+
+	if (!callback)
+		init_completion(&ent->done);
+
+	INIT_WORK(&ent->work, cmd_work_handler);
+	if (page_queue) {
+		cmd_work_handler(&ent->work);
+	} else if (!queue_work(cmd->wq, &ent->work)) {
+		mlx5_core_warn(dev, "failed to queue work\n");
+		err = -ENOMEM;
+		goto out_free;
+	}
+
+	if (!callback) {
+		err = wait_func(dev, ent);
+		if (err == -ETIMEDOUT)
+			goto out;
+
+		t1 = timespec_to_ktime(ent->ts1);
+		t2 = timespec_to_ktime(ent->ts2);
+		delta = ktime_sub(t2, t1);
+		ds = ktime_to_ns(delta);
+		op = be16_to_cpu(((struct mlx5_inbox_hdr *)in->first.data)->opcode);
+		if (op < ARRAY_SIZE(cmd->stats)) {
+			stats = &cmd->stats[op];
+			spin_lock(&stats->lock);
+			stats->sum += ds;
+			++stats->n;
+			spin_unlock(&stats->lock);
+		}
+		mlx5_core_dbg_mask(dev, 1 << MLX5_CMD_TIME,
+				   "fw exec time for %s is %lld nsec\n",
+				   mlx5_command_str(op), ds);
+		*status = ent->status;
+		free_cmd(ent);
+	}
+
+	return err;
+
+out_free:
+	free_cmd(ent);
+out:
+	return err;
+}
+
+static ssize_t dbg_write(struct file *filp, const char __user *buf,
+			 size_t count, loff_t *pos)
+{
+	struct mlx5_core_dev *dev = filp->private_data;
+	struct mlx5_cmd_debug *dbg = &dev->cmd.dbg;
+	char lbuf[3];
+	int err;
+
+	if (!dbg->in_msg || !dbg->out_msg)
+		return -ENOMEM;
+
+	if (copy_from_user(lbuf, buf, sizeof(lbuf)))
+		return -EPERM;
+
+	lbuf[sizeof(lbuf) - 1] = 0;
+
+	if (strcmp(lbuf, "go"))
+		return -EINVAL;
+
+	err = mlx5_cmd_exec(dev, dbg->in_msg, dbg->inlen, dbg->out_msg, dbg->outlen);
+
+	return err ? err : count;
+}
+
+
+static const struct file_operations fops = {
+	.owner	= THIS_MODULE,
+	.open	= simple_open,
+	.write	= dbg_write,
+};
+
+static int mlx5_copy_to_msg(struct mlx5_cmd_msg *to, void *from, int size)
+{
+	struct mlx5_cmd_prot_block *block;
+	struct mlx5_cmd_mailbox *next;
+	int copy;
+
+	if (!to || !from)
+		return -ENOMEM;
+
+	copy = min_t(int, size, sizeof(to->first.data));
+	memcpy(to->first.data, from, copy);
+	size -= copy;
+	from += copy;
+
+	next = to->next;
+	while (size) {
+		if (!next) {
+			/* this is a BUG */
+			return -ENOMEM;
+		}
+
+		copy = min_t(int, size, MLX5_CMD_DATA_BLOCK_SIZE);
+		block = next->buf;
+		memcpy(block->data, from, copy);
+		from += copy;
+		size -= copy;
+		next = next->next;
+	}
+
+	return 0;
+}
+
+static int mlx5_copy_from_msg(void *to, struct mlx5_cmd_msg *from, int size)
+{
+	struct mlx5_cmd_prot_block *block;
+	struct mlx5_cmd_mailbox *next;
+	int copy;
+
+	if (!to || !from)
+		return -ENOMEM;
+
+	copy = min_t(int, size, sizeof(from->first.data));
+	memcpy(to, from->first.data, copy);
+	size -= copy;
+	to += copy;
+
+	next = from->next;
+	while (size) {
+		if (!next) {
+			/* this is a BUG */
+			return -ENOMEM;
+		}
+
+		copy = min_t(int, size, MLX5_CMD_DATA_BLOCK_SIZE);
+		block = next->buf;
+		if (xor8_buf(block, sizeof(*block)) != 0xff)
+			return -EINVAL;
+
+		memcpy(to, block->data, copy);
+		to += copy;
+		size -= copy;
+		next = next->next;
+	}
+
+	return 0;
+}
+
+static struct mlx5_cmd_mailbox *alloc_cmd_box(struct mlx5_core_dev *dev,
+					      gfp_t flags)
+{
+	struct mlx5_cmd_mailbox *mailbox;
+
+	mailbox = kmalloc(sizeof(*mailbox), flags);
+	if (!mailbox)
+		return ERR_PTR(-ENOMEM);
+
+	mailbox->buf = pci_pool_alloc(dev->cmd.pool, flags,
+				      &mailbox->dma);
+	if (!mailbox->buf) {
+		mlx5_core_dbg(dev, "failed allocation\n");
+		kfree(mailbox);
+		return ERR_PTR(-ENOMEM);
+	}
+	memset(mailbox->buf, 0, sizeof(struct mlx5_cmd_prot_block));
+	mailbox->next = NULL;
+
+	return mailbox;
+}
+
+static void free_cmd_box(struct mlx5_core_dev *dev,
+			 struct mlx5_cmd_mailbox *mailbox)
+{
+	pci_pool_free(dev->cmd.pool, mailbox->buf, mailbox->dma);
+	kfree(mailbox);
+}
+
+static struct mlx5_cmd_msg *mlx5_alloc_cmd_msg(struct mlx5_core_dev *dev,
+					       gfp_t flags, int size)
+{
+	struct mlx5_cmd_mailbox *tmp, *head = NULL;
+	struct mlx5_cmd_prot_block *block;
+	struct mlx5_cmd_msg *msg;
+	int blen;
+	int err;
+	int n;
+	int i;
+
+	msg = kzalloc(sizeof(*msg), GFP_KERNEL);
+	if (!msg)
+		return ERR_PTR(-ENOMEM);
+
+	blen = size - min_t(int, sizeof(msg->first.data), size);
+	n = (blen + MLX5_CMD_DATA_BLOCK_SIZE - 1) / MLX5_CMD_DATA_BLOCK_SIZE;
+
+	for (i = 0; i < n; i++) {
+		tmp = alloc_cmd_box(dev, flags);
+		if (IS_ERR(tmp)) {
+			mlx5_core_warn(dev, "failed allocating block\n");
+			err = PTR_ERR(tmp);
+			goto err_alloc;
+		}
+
+		block = tmp->buf;
+		tmp->next = head;
+		block->next = cpu_to_be64(tmp->next ? tmp->next->dma : 0);
+		block->block_num = cpu_to_be32(n - i - 1);
+		head = tmp;
+	}
+	msg->next = head;
+	msg->len = size;
+	return msg;
+
+err_alloc:
+	while (head) {
+		tmp = head->next;
+		free_cmd_box(dev, head);
+		head = tmp;
+	}
+	kfree(msg);
+
+	return ERR_PTR(err);
+}
+
+static void mlx5_free_cmd_msg(struct mlx5_core_dev *dev,
+				  struct mlx5_cmd_msg *msg)
+{
+	struct mlx5_cmd_mailbox *head = msg->next;
+	struct mlx5_cmd_mailbox *next;
+
+	while (head) {
+		next = head->next;
+		free_cmd_box(dev, head);
+		head = next;
+	}
+	kfree(msg);
+}
+
+static ssize_t data_write(struct file *filp, const char __user *buf,
+			  size_t count, loff_t *pos)
+{
+	struct mlx5_core_dev *dev = filp->private_data;
+	struct mlx5_cmd_debug *dbg = &dev->cmd.dbg;
+	void *ptr;
+	int err;
+
+	if (*pos != 0)
+		return -EINVAL;
+
+	kfree(dbg->in_msg);
+	dbg->in_msg = NULL;
+	dbg->inlen = 0;
+
+	ptr = kzalloc(count, GFP_KERNEL);
+	if (!ptr)
+		return -ENOMEM;
+
+	if (copy_from_user(ptr, buf, count)) {
+		err = -EPERM;
+		goto out;
+	}
+	dbg->in_msg = ptr;
+	dbg->inlen = count;
+
+	*pos = count;
+
+	return count;
+
+out:
+	kfree(ptr);
+	return err;
+}
+
+static ssize_t data_read(struct file *filp, char __user *buf, size_t count,
+			 loff_t *pos)
+{
+	struct mlx5_core_dev *dev = filp->private_data;
+	struct mlx5_cmd_debug *dbg = &dev->cmd.dbg;
+	int copy;
+
+	if (*pos)
+		return 0;
+
+	if (!dbg->out_msg)
+		return -ENOMEM;
+
+	copy = min_t(int, count, dbg->outlen);
+	if (copy_to_user(buf, dbg->out_msg, copy))
+		return -EPERM;
+
+	*pos += copy;
+
+	return copy;
+}
+
+static const struct file_operations dfops = {
+	.owner	= THIS_MODULE,
+	.open	= simple_open,
+	.write	= data_write,
+	.read	= data_read,
+};
+
+static ssize_t outlen_read(struct file *filp, char __user *buf, size_t count,
+			   loff_t *pos)
+{
+	struct mlx5_core_dev *dev = filp->private_data;
+	struct mlx5_cmd_debug *dbg = &dev->cmd.dbg;
+	char outlen[8];
+	int err;
+
+	if (*pos)
+		return 0;
+
+	err = snprintf(outlen, sizeof(outlen), "%d", dbg->outlen);
+	if (err < 0)
+		return err;
+
+	if (copy_to_user(buf, &outlen, err))
+		return -EPERM;
+
+	*pos += err;
+
+	return err;
+}
+
+static ssize_t outlen_write(struct file *filp, const char __user *buf,
+			    size_t count, loff_t *pos)
+{
+	struct mlx5_core_dev *dev = filp->private_data;
+	struct mlx5_cmd_debug *dbg = &dev->cmd.dbg;
+	char outlen_str[8];
+	int outlen;
+	void *ptr;
+	int err;
+
+	if (*pos != 0 || count > 6)
+		return -EINVAL;
+
+	kfree(dbg->out_msg);
+	dbg->out_msg = NULL;
+	dbg->outlen = 0;
+
+	if (copy_from_user(outlen_str, buf, count))
+		return -EPERM;
+
+	outlen_str[7] = 0;
+
+	err = sscanf(outlen_str, "%d", &outlen);
+	if (err < 0)
+		return err;
+
+	ptr = kzalloc(outlen, GFP_KERNEL);
+	if (!ptr)
+		return -ENOMEM;
+
+	dbg->out_msg = ptr;
+	dbg->outlen = outlen;
+
+	*pos = count;
+
+	return count;
+}
+
+static const struct file_operations olfops = {
+	.owner	= THIS_MODULE,
+	.open	= simple_open,
+	.write	= outlen_write,
+	.read	= outlen_read,
+};
+
+static void set_wqname(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd *cmd = &dev->cmd;
+
+	snprintf(cmd->wq_name, sizeof(cmd->wq_name), "mlx5_cmd_%s",
+		 dev_name(&dev->pdev->dev));
+}
+
+static void clean_debug_files(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd_debug *dbg = &dev->cmd.dbg;
+
+	if (!mlx5_debugfs_root)
+		return;
+
+	mlx5_cmdif_debugfs_cleanup(dev);
+	debugfs_remove_recursive(dbg->dbg_root);
+}
+
+static int create_debugfs_files(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd_debug *dbg = &dev->cmd.dbg;
+	int err = -ENOMEM;
+
+	if (!mlx5_debugfs_root)
+		return 0;
+
+	dbg->dbg_root = debugfs_create_dir("cmd", dev->priv.dbg_root);
+	if (!dbg->dbg_root)
+		return err;
+
+	dbg->dbg_in = debugfs_create_file("in", 0400, dbg->dbg_root,
+					  dev, &dfops);
+	if (!dbg->dbg_in)
+		goto err_dbg;
+
+	dbg->dbg_out = debugfs_create_file("out", 0200, dbg->dbg_root,
+					   dev, &dfops);
+	if (!dbg->dbg_out)
+		goto err_dbg;
+
+	dbg->dbg_outlen = debugfs_create_file("out_len", 0600, dbg->dbg_root,
+					      dev, &olfops);
+	if (!dbg->dbg_outlen)
+		goto err_dbg;
+
+	dbg->dbg_status = debugfs_create_u8("status", 0600, dbg->dbg_root,
+					    &dbg->status);
+	if (!dbg->dbg_status)
+		goto err_dbg;
+
+	dbg->dbg_run = debugfs_create_file("run", 0200, dbg->dbg_root, dev, &fops);
+	if (!dbg->dbg_run)
+		goto err_dbg;
+
+	mlx5_cmdif_debugfs_init(dev);
+
+	return 0;
+
+err_dbg:
+	clean_debug_files(dev);
+	return err;
+}
+
+void mlx5_cmd_use_events(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd *cmd = &dev->cmd;
+	int i;
+
+	for (i = 0; i < cmd->max_reg_cmds; i++)
+		down(&cmd->sem);
+
+	down(&cmd->pages_sem);
+
+	flush_workqueue(cmd->wq);
+
+	cmd->mode = CMD_MODE_EVENTS;
+
+	up(&cmd->pages_sem);
+	for (i = 0; i < cmd->max_reg_cmds; i++)
+		up(&cmd->sem);
+}
+
+void mlx5_cmd_use_polling(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd *cmd = &dev->cmd;
+	int i;
+
+	for (i = 0; i < cmd->max_reg_cmds; i++)
+		down(&cmd->sem);
+
+	down(&cmd->pages_sem);
+
+	flush_workqueue(cmd->wq);
+	cmd->mode = CMD_MODE_POLLING;
+
+	up(&cmd->pages_sem);
+	for (i = 0; i < cmd->max_reg_cmds; i++)
+		up(&cmd->sem);
+}
+
+void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, unsigned long vector)
+{
+	struct mlx5_cmd *cmd = &dev->cmd;
+	struct mlx5_cmd_work_ent *ent;
+	mlx5_cmd_cbk_t callback;
+	void *context;
+	int err;
+	int i;
+
+	for (i = 0; i < (1 << cmd->log_sz); i++) {
+		if (test_bit(i, &vector)) {
+			ent = cmd->ent_arr[i];
+			ktime_get_ts(&ent->ts2);
+			memcpy(ent->out->first.data, ent->lay->out, sizeof(ent->lay->out));
+			dump_command(dev, ent, 0);
+			if (!ent->ret) {
+				if (!cmd->checksum_disabled)
+					ent->ret = verify_signature(ent);
+				else
+					ent->ret = 0;
+				ent->status = ent->lay->status_own >> 1;
+				mlx5_core_dbg(dev, "command completed. ret 0x%x, delivery status %s(0x%x)\n",
+					      ent->ret, deliv_status_to_str(ent->status), ent->status);
+			}
+			free_ent(cmd, ent->idx);
+			if (ent->callback) {
+				callback = ent->callback;
+				context = ent->context;
+				err = ent->ret;
+				free_cmd(ent);
+				callback(err, context);
+			} else {
+				complete(&ent->done);
+			}
+			if (ent->page_queue)
+				up(&cmd->pages_sem);
+			else
+				up(&cmd->sem);
+		}
+	}
+}
+EXPORT_SYMBOL(mlx5_cmd_comp_handler);
+
+static int status_to_err(u8 status)
+{
+	return status ? -1 : 0; /* TBD more meaningful codes */
+}
+
+static struct mlx5_cmd_msg *alloc_msg(struct mlx5_core_dev *dev, int in_size)
+{
+	struct mlx5_cmd_msg *msg = ERR_PTR(-ENOMEM);
+	struct mlx5_cmd *cmd = &dev->cmd;
+	struct cache_ent *ent = NULL;
+
+	if (in_size > MED_LIST_SIZE && in_size <= LONG_LIST_SIZE)
+		ent = &cmd->cache.large;
+	else if (in_size > 16 && in_size <= MED_LIST_SIZE)
+		ent = &cmd->cache.med;
+
+	if (ent) {
+		spin_lock(&ent->lock);
+		if (!list_empty(&ent->head)) {
+			msg = list_entry(ent->head.next, typeof(*msg), list);
+			/* For cached lists, we must explicitly state what is
+			 * the real size
+			 */
+			msg->len = in_size;
+			list_del(&msg->list);
+		}
+		spin_unlock(&ent->lock);
+	}
+
+	if (IS_ERR(msg))
+		msg = mlx5_alloc_cmd_msg(dev, GFP_KERNEL, in_size);
+
+	return msg;
+}
+
+static void free_msg(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *msg)
+{
+	if (msg->cache) {
+		spin_lock(&msg->cache->lock);
+		list_add_tail(&msg->list, &msg->cache->head);
+		spin_unlock(&msg->cache->lock);
+	} else {
+		mlx5_free_cmd_msg(dev, msg);
+	}
+}
+
+static int is_manage_pages(struct mlx5_inbox_hdr *in)
+{
+	return be16_to_cpu(in->opcode) == MLX5_CMD_OP_MANAGE_PAGES;
+}
+
+int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
+		  int out_size)
+{
+	struct mlx5_cmd_msg *inb;
+	struct mlx5_cmd_msg *outb;
+	int pages_queue;
+	int err;
+	u8 status = 0;
+
+	pages_queue = is_manage_pages(in);
+
+	inb = alloc_msg(dev, in_size);
+	if (IS_ERR(inb)) {
+		err = PTR_ERR(inb);
+		return err;
+	}
+
+	err = mlx5_copy_to_msg(inb, in, in_size);
+	if (err) {
+		mlx5_core_warn(dev, "err %d\n", err);
+		goto out_in;
+	}
+
+	outb = mlx5_alloc_cmd_msg(dev, GFP_KERNEL, out_size);
+	if (IS_ERR(outb)) {
+		err = PTR_ERR(outb);
+		goto out_in;
+	}
+
+	err = mlx5_cmd_invoke(dev, inb, outb, NULL, NULL, pages_queue, &status);
+	if (err)
+		goto out_out;
+
+	mlx5_core_dbg(dev, "err %d, status %d\n", err, status);
+	if (status) {
+		err = status_to_err(status);
+		goto out_out;
+	}
+
+	err = mlx5_copy_from_msg(out, outb, out_size);
+
+out_out:
+	mlx5_free_cmd_msg(dev, outb);
+
+out_in:
+	free_msg(dev, inb);
+	return err;
+}
+EXPORT_SYMBOL(mlx5_cmd_exec);
+
+static void destroy_msg_cache(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd *cmd = &dev->cmd;
+	struct mlx5_cmd_msg *msg;
+	struct mlx5_cmd_msg *n;
+
+	list_for_each_entry_safe(msg, n, &cmd->cache.large.head, list) {
+		list_del(&msg->list);
+		mlx5_free_cmd_msg(dev, msg);
+	}
+
+	list_for_each_entry_safe(msg, n, &cmd->cache.med.head, list) {
+		list_del(&msg->list);
+		mlx5_free_cmd_msg(dev, msg);
+	}
+}
+
+static int create_msg_cache(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd *cmd = &dev->cmd;
+	struct mlx5_cmd_msg *msg;
+	int err;
+	int i;
+
+	spin_lock_init(&cmd->cache.large.lock);
+	INIT_LIST_HEAD(&cmd->cache.large.head);
+	spin_lock_init(&cmd->cache.med.lock);
+	INIT_LIST_HEAD(&cmd->cache.med.head);
+
+	for (i = 0; i < NUM_LONG_LISTS; i++) {
+		msg = mlx5_alloc_cmd_msg(dev, GFP_KERNEL, LONG_LIST_SIZE);
+		if (IS_ERR(msg)) {
+			err = PTR_ERR(msg);
+			goto ex_err;
+		}
+		msg->cache = &cmd->cache.large;
+		list_add_tail(&msg->list, &cmd->cache.large.head);
+	}
+
+	for (i = 0; i < NUM_MED_LISTS; i++) {
+		msg = mlx5_alloc_cmd_msg(dev, GFP_KERNEL, MED_LIST_SIZE);
+		if (IS_ERR(msg)) {
+			err = PTR_ERR(msg);
+			goto ex_err;
+		}
+		msg->cache = &cmd->cache.med;
+		list_add_tail(&msg->list, &cmd->cache.med.head);
+	}
+
+	return 0;
+
+ex_err:
+	destroy_msg_cache(dev);
+	return err;
+}
+
+int mlx5_cmd_init(struct mlx5_core_dev *dev)
+{
+	int size = sizeof(struct mlx5_cmd_prot_block);
+	int align = roundup_pow_of_two(size);
+	struct mlx5_cmd *cmd = &dev->cmd;
+	u32 cmd_h, cmd_l;
+	u16 cmd_if_rev;
+	int err;
+	int i;
+
+	cmd_if_rev = cmdif_rev(dev);
+	if (cmd_if_rev != CMD_IF_REV) {
+		dev_err(&dev->pdev->dev,
+			"Driver cmdif rev(%d) differs from firmware's(%d)\n",
+			CMD_IF_REV, cmd_if_rev);
+		return -EINVAL;
+	}
+
+	cmd->pool = pci_pool_create("mlx5_cmd", dev->pdev, size, align, 0);
+	if (!cmd->pool)
+		return -ENOMEM;
+
+	cmd->cmd_buf = (void *)__get_free_pages(GFP_ATOMIC, 0);
+	if (!cmd->cmd_buf) {
+		err = -ENOMEM;
+		goto err_free_pool;
+	}
+	cmd->dma = dma_map_single(&dev->pdev->dev, cmd->cmd_buf, PAGE_SIZE,
+				  DMA_BIDIRECTIONAL);
+	if (dma_mapping_error(&dev->pdev->dev, cmd->dma)) {
+		err = -ENOMEM;
+		goto err_free;
+	}
+
+	cmd_l = ioread32be(&dev->iseg->cmdq_addr_l_sz) & 0xff;
+	cmd->log_sz = cmd_l >> 4 & 0xf;
+	cmd->log_stride = cmd_l & 0xf;
+	if (1 << cmd->log_sz > MLX5_MAX_COMMANDS) {
+		dev_err(&dev->pdev->dev, "firmware reports too many outstanding commands %d\n",
+			1 << cmd->log_sz);
+		err = -EINVAL;
+		goto err_map;
+	}
+
+	if (cmd->log_sz + cmd->log_stride > PAGE_SHIFT) {
+		dev_err(&dev->pdev->dev, "command queue size overflow\n");
+		err = -EINVAL;
+		goto err_map;
+	}
+
+	cmd->max_reg_cmds = (1 << cmd->log_sz) - 1;
+	cmd->bitmask = (1 << cmd->max_reg_cmds) - 1;
+
+	cmd->cmdif_rev = ioread32be(&dev->iseg->cmdif_rev_fw_sub) >> 16;
+	if (cmd->cmdif_rev > CMD_IF_REV) {
+		dev_err(&dev->pdev->dev, "driver does not support command interface version. driver %d, firmware %d\n",
+			CMD_IF_REV, cmd->cmdif_rev);
+		err = -ENOTSUPP;
+		goto err_map;
+	}
+
+	spin_lock_init(&cmd->alloc_lock);
+	spin_lock_init(&cmd->token_lock);
+	for (i = 0; i < ARRAY_SIZE(cmd->stats); i++)
+		spin_lock_init(&cmd->stats[i].lock);
+
+	sema_init(&cmd->sem, cmd->max_reg_cmds);
+	sema_init(&cmd->pages_sem, 1);
+
+	cmd_h = (u32)((u64)(cmd->dma) >> 32);
+	cmd_l = (u32)(cmd->dma);
+	if (cmd_l & 0xfff) {
+		dev_err(&dev->pdev->dev, "invalid command queue address\n");
+		err = -ENOMEM;
+		goto err_map;
+	}
+
+	iowrite32be(cmd_h, &dev->iseg->cmdq_addr_h);
+	iowrite32be(cmd_l, &dev->iseg->cmdq_addr_l_sz);
+
+	/* Make sure firmware sees the complete address before we proceed */
+	wmb();
+
+	mlx5_core_dbg(dev, "descriptor at dma 0x%llx\n", (unsigned long long)(cmd->dma));
+
+	cmd->mode = CMD_MODE_POLLING;
+
+	err = create_msg_cache(dev);
+	if (err) {
+		dev_err(&dev->pdev->dev, "failed to create command cache\n");
+		goto err_map;
+	}
+
+	set_wqname(dev);
+	cmd->wq = create_singlethread_workqueue(cmd->wq_name);
+	if (!cmd->wq) {
+		dev_err(&dev->pdev->dev, "failed to create command workqueue\n");
+		err = -ENOMEM;
+		goto err_cache;
+	}
+
+	err = create_debugfs_files(dev);
+	if (err) {
+		err = -ENOMEM;
+		goto err_wq;
+	}
+
+	return 0;
+
+err_wq:
+	destroy_workqueue(cmd->wq);
+
+err_cache:
+	destroy_msg_cache(dev);
+
+err_map:
+	dma_unmap_single(&dev->pdev->dev, cmd->dma, PAGE_SIZE,
+			 DMA_BIDIRECTIONAL);
+err_free:
+	free_pages((unsigned long)cmd->cmd_buf, 0);
+
+err_free_pool:
+	pci_pool_destroy(cmd->pool);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_cmd_init);
+
+void mlx5_cmd_cleanup(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd *cmd = &dev->cmd;
+
+	clean_debug_files(dev);
+	destroy_workqueue(cmd->wq);
+	destroy_msg_cache(dev);
+	dma_unmap_single(&dev->pdev->dev, cmd->dma, PAGE_SIZE,
+			 DMA_BIDIRECTIONAL);
+	free_pages((unsigned long)cmd->cmd_buf, 0);
+	pci_pool_destroy(cmd->pool);
+}
+EXPORT_SYMBOL(mlx5_cmd_cleanup);
+
+static const char *cmd_status_str(u8 status)
+{
+	switch (status) {
+	case MLX5_CMD_STAT_OK:
+		return "OK";
+	case MLX5_CMD_STAT_INT_ERR:
+		return "internal error";
+	case MLX5_CMD_STAT_BAD_OP_ERR:
+		return "bad operation";
+	case MLX5_CMD_STAT_BAD_PARAM_ERR:
+		return "bad parameter";
+	case MLX5_CMD_STAT_BAD_SYS_STATE_ERR:
+		return "bad system state";
+	case MLX5_CMD_STAT_BAD_RES_ERR:
+		return "bad resource";
+	case MLX5_CMD_STAT_RES_BUSY:
+		return "resource busy";
+	case MLX5_CMD_STAT_LIM_ERR:
+		return "limits exceeded";
+	case MLX5_CMD_STAT_BAD_RES_STATE_ERR:
+		return "bad resource state";
+	case MLX5_CMD_STAT_IX_ERR:
+		return "bad index";
+	case MLX5_CMD_STAT_NO_RES_ERR:
+		return "no resources";
+	case MLX5_CMD_STAT_BAD_INP_LEN_ERR:
+		return "bad input length";
+	case MLX5_CMD_STAT_BAD_OUTP_LEN_ERR:
+		return "bad output length";
+	case MLX5_CMD_STAT_BAD_QP_STATE_ERR:
+		return "bad QP state";
+	case MLX5_CMD_STAT_BAD_PKT_ERR:
+		return "bad packet (discarded)";
+	case MLX5_CMD_STAT_BAD_SIZE_OUTS_CQES_ERR:
+		return "bad size too many outstanding CQEs";
+	default:
+		return "unknown status";
+	}
+}
+
+int mlx5_cmd_status_to_err(struct mlx5_outbox_hdr *hdr)
+{
+	if (!hdr->status)
+		return 0;
+
+	pr_warn("command failed, status %s(0x%x), syndrome 0x%x\n",
+		cmd_status_str(hdr->status), hdr->status,
+		be32_to_cpu(hdr->syndrome));
+
+	switch (hdr->status) {
+	case MLX5_CMD_STAT_OK:				return 0;
+	case MLX5_CMD_STAT_INT_ERR:			return -EIO;
+	case MLX5_CMD_STAT_BAD_OP_ERR:			return -EINVAL;
+	case MLX5_CMD_STAT_BAD_PARAM_ERR:		return -EINVAL;
+	case MLX5_CMD_STAT_BAD_SYS_STATE_ERR:		return -EIO;
+	case MLX5_CMD_STAT_BAD_RES_ERR:			return -EINVAL;
+	case MLX5_CMD_STAT_RES_BUSY:			return -EBUSY;
+	case MLX5_CMD_STAT_LIM_ERR:			return -EINVAL;
+	case MLX5_CMD_STAT_BAD_RES_STATE_ERR:		return -EINVAL;
+	case MLX5_CMD_STAT_IX_ERR:			return -EINVAL;
+	case MLX5_CMD_STAT_NO_RES_ERR:			return -EAGAIN;
+	case MLX5_CMD_STAT_BAD_INP_LEN_ERR:		return -EIO;
+	case MLX5_CMD_STAT_BAD_OUTP_LEN_ERR:		return -EIO;
+	case MLX5_CMD_STAT_BAD_QP_STATE_ERR:		return -EINVAL;
+	case MLX5_CMD_STAT_BAD_PKT_ERR:			return -EINVAL;
+	case MLX5_CMD_STAT_BAD_SIZE_OUTS_CQES_ERR:	return -EINVAL;
+	default:					return -EIO;
+	}
+}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/cq.c b/drivers/net/ethernet/mellanox/mlx5/core/cq.c
new file mode 100644
index 0000000..c2d660b
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/cq.c
@@ -0,0 +1,224 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/hardirq.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include <rdma/ib_verbs.h>
+#include <linux/mlx5/cq.h>
+#include "mlx5_core.h"
+
+void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn)
+{
+	struct mlx5_core_cq *cq;
+	struct mlx5_cq_table *table = &dev->priv.cq_table;
+
+	spin_lock(&table->lock);
+	cq = radix_tree_lookup(&table->tree, cqn);
+	if (likely(cq))
+		atomic_inc(&cq->refcount);
+	spin_unlock(&table->lock);
+
+	if (!cq) {
+		mlx5_core_warn(dev, "Completion event for bogus CQ 0x%x\n", cqn);
+		return;
+	}
+
+	++cq->arm_sn;
+
+	cq->comp(cq);
+
+	if (atomic_dec_and_test(&cq->refcount))
+		complete(&cq->free);
+}
+
+void mlx5_cq_event(struct mlx5_core_dev *dev, u32 cqn, int event_type)
+{
+	struct mlx5_cq_table *table = &dev->priv.cq_table;
+	struct mlx5_core_cq *cq;
+
+	spin_lock(&table->lock);
+
+	cq = radix_tree_lookup(&table->tree, cqn);
+	if (cq)
+		atomic_inc(&cq->refcount);
+
+	spin_unlock(&table->lock);
+
+	if (!cq) {
+		mlx5_core_warn(dev, "Async event for bogus CQ 0x%x\n", cqn);
+		return;
+	}
+
+	cq->event(cq, event_type);
+
+	if (atomic_dec_and_test(&cq->refcount))
+		complete(&cq->free);
+}
+
+
+int mlx5_core_create_cq(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq,
+			struct mlx5_create_cq_mbox_in *in, int inlen)
+{
+	int err;
+	struct mlx5_cq_table *table = &dev->priv.cq_table;
+	struct mlx5_create_cq_mbox_out out;
+	struct mlx5_destroy_cq_mbox_in din;
+	struct mlx5_destroy_cq_mbox_out dout;
+
+	in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_CREATE_CQ);
+	memset(&out, 0, sizeof(out));
+	err = mlx5_cmd_exec(dev, in, inlen, &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	cq->cqn = be32_to_cpu(out.cqn) & 0xffffff;
+	cq->cons_index = 0;
+	cq->arm_sn     = 0;
+	atomic_set(&cq->refcount, 1);
+	init_completion(&cq->free);
+
+	spin_lock_irq(&table->lock);
+	err = radix_tree_insert(&table->tree, cq->cqn, cq);
+	spin_unlock_irq(&table->lock);
+	if (err)
+		goto err_cmd;
+
+	cq->pid = current->pid;
+	err = mlx5_debug_cq_add(dev, cq);
+	if (err)
+		mlx5_core_dbg(dev, "failed adding CP 0x%x to debug file system\n",
+			      cq->cqn);
+
+	return 0;
+
+err_cmd:
+	memset(&din, 0, sizeof(din));
+	memset(&dout, 0, sizeof(dout));
+	din.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DESTROY_CQ);
+	mlx5_cmd_exec(dev, &din, sizeof(din), &dout, sizeof(dout));
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_create_cq);
+
+int mlx5_core_destroy_cq(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq)
+{
+	struct mlx5_cq_table *table = &dev->priv.cq_table;
+	struct mlx5_destroy_cq_mbox_in in;
+	struct mlx5_destroy_cq_mbox_out out;
+	struct mlx5_core_cq *tmp;
+	int err;
+
+	spin_lock_irq(&table->lock);
+	tmp = radix_tree_delete(&table->tree, cq->cqn);
+	spin_unlock_irq(&table->lock);
+	if (!tmp) {
+		mlx5_core_warn(dev, "cq 0x%x not found in tree\n", cq->cqn);
+		return -EINVAL;
+	}
+	if (tmp != cq) {
+		mlx5_core_warn(dev, "corruption on srqn 0x%x\n", cq->cqn);
+		return -EINVAL;
+	}
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DESTROY_CQ);
+	in.cqn = cpu_to_be32(cq->cqn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	synchronize_irq(cq->irqn);
+
+	mlx5_debug_cq_remove(dev, cq);
+	if (atomic_dec_and_test(&cq->refcount))
+		complete(&cq->free);
+	wait_for_completion(&cq->free);
+
+	return 0;
+}
+EXPORT_SYMBOL(mlx5_core_destroy_cq);
+
+int mlx5_core_query_cq(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq,
+		       struct mlx5_query_cq_mbox_out *out)
+{
+	struct mlx5_query_cq_mbox_in in;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(out, 0, sizeof(*out));
+
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_CQ);
+	in.cqn = cpu_to_be32(cq->cqn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), out, sizeof(*out));
+	if (err)
+		return err;
+
+	if (out->hdr.status)
+		return mlx5_cmd_status_to_err(&out->hdr);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_query_cq);
+
+
+int mlx5_core_modify_cq(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq,
+			int type, struct mlx5_cq_modify_params *params)
+{
+	return -ENOSYS;
+}
+
+int mlx5_init_cq_table(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cq_table *table = &dev->priv.cq_table;
+	int err;
+
+	spin_lock_init(&table->lock);
+	INIT_RADIX_TREE(&table->tree, GFP_ATOMIC);
+	err = mlx5_cq_debugfs_init(dev);
+
+	return err;
+}
+
+void mlx5_cleanup_cq_table(struct mlx5_core_dev *dev)
+{
+	mlx5_cq_debugfs_cleanup(dev);
+}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/debugfs.c b/drivers/net/ethernet/mellanox/mlx5/core/debugfs.c
new file mode 100644
index 0000000..5e9cf2b
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/debugfs.c
@@ -0,0 +1,587 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/module.h>
+#include <linux/debugfs.h>
+#include <linux/mlx5/qp.h>
+#include <linux/mlx5/cq.h>
+#include <linux/mlx5/driver.h>
+#include "mlx5_core.h"
+
+enum {
+	QP_PID,
+	QP_STATE,
+	QP_XPORT,
+	QP_MTU,
+	QP_N_RECV,
+	QP_RECV_SZ,
+	QP_N_SEND,
+	QP_LOG_PG_SZ,
+	QP_RQPN,
+};
+
+static char *qp_fields[] = {
+	[QP_PID]	= "pid",
+	[QP_STATE]	= "state",
+	[QP_XPORT]	= "transport",
+	[QP_MTU]	= "mtu",
+	[QP_N_RECV]	= "num_recv",
+	[QP_RECV_SZ]	= "rcv_wqe_sz",
+	[QP_N_SEND]	= "num_send",
+	[QP_LOG_PG_SZ]	= "log2_page_sz",
+	[QP_RQPN]	= "remote_qpn",
+};
+
+enum {
+	EQ_NUM_EQES,
+	EQ_INTR,
+	EQ_LOG_PG_SZ,
+};
+
+static char *eq_fields[] = {
+	[EQ_NUM_EQES]	= "num_eqes",
+	[EQ_INTR]	= "intr",
+	[EQ_LOG_PG_SZ]	= "log_page_size",
+};
+
+enum {
+	CQ_PID,
+	CQ_NUM_CQES,
+	CQ_LOG_PG_SZ,
+};
+
+static char *cq_fields[] = {
+	[CQ_PID]	= "pid",
+	[CQ_NUM_CQES]	= "num_cqes",
+	[CQ_LOG_PG_SZ]	= "log_page_size",
+};
+
+struct dentry *mlx5_debugfs_root;
+EXPORT_SYMBOL(mlx5_debugfs_root);
+
+void mlx5_register_debugfs(void)
+{
+	mlx5_debugfs_root = debugfs_create_dir("mlx5", NULL);
+	if (IS_ERR_OR_NULL(mlx5_debugfs_root))
+		mlx5_debugfs_root = NULL;
+}
+
+void mlx5_unregister_debugfs(void)
+{
+	debugfs_remove(mlx5_debugfs_root);
+}
+
+int mlx5_qp_debugfs_init(struct mlx5_core_dev *dev)
+{
+	if (!mlx5_debugfs_root)
+		return 0;
+
+	atomic_set(&dev->num_qps, 0);
+
+	dev->priv.qp_debugfs = debugfs_create_dir("QPs",  dev->priv.dbg_root);
+	if (!dev->priv.qp_debugfs)
+		return -ENOMEM;
+
+	return 0;
+}
+
+void mlx5_qp_debugfs_cleanup(struct mlx5_core_dev *dev)
+{
+	if (!mlx5_debugfs_root)
+		return;
+
+	debugfs_remove_recursive(dev->priv.qp_debugfs);
+}
+
+int mlx5_eq_debugfs_init(struct mlx5_core_dev *dev)
+{
+	if (!mlx5_debugfs_root)
+		return 0;
+
+	dev->priv.eq_debugfs = debugfs_create_dir("EQs",  dev->priv.dbg_root);
+	if (!dev->priv.eq_debugfs)
+		return -ENOMEM;
+
+	return 0;
+}
+
+void mlx5_eq_debugfs_cleanup(struct mlx5_core_dev *dev)
+{
+	if (!mlx5_debugfs_root)
+		return;
+
+	debugfs_remove_recursive(dev->priv.eq_debugfs);
+}
+
+static ssize_t average_read(struct file *filp, char __user *buf, size_t count,
+			    loff_t *pos)
+{
+	struct mlx5_cmd_stats *stats;
+	u64 field = 0;
+	int ret;
+	int err;
+	char tbuf[22];
+
+	if (*pos)
+		return 0;
+
+	stats = filp->private_data;
+	spin_lock(&stats->lock);
+	if (stats->n)
+		field = stats->sum / stats->n;
+	spin_unlock(&stats->lock);
+	ret = snprintf(tbuf, sizeof(tbuf), "%llu\n", field);
+	if (ret > 0) {
+		err = copy_to_user(buf, tbuf, ret);
+		if (err)
+			return err;
+	}
+
+	*pos += ret;
+	return ret;
+}
+
+
+static ssize_t average_write(struct file *filp, const char __user *buf,
+			     size_t count, loff_t *pos)
+{
+	struct mlx5_cmd_stats *stats;
+
+	stats = filp->private_data;
+	spin_lock(&stats->lock);
+	stats->sum = 0;
+	stats->n = 0;
+	spin_unlock(&stats->lock);
+
+	*pos += count;
+
+	return count;
+}
+
+static const struct file_operations stats_fops = {
+	.owner	= THIS_MODULE,
+	.open	= simple_open,
+	.read	= average_read,
+	.write	= average_write,
+};
+
+int mlx5_cmdif_debugfs_init(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd_stats *stats;
+	struct dentry **cmd;
+	const char *namep;
+	int err;
+	int i;
+
+	if (!mlx5_debugfs_root)
+		return 0;
+
+	cmd = &dev->priv.cmdif_debugfs;
+	*cmd = debugfs_create_dir("commands", dev->priv.dbg_root);
+	if (!*cmd)
+		return -ENOMEM;
+
+	for (i = 0; i < ARRAY_SIZE(dev->cmd.stats); i++) {
+		stats = &dev->cmd.stats[i];
+		namep = mlx5_command_str(i);
+		if (strcmp(namep, "unknown command opcode")) {
+			stats->root = debugfs_create_dir(namep, *cmd);
+			if (!stats->root) {
+				mlx5_core_warn(dev, "failed adding command %d\n",
+					       i);
+				err = -ENOMEM;
+				goto out;
+			}
+
+			stats->avg = debugfs_create_file("average", 0400,
+							 stats->root, stats,
+							 &stats_fops);
+			if (!stats->avg) {
+				mlx5_core_warn(dev, "failed creating debugfs file\n");
+				err = -ENOMEM;
+				goto out;
+			}
+
+			stats->count = debugfs_create_u64("n", 0400,
+							  stats->root,
+							  &stats->n);
+			if (!stats->count) {
+				mlx5_core_warn(dev, "failed creating debugfs file\n");
+				err = -ENOMEM;
+				goto out;
+			}
+		}
+	}
+
+	return 0;
+out:
+	debugfs_remove_recursive(dev->priv.cmdif_debugfs);
+	return err;
+}
+
+void mlx5_cmdif_debugfs_cleanup(struct mlx5_core_dev *dev)
+{
+	if (!mlx5_debugfs_root)
+		return;
+
+	debugfs_remove_recursive(dev->priv.cmdif_debugfs);
+}
+
+int mlx5_cq_debugfs_init(struct mlx5_core_dev *dev)
+{
+	if (!mlx5_debugfs_root)
+		return 0;
+
+	dev->priv.cq_debugfs = debugfs_create_dir("CQs",  dev->priv.dbg_root);
+	if (!dev->priv.cq_debugfs)
+		return -ENOMEM;
+
+	return 0;
+}
+
+void mlx5_cq_debugfs_cleanup(struct mlx5_core_dev *dev)
+{
+	if (!mlx5_debugfs_root)
+		return;
+
+	debugfs_remove_recursive(dev->priv.cq_debugfs);
+}
+
+static u64 qp_read_field(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp,
+			 int index)
+{
+	struct mlx5_query_qp_mbox_out *out;
+	struct mlx5_qp_context *ctx;
+	u64 param = 0;
+	int err;
+	int no_sq;
+
+	out = kzalloc(sizeof(*out), GFP_KERNEL);
+	if (!out)
+		return param;
+
+	err = mlx5_core_qp_query(dev, qp, out, sizeof(*out));
+	if (err) {
+		mlx5_core_warn(dev, "failed to query qp\n");
+		goto out;
+	}
+
+	ctx = &out->ctx;
+	switch (index) {
+	case QP_PID:
+		param = qp->pid;
+		break;
+	case QP_STATE:
+		param = be32_to_cpu(ctx->flags) >> 28;
+		break;
+	case QP_XPORT:
+		param = (be32_to_cpu(ctx->flags) >> 16) & 0xff;
+		break;
+	case QP_MTU:
+		param = ctx->mtu_msgmax >> 5;
+		break;
+	case QP_N_RECV:
+		param = 1 << ((ctx->rq_size_stride >> 3) & 0xf);
+		break;
+	case QP_RECV_SZ:
+		param = 1 << ((ctx->rq_size_stride & 7) + 4);
+		break;
+	case QP_N_SEND:
+		no_sq = be16_to_cpu(ctx->sq_crq_size) >> 15;
+		if (!no_sq)
+			param = 1 << (be16_to_cpu(ctx->sq_crq_size) >> 11);
+		else
+			param = 0;
+		break;
+	case QP_LOG_PG_SZ:
+		param = ((cpu_to_be32(ctx->log_pg_sz_remote_qpn) >> 24) & 0x1f);
+		param += 12;
+		break;
+	case QP_RQPN:
+		param = cpu_to_be32(ctx->log_pg_sz_remote_qpn) & 0xffffff;
+		break;
+	}
+
+out:
+	kfree(out);
+	return param;
+}
+
+static u64 eq_read_field(struct mlx5_core_dev *dev, struct mlx5_eq *eq,
+			 int index)
+{
+	struct mlx5_query_eq_mbox_out *out;
+	struct mlx5_eq_context *ctx;
+	u64 param = 0;
+	int err;
+
+	out = kzalloc(sizeof(*out), GFP_KERNEL);
+	if (!out)
+		return param;
+
+	ctx = &out->ctx;
+
+	err = mlx5_core_eq_query(dev, eq, out, sizeof(*out));
+	if (err) {
+		mlx5_core_warn(dev, "failed to query eq\n");
+		goto out;
+	}
+
+	switch (index) {
+	case EQ_NUM_EQES:
+		param = 1 << ((be32_to_cpu(ctx->log_sz_usr_page) >> 24) & 0x1f);
+		break;
+	case EQ_INTR:
+		param = ctx->intr;
+		break;
+	case EQ_LOG_PG_SZ:
+		param = (ctx->log_page_size & 0x1f) + 12;
+		break;
+	}
+
+out:
+	kfree(out);
+	return param;
+}
+
+static u64 cq_read_field(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq,
+			 int index)
+{
+	struct mlx5_query_cq_mbox_out *out;
+	struct mlx5_cq_context *ctx;
+	u64 param = 0;
+	int err;
+
+	out = kzalloc(sizeof(*out), GFP_KERNEL);
+	if (!out)
+		return param;
+
+	ctx = &out->ctx;
+
+	err = mlx5_core_query_cq(dev, cq, out);
+	if (err) {
+		mlx5_core_warn(dev, "failed to query cq\n");
+		goto out;
+	}
+
+	switch (index) {
+	case CQ_PID:
+		param = cq->pid;
+		break;
+	case CQ_NUM_CQES:
+		param = 1 << ((be32_to_cpu(ctx->log_sz_usr_page) >> 24) & 0x1f);
+		break;
+	case CQ_LOG_PG_SZ:
+		param = (ctx->log_pg_sz & 0x1f) + 12;
+		break;
+	}
+
+out:
+	kfree(out);
+	return param;
+}
+
+static ssize_t dbg_read(struct file *filp, char __user *buf, size_t count,
+			loff_t *pos)
+{
+	struct mlx5_field_desc *desc;
+	struct mlx5_rsc_debug *d;
+	char tbuf[18];
+	u64 field;
+	int ret;
+	int err;
+
+	if (*pos)
+		return 0;
+
+	desc = filp->private_data;
+	d = (void *)(desc - desc->i) - sizeof(*d);
+	switch (d->type) {
+	case MLX5_DBG_RSC_QP:
+		field = qp_read_field(d->dev, d->object, desc->i);
+		break;
+
+	case MLX5_DBG_RSC_EQ:
+		field = eq_read_field(d->dev, d->object, desc->i);
+		break;
+
+	case MLX5_DBG_RSC_CQ:
+		field = cq_read_field(d->dev, d->object, desc->i);
+		break;
+
+	default:
+		mlx5_core_warn(d->dev, "invalid resource type %d\n", d->type);
+		return -EINVAL;
+	}
+
+	ret = snprintf(tbuf, sizeof(tbuf), "0x%llx\n", field);
+	if (ret > 0) {
+		err = copy_to_user(buf, tbuf, ret);
+		if (err)
+			return err;
+	}
+
+	*pos += ret;
+	return ret;
+}
+
+static const struct file_operations fops = {
+	.owner	= THIS_MODULE,
+	.open	= simple_open,
+	.read	= dbg_read,
+};
+
+static int add_res_tree(struct mlx5_core_dev *dev, enum dbg_rsc_type type,
+			struct dentry *root, struct mlx5_rsc_debug **dbg,
+			int rsn, char **field, int nfile, void *data)
+{
+	struct mlx5_rsc_debug *d;
+	char resn[32];
+	int err;
+	int i;
+
+	d = kzalloc(sizeof(*d) + nfile * sizeof(d->fields[0]), GFP_KERNEL);
+	if (!d)
+		return -ENOMEM;
+
+	d->dev = dev;
+	d->object = data;
+	d->type = type;
+	sprintf(resn, "0x%x", rsn);
+	d->root = debugfs_create_dir(resn,  root);
+	if (!d->root) {
+		err = -ENOMEM;
+		goto out_free;
+	}
+
+	for (i = 0; i < nfile; i++) {
+		d->fields[i].i = i;
+		d->fields[i].dent = debugfs_create_file(field[i], 0400,
+							d->root, &d->fields[i],
+							&fops);
+		if (!d->fields[i].dent) {
+			err = -ENOMEM;
+			goto out_rem;
+		}
+	}
+	*dbg = d;
+
+	return 0;
+out_rem:
+	debugfs_remove_recursive(d->root);
+
+out_free:
+	kfree(d);
+	return err;
+}
+
+static void rem_res_tree(struct mlx5_rsc_debug *d)
+{
+	debugfs_remove_recursive(d->root);
+	kfree(d);
+}
+
+int mlx5_debug_qp_add(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp)
+{
+	int err;
+
+	if (!mlx5_debugfs_root)
+		return 0;
+
+	err = add_res_tree(dev, MLX5_DBG_RSC_QP, dev->priv.qp_debugfs,
+			   &qp->dbg, qp->qpn, qp_fields,
+			   ARRAY_SIZE(qp_fields), qp);
+	if (err)
+		qp->dbg = NULL;
+
+	return err;
+}
+
+void mlx5_debug_qp_remove(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp)
+{
+	if (!mlx5_debugfs_root)
+		return;
+
+	if (qp->dbg)
+		rem_res_tree(qp->dbg);
+}
+
+
+int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq)
+{
+	int err;
+
+	if (!mlx5_debugfs_root)
+		return 0;
+
+	err = add_res_tree(dev, MLX5_DBG_RSC_EQ, dev->priv.eq_debugfs,
+			   &eq->dbg, eq->eqn, eq_fields,
+			   ARRAY_SIZE(eq_fields), eq);
+	if (err)
+		eq->dbg = NULL;
+
+	return err;
+}
+
+void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq)
+{
+	if (!mlx5_debugfs_root)
+		return;
+
+	if (eq->dbg)
+		rem_res_tree(eq->dbg);
+}
+
+int mlx5_debug_cq_add(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq)
+{
+	int err;
+
+	if (!mlx5_debugfs_root)
+		return 0;
+
+	err = add_res_tree(dev, MLX5_DBG_RSC_CQ, dev->priv.cq_debugfs,
+			   &cq->dbg, cq->cqn, cq_fields,
+			   ARRAY_SIZE(cq_fields), cq);
+	if (err)
+		cq->dbg = NULL;
+
+	return err;
+}
+
+void mlx5_debug_cq_remove(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq)
+{
+	if (!mlx5_debugfs_root)
+		return;
+
+	if (cq->dbg)
+		rem_res_tree(cq->dbg);
+}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eq.c b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
new file mode 100644
index 0000000..c02cbcf
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
@@ -0,0 +1,521 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/interrupt.h>
+#include <linux/module.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include "mlx5_core.h"
+
+enum {
+	MLX5_EQE_SIZE		= sizeof(struct mlx5_eqe),
+	MLX5_EQE_OWNER_INIT_VAL	= 0x1,
+};
+
+enum {
+	MLX5_EQ_STATE_ARMED		= 0x9,
+	MLX5_EQ_STATE_FIRED		= 0xa,
+	MLX5_EQ_STATE_ALWAYS_ARMED	= 0xb,
+};
+
+enum {
+	MLX5_NUM_SPARE_EQE	= 0x80,
+	MLX5_NUM_ASYNC_EQE	= 0x100,
+	MLX5_NUM_CMD_EQE	= 32,
+};
+
+enum {
+	MLX5_EQ_DOORBEL_OFFSET	= 0x40,
+};
+
+#define MLX5_ASYNC_EVENT_MASK ((1ull << MLX5_EVENT_TYPE_PATH_MIG)	    | \
+			       (1ull << MLX5_EVENT_TYPE_COMM_EST)	    | \
+			       (1ull << MLX5_EVENT_TYPE_SQ_DRAINED)	    | \
+			       (1ull << MLX5_EVENT_TYPE_CQ_ERROR)	    | \
+			       (1ull << MLX5_EVENT_TYPE_WQ_CATAS_ERROR)	    | \
+			       (1ull << MLX5_EVENT_TYPE_PATH_MIG_FAILED)    | \
+			       (1ull << MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR) | \
+			       (1ull << MLX5_EVENT_TYPE_WQ_ACCESS_ERROR)    | \
+			       (1ull << MLX5_EVENT_TYPE_PORT_CHANGE)	    | \
+			       (1ull << MLX5_EVENT_TYPE_SRQ_CATAS_ERROR)    | \
+			       (1ull << MLX5_EVENT_TYPE_SRQ_LAST_WQE)	    | \
+			       (1ull << MLX5_EVENT_TYPE_SRQ_RQ_LIMIT))
+
+struct map_eq_in {
+	u64	mask;
+	u32	reserved;
+	u32	unmap_eqn;
+};
+
+struct cre_des_eq {
+	u8	reserved[15];
+	u8	eqn;
+};
+
+static int mlx5_cmd_destroy_eq(struct mlx5_core_dev *dev, u8 eqn)
+{
+	struct mlx5_destroy_eq_mbox_in in;
+	struct mlx5_destroy_eq_mbox_out out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DESTROY_EQ);
+	in.eqn = eqn;
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (!err)
+		goto ex;
+
+	if (out.hdr.status)
+		err = mlx5_cmd_status_to_err(&out.hdr);
+
+ex:
+	return err;
+}
+
+static struct mlx5_eqe *get_eqe(struct mlx5_eq *eq, u32 entry)
+{
+	return mlx5_buf_offset(&eq->buf, entry * MLX5_EQE_SIZE);
+}
+
+static struct mlx5_eqe *next_eqe_sw(struct mlx5_eq *eq)
+{
+	struct mlx5_eqe *eqe = get_eqe(eq, eq->cons_index & (eq->nent - 1));
+
+	return ((eqe->owner & 1) ^ !!(eq->cons_index & eq->nent)) ? NULL : eqe;
+}
+
+static const char *eqe_type_str(u8 type)
+{
+	switch (type) {
+	case MLX5_EVENT_TYPE_COMP:
+		return "MLX5_EVENT_TYPE_COMP";
+	case MLX5_EVENT_TYPE_PATH_MIG:
+		return "MLX5_EVENT_TYPE_PATH_MIG";
+	case MLX5_EVENT_TYPE_COMM_EST:
+		return "MLX5_EVENT_TYPE_COMM_EST";
+	case MLX5_EVENT_TYPE_SQ_DRAINED:
+		return "MLX5_EVENT_TYPE_SQ_DRAINED";
+	case MLX5_EVENT_TYPE_SRQ_LAST_WQE:
+		return "MLX5_EVENT_TYPE_SRQ_LAST_WQE";
+	case MLX5_EVENT_TYPE_SRQ_RQ_LIMIT:
+		return "MLX5_EVENT_TYPE_SRQ_RQ_LIMIT";
+	case MLX5_EVENT_TYPE_CQ_ERROR:
+		return "MLX5_EVENT_TYPE_CQ_ERROR";
+	case MLX5_EVENT_TYPE_WQ_CATAS_ERROR:
+		return "MLX5_EVENT_TYPE_WQ_CATAS_ERROR";
+	case MLX5_EVENT_TYPE_PATH_MIG_FAILED:
+		return "MLX5_EVENT_TYPE_PATH_MIG_FAILED";
+	case MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR:
+		return "MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR";
+	case MLX5_EVENT_TYPE_WQ_ACCESS_ERROR:
+		return "MLX5_EVENT_TYPE_WQ_ACCESS_ERROR";
+	case MLX5_EVENT_TYPE_SRQ_CATAS_ERROR:
+		return "MLX5_EVENT_TYPE_SRQ_CATAS_ERROR";
+	case MLX5_EVENT_TYPE_INTERNAL_ERROR:
+		return "MLX5_EVENT_TYPE_INTERNAL_ERROR";
+	case MLX5_EVENT_TYPE_PORT_CHANGE:
+		return "MLX5_EVENT_TYPE_PORT_CHANGE";
+	case MLX5_EVENT_TYPE_GPIO_EVENT:
+		return "MLX5_EVENT_TYPE_GPIO_EVENT";
+	case MLX5_EVENT_TYPE_REMOTE_CONFIG:
+		return "MLX5_EVENT_TYPE_REMOTE_CONFIG";
+	case MLX5_EVENT_TYPE_DB_BF_CONGESTION:
+		return "MLX5_EVENT_TYPE_DB_BF_CONGESTION";
+	case MLX5_EVENT_TYPE_STALL_EVENT:
+		return "MLX5_EVENT_TYPE_STALL_EVENT";
+	case MLX5_EVENT_TYPE_CMD:
+		return "MLX5_EVENT_TYPE_CMD";
+	case MLX5_EVENT_TYPE_PAGE_REQUEST:
+		return "MLX5_EVENT_TYPE_PAGE_REQUEST";
+	default:
+		return "Unrecognized event";
+	}
+}
+
+static enum mlx5_dev_event port_subtype_event(u8 subtype)
+{
+	switch (subtype) {
+	case MLX5_PORT_CHANGE_SUBTYPE_DOWN:
+		return MLX5_DEV_EVENT_PORT_DOWN;
+	case MLX5_PORT_CHANGE_SUBTYPE_ACTIVE:
+		return MLX5_DEV_EVENT_PORT_UP;
+	case MLX5_PORT_CHANGE_SUBTYPE_INITIALIZED:
+		return MLX5_DEV_EVENT_PORT_INITIALIZED;
+	case MLX5_PORT_CHANGE_SUBTYPE_LID:
+		return MLX5_DEV_EVENT_LID_CHANGE;
+	case MLX5_PORT_CHANGE_SUBTYPE_PKEY:
+		return MLX5_DEV_EVENT_PKEY_CHANGE;
+	case MLX5_PORT_CHANGE_SUBTYPE_GUID:
+		return MLX5_DEV_EVENT_GUID_CHANGE;
+	case MLX5_PORT_CHANGE_SUBTYPE_CLIENT_REREG:
+		return MLX5_DEV_EVENT_CLIENT_REREG;
+	}
+	return -1;
+}
+
+static void eq_update_ci(struct mlx5_eq *eq, int arm)
+{
+	__be32 __iomem *addr = eq->doorbell + (arm ? 0 : 2);
+	u32 val = (eq->cons_index & 0xffffff) | (eq->eqn << 24);
+	__raw_writel((__force u32) cpu_to_be32(val), addr);
+	/* We still want ordering, just not swabbing, so add a barrier */
+	mb();
+}
+
+static int mlx5_eq_int(struct mlx5_core_dev *dev, struct mlx5_eq *eq)
+{
+	struct mlx5_eqe *eqe;
+	int eqes_found = 0;
+	int set_ci = 0;
+	u32 cqn;
+	u32 srqn;
+	u8 port;
+
+	while ((eqe = next_eqe_sw(eq))) {
+		/*
+		 * Make sure we read EQ entry contents after we've
+		 * checked the ownership bit.
+		 */
+		rmb();
+
+		mlx5_core_dbg(eq->dev, "eqn %d, eqe type %s\n", eq->eqn, eqe_type_str(eqe->type));
+		switch (eqe->type) {
+		case MLX5_EVENT_TYPE_COMP:
+			cqn = be32_to_cpu(eqe->data.comp.cqn) & 0xffffff;
+			mlx5_cq_completion(dev, cqn);
+			break;
+
+		case MLX5_EVENT_TYPE_PATH_MIG:
+		case MLX5_EVENT_TYPE_COMM_EST:
+		case MLX5_EVENT_TYPE_SQ_DRAINED:
+		case MLX5_EVENT_TYPE_SRQ_LAST_WQE:
+		case MLX5_EVENT_TYPE_WQ_CATAS_ERROR:
+		case MLX5_EVENT_TYPE_PATH_MIG_FAILED:
+		case MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR:
+		case MLX5_EVENT_TYPE_WQ_ACCESS_ERROR:
+			mlx5_core_dbg(dev, "event %s(%d) arrived\n",
+				      eqe_type_str(eqe->type), eqe->type);
+			mlx5_qp_event(dev, be32_to_cpu(eqe->data.qp_srq.qp_srq_n) & 0xffffff,
+				      eqe->type);
+			break;
+
+		case MLX5_EVENT_TYPE_SRQ_RQ_LIMIT:
+		case MLX5_EVENT_TYPE_SRQ_CATAS_ERROR:
+			srqn = be32_to_cpu(eqe->data.qp_srq.qp_srq_n) & 0xffffff;
+			mlx5_core_dbg(dev, "SRQ event %s(%d): srqn 0x%x\n",
+				      eqe_type_str(eqe->type), eqe->type, srqn);
+			mlx5_srq_event(dev, srqn, eqe->type);
+			break;
+
+		case MLX5_EVENT_TYPE_CMD:
+			mlx5_cmd_comp_handler(dev, be32_to_cpu(eqe->data.cmd.vector));
+			break;
+
+		case MLX5_EVENT_TYPE_PORT_CHANGE:
+			port = (eqe->data.port.port >> 4) & 0xf;
+			switch (eqe->sub_type) {
+			case MLX5_PORT_CHANGE_SUBTYPE_DOWN:
+			case MLX5_PORT_CHANGE_SUBTYPE_ACTIVE:
+			case MLX5_PORT_CHANGE_SUBTYPE_LID:
+			case MLX5_PORT_CHANGE_SUBTYPE_PKEY:
+			case MLX5_PORT_CHANGE_SUBTYPE_GUID:
+			case MLX5_PORT_CHANGE_SUBTYPE_CLIENT_REREG:
+			case MLX5_PORT_CHANGE_SUBTYPE_INITIALIZED:
+				dev->event(dev, port_subtype_event(eqe->sub_type), &port);
+				break;
+			default:
+				mlx5_core_warn(dev, "Port event with unrecognized subtype: port %d, sub_type %d\n",
+					       port, eqe->sub_type);
+			}
+			break;
+		case MLX5_EVENT_TYPE_CQ_ERROR:
+			cqn = be32_to_cpu(eqe->data.cq_err.cqn) & 0xffffff;
+			mlx5_core_warn(dev, "CQ error on CQN 0x%x, syndrom 0x%x\n",
+				       cqn, eqe->data.cq_err.syndrome);
+			mlx5_cq_event(dev, cqn, eqe->type);
+			break;
+
+		case MLX5_EVENT_TYPE_PAGE_REQUEST:
+			{
+				u16 func_id = be16_to_cpu(eqe->data.req_pages.func_id);
+				s16 npages = be16_to_cpu(eqe->data.req_pages.num_pages);
+
+				mlx5_core_dbg(dev, "page request for func 0x%x, napges %d\n", func_id, npages);
+				mlx5_core_req_pages_handler(dev, func_id, npages);
+			}
+			break;
+
+
+		default:
+			mlx5_core_warn(dev, "Unhandled event 0x%x on EQ 0x%x\n", eqe->type, eq->eqn);
+			break;
+		}
+
+		++eq->cons_index;
+		eqes_found = 1;
+		++set_ci;
+
+		/* The HCA will think the queue has overflowed if we
+		 * don't tell it we've been processing events.  We
+		 * create our EQs with MLX5_NUM_SPARE_EQE extra
+		 * entries, so we must update our consumer index at
+		 * least that often.
+		 */
+		if (unlikely(set_ci >= MLX5_NUM_SPARE_EQE)) {
+			eq_update_ci(eq, 0);
+			set_ci = 0;
+		}
+	}
+
+	eq_update_ci(eq, 1);
+
+	return eqes_found;
+}
+
+static irqreturn_t mlx5_msix_handler(int irq, void *eq_ptr)
+{
+	struct mlx5_eq *eq = eq_ptr;
+	struct mlx5_core_dev *dev = eq->dev;
+
+	mlx5_eq_int(dev, eq);
+
+	/* MSI-X vectors always belong to us */
+	return IRQ_HANDLED;
+}
+
+static void init_eq_buf(struct mlx5_eq *eq)
+{
+	struct mlx5_eqe *eqe;
+	int i;
+
+	for (i = 0; i < eq->nent; i++) {
+		eqe = get_eqe(eq, i);
+		eqe->owner = MLX5_EQE_OWNER_INIT_VAL;
+	}
+}
+
+int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
+		       int nent, u64 mask, const char *name, struct mlx5_uar *uar)
+{
+	struct mlx5_eq_table *table = &dev->priv.eq_table;
+	struct mlx5_create_eq_mbox_in *in;
+	struct mlx5_create_eq_mbox_out out;
+	int err;
+	int inlen;
+
+	eq->nent = roundup_pow_of_two(nent + MLX5_NUM_SPARE_EQE);
+	err = mlx5_buf_alloc(dev, eq->nent * MLX5_EQE_SIZE, 2 * PAGE_SIZE,
+			     &eq->buf);
+	if (err)
+		return err;
+
+	init_eq_buf(eq);
+
+	inlen = sizeof(*in) + sizeof(in->pas[0]) * eq->buf.npages;
+	in = mlx5_vzalloc(inlen);
+	if (!in) {
+		err = -ENOMEM;
+		goto err_buf;
+	}
+	memset(&out, 0, sizeof(out));
+
+	mlx5_fill_page_array(&eq->buf, in->pas);
+
+	in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_CREATE_EQ);
+	in->ctx.log_sz_usr_page = cpu_to_be32(ilog2(eq->nent) << 24 | uar->index);
+	in->ctx.intr = vecidx;
+	in->ctx.log_page_size = PAGE_SHIFT - 12;
+	in->events_mask = cpu_to_be64(mask);
+
+	err = mlx5_cmd_exec(dev, in, inlen, &out, sizeof(out));
+	if (err)
+		goto err_in;
+
+	if (out.hdr.status) {
+		err = mlx5_cmd_status_to_err(&out.hdr);
+		goto err_in;
+	}
+
+	eq->eqn = out.eq_number;
+	err = request_irq(table->msix_arr[vecidx].vector, mlx5_msix_handler, 0,
+			  name, eq);
+	if (err)
+		goto err_eq;
+
+	eq->irqn = vecidx;
+	eq->dev = dev;
+	eq->doorbell = uar->map + MLX5_EQ_DOORBEL_OFFSET;
+
+	err = mlx5_debug_eq_add(dev, eq);
+	if (err)
+		goto err_irq;
+
+	/* EQs are created in ARMED state
+	 */
+	eq_update_ci(eq, 1);
+
+	mlx5_vfree(in);
+	return 0;
+
+err_irq:
+	free_irq(table->msix_arr[vecidx].vector, eq);
+
+err_eq:
+	mlx5_cmd_destroy_eq(dev, eq->eqn);
+
+err_in:
+	mlx5_vfree(in);
+
+err_buf:
+	mlx5_buf_free(dev, &eq->buf);
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_create_map_eq);
+
+int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq)
+{
+	struct mlx5_eq_table *table = &dev->priv.eq_table;
+	int err;
+
+	mlx5_debug_eq_remove(dev, eq);
+	free_irq(table->msix_arr[eq->irqn].vector, eq);
+	err = mlx5_cmd_destroy_eq(dev, eq->eqn);
+	if (err)
+		mlx5_core_warn(dev, "failed to destroy a previously created eq: eqn %d\n",
+			       eq->eqn);
+	mlx5_buf_free(dev, &eq->buf);
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_destroy_unmap_eq);
+
+int mlx5_eq_init(struct mlx5_core_dev *dev)
+{
+	int err;
+
+	spin_lock_init(&dev->priv.eq_table.lock);
+
+	err = mlx5_eq_debugfs_init(dev);
+
+	return err;
+}
+
+
+void mlx5_eq_cleanup(struct mlx5_core_dev *dev)
+{
+	mlx5_eq_debugfs_cleanup(dev);
+}
+
+int mlx5_start_eqs(struct mlx5_core_dev *dev)
+{
+	struct mlx5_eq_table *table = &dev->priv.eq_table;
+	int err;
+
+	err = mlx5_create_map_eq(dev, &table->cmd_eq, MLX5_EQ_VEC_CMD,
+				 MLX5_NUM_CMD_EQE, 1ull << MLX5_EVENT_TYPE_CMD,
+				 "mlx5_cmd_eq", &dev->priv.uuari.uars[0]);
+	if (err) {
+		mlx5_core_warn(dev, "failed to create cmd EQ %d\n", err);
+		return err;
+	}
+
+	mlx5_cmd_use_events(dev);
+
+	err = mlx5_create_map_eq(dev, &table->async_eq, MLX5_EQ_VEC_ASYNC,
+				 MLX5_NUM_ASYNC_EQE, MLX5_ASYNC_EVENT_MASK,
+				 "mlx5_async_eq", &dev->priv.uuari.uars[0]);
+	if (err) {
+		mlx5_core_warn(dev, "failed to create async EQ %d\n", err);
+		goto err1;
+	}
+
+	err = mlx5_create_map_eq(dev, &table->pages_eq,
+				 MLX5_EQ_VEC_PAGES,
+				 dev->caps.max_vf + 1,
+				 1 << MLX5_EVENT_TYPE_PAGE_REQUEST, "mlx5_pages_eq",
+				 &dev->priv.uuari.uars[0]);
+	if (err) {
+		mlx5_core_warn(dev, "failed to create pages EQ %d\n", err);
+		goto err2;
+	}
+
+	return err;
+
+err2:
+	mlx5_destroy_unmap_eq(dev, &table->async_eq);
+
+err1:
+	mlx5_cmd_use_polling(dev);
+	mlx5_destroy_unmap_eq(dev, &table->cmd_eq);
+	return err;
+}
+
+int mlx5_stop_eqs(struct mlx5_core_dev *dev)
+{
+	struct mlx5_eq_table *table = &dev->priv.eq_table;
+	int err;
+
+	err = mlx5_destroy_unmap_eq(dev, &table->pages_eq);
+	if (err)
+		return err;
+
+	mlx5_destroy_unmap_eq(dev, &table->async_eq);
+	mlx5_cmd_use_polling(dev);
+
+	err = mlx5_destroy_unmap_eq(dev, &table->cmd_eq);
+	if (err)
+		mlx5_cmd_use_events(dev);
+
+	return err;
+}
+
+int mlx5_core_eq_query(struct mlx5_core_dev *dev, struct mlx5_eq *eq,
+		       struct mlx5_query_eq_mbox_out *out, int outlen)
+{
+	struct mlx5_query_eq_mbox_in in;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(out, 0, outlen);
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_EQ);
+	in.eqn = eq->eqn;
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), out, outlen);
+	if (err)
+		return err;
+
+	if (out->hdr.status)
+		err = mlx5_cmd_status_to_err(&out->hdr);
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_core_eq_query);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/fw.c b/drivers/net/ethernet/mellanox/mlx5/core/fw.c
new file mode 100644
index 0000000..72a5222
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fw.c
@@ -0,0 +1,185 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include <linux/module.h>
+#include "mlx5_core.h"
+
+int mlx5_cmd_query_adapter(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd_query_adapter_mbox_out *out;
+	struct mlx5_cmd_query_adapter_mbox_in in;
+	int err;
+
+	out = kzalloc(sizeof(*out), GFP_KERNEL);
+	if (!out)
+		return -ENOMEM;
+
+	memset(&in, 0, sizeof(in));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_ADAPTER);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), out, sizeof(*out));
+	if (err)
+		goto out_out;
+
+	if (out->hdr.status) {
+		err = mlx5_cmd_status_to_err(&out->hdr);
+		goto out_out;
+	}
+
+	memcpy(dev->board_id, out->vsd_psid, sizeof(out->vsd_psid));
+
+out_out:
+	kfree(out);
+
+	return err;
+}
+
+int mlx5_cmd_query_hca_cap(struct mlx5_core_dev *dev,
+			   struct mlx5_caps *caps)
+{
+	struct mlx5_cmd_query_hca_cap_mbox_out *out;
+	struct mlx5_cmd_query_hca_cap_mbox_in in;
+	struct mlx5_query_special_ctxs_mbox_out ctx_out;
+	struct mlx5_query_special_ctxs_mbox_in ctx_in;
+	int err;
+	u16 t16;
+
+	out = kzalloc(sizeof(*out), GFP_KERNEL);
+	if (!out)
+		return -ENOMEM;
+
+	memset(&in, 0, sizeof(in));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_HCA_CAP);
+	in.hdr.opmod  = cpu_to_be16(0x1);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), out, sizeof(*out));
+	if (err)
+		goto out_out;
+
+	if (out->hdr.status) {
+		err = mlx5_cmd_status_to_err(&out->hdr);
+		goto out_out;
+	}
+
+
+	caps->log_max_eq = out->hca_cap.log_max_eq & 0xf;
+	caps->max_cqes = 1 << out->hca_cap.log_max_cq_sz;
+	caps->max_wqes = 1 << out->hca_cap.log_max_qp_sz;
+	caps->max_sq_desc_sz = be16_to_cpu(out->hca_cap.max_desc_sz_sq);
+	caps->max_rq_desc_sz = be16_to_cpu(out->hca_cap.max_desc_sz_rq);
+	caps->flags = be64_to_cpu(out->hca_cap.flags);
+	caps->stat_rate_support = be16_to_cpu(out->hca_cap.stat_rate_support);
+	caps->log_max_msg = out->hca_cap.log_max_msg & 0x1f;
+	caps->num_ports = out->hca_cap.num_ports & 0xf;
+	caps->log_max_cq = out->hca_cap.log_max_cq & 0x1f;
+	if (caps->num_ports > MLX5_MAX_PORTS) {
+		mlx5_core_err(dev, "device has %d ports while the driver supports max %d ports\n",
+			      caps->num_ports, MLX5_MAX_PORTS);
+		err = -EINVAL;
+		goto out_out;
+	}
+	caps->log_max_qp = out->hca_cap.log_max_qp & 0x1f;
+	caps->log_max_mkey = out->hca_cap.log_max_mkey & 0x3f;
+	caps->log_max_pd = out->hca_cap.log_max_pd & 0x1f;
+	caps->log_max_srq = out->hca_cap.log_max_srqs & 0x1f;
+	caps->local_ca_ack_delay = out->hca_cap.local_ca_ack_delay & 0x1f;
+	caps->log_max_mcg = out->hca_cap.log_max_mcg;
+	caps->max_qp_mcg = be16_to_cpu(out->hca_cap.max_qp_mcg);
+	caps->max_ra_res_qp = 1 << (out->hca_cap.log_max_ra_res_qp & 0x3f);
+	caps->max_ra_req_qp = 1 << (out->hca_cap.log_max_ra_req_qp & 0x3f);
+	caps->max_srq_wqes = 1 << out->hca_cap.log_max_srq_sz;
+	t16 = be16_to_cpu(out->hca_cap.bf_log_bf_reg_size);
+	if (t16 & 0x8000) {
+		caps->bf_reg_size = 1 << (t16 & 0x1f);
+		caps->bf_regs_per_page = MLX5_BF_REGS_PER_PAGE;
+	} else {
+		caps->bf_reg_size = 0;
+		caps->bf_regs_per_page = 0;
+	}
+	caps->min_page_sz = ~(u32)((1 << out->hca_cap.log_pg_sz) - 1);
+
+	memset(&ctx_in, 0, sizeof(ctx_in));
+	memset(&ctx_out, 0, sizeof(ctx_out));
+	ctx_in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_SPECIAL_CONTEXTS);
+	err = mlx5_cmd_exec(dev, &ctx_in, sizeof(ctx_in),
+				 &ctx_out, sizeof(ctx_out));
+	if (err)
+		goto out_out;
+
+	if (ctx_out.hdr.status)
+		err = mlx5_cmd_status_to_err(&ctx_out.hdr);
+
+	caps->reserved_lkey = be32_to_cpu(ctx_out.reserved_lkey);
+
+out_out:
+	kfree(out);
+
+	return err;
+}
+
+int mlx5_cmd_init_hca(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd_init_hca_mbox_in in;
+	struct mlx5_cmd_init_hca_mbox_out out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_INIT_HCA);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		err = mlx5_cmd_status_to_err(&out.hdr);
+
+	return err;
+}
+
+int mlx5_cmd_teardown_hca(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd_teardown_hca_mbox_in in;
+	struct mlx5_cmd_teardown_hca_mbox_out out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_TEARDOWN_HCA);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		err = mlx5_cmd_status_to_err(&out.hdr);
+
+	return err;
+}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/health.c b/drivers/net/ethernet/mellanox/mlx5/core/health.c
new file mode 100644
index 0000000..ea4b9bc
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/health.c
@@ -0,0 +1,217 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/random.h>
+#include <linux/vmalloc.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include "mlx5_core.h"
+
+enum {
+	MLX5_HEALTH_POLL_INTERVAL	= 2 * HZ,
+	MAX_MISSES			= 3,
+};
+
+enum {
+	MLX5_HEALTH_SYNDR_FW_ERR		= 0x1,
+	MLX5_HEALTH_SYNDR_IRISC_ERR		= 0x7,
+	MLX5_HEALTH_SYNDR_CRC_ERR		= 0x9,
+	MLX5_HEALTH_SYNDR_FETCH_PCI_ERR		= 0xa,
+	MLX5_HEALTH_SYNDR_HW_FTL_ERR		= 0xb,
+	MLX5_HEALTH_SYNDR_ASYNC_EQ_OVERRUN_ERR	= 0xc,
+	MLX5_HEALTH_SYNDR_EQ_ERR		= 0xd,
+	MLX5_HEALTH_SYNDR_FFSER_ERR		= 0xf,
+};
+
+static DEFINE_SPINLOCK(health_lock);
+
+static LIST_HEAD(health_list);
+static struct work_struct health_work;
+
+static health_handler_t reg_handler;
+int mlx5_register_health_report_handler(health_handler_t handler)
+{
+	spin_lock_irq(&health_lock);
+	if (reg_handler) {
+		spin_unlock_irq(&health_lock);
+		return -EEXIST;
+	}
+	reg_handler = handler;
+	spin_unlock_irq(&health_lock);
+
+	return 0;
+}
+EXPORT_SYMBOL(mlx5_register_health_report_handler);
+
+void mlx5_unregister_health_report_handler(void)
+{
+	spin_lock_irq(&health_lock);
+	reg_handler = NULL;
+	spin_unlock_irq(&health_lock);
+}
+EXPORT_SYMBOL(mlx5_unregister_health_report_handler);
+
+static void health_care(struct work_struct *work)
+{
+	struct mlx5_core_health *health, *n;
+	struct mlx5_core_dev *dev;
+	struct mlx5_priv *priv;
+	LIST_HEAD(tlist);
+
+	spin_lock_irq(&health_lock);
+	list_splice_init(&health_list, &tlist);
+
+	spin_unlock_irq(&health_lock);
+
+	list_for_each_entry_safe(health, n, &tlist, list) {
+		priv = container_of(health, struct mlx5_priv, health);
+		dev = container_of(priv, struct mlx5_core_dev, priv);
+		mlx5_core_warn(dev, "handling bad device here\n");
+		spin_lock_irq(&health_lock);
+		if (reg_handler)
+			reg_handler(dev->pdev, health->health,
+				    sizeof(health->health));
+
+		list_del_init(&health->list);
+		spin_unlock_irq(&health_lock);
+	}
+}
+
+static const char *hsynd_str(u8 synd)
+{
+	switch (synd) {
+	case MLX5_HEALTH_SYNDR_FW_ERR:
+		return "firmware internal error";
+	case MLX5_HEALTH_SYNDR_IRISC_ERR:
+		return "irisc not responding";
+	case MLX5_HEALTH_SYNDR_CRC_ERR:
+		return "firmware CRC error";
+	case MLX5_HEALTH_SYNDR_FETCH_PCI_ERR:
+		return "ICM fetch PCI error";
+	case MLX5_HEALTH_SYNDR_HW_FTL_ERR:
+		return "HW fatal error\n";
+	case MLX5_HEALTH_SYNDR_ASYNC_EQ_OVERRUN_ERR:
+		return "async EQ buffer overrun";
+	case MLX5_HEALTH_SYNDR_EQ_ERR:
+		return "EQ error";
+	case MLX5_HEALTH_SYNDR_FFSER_ERR:
+		return "FFSER error";
+	default:
+		return "unrecognized error";
+	}
+}
+
+static void print_health_info(struct mlx5_core_dev *dev)
+{
+	struct mlx5_core_health *health = &dev->priv.health;
+	struct health_buffer __iomem *h = health->health;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(h->assert_var); i++)
+		pr_info("assert_var[%d] 0x%08x\n", i, be32_to_cpu(h->assert_var[i]));
+
+	pr_info("assert_exit_ptr 0x%08x\n", be32_to_cpu(h->assert_exit_ptr));
+	pr_info("assert_callra 0x%08x\n", be32_to_cpu(h->assert_callra));
+	pr_info("fw_ver 0x%08x\n", be32_to_cpu(h->fw_ver));
+	pr_info("hw_id 0x%08x\n", be32_to_cpu(h->hw_id));
+	pr_info("irisc_index %d\n", h->irisc_index);
+	pr_info("synd 0x%x: %s\n", h->synd, hsynd_str(h->synd));
+	pr_info("ext_sync 0x%04x\n", be16_to_cpu(h->ext_sync));
+}
+
+static void poll_health(unsigned long data)
+{
+	struct mlx5_core_dev *dev = (struct mlx5_core_dev *)data;
+	struct mlx5_core_health *health = &dev->priv.health;
+	unsigned long next;
+	u32 count;
+
+	count = ioread32be(health->health_counter);
+	if (count == health->prev)
+		++health->miss_counter;
+	else
+		health->miss_counter = 0;
+
+	health->prev = count;
+	if (health->miss_counter == MAX_MISSES) {
+		mlx5_core_err(dev, "device's health compromised\n");
+		print_health_info(dev);
+		spin_lock_irq(&health_lock);
+		list_add_tail(&health->list, &health_list);
+		spin_unlock_irq(&health_lock);
+
+		queue_work(mlx5_core_wq, &health_work);
+	} else {
+		get_random_bytes(&next, sizeof(next));
+		next %= HZ;
+		next += jiffies + MLX5_HEALTH_POLL_INTERVAL;
+		mod_timer(&health->timer, next);
+	}
+}
+
+void mlx5_start_health_poll(struct mlx5_core_dev *dev)
+{
+	struct mlx5_core_health *health = &dev->priv.health;
+
+	INIT_LIST_HEAD(&health->list);
+	init_timer(&health->timer);
+	health->health = &dev->iseg->health;
+	health->health_counter = &dev->iseg->health_counter;
+
+	health->timer.data = (unsigned long)dev;
+	health->timer.function = poll_health;
+	health->timer.expires = round_jiffies(jiffies + MLX5_HEALTH_POLL_INTERVAL);
+	add_timer(&health->timer);
+}
+
+void mlx5_stop_health_poll(struct mlx5_core_dev *dev)
+{
+	struct mlx5_core_health *health = &dev->priv.health;
+
+	del_timer_sync(&health->timer);
+
+	spin_lock_irq(&health_lock);
+	if (!list_empty(&health->list))
+		list_del_init(&health->list);
+	spin_unlock_irq(&health_lock);
+}
+
+void mlx5_health_cleanup(void)
+{
+}
+
+void  __init mlx5_health_init(void)
+{
+	INIT_WORK(&health_work, health_care);
+}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/mad.c b/drivers/net/ethernet/mellanox/mlx5/core/mad.c
new file mode 100644
index 0000000..18d6fd5
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/mad.c
@@ -0,0 +1,78 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include "mlx5_core.h"
+
+int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, void *inb, void *outb,
+		      u16 opmod, int port)
+{
+	struct mlx5_mad_ifc_mbox_in *in = NULL;
+	struct mlx5_mad_ifc_mbox_out *out = NULL;
+	int err;
+
+	in = kzalloc(sizeof(*in), GFP_KERNEL);
+	if (!in)
+		return -ENOMEM;
+
+	out = kzalloc(sizeof(*out), GFP_KERNEL);
+	if (!out) {
+		err = -ENOMEM;
+		goto out;
+	}
+
+	in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_MAD_IFC);
+	in->hdr.opmod = cpu_to_be16(opmod);
+	in->port = port;
+
+	memcpy(in->data, inb, sizeof(in->data));
+
+	err = mlx5_cmd_exec(dev, in, sizeof(*in), out, sizeof(*out));
+	if (err)
+		goto out;
+
+	if (out->hdr.status) {
+		err = mlx5_cmd_status_to_err(&out->hdr);
+		goto out;
+	}
+
+	memcpy(outb, out->data, sizeof(out->data));
+
+out:
+	kfree(out);
+	kfree(in);
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_core_mad_ifc);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/main.c b/drivers/net/ethernet/mellanox/mlx5/core/main.c
new file mode 100644
index 0000000..f21cc39
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/main.c
@@ -0,0 +1,475 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <asm-generic/kmap_types.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/pci.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/io-mapping.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cq.h>
+#include <linux/mlx5/qp.h>
+#include <linux/mlx5/srq.h>
+#include <linux/debugfs.h>
+#include "mlx5_core.h"
+
+#define DRIVER_NAME "mlx5_core"
+#define DRIVER_VERSION "1.0"
+#define DRIVER_RELDATE	"June 2013"
+
+MODULE_AUTHOR("Eli Cohen <eli@mellanox.com>");
+MODULE_DESCRIPTION("Mellanox ConnectX-IB HCA core library");
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_VERSION(DRIVER_VERSION);
+
+int mlx5_core_debug_mask;
+module_param_named(debug_mask, mlx5_core_debug_mask, int, 0644);
+MODULE_PARM_DESC(debug_mask, "debug mask: 1 = dump cmd data, 2 = dump cmd exec time, 3 = both. Default=0");
+
+struct workqueue_struct *mlx5_core_wq;
+
+static int set_dma_caps(struct pci_dev *pdev)
+{
+	int err;
+
+	err = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));
+	if (err) {
+		dev_warn(&pdev->dev, "Warning: couldn't set 64-bit PCI DMA mask.\n");
+		err = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
+		if (err) {
+			dev_err(&pdev->dev, "Can't set PCI DMA mask, aborting.\n");
+			return err;
+		}
+	}
+
+	err = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));
+	if (err) {
+		dev_warn(&pdev->dev,
+			 "Warning: couldn't set 64-bit consistent PCI DMA mask.\n");
+		err = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));
+		if (err) {
+			dev_err(&pdev->dev,
+				"Can't set consistent PCI DMA mask, aborting.\n");
+			return err;
+		}
+	}
+
+	dma_set_max_seg_size(&pdev->dev, 2u * 1024 * 1024 * 1024);
+	return err;
+}
+
+static int request_bar(struct pci_dev *pdev)
+{
+	int err = 0;
+
+	if (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {
+		dev_err(&pdev->dev, "Missing registers BAR, aborting.\n");
+		return -ENODEV;
+	}
+
+	err = pci_request_regions(pdev, DRIVER_NAME);
+	if (err)
+		dev_err(&pdev->dev, "Couldn't get PCI resources, aborting\n");
+
+	return err;
+}
+
+static void release_bar(struct pci_dev *pdev)
+{
+	pci_release_regions(pdev);
+}
+
+static int mlx5_enable_msix(struct mlx5_core_dev *dev)
+{
+	struct mlx5_eq_table *table = &dev->priv.eq_table;
+	int num_eqs = 1 << dev->caps.log_max_eq;
+	int nvec;
+	int err;
+	int i;
+
+	nvec = dev->caps.num_ports * num_online_cpus() + MLX5_EQ_VEC_COMP_BASE;
+	nvec = min_t(int, nvec, num_eqs);
+	if (nvec <= MLX5_EQ_VEC_COMP_BASE)
+		return -ENOMEM;
+
+	table->msix_arr = kzalloc(nvec * sizeof(*table->msix_arr), GFP_KERNEL);
+	if (!table->msix_arr)
+		return -ENOMEM;
+
+	for (i = 0; i < nvec; i++)
+		table->msix_arr[i].entry = i;
+
+retry:
+	table->num_comp_vectors = nvec - MLX5_EQ_VEC_COMP_BASE;
+	err = pci_enable_msix(dev->pdev, table->msix_arr, nvec);
+	if (err <= 0) {
+		return err;
+	} else if (err > 2) {
+		nvec = err;
+		goto retry;
+	}
+
+	mlx5_core_dbg(dev, "received %d MSI vectors out of %d requested\n", err, nvec);
+
+	return 0;
+}
+
+static void mlx5_disable_msix(struct mlx5_core_dev *dev)
+{
+	struct mlx5_eq_table *table = &dev->priv.eq_table;
+
+	pci_disable_msix(dev->pdev);
+	kfree(table->msix_arr);
+}
+
+struct mlx5_reg_host_endianess {
+	u8	he;
+	u8      rsvd[15];
+};
+
+static int handle_hca_cap(struct mlx5_core_dev *dev)
+{
+	struct mlx5_cmd_query_hca_cap_mbox_out *query_out = NULL;
+	struct mlx5_cmd_set_hca_cap_mbox_in *set_ctx = NULL;
+	struct mlx5_cmd_query_hca_cap_mbox_in query_ctx;
+	struct mlx5_cmd_set_hca_cap_mbox_out set_out;
+	struct mlx5_profile *prof = dev->profile;
+	u64 flags;
+	int csum = 1;
+	int err;
+
+	memset(&query_ctx, 0, sizeof(query_ctx));
+	query_out = kzalloc(sizeof(*query_out), GFP_KERNEL);
+	if (!query_out)
+		return -ENOMEM;
+
+	set_ctx = kzalloc(sizeof(*set_ctx), GFP_KERNEL);
+	if (!set_ctx) {
+		err = -ENOMEM;
+		goto query_ex;
+	}
+
+	query_ctx.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_HCA_CAP);
+	query_ctx.hdr.opmod  = cpu_to_be16(0x1);
+	err = mlx5_cmd_exec(dev, &query_ctx, sizeof(query_ctx),
+				 query_out, sizeof(*query_out));
+	if (err)
+		goto query_ex;
+
+	err = mlx5_cmd_status_to_err(&query_out->hdr);
+	if (err) {
+		mlx5_core_warn(dev, "query hca cap failed, %d\n", err);
+		goto query_ex;
+	}
+
+	memcpy(&set_ctx->hca_cap, &query_out->hca_cap,
+	       sizeof(set_ctx->hca_cap));
+
+	if (prof->mask & MLX5_PROF_MASK_CMDIF_CSUM) {
+		csum = !!prof->cmdif_csum;
+		flags = be64_to_cpu(set_ctx->hca_cap.flags);
+		if (csum)
+			flags |= MLX5_DEV_CAP_FLAG_CMDIF_CSUM;
+		else
+			flags &= ~MLX5_DEV_CAP_FLAG_CMDIF_CSUM;
+
+		set_ctx->hca_cap.flags = cpu_to_be64(flags);
+	}
+
+	if (dev->profile->mask & MLX5_PROF_MASK_QP_SIZE)
+		set_ctx->hca_cap.log_max_qp = dev->profile->log_max_qp;
+
+	memset(&set_out, 0, sizeof(set_out));
+	set_ctx->hca_cap.uar_page_sz = cpu_to_be16(PAGE_SHIFT - 12);
+	set_ctx->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_SET_HCA_CAP);
+	err = mlx5_cmd_exec(dev, set_ctx, sizeof(*set_ctx),
+				 &set_out, sizeof(set_out));
+	if (err) {
+		mlx5_core_warn(dev, "set hca cap failed, %d\n", err);
+		goto query_ex;
+	}
+
+	err = mlx5_cmd_status_to_err(&set_out.hdr);
+	if (err)
+		goto query_ex;
+
+	if (!csum)
+		dev->cmd.checksum_disabled = 1;
+
+query_ex:
+	kfree(query_out);
+	kfree(set_ctx);
+
+	return err;
+}
+
+static int set_hca_ctrl(struct mlx5_core_dev *dev)
+{
+	struct mlx5_reg_host_endianess he_in;
+	struct mlx5_reg_host_endianess he_out;
+	int err;
+
+	memset(&he_in, 0, sizeof(he_in));
+	he_in.he = MLX5_SET_HOST_ENDIANNESS;
+	err = mlx5_core_access_reg(dev, &he_in,  sizeof(he_in),
+					&he_out, sizeof(he_out),
+					MLX5_REG_HOST_ENDIANNESS, 0, 1);
+	return err;
+}
+
+int mlx5_dev_init(struct mlx5_core_dev *dev, struct pci_dev *pdev)
+{
+	struct mlx5_priv *priv = &dev->priv;
+	int err;
+
+	dev->pdev = pdev;
+	pci_set_drvdata(dev->pdev, dev);
+	strncpy(priv->name, dev_name(&pdev->dev), MLX5_MAX_NAME_LEN);
+	priv->name[MLX5_MAX_NAME_LEN - 1] = 0;
+
+	mutex_init(&priv->pgdir_mutex);
+	INIT_LIST_HEAD(&priv->pgdir_list);
+	spin_lock_init(&priv->mkey_lock);
+
+	priv->dbg_root = debugfs_create_dir(dev_name(&pdev->dev), mlx5_debugfs_root);
+	if (!priv->dbg_root)
+		return -ENOMEM;
+
+	err = pci_enable_device(pdev);
+	if (err) {
+		dev_err(&pdev->dev, "Cannot enable PCI device, aborting.\n");
+		goto err_dbg;
+	}
+
+	err = request_bar(pdev);
+	if (err) {
+		dev_err(&pdev->dev, "error requesting BARs, aborting.\n");
+		goto err_disable;
+	}
+
+	pci_set_master(pdev);
+
+	err = set_dma_caps(pdev);
+	if (err) {
+		dev_err(&pdev->dev, "Failed setting DMA capabilities mask, aborting\n");
+		goto err_clr_master;
+	}
+
+	dev->iseg_base = pci_resource_start(dev->pdev, 0);
+	dev->iseg = ioremap(dev->iseg_base, sizeof(*dev->iseg));
+	if (!dev->iseg) {
+		err = -ENOMEM;
+		dev_err(&pdev->dev, "Failed mapping initialization segment, aborting\n");
+		goto err_clr_master;
+	}
+	dev_info(&pdev->dev, "firmware version: %d.%d.%d\n", fw_rev_maj(dev),
+		 fw_rev_min(dev), fw_rev_sub(dev));
+
+	err = mlx5_cmd_init(dev);
+	if (err) {
+		dev_err(&pdev->dev, "Failed initializing command interface, aborting\n");
+		goto err_unmap;
+	}
+
+	mlx5_pagealloc_init(dev);
+	err = set_hca_ctrl(dev);
+	if (err) {
+		dev_err(&pdev->dev, "set_hca_ctrl failed\n");
+		goto err_pagealloc_cleanup;
+	}
+
+	err = handle_hca_cap(dev);
+	if (err) {
+		dev_err(&pdev->dev, "handle_hca_cap failed\n");
+		goto err_pagealloc_cleanup;
+	}
+
+	err = mlx5_satisfy_startup_pages(dev);
+	if (err) {
+		dev_err(&pdev->dev, "failed to allocate startup pages\n");
+		goto err_pagealloc_cleanup;
+	}
+
+	err = mlx5_pagealloc_start(dev);
+	if (err) {
+		dev_err(&pdev->dev, "mlx5_pagealloc_start failed\n");
+		goto err_reclaim_pages;
+	}
+
+	err = mlx5_cmd_init_hca(dev);
+	if (err) {
+		dev_err(&pdev->dev, "init hca failed\n");
+		goto err_pagealloc_stop;
+	}
+
+	mlx5_start_health_poll(dev);
+
+	err = mlx5_cmd_query_hca_cap(dev, &dev->caps);
+	if (err) {
+		dev_err(&pdev->dev, "query hca failed\n");
+		goto err_stop_poll;
+	}
+
+	err = mlx5_cmd_query_adapter(dev);
+	if (err) {
+		dev_err(&pdev->dev, "query adapter failed\n");
+		goto err_stop_poll;
+	}
+
+	err = mlx5_enable_msix(dev);
+	if (err) {
+		dev_err(&pdev->dev, "enable msix failed\n");
+		goto err_stop_poll;
+	}
+
+	err = mlx5_eq_init(dev);
+	if (err) {
+		dev_err(&pdev->dev, "failed to initialize eq\n");
+		goto disable_msix;
+	}
+
+	err = mlx5_alloc_uuars(dev, &priv->uuari);
+	if (err) {
+		dev_err(&pdev->dev, "Failed allocating uar, aborting\n");
+		goto err_eq_cleanup;
+	}
+
+	err = mlx5_start_eqs(dev);
+	if (err) {
+		dev_err(&pdev->dev, "Failed to start pages and async EQs\n");
+		goto err_free_uar;
+	}
+
+	MLX5_INIT_DOORBELL_LOCK(&priv->cq_uar_lock);
+
+	mlx5_init_cq_table(dev);
+	mlx5_init_qp_table(dev);
+	mlx5_init_srq_table(dev);
+
+	return 0;
+
+err_free_uar:
+	mlx5_free_uuars(dev, &priv->uuari);
+
+err_eq_cleanup:
+	mlx5_eq_cleanup(dev);
+
+disable_msix:
+	mlx5_disable_msix(dev);
+
+err_stop_poll:
+	mlx5_stop_health_poll(dev);
+	mlx5_cmd_teardown_hca(dev);
+
+err_pagealloc_stop:
+	mlx5_pagealloc_stop(dev);
+
+err_reclaim_pages:
+	mlx5_reclaim_startup_pages(dev);
+
+err_pagealloc_cleanup:
+	mlx5_pagealloc_cleanup(dev);
+	mlx5_cmd_cleanup(dev);
+
+err_unmap:
+	iounmap(dev->iseg);
+
+err_clr_master:
+	pci_clear_master(dev->pdev);
+	release_bar(dev->pdev);
+
+err_disable:
+	pci_disable_device(dev->pdev);
+
+err_dbg:
+	debugfs_remove(priv->dbg_root);
+	return err;
+}
+EXPORT_SYMBOL(mlx5_dev_init);
+
+void mlx5_dev_cleanup(struct mlx5_core_dev *dev)
+{
+	struct mlx5_priv *priv = &dev->priv;
+
+	mlx5_cleanup_srq_table(dev);
+	mlx5_cleanup_qp_table(dev);
+	mlx5_cleanup_cq_table(dev);
+	mlx5_stop_eqs(dev);
+	mlx5_free_uuars(dev, &priv->uuari);
+	mlx5_eq_cleanup(dev);
+	mlx5_disable_msix(dev);
+	mlx5_stop_health_poll(dev);
+	mlx5_cmd_teardown_hca(dev);
+	mlx5_pagealloc_stop(dev);
+	mlx5_reclaim_startup_pages(dev);
+	mlx5_pagealloc_cleanup(dev);
+	mlx5_cmd_cleanup(dev);
+	iounmap(dev->iseg);
+	pci_clear_master(dev->pdev);
+	release_bar(dev->pdev);
+	pci_disable_device(dev->pdev);
+	debugfs_remove(priv->dbg_root);
+}
+EXPORT_SYMBOL(mlx5_dev_cleanup);
+
+static int __init init(void)
+{
+	int err;
+
+	mlx5_register_debugfs();
+	mlx5_core_wq = create_singlethread_workqueue("mlx5_core_wq");
+	if (!mlx5_core_wq) {
+		err = -ENOMEM;
+		goto err_debug;
+	}
+	mlx5_health_init();
+
+	return 0;
+
+	mlx5_health_cleanup();
+err_debug:
+	mlx5_unregister_debugfs();
+	return err;
+}
+
+static void __exit cleanup(void)
+{
+	mlx5_health_cleanup();
+	destroy_workqueue(mlx5_core_wq);
+	mlx5_unregister_debugfs();
+}
+
+module_init(init);
+module_exit(cleanup);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/mcg.c b/drivers/net/ethernet/mellanox/mlx5/core/mcg.c
new file mode 100644
index 0000000..4483764
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/mcg.c
@@ -0,0 +1,106 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include <rdma/ib_verbs.h>
+#include "mlx5_core.h"
+
+struct mlx5_attach_mcg_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	__be32			rsvd;
+	u8			gid[16];
+};
+
+struct mlx5_attach_mcg_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvf[8];
+};
+
+struct mlx5_detach_mcg_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	__be32			rsvd;
+	u8			gid[16];
+};
+
+struct mlx5_detach_mcg_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvf[8];
+};
+
+int mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn)
+{
+	struct mlx5_attach_mcg_mbox_in in;
+	struct mlx5_attach_mcg_mbox_out out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_ATTACH_TO_MCG);
+	memcpy(in.gid, mgid, sizeof(*mgid));
+	in.qpn = cpu_to_be32(qpn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		err = mlx5_cmd_status_to_err(&out.hdr);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_attach_mcg);
+
+int mlx5_core_detach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn)
+{
+	struct mlx5_detach_mcg_mbox_in in;
+	struct mlx5_detach_mcg_mbox_out out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DETACH_FROM_MCG);
+	memcpy(in.gid, mgid, sizeof(*mgid));
+	in.qpn = cpu_to_be32(qpn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		err = mlx5_cmd_status_to_err(&out.hdr);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_detach_mcg);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
new file mode 100644
index 0000000..68b74e1
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
@@ -0,0 +1,73 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef __MLX5_CORE_H__
+#define __MLX5_CORE_H__
+
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+
+extern int mlx5_core_debug_mask;
+
+#define mlx5_core_dbg(dev, format, arg...)				       \
+pr_debug("%s:%s:%d:(pid %d): " format, (dev)->priv.name, __func__, __LINE__,   \
+	 current->pid, ##arg)
+
+#define mlx5_core_dbg_mask(dev, mask, format, arg...)			       \
+do {									       \
+	if ((mask) & mlx5_core_debug_mask)				       \
+		pr_debug("%s:%s:%d:(pid %d): " format, (dev)->priv.name,       \
+			 __func__, __LINE__, current->pid, ##arg);	       \
+} while (0)
+
+#define mlx5_core_err(dev, format, arg...) \
+pr_err("%s:%s:%d:(pid %d): " format, (dev)->priv.name, __func__, __LINE__,     \
+	current->pid, ##arg)
+
+#define mlx5_core_warn(dev, format, arg...) \
+pr_warn("%s:%s:%d:(pid %d): " format, (dev)->priv.name, __func__, __LINE__,    \
+	current->pid, ##arg)
+
+enum {
+	MLX5_CMD_DATA, /* print command payload only */
+	MLX5_CMD_TIME, /* print command execution time */
+};
+
+
+int mlx5_cmd_query_hca_cap(struct mlx5_core_dev *dev,
+			   struct mlx5_caps *caps);
+int mlx5_cmd_query_adapter(struct mlx5_core_dev *dev);
+int mlx5_cmd_init_hca(struct mlx5_core_dev *dev);
+int mlx5_cmd_teardown_hca(struct mlx5_core_dev *dev);
+
+#endif /* __MLX5_CORE_H__ */
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/mr.c b/drivers/net/ethernet/mellanox/mlx5/core/mr.c
new file mode 100644
index 0000000..5b44e2e
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/mr.c
@@ -0,0 +1,136 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include "mlx5_core.h"
+
+int mlx5_core_create_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+			  struct mlx5_create_mkey_mbox_in *in, int inlen)
+{
+	struct mlx5_create_mkey_mbox_out out;
+	int err;
+	u8 key;
+
+	memset(&out, 0, sizeof(out));
+	spin_lock(&dev->priv.mkey_lock);
+	key = dev->priv.mkey_key++;
+	spin_unlock(&dev->priv.mkey_lock);
+	in->seg.qpn_mkey7_0 |= cpu_to_be32(key);
+	in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_CREATE_MKEY);
+	err = mlx5_cmd_exec(dev, in, inlen, &out, sizeof(out));
+	if (err) {
+		mlx5_core_dbg(dev, "cmd exec faile %d\n", err);
+		return err;
+	}
+
+	if (out.hdr.status) {
+		mlx5_core_dbg(dev, "status %d\n", out.hdr.status);
+		return mlx5_cmd_status_to_err(&out.hdr);
+	}
+
+	mr->key = mlx5_idx_to_mkey(be32_to_cpu(out.mkey) & 0xffffff) | key;
+	mlx5_core_dbg(dev, "out 0x%x, key 0x%x, mkey 0x%x\n", be32_to_cpu(out.mkey), key, mr->key);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_create_mkey);
+
+int mlx5_core_destroy_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr)
+{
+	struct mlx5_destroy_mkey_mbox_in in;
+	struct mlx5_destroy_mkey_mbox_out out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DESTROY_MKEY);
+	in.mkey = cpu_to_be32(mlx5_mkey_to_idx(mr->key));
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_destroy_mkey);
+
+int mlx5_core_query_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+			 struct mlx5_query_mkey_mbox_out *out, int outlen)
+{
+	struct mlx5_destroy_mkey_mbox_in in;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(out, 0, outlen);
+
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_MKEY);
+	in.mkey = cpu_to_be32(mlx5_mkey_to_idx(mr->key));
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), out, outlen);
+	if (err)
+		return err;
+
+	if (out->hdr.status)
+		return mlx5_cmd_status_to_err(&out->hdr);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_query_mkey);
+
+int mlx5_core_dump_fill_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+			     u32 *mkey)
+{
+	struct mlx5_query_special_ctxs_mbox_in in;
+	struct mlx5_query_special_ctxs_mbox_out out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_SPECIAL_CONTEXTS);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	*mkey = be32_to_cpu(out.dump_fill_mkey);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_dump_fill_mkey);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c b/drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c
new file mode 100644
index 0000000..f0bf463
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c
@@ -0,0 +1,435 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <asm-generic/kmap_types.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include "mlx5_core.h"
+
+enum {
+	MLX5_PAGES_CANT_GIVE	= 0,
+	MLX5_PAGES_GIVE		= 1,
+	MLX5_PAGES_TAKE		= 2
+};
+
+struct mlx5_pages_req {
+	struct mlx5_core_dev *dev;
+	u32	func_id;
+	s16	npages;
+	struct work_struct work;
+};
+
+struct fw_page {
+	struct rb_node	rb_node;
+	u64		addr;
+	struct page	*page;
+	u16		func_id;
+};
+
+struct mlx5_query_pages_inbox {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_query_pages_outbox {
+	struct mlx5_outbox_hdr	hdr;
+	u8			reserved[2];
+	__be16			func_id;
+	__be16			init_pages;
+	__be16			num_pages;
+};
+
+struct mlx5_manage_pages_inbox {
+	struct mlx5_inbox_hdr	hdr;
+	__be16			rsvd0;
+	__be16			func_id;
+	__be16			rsvd1;
+	__be16			num_entries;
+	u8			rsvd2[16];
+	__be64			pas[0];
+};
+
+struct mlx5_manage_pages_outbox {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[2];
+	__be16			num_entries;
+	u8			rsvd1[20];
+	__be64			pas[0];
+};
+
+static int insert_page(struct mlx5_core_dev *dev, u64 addr, struct page *page, u16 func_id)
+{
+	struct rb_root *root = &dev->priv.page_root;
+	struct rb_node **new = &root->rb_node;
+	struct rb_node *parent = NULL;
+	struct fw_page *nfp;
+	struct fw_page *tfp;
+
+	while (*new) {
+		parent = *new;
+		tfp = rb_entry(parent, struct fw_page, rb_node);
+		if (tfp->addr < addr)
+			new = &parent->rb_left;
+		else if (tfp->addr > addr)
+			new = &parent->rb_right;
+		else
+			return -EEXIST;
+	}
+
+	nfp = kmalloc(sizeof(*nfp), GFP_KERNEL);
+	if (!nfp)
+		return -ENOMEM;
+
+	nfp->addr = addr;
+	nfp->page = page;
+	nfp->func_id = func_id;
+
+	rb_link_node(&nfp->rb_node, parent, new);
+	rb_insert_color(&nfp->rb_node, root);
+
+	return 0;
+}
+
+static struct page *remove_page(struct mlx5_core_dev *dev, u64 addr)
+{
+	struct rb_root *root = &dev->priv.page_root;
+	struct rb_node *tmp = root->rb_node;
+	struct page *result = NULL;
+	struct fw_page *tfp;
+
+	while (tmp) {
+		tfp = rb_entry(tmp, struct fw_page, rb_node);
+		if (tfp->addr < addr) {
+			tmp = tmp->rb_left;
+		} else if (tfp->addr > addr) {
+			tmp = tmp->rb_right;
+		} else {
+			rb_erase(&tfp->rb_node, root);
+			result = tfp->page;
+			kfree(tfp);
+			break;
+		}
+	}
+
+	return result;
+}
+
+static int mlx5_cmd_query_pages(struct mlx5_core_dev *dev, u16 *func_id,
+				s16 *pages, s16 *init_pages)
+{
+	struct mlx5_query_pages_inbox	in;
+	struct mlx5_query_pages_outbox	out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_PAGES);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	if (pages)
+		*pages = be16_to_cpu(out.num_pages);
+	if (init_pages)
+		*init_pages = be16_to_cpu(out.init_pages);
+	*func_id = be16_to_cpu(out.func_id);
+
+	return err;
+}
+
+static int give_pages(struct mlx5_core_dev *dev, u16 func_id, int npages,
+		      int notify_fail)
+{
+	struct mlx5_manage_pages_inbox *in;
+	struct mlx5_manage_pages_outbox out;
+	struct page *page;
+	int inlen;
+	u64 addr;
+	int err;
+	int i;
+
+	inlen = sizeof(*in) + npages * sizeof(in->pas[0]);
+	in = mlx5_vzalloc(inlen);
+	if (!in) {
+		mlx5_core_warn(dev, "vzalloc failed %d\n", inlen);
+		return -ENOMEM;
+	}
+	memset(&out, 0, sizeof(out));
+
+	for (i = 0; i < npages; i++) {
+		page = alloc_page(GFP_HIGHUSER);
+		if (!page) {
+			err = -ENOMEM;
+			mlx5_core_warn(dev, "failed to allocate page\n");
+			goto out_alloc;
+		}
+		addr = dma_map_page(&dev->pdev->dev, page, 0,
+				    PAGE_SIZE, DMA_BIDIRECTIONAL);
+		if (dma_mapping_error(&dev->pdev->dev, addr)) {
+			mlx5_core_warn(dev, "failed dma mapping page\n");
+			__free_page(page);
+			err = -ENOMEM;
+			goto out_alloc;
+		}
+		err = insert_page(dev, addr, page, func_id);
+		if (err) {
+			mlx5_core_err(dev, "failed to track allocated page\n");
+			dma_unmap_page(&dev->pdev->dev, addr, PAGE_SIZE, DMA_BIDIRECTIONAL);
+			__free_page(page);
+			err = -ENOMEM;
+			goto out_alloc;
+		}
+		in->pas[i] = cpu_to_be64(addr);
+	}
+
+	in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_MANAGE_PAGES);
+	in->hdr.opmod = cpu_to_be16(MLX5_PAGES_GIVE);
+	in->func_id = cpu_to_be16(func_id);
+	in->num_entries = cpu_to_be16(npages);
+	err = mlx5_cmd_exec(dev, in, inlen, &out, sizeof(out));
+	mlx5_core_dbg(dev, "err %d\n", err);
+	if (err) {
+		mlx5_core_warn(dev, "func_id 0x%x, npages %d, err %d\n", func_id, npages, err);
+		goto out_alloc;
+	}
+	dev->priv.fw_pages += npages;
+
+	if (out.hdr.status) {
+		err = mlx5_cmd_status_to_err(&out.hdr);
+		if (err) {
+			mlx5_core_warn(dev, "func_id 0x%x, npages %d, status %d\n", func_id, npages, out.hdr.status);
+			goto out_alloc;
+		}
+	}
+
+	mlx5_core_dbg(dev, "err %d\n", err);
+
+	goto out_free;
+
+out_alloc:
+	if (notify_fail) {
+		memset(in, 0, inlen);
+		memset(&out, 0, sizeof(out));
+		in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_MANAGE_PAGES);
+		in->hdr.opmod = cpu_to_be16(MLX5_PAGES_CANT_GIVE);
+		if (mlx5_cmd_exec(dev, in, sizeof(*in), &out, sizeof(out)))
+			mlx5_core_warn(dev, "\n");
+	}
+	for (i--; i >= 0; i--) {
+		addr = be64_to_cpu(in->pas[i]);
+		page = remove_page(dev, addr);
+		if (!page) {
+			mlx5_core_err(dev, "BUG: can't remove page at addr 0x%llx\n",
+				      addr);
+			continue;
+		}
+		dma_unmap_page(&dev->pdev->dev, addr, PAGE_SIZE, DMA_BIDIRECTIONAL);
+		__free_page(page);
+	}
+
+out_free:
+	mlx5_vfree(in);
+	return err;
+}
+
+static int reclaim_pages(struct mlx5_core_dev *dev, u32 func_id, int npages,
+			 int *nclaimed)
+{
+	struct mlx5_manage_pages_inbox   in;
+	struct mlx5_manage_pages_outbox *out;
+	struct page *page;
+	int num_claimed;
+	int outlen;
+	u64 addr;
+	int err;
+	int i;
+
+	memset(&in, 0, sizeof(in));
+	outlen = sizeof(*out) + npages * sizeof(out->pas[0]);
+	out = mlx5_vzalloc(outlen);
+	if (!out)
+		return -ENOMEM;
+
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_MANAGE_PAGES);
+	in.hdr.opmod = cpu_to_be16(MLX5_PAGES_TAKE);
+	in.func_id = cpu_to_be16(func_id);
+	in.num_entries = cpu_to_be16(npages);
+	mlx5_core_dbg(dev, "npages %d, outlen %d\n", npages, outlen);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), out, outlen);
+	if (err) {
+		mlx5_core_err(dev, "failed recliaming pages\n");
+		goto out_free;
+	}
+	dev->priv.fw_pages -= npages;
+
+	if (out->hdr.status) {
+		err = mlx5_cmd_status_to_err(&out->hdr);
+		goto out_free;
+	}
+
+	num_claimed = be16_to_cpu(out->num_entries);
+	if (nclaimed)
+		*nclaimed = num_claimed;
+
+	for (i = 0; i < num_claimed; i++) {
+		addr = be64_to_cpu(out->pas[i]);
+		page = remove_page(dev, addr);
+		if (!page) {
+			mlx5_core_warn(dev, "FW reported unknown DMA address 0x%llx\n", addr);
+		} else {
+			dma_unmap_page(&dev->pdev->dev, addr, PAGE_SIZE, DMA_BIDIRECTIONAL);
+			__free_page(page);
+		}
+	}
+
+out_free:
+	mlx5_vfree(out);
+	return err;
+}
+
+static void pages_work_handler(struct work_struct *work)
+{
+	struct mlx5_pages_req *req = container_of(work, struct mlx5_pages_req, work);
+	struct mlx5_core_dev *dev = req->dev;
+	int err = 0;
+
+	if (req->npages < 0)
+		err = reclaim_pages(dev, req->func_id, -1 * req->npages, NULL);
+	else if (req->npages > 0)
+		err = give_pages(dev, req->func_id, req->npages, 1);
+
+	if (err)
+		mlx5_core_warn(dev, "%s fail %d\n", req->npages < 0 ?
+			       "reclaim" : "give", err);
+
+	kfree(req);
+}
+
+void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
+				 s16 npages)
+{
+	struct mlx5_pages_req *req;
+
+	req = kzalloc(sizeof(*req), GFP_ATOMIC);
+	if (!req) {
+		mlx5_core_warn(dev, "failed to allocate pages request\n");
+		return;
+	}
+
+	req->dev = dev;
+	req->func_id = func_id;
+	req->npages = npages;
+	INIT_WORK(&req->work, pages_work_handler);
+	queue_work(dev->priv.pg_wq, &req->work);
+}
+
+int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev)
+{
+	s16 uninitialized_var(init_pages);
+	u16 uninitialized_var(func_id);
+	int err;
+
+	err = mlx5_cmd_query_pages(dev, &func_id, NULL, &init_pages);
+	if (err)
+		return err;
+
+	mlx5_core_dbg(dev, "requested %d init pages for func_id 0x%x\n", init_pages, func_id);
+
+	return give_pages(dev, func_id, init_pages, 0);
+}
+
+static int optimal_reclaimed_pages(void)
+{
+	struct mlx5_cmd_prot_block *block;
+	struct mlx5_cmd_layout *lay;
+	int ret;
+
+	ret = (sizeof(lay->in) + sizeof(block->data) -
+	       sizeof(struct mlx5_manage_pages_outbox)) / 8;
+
+	return ret;
+}
+
+int mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev)
+{
+	unsigned long end = jiffies + msecs_to_jiffies(5000);
+	struct fw_page *fwp;
+	struct rb_node *p;
+	int err;
+
+	do {
+		p = rb_first(&dev->priv.page_root);
+		if (p) {
+			fwp = rb_entry(p, struct fw_page, rb_node);
+			err = reclaim_pages(dev, fwp->func_id, optimal_reclaimed_pages(), NULL);
+			if (err) {
+				mlx5_core_warn(dev, "failed reclaiming pages (%d)\n", err);
+				return err;
+			}
+		}
+		if (time_after(jiffies, end)) {
+			mlx5_core_warn(dev, "FW did not return all pages. giving up...\n");
+			break;
+		}
+	} while (p);
+
+	return 0;
+}
+
+void mlx5_pagealloc_init(struct mlx5_core_dev *dev)
+{
+	dev->priv.page_root = RB_ROOT;
+}
+
+void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev)
+{
+	/* nothing */
+}
+
+int mlx5_pagealloc_start(struct mlx5_core_dev *dev)
+{
+	dev->priv.pg_wq = create_singlethread_workqueue("mlx5_page_allocator");
+	if (!dev->priv.pg_wq)
+		return -ENOMEM;
+
+	return 0;
+}
+
+void mlx5_pagealloc_stop(struct mlx5_core_dev *dev)
+{
+	destroy_workqueue(dev->priv.pg_wq);
+}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/pd.c b/drivers/net/ethernet/mellanox/mlx5/core/pd.c
new file mode 100644
index 0000000..790da5c
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/pd.c
@@ -0,0 +1,101 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include "mlx5_core.h"
+
+struct mlx5_alloc_pd_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_alloc_pd_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			pdn;
+	u8			rsvd[4];
+};
+
+struct mlx5_dealloc_pd_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			pdn;
+	u8			rsvd[4];
+};
+
+struct mlx5_dealloc_pd_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn)
+{
+	struct mlx5_alloc_pd_mbox_in	in;
+	struct mlx5_alloc_pd_mbox_out	out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_ALLOC_PD);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	*pdn = be32_to_cpu(out.pdn) & 0xffffff;
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_alloc_pd);
+
+int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn)
+{
+	struct mlx5_dealloc_pd_mbox_in	in;
+	struct mlx5_dealloc_pd_mbox_out	out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DEALLOC_PD);
+	in.pdn = cpu_to_be32(pdn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_dealloc_pd);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/port.c b/drivers/net/ethernet/mellanox/mlx5/core/port.c
new file mode 100644
index 0000000..f6afe7b
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/port.c
@@ -0,0 +1,104 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/module.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include "mlx5_core.h"
+
+int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
+			 int size_in, void *data_out, int size_out,
+			 u16 reg_num, int arg, int write)
+{
+	struct mlx5_access_reg_mbox_in *in = NULL;
+	struct mlx5_access_reg_mbox_out *out = NULL;
+	int err = -ENOMEM;
+
+	in = mlx5_vzalloc(sizeof(*in) + size_in);
+	if (!in)
+		return -ENOMEM;
+
+	out = mlx5_vzalloc(sizeof(*out) + size_out);
+	if (!out)
+		goto ex1;
+
+	memcpy(in->data, data_in, size_in);
+	in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_ACCESS_REG);
+	in->hdr.opmod = cpu_to_be16(!write);
+	in->arg = cpu_to_be32(arg);
+	in->register_id = cpu_to_be16(reg_num);
+	err = mlx5_cmd_exec(dev, in, sizeof(*in) + size_in, out,
+			    sizeof(out) + size_out);
+	if (err)
+		goto ex2;
+
+	if (out->hdr.status)
+		err = mlx5_cmd_status_to_err(&out->hdr);
+
+	if (!err)
+		memcpy(data_out, out->data, size_out);
+
+ex2:
+	mlx5_vfree(out);
+ex1:
+	mlx5_vfree(in);
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_core_access_reg);
+
+
+struct mlx5_reg_pcap {
+	u8			rsvd0;
+	u8			port_num;
+	u8			rsvd1[2];
+	__be32			caps_127_96;
+	__be32			caps_95_64;
+	__be32			caps_63_32;
+	__be32			caps_31_0;
+};
+
+int mlx5_set_port_caps(struct mlx5_core_dev *dev, int port_num, u32 caps)
+{
+	struct mlx5_reg_pcap in;
+	struct mlx5_reg_pcap out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	in.caps_127_96 = cpu_to_be32(caps);
+	in.port_num = port_num;
+
+	err = mlx5_core_access_reg(dev, &in, sizeof(in), &out,
+				   sizeof(out), MLX5_REG_PCAP, 0, 1);
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_set_port_caps);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/qp.c b/drivers/net/ethernet/mellanox/mlx5/core/qp.c
new file mode 100644
index 0000000..54faf8b
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/qp.c
@@ -0,0 +1,301 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+
+#include <linux/gfp.h>
+#include <linux/export.h>
+#include <linux/mlx5/cmd.h>
+#include <linux/mlx5/qp.h>
+#include <linux/mlx5/driver.h>
+
+#include "mlx5_core.h"
+
+void mlx5_qp_event(struct mlx5_core_dev *dev, u32 qpn, int event_type)
+{
+	struct mlx5_qp_table *table = &dev->priv.qp_table;
+	struct mlx5_core_qp *qp;
+
+	spin_lock(&table->lock);
+
+	qp = radix_tree_lookup(&table->tree, qpn);
+	if (qp)
+		atomic_inc(&qp->refcount);
+
+	spin_unlock(&table->lock);
+
+	if (!qp) {
+		mlx5_core_warn(dev, "Async event for bogus QP 0x%x\n", qpn);
+		return;
+	}
+
+	qp->event(qp, event_type);
+
+	if (atomic_dec_and_test(&qp->refcount))
+		complete(&qp->free);
+}
+
+int mlx5_core_create_qp(struct mlx5_core_dev *dev,
+			struct mlx5_core_qp *qp,
+			struct mlx5_create_qp_mbox_in *in,
+			int inlen)
+{
+	struct mlx5_qp_table *table = &dev->priv.qp_table;
+	struct mlx5_create_qp_mbox_out out;
+	struct mlx5_destroy_qp_mbox_in din;
+	struct mlx5_destroy_qp_mbox_out dout;
+	int err;
+
+	memset(&dout, 0, sizeof(dout));
+	in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_CREATE_QP);
+
+	err = mlx5_cmd_exec(dev, in, inlen, &out, sizeof(out));
+	if (err) {
+		mlx5_core_warn(dev, "ret %d", err);
+		return err;
+	}
+
+	if (out.hdr.status) {
+		pr_warn("current num of QPs 0x%x\n", atomic_read(&dev->num_qps));
+		return mlx5_cmd_status_to_err(&out.hdr);
+	}
+
+	qp->qpn = be32_to_cpu(out.qpn) & 0xffffff;
+	mlx5_core_dbg(dev, "qpn = 0x%x\n", qp->qpn);
+
+	spin_lock_irq(&table->lock);
+	err = radix_tree_insert(&table->tree, qp->qpn, qp);
+	spin_unlock_irq(&table->lock);
+	if (err) {
+		mlx5_core_warn(dev, "err %d", err);
+		goto err_cmd;
+	}
+
+	err = mlx5_debug_qp_add(dev, qp);
+	if (err)
+		mlx5_core_dbg(dev, "failed adding QP 0x%x to debug file system\n",
+			      qp->qpn);
+
+	qp->pid = current->pid;
+	atomic_set(&qp->refcount, 1);
+	atomic_inc(&dev->num_qps);
+	init_completion(&qp->free);
+
+	return 0;
+
+err_cmd:
+	memset(&din, 0, sizeof(din));
+	memset(&dout, 0, sizeof(dout));
+	din.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DESTROY_QP);
+	din.qpn = cpu_to_be32(qp->qpn);
+	mlx5_cmd_exec(dev, &din, sizeof(din), &out, sizeof(dout));
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_core_create_qp);
+
+int mlx5_core_destroy_qp(struct mlx5_core_dev *dev,
+			 struct mlx5_core_qp *qp)
+{
+	struct mlx5_destroy_qp_mbox_in in;
+	struct mlx5_destroy_qp_mbox_out out;
+	struct mlx5_qp_table *table = &dev->priv.qp_table;
+	unsigned long flags;
+	int err;
+
+	mlx5_debug_qp_remove(dev, qp);
+
+	spin_lock_irqsave(&table->lock, flags);
+	radix_tree_delete(&table->tree, qp->qpn);
+	spin_unlock_irqrestore(&table->lock, flags);
+
+	if (atomic_dec_and_test(&qp->refcount))
+		complete(&qp->free);
+	wait_for_completion(&qp->free);
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DESTROY_QP);
+	in.qpn = cpu_to_be32(qp->qpn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	atomic_dec(&dev->num_qps);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mlx5_core_destroy_qp);
+
+int mlx5_core_qp_modify(struct mlx5_core_dev *dev, enum mlx5_qp_state cur_state,
+			enum mlx5_qp_state new_state,
+			struct mlx5_modify_qp_mbox_in *in, int sqd_event,
+			struct mlx5_core_qp *qp)
+{
+	static const u16 optab[MLX5_QP_NUM_STATE][MLX5_QP_NUM_STATE] = {
+		[MLX5_QP_STATE_RST] = {
+			[MLX5_QP_STATE_RST]	= MLX5_CMD_OP_2RST_QP,
+			[MLX5_QP_STATE_ERR]	= MLX5_CMD_OP_2ERR_QP,
+			[MLX5_QP_STATE_INIT]	= MLX5_CMD_OP_RST2INIT_QP,
+		},
+		[MLX5_QP_STATE_INIT]  = {
+			[MLX5_QP_STATE_RST]	= MLX5_CMD_OP_2RST_QP,
+			[MLX5_QP_STATE_ERR]	= MLX5_CMD_OP_2ERR_QP,
+			[MLX5_QP_STATE_INIT]	= MLX5_CMD_OP_INIT2INIT_QP,
+			[MLX5_QP_STATE_RTR]	= MLX5_CMD_OP_INIT2RTR_QP,
+		},
+		[MLX5_QP_STATE_RTR]   = {
+			[MLX5_QP_STATE_RST]	= MLX5_CMD_OP_2RST_QP,
+			[MLX5_QP_STATE_ERR]	= MLX5_CMD_OP_2ERR_QP,
+			[MLX5_QP_STATE_RTS]	= MLX5_CMD_OP_RTR2RTS_QP,
+		},
+		[MLX5_QP_STATE_RTS]   = {
+			[MLX5_QP_STATE_RST]	= MLX5_CMD_OP_2RST_QP,
+			[MLX5_QP_STATE_ERR]	= MLX5_CMD_OP_2ERR_QP,
+			[MLX5_QP_STATE_RTS]	= MLX5_CMD_OP_RTS2RTS_QP,
+			[MLX5_QP_STATE_SQD]	= MLX5_CMD_OP_RTS2SQD_QP,
+		},
+		[MLX5_QP_STATE_SQD] = {
+			[MLX5_QP_STATE_RST]	= MLX5_CMD_OP_2RST_QP,
+			[MLX5_QP_STATE_ERR]	= MLX5_CMD_OP_2ERR_QP,
+			[MLX5_QP_STATE_RTS]	= MLX5_CMD_OP_SQD2RTS_QP,
+			[MLX5_QP_STATE_SQD]	= MLX5_CMD_OP_SQD2SQD_QP,
+		},
+		[MLX5_QP_STATE_SQER] = {
+			[MLX5_QP_STATE_RST]	= MLX5_CMD_OP_2RST_QP,
+			[MLX5_QP_STATE_ERR]	= MLX5_CMD_OP_2ERR_QP,
+			[MLX5_QP_STATE_RTS]	= MLX5_CMD_OP_SQERR2RTS_QP,
+		},
+		[MLX5_QP_STATE_ERR] = {
+			[MLX5_QP_STATE_RST]	= MLX5_CMD_OP_2RST_QP,
+			[MLX5_QP_STATE_ERR]	= MLX5_CMD_OP_2ERR_QP,
+		}
+	};
+
+	struct mlx5_modify_qp_mbox_out out;
+	int err = 0;
+	u16 op;
+
+	if (cur_state >= MLX5_QP_NUM_STATE || new_state >= MLX5_QP_NUM_STATE ||
+	    !optab[cur_state][new_state])
+		return -EINVAL;
+
+	memset(&out, 0, sizeof(out));
+	op = optab[cur_state][new_state];
+	in->hdr.opcode = cpu_to_be16(op);
+	in->qpn = cpu_to_be32(qp->qpn);
+	err = mlx5_cmd_exec(dev, in, sizeof(*in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	return mlx5_cmd_status_to_err(&out.hdr);
+}
+EXPORT_SYMBOL_GPL(mlx5_core_qp_modify);
+
+void mlx5_init_qp_table(struct mlx5_core_dev *dev)
+{
+	struct mlx5_qp_table *table = &dev->priv.qp_table;
+
+	spin_lock_init(&table->lock);
+	INIT_RADIX_TREE(&table->tree, GFP_ATOMIC);
+	mlx5_qp_debugfs_init(dev);
+}
+
+void mlx5_cleanup_qp_table(struct mlx5_core_dev *dev)
+{
+	mlx5_qp_debugfs_cleanup(dev);
+}
+
+int mlx5_core_qp_query(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp,
+		       struct mlx5_query_qp_mbox_out *out, int outlen)
+{
+	struct mlx5_query_qp_mbox_in in;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(out, 0, outlen);
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_QP);
+	in.qpn = cpu_to_be32(qp->qpn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), out, outlen);
+	if (err)
+		return err;
+
+	if (out->hdr.status)
+		return mlx5_cmd_status_to_err(&out->hdr);
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_core_qp_query);
+
+int mlx5_core_xrcd_alloc(struct mlx5_core_dev *dev, u32 *xrcdn)
+{
+	struct mlx5_alloc_xrcd_mbox_in in;
+	struct mlx5_alloc_xrcd_mbox_out out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_ALLOC_XRCD);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		err = mlx5_cmd_status_to_err(&out.hdr);
+	else
+		*xrcdn = be32_to_cpu(out.xrcdn);
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_core_xrcd_alloc);
+
+int mlx5_core_xrcd_dealloc(struct mlx5_core_dev *dev, u32 xrcdn)
+{
+	struct mlx5_dealloc_xrcd_mbox_in in;
+	struct mlx5_dealloc_xrcd_mbox_out out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DEALLOC_XRCD);
+	in.xrcdn = cpu_to_be32(xrcdn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		err = mlx5_cmd_status_to_err(&out.hdr);
+
+	return err;
+}
+EXPORT_SYMBOL_GPL(mlx5_core_xrcd_dealloc);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/srq.c b/drivers/net/ethernet/mellanox/mlx5/core/srq.c
new file mode 100644
index 0000000..38bce93
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/srq.c
@@ -0,0 +1,223 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include <linux/mlx5/srq.h>
+#include <rdma/ib_verbs.h>
+#include "mlx5_core.h"
+
+void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type)
+{
+	struct mlx5_srq_table *table = &dev->priv.srq_table;
+	struct mlx5_core_srq *srq;
+
+	spin_lock(&table->lock);
+
+	srq = radix_tree_lookup(&table->tree, srqn);
+	if (srq)
+		atomic_inc(&srq->refcount);
+
+	spin_unlock(&table->lock);
+
+	if (!srq) {
+		mlx5_core_warn(dev, "Async event for bogus SRQ 0x%08x\n", srqn);
+		return;
+	}
+
+	srq->event(srq, event_type);
+
+	if (atomic_dec_and_test(&srq->refcount))
+		complete(&srq->free);
+}
+
+struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn)
+{
+	struct mlx5_srq_table *table = &dev->priv.srq_table;
+	struct mlx5_core_srq *srq;
+
+	spin_lock(&table->lock);
+
+	srq = radix_tree_lookup(&table->tree, srqn);
+	if (srq)
+		atomic_inc(&srq->refcount);
+
+	spin_unlock(&table->lock);
+
+	return srq;
+}
+EXPORT_SYMBOL(mlx5_core_get_srq);
+
+int mlx5_core_create_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
+			 struct mlx5_create_srq_mbox_in *in, int inlen)
+{
+	struct mlx5_create_srq_mbox_out out;
+	struct mlx5_srq_table *table = &dev->priv.srq_table;
+	struct mlx5_destroy_srq_mbox_in din;
+	struct mlx5_destroy_srq_mbox_out dout;
+	int err;
+
+	memset(&out, 0, sizeof(out));
+	in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_CREATE_SRQ);
+	err = mlx5_cmd_exec(dev, in, inlen, &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	srq->srqn = be32_to_cpu(out.srqn) & 0xffffff;
+
+	atomic_set(&srq->refcount, 1);
+	init_completion(&srq->free);
+
+	spin_lock_irq(&table->lock);
+	err = radix_tree_insert(&table->tree, srq->srqn, srq);
+	spin_unlock_irq(&table->lock);
+	if (err) {
+		mlx5_core_warn(dev, "err %d, srqn 0x%x\n", err, srq->srqn);
+		goto err_cmd;
+	}
+
+	return 0;
+
+err_cmd:
+	memset(&din, 0, sizeof(din));
+	memset(&dout, 0, sizeof(dout));
+	din.srqn = cpu_to_be32(srq->srqn);
+	din.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DESTROY_SRQ);
+	mlx5_cmd_exec(dev, &din, sizeof(din), &dout, sizeof(dout));
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_create_srq);
+
+int mlx5_core_destroy_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq)
+{
+	struct mlx5_destroy_srq_mbox_in in;
+	struct mlx5_destroy_srq_mbox_out out;
+	struct mlx5_srq_table *table = &dev->priv.srq_table;
+	struct mlx5_core_srq *tmp;
+	int err;
+
+	spin_lock_irq(&table->lock);
+	tmp = radix_tree_delete(&table->tree, srq->srqn);
+	spin_unlock_irq(&table->lock);
+	if (!tmp) {
+		mlx5_core_warn(dev, "srq 0x%x not found in tree\n", srq->srqn);
+		return -EINVAL;
+	}
+	if (tmp != srq) {
+		mlx5_core_warn(dev, "corruption on srqn 0x%x\n", srq->srqn);
+		return -EINVAL;
+	}
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DESTROY_SRQ);
+	in.srqn = cpu_to_be32(srq->srqn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	if (atomic_dec_and_test(&srq->refcount))
+		complete(&srq->free);
+	wait_for_completion(&srq->free);
+
+	return 0;
+}
+EXPORT_SYMBOL(mlx5_core_destroy_srq);
+
+int mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
+			struct mlx5_query_srq_mbox_out *out)
+{
+	struct mlx5_query_srq_mbox_in in;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(out, 0, sizeof(*out));
+
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_QUERY_SRQ);
+	in.srqn = cpu_to_be32(srq->srqn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), out, sizeof(*out));
+	if (err)
+		return err;
+
+	if (out->hdr.status)
+		return mlx5_cmd_status_to_err(&out->hdr);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_query_srq);
+
+int mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
+		      u16 lwm, int is_srq)
+{
+	struct mlx5_arm_srq_mbox_in	in;
+	struct mlx5_arm_srq_mbox_out	out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_ARM_RQ);
+	in.hdr.opmod = cpu_to_be16(!!is_srq);
+	in.srqn = cpu_to_be32(srq->srqn);
+	in.lwm = cpu_to_be16(lwm);
+
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		return err;
+
+	if (out.hdr.status)
+		return mlx5_cmd_status_to_err(&out.hdr);
+
+	return err;
+}
+EXPORT_SYMBOL(mlx5_core_arm_srq);
+
+void mlx5_init_srq_table(struct mlx5_core_dev *dev)
+{
+	struct mlx5_srq_table *table = &dev->priv.srq_table;
+
+	spin_lock_init(&table->lock);
+	INIT_RADIX_TREE(&table->tree, GFP_ATOMIC);
+}
+
+void mlx5_cleanup_srq_table(struct mlx5_core_dev *dev)
+{
+	/* nothing */
+}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/uar.c b/drivers/net/ethernet/mellanox/mlx5/core/uar.c
new file mode 100644
index 0000000..71d4a39
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/uar.c
@@ -0,0 +1,223 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/cmd.h>
+#include "mlx5_core.h"
+
+enum {
+	NUM_DRIVER_UARS		= 4,
+	NUM_LOW_LAT_UUARS	= 4,
+};
+
+
+struct mlx5_alloc_uar_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_alloc_uar_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			uarn;
+	u8			rsvd[4];
+};
+
+struct mlx5_free_uar_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			uarn;
+	u8			rsvd[4];
+};
+
+struct mlx5_free_uar_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn)
+{
+	struct mlx5_alloc_uar_mbox_in	in;
+	struct mlx5_alloc_uar_mbox_out	out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	memset(&out, 0, sizeof(out));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_ALLOC_UAR);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		goto ex;
+
+	if (out.hdr.status) {
+		err = mlx5_cmd_status_to_err(&out.hdr);
+		goto ex;
+	}
+
+	*uarn = be32_to_cpu(out.uarn) & 0xffffff;
+
+ex:
+	return err;
+}
+EXPORT_SYMBOL(mlx5_cmd_alloc_uar);
+
+int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn)
+{
+	struct mlx5_free_uar_mbox_in	in;
+	struct mlx5_free_uar_mbox_out	out;
+	int err;
+
+	memset(&in, 0, sizeof(in));
+	in.hdr.opcode = cpu_to_be16(MLX5_CMD_OP_DEALLOC_UAR);
+	in.uarn = cpu_to_be32(uarn);
+	err = mlx5_cmd_exec(dev, &in, sizeof(in), &out, sizeof(out));
+	if (err)
+		goto ex;
+
+	if (out.hdr.status)
+		err = mlx5_cmd_status_to_err(&out.hdr);
+
+ex:
+	return err;
+}
+EXPORT_SYMBOL(mlx5_cmd_free_uar);
+
+static int need_uuar_lock(int uuarn)
+{
+	int tot_uuars = NUM_DRIVER_UARS * MLX5_BF_REGS_PER_PAGE;
+
+	if (uuarn == 0 || tot_uuars - NUM_LOW_LAT_UUARS)
+		return 0;
+
+	return 1;
+}
+
+int mlx5_alloc_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari)
+{
+	int tot_uuars = NUM_DRIVER_UARS * MLX5_BF_REGS_PER_PAGE;
+	struct mlx5_bf *bf;
+	phys_addr_t addr;
+	int err;
+	int i;
+
+	uuari->num_uars = NUM_DRIVER_UARS;
+	uuari->num_low_latency_uuars = NUM_LOW_LAT_UUARS;
+
+	mutex_init(&uuari->lock);
+	uuari->uars = kcalloc(uuari->num_uars, sizeof(*uuari->uars), GFP_KERNEL);
+	if (!uuari->uars)
+		return -ENOMEM;
+
+	uuari->bfs = kcalloc(tot_uuars, sizeof(*uuari->bfs), GFP_KERNEL);
+	if (!uuari->bfs) {
+		err = -ENOMEM;
+		goto out_uars;
+	}
+
+	uuari->bitmap = kcalloc(BITS_TO_LONGS(tot_uuars), sizeof(*uuari->bitmap),
+				GFP_KERNEL);
+	if (!uuari->bitmap) {
+		err = -ENOMEM;
+		goto out_bfs;
+	}
+
+	uuari->count = kcalloc(tot_uuars, sizeof(*uuari->count), GFP_KERNEL);
+	if (!uuari->count) {
+		err = -ENOMEM;
+		goto out_bitmap;
+	}
+
+	for (i = 0; i < uuari->num_uars; i++) {
+		err = mlx5_cmd_alloc_uar(dev, &uuari->uars[i].index);
+		if (err)
+			goto out_count;
+
+		addr = dev->iseg_base + ((phys_addr_t)(uuari->uars[i].index) << PAGE_SHIFT);
+		uuari->uars[i].map = ioremap(addr, PAGE_SIZE);
+		if (!uuari->uars[i].map) {
+			mlx5_cmd_free_uar(dev, uuari->uars[i].index);
+			goto out_count;
+		}
+		mlx5_core_dbg(dev, "allocated uar index 0x%x, mmaped at %p\n",
+			      uuari->uars[i].index, uuari->uars[i].map);
+	}
+
+	for (i = 0; i < tot_uuars; i++) {
+		bf = &uuari->bfs[i];
+
+		bf->buf_size = dev->caps.bf_reg_size / 2;
+		bf->uar = &uuari->uars[i / MLX5_BF_REGS_PER_PAGE];
+		bf->regreg = uuari->uars[i / MLX5_BF_REGS_PER_PAGE].map;
+		bf->reg = NULL; /* Add WC support */
+		bf->offset = (i % MLX5_BF_REGS_PER_PAGE) * dev->caps.bf_reg_size +
+			MLX5_BF_OFFSET;
+		bf->need_lock = need_uuar_lock(i);
+		spin_lock_init(&bf->lock);
+		spin_lock_init(&bf->lock32);
+		bf->uuarn = i;
+	}
+
+	return 0;
+
+out_count:
+	for (i--; i >= 0; i--) {
+		iounmap(uuari->uars[i].map);
+		mlx5_cmd_free_uar(dev, uuari->uars[i].index);
+	}
+	kfree(uuari->count);
+
+out_bitmap:
+	kfree(uuari->bitmap);
+
+out_bfs:
+	kfree(uuari->bfs);
+
+out_uars:
+	kfree(uuari->uars);
+	return err;
+}
+
+int mlx5_free_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari)
+{
+	int i = uuari->num_uars;
+
+	for (i--; i >= 0; i--) {
+		iounmap(uuari->uars[i].map);
+		mlx5_cmd_free_uar(dev, uuari->uars[i].index);
+	}
+
+	kfree(uuari->count);
+	kfree(uuari->bitmap);
+	kfree(uuari->bfs);
+	kfree(uuari->uars);
+
+	return 0;
+}
diff --git a/include/linux/mlx5/cmd.h b/include/linux/mlx5/cmd.h
new file mode 100644
index 0000000..2826a4b
--- /dev/null
+++ b/include/linux/mlx5/cmd.h
@@ -0,0 +1,51 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_CMD_H
+#define MLX5_CMD_H
+
+#include <linux/types.h>
+
+struct manage_pages_layout {
+	u64	ptr;
+	u32	reserved;
+	u16	num_entries;
+	u16	func_id;
+};
+
+
+struct mlx5_cmd_alloc_uar_imm_out {
+	u32	rsvd[3];
+	u32	uarn;
+};
+
+#endif /* MLX5_CMD_H */
diff --git a/include/linux/mlx5/cq.h b/include/linux/mlx5/cq.h
new file mode 100644
index 0000000..3db67f7
--- /dev/null
+++ b/include/linux/mlx5/cq.h
@@ -0,0 +1,165 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_CORE_CQ_H
+#define MLX5_CORE_CQ_H
+
+#include <rdma/ib_verbs.h>
+#include <linux/mlx5/driver.h>
+
+
+struct mlx5_core_cq {
+	u32			cqn;
+	int			cqe_sz;
+	__be32		       *set_ci_db;
+	__be32		       *arm_db;
+	atomic_t		refcount;
+	struct completion	free;
+	unsigned		vector;
+	int			irqn;
+	void (*comp)		(struct mlx5_core_cq *);
+	void (*event)		(struct mlx5_core_cq *, enum mlx5_event);
+	struct mlx5_uar	       *uar;
+	u32			cons_index;
+	unsigned		arm_sn;
+	struct mlx5_rsc_debug	*dbg;
+	int			pid;
+};
+
+
+enum {
+	MLX5_CQE_SYNDROME_LOCAL_LENGTH_ERR		= 0x01,
+	MLX5_CQE_SYNDROME_LOCAL_QP_OP_ERR		= 0x02,
+	MLX5_CQE_SYNDROME_LOCAL_PROT_ERR		= 0x04,
+	MLX5_CQE_SYNDROME_WR_FLUSH_ERR			= 0x05,
+	MLX5_CQE_SYNDROME_MW_BIND_ERR			= 0x06,
+	MLX5_CQE_SYNDROME_BAD_RESP_ERR			= 0x10,
+	MLX5_CQE_SYNDROME_LOCAL_ACCESS_ERR		= 0x11,
+	MLX5_CQE_SYNDROME_REMOTE_INVAL_REQ_ERR		= 0x12,
+	MLX5_CQE_SYNDROME_REMOTE_ACCESS_ERR		= 0x13,
+	MLX5_CQE_SYNDROME_REMOTE_OP_ERR			= 0x14,
+	MLX5_CQE_SYNDROME_TRANSPORT_RETRY_EXC_ERR	= 0x15,
+	MLX5_CQE_SYNDROME_RNR_RETRY_EXC_ERR		= 0x16,
+	MLX5_CQE_SYNDROME_REMOTE_ABORTED_ERR		= 0x22,
+};
+
+enum {
+	MLX5_CQE_OWNER_MASK	= 1,
+	MLX5_CQE_REQ		= 0,
+	MLX5_CQE_RESP_WR_IMM	= 1,
+	MLX5_CQE_RESP_SEND	= 2,
+	MLX5_CQE_RESP_SEND_IMM	= 3,
+	MLX5_CQE_RESP_SEND_INV	= 4,
+	MLX5_CQE_RESIZE_CQ	= 0xff, /* TBD */
+	MLX5_CQE_REQ_ERR	= 13,
+	MLX5_CQE_RESP_ERR	= 14,
+};
+
+enum {
+	MLX5_CQ_MODIFY_RESEIZE = 0,
+	MLX5_CQ_MODIFY_MODER = 1,
+	MLX5_CQ_MODIFY_MAPPING = 2,
+};
+
+struct mlx5_cq_modify_params {
+	int	type;
+	union {
+		struct {
+			u32	page_offset;
+			u8	log_cq_size;
+		} resize;
+
+		struct {
+		} moder;
+
+		struct {
+		} mapping;
+	} params;
+};
+
+enum {
+	CQE_SIZE_64 = 0,
+	CQE_SIZE_128 = 1,
+};
+
+static inline int cqe_sz_to_mlx_sz(u8 size)
+{
+	return size == 64 ? CQE_SIZE_64 : CQE_SIZE_128;
+}
+
+static inline void mlx5_cq_set_ci(struct mlx5_core_cq *cq)
+{
+	*cq->set_ci_db = cpu_to_be32(cq->cons_index & 0xffffff);
+}
+
+enum {
+	MLX5_CQ_DB_REQ_NOT_SOL		= 1 << 24,
+	MLX5_CQ_DB_REQ_NOT		= 0 << 24
+};
+
+static inline void mlx5_cq_arm(struct mlx5_core_cq *cq, u32 cmd,
+			       void __iomem *uar_page,
+			       spinlock_t *doorbell_lock)
+{
+	__be32 doorbell[2];
+	u32 sn;
+	u32 ci;
+
+	sn = cq->arm_sn & 3;
+	ci = cq->cons_index & 0xffffff;
+
+	*cq->arm_db = cpu_to_be32(sn << 28 | cmd | ci);
+
+	/* Make sure that the doorbell record in host memory is
+	 * written before ringing the doorbell via PCI MMIO.
+	 */
+	wmb();
+
+	doorbell[0] = cpu_to_be32(sn << 28 | cmd | ci);
+	doorbell[1] = cpu_to_be32(cq->cqn);
+
+	mlx5_write64(doorbell, uar_page + MLX5_CQ_DOORBELL, doorbell_lock);
+}
+
+int mlx5_init_cq_table(struct mlx5_core_dev *dev);
+void mlx5_cleanup_cq_table(struct mlx5_core_dev *dev);
+int mlx5_core_create_cq(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq,
+			struct mlx5_create_cq_mbox_in *in, int inlen);
+int mlx5_core_destroy_cq(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq);
+int mlx5_core_query_cq(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq,
+		       struct mlx5_query_cq_mbox_out *out);
+int mlx5_core_modify_cq(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq,
+			int type, struct mlx5_cq_modify_params *params);
+int mlx5_debug_cq_add(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq);
+void mlx5_debug_cq_remove(struct mlx5_core_dev *dev, struct mlx5_core_cq *cq);
+
+#endif /* MLX5_CORE_CQ_H */
diff --git a/include/linux/mlx5/device.h b/include/linux/mlx5/device.h
new file mode 100644
index 0000000..5139091
--- /dev/null
+++ b/include/linux/mlx5/device.h
@@ -0,0 +1,893 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_DEVICE_H
+#define MLX5_DEVICE_H
+
+#include <linux/types.h>
+#include <rdma/ib_verbs.h>
+
+#if defined(__LITTLE_ENDIAN)
+#define MLX5_SET_HOST_ENDIANNESS	0
+#elif defined(__BIG_ENDIAN)
+#define MLX5_SET_HOST_ENDIANNESS	0x80
+#else
+#error Host endianness not defined
+#endif
+
+enum {
+	MLX5_MAX_COMMANDS		= 32,
+	MLX5_CMD_DATA_BLOCK_SIZE	= 512,
+	MLX5_PCI_CMD_XPORT		= 7,
+};
+
+enum {
+	MLX5_EXTENDED_UD_AV		= 0x80000000,
+};
+
+enum {
+	MLX5_CQ_STATE_ARMED		= 9,
+	MLX5_CQ_STATE_ALWAYS_ARMED	= 0xb,
+	MLX5_CQ_STATE_FIRED		= 0xa,
+};
+
+enum {
+	MLX5_STAT_RATE_OFFSET	= 5,
+};
+
+enum {
+	MLX5_INLINE_SEG = 0x80000000,
+};
+
+enum {
+	MLX5_PERM_LOCAL_READ	= 1 << 2,
+	MLX5_PERM_LOCAL_WRITE	= 1 << 3,
+	MLX5_PERM_REMOTE_READ	= 1 << 4,
+	MLX5_PERM_REMOTE_WRITE	= 1 << 5,
+	MLX5_PERM_ATOMIC	= 1 << 6,
+	MLX5_PERM_UMR_EN	= 1 << 7,
+};
+
+enum {
+	MLX5_PCIE_CTRL_SMALL_FENCE	= 1 << 0,
+	MLX5_PCIE_CTRL_RELAXED_ORDERING	= 1 << 2,
+	MLX5_PCIE_CTRL_NO_SNOOP		= 1 << 3,
+	MLX5_PCIE_CTRL_TLP_PROCE_EN	= 1 << 6,
+	MLX5_PCIE_CTRL_TPH_MASK		= 3 << 4,
+};
+
+enum {
+	MLX5_ACCESS_MODE_PA	= 0,
+	MLX5_ACCESS_MODE_MTT	= 1,
+	MLX5_ACCESS_MODE_KLM	= 2
+};
+
+enum {
+	MLX5_MKEY_REMOTE_INVAL	= 1 << 24,
+	MLX5_MKEY_FLAG_SYNC_UMR = 1 << 29,
+	MLX5_MKEY_BSF_EN	= 1 << 30,
+	MLX5_MKEY_LEN64		= 1 << 31,
+};
+
+enum {
+	MLX5_EN_RD	= (u64)1,
+	MLX5_EN_WR	= (u64)2
+};
+
+enum {
+	MLX5_BF_REGS_PER_PAGE	= 4,
+	MLX5_MAX_UAR_PAGES	= 1 << 8,
+	MLX5_MAX_UUARS		= MLX5_MAX_UAR_PAGES * MLX5_BF_REGS_PER_PAGE,
+};
+
+enum {
+	MLX5_MKEY_MASK_LEN		= 1ull << 0,
+	MLX5_MKEY_MASK_PAGE_SIZE	= 1ull << 1,
+	MLX5_MKEY_MASK_START_ADDR	= 1ull << 6,
+	MLX5_MKEY_MASK_PD		= 1ull << 7,
+	MLX5_MKEY_MASK_EN_RINVAL	= 1ull << 8,
+	MLX5_MKEY_MASK_BSF_EN		= 1ull << 12,
+	MLX5_MKEY_MASK_KEY		= 1ull << 13,
+	MLX5_MKEY_MASK_QPN		= 1ull << 14,
+	MLX5_MKEY_MASK_LR		= 1ull << 17,
+	MLX5_MKEY_MASK_LW		= 1ull << 18,
+	MLX5_MKEY_MASK_RR		= 1ull << 19,
+	MLX5_MKEY_MASK_RW		= 1ull << 20,
+	MLX5_MKEY_MASK_A		= 1ull << 21,
+	MLX5_MKEY_MASK_SMALL_FENCE	= 1ull << 23,
+	MLX5_MKEY_MASK_FREE		= 1ull << 29,
+};
+
+enum mlx5_event {
+	MLX5_EVENT_TYPE_COMP		   = 0x0,
+
+	MLX5_EVENT_TYPE_PATH_MIG	   = 0x01,
+	MLX5_EVENT_TYPE_COMM_EST	   = 0x02,
+	MLX5_EVENT_TYPE_SQ_DRAINED	   = 0x03,
+	MLX5_EVENT_TYPE_SRQ_LAST_WQE	   = 0x13,
+	MLX5_EVENT_TYPE_SRQ_RQ_LIMIT	   = 0x14,
+
+	MLX5_EVENT_TYPE_CQ_ERROR	   = 0x04,
+	MLX5_EVENT_TYPE_WQ_CATAS_ERROR	   = 0x05,
+	MLX5_EVENT_TYPE_PATH_MIG_FAILED	   = 0x07,
+	MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR = 0x10,
+	MLX5_EVENT_TYPE_WQ_ACCESS_ERROR	   = 0x11,
+	MLX5_EVENT_TYPE_SRQ_CATAS_ERROR	   = 0x12,
+
+	MLX5_EVENT_TYPE_INTERNAL_ERROR	   = 0x08,
+	MLX5_EVENT_TYPE_PORT_CHANGE	   = 0x09,
+	MLX5_EVENT_TYPE_GPIO_EVENT	   = 0x15,
+	MLX5_EVENT_TYPE_REMOTE_CONFIG	   = 0x19,
+
+	MLX5_EVENT_TYPE_DB_BF_CONGESTION   = 0x1a,
+	MLX5_EVENT_TYPE_STALL_EVENT	   = 0x1b,
+
+	MLX5_EVENT_TYPE_CMD		   = 0x0a,
+	MLX5_EVENT_TYPE_PAGE_REQUEST	   = 0xb,
+};
+
+enum {
+	MLX5_PORT_CHANGE_SUBTYPE_DOWN		= 1,
+	MLX5_PORT_CHANGE_SUBTYPE_ACTIVE		= 4,
+	MLX5_PORT_CHANGE_SUBTYPE_INITIALIZED	= 5,
+	MLX5_PORT_CHANGE_SUBTYPE_LID		= 6,
+	MLX5_PORT_CHANGE_SUBTYPE_PKEY		= 7,
+	MLX5_PORT_CHANGE_SUBTYPE_GUID		= 8,
+	MLX5_PORT_CHANGE_SUBTYPE_CLIENT_REREG	= 9,
+};
+
+enum {
+	MLX5_DEV_CAP_FLAG_RC		= 1LL <<  0,
+	MLX5_DEV_CAP_FLAG_UC		= 1LL <<  1,
+	MLX5_DEV_CAP_FLAG_UD		= 1LL <<  2,
+	MLX5_DEV_CAP_FLAG_XRC		= 1LL <<  3,
+	MLX5_DEV_CAP_FLAG_SRQ		= 1LL <<  6,
+	MLX5_DEV_CAP_FLAG_BAD_PKEY_CNTR	= 1LL <<  8,
+	MLX5_DEV_CAP_FLAG_BAD_QKEY_CNTR	= 1LL <<  9,
+	MLX5_DEV_CAP_FLAG_APM		= 1LL << 17,
+	MLX5_DEV_CAP_FLAG_ATOMIC	= 1LL << 18,
+	MLX5_DEV_CAP_FLAG_ON_DMND_PG	= 1LL << 24,
+	MLX5_DEV_CAP_FLAG_RESIZE_SRQ	= 1LL << 32,
+	MLX5_DEV_CAP_FLAG_REMOTE_FENCE	= 1LL << 38,
+	MLX5_DEV_CAP_FLAG_TLP_HINTS	= 1LL << 39,
+	MLX5_DEV_CAP_FLAG_SIG_HAND_OVER	= 1LL << 40,
+	MLX5_DEV_CAP_FLAG_DCT		= 1LL << 41,
+	MLX5_DEV_CAP_FLAG_CMDIF_CSUM	= 1LL << 46,
+};
+
+enum {
+	MLX5_OPCODE_NOP			= 0x00,
+	MLX5_OPCODE_SEND_INVAL		= 0x01,
+	MLX5_OPCODE_RDMA_WRITE		= 0x08,
+	MLX5_OPCODE_RDMA_WRITE_IMM	= 0x09,
+	MLX5_OPCODE_SEND		= 0x0a,
+	MLX5_OPCODE_SEND_IMM		= 0x0b,
+	MLX5_OPCODE_RDMA_READ		= 0x10,
+	MLX5_OPCODE_ATOMIC_CS		= 0x11,
+	MLX5_OPCODE_ATOMIC_FA		= 0x12,
+	MLX5_OPCODE_ATOMIC_MASKED_CS	= 0x14,
+	MLX5_OPCODE_ATOMIC_MASKED_FA	= 0x15,
+	MLX5_OPCODE_BIND_MW		= 0x18,
+	MLX5_OPCODE_CONFIG_CMD		= 0x1f,
+
+	MLX5_RECV_OPCODE_RDMA_WRITE_IMM	= 0x00,
+	MLX5_RECV_OPCODE_SEND		= 0x01,
+	MLX5_RECV_OPCODE_SEND_IMM	= 0x02,
+	MLX5_RECV_OPCODE_SEND_INVAL	= 0x03,
+
+	MLX5_CQE_OPCODE_ERROR		= 0x1e,
+	MLX5_CQE_OPCODE_RESIZE		= 0x16,
+
+	MLX5_OPCODE_SET_PSV		= 0x20,
+	MLX5_OPCODE_GET_PSV		= 0x21,
+	MLX5_OPCODE_CHECK_PSV		= 0x22,
+	MLX5_OPCODE_RGET_PSV		= 0x26,
+	MLX5_OPCODE_RCHECK_PSV		= 0x27,
+
+	MLX5_OPCODE_UMR			= 0x25,
+
+};
+
+enum {
+	MLX5_SET_PORT_RESET_QKEY	= 0,
+	MLX5_SET_PORT_GUID0		= 16,
+	MLX5_SET_PORT_NODE_GUID		= 17,
+	MLX5_SET_PORT_SYS_GUID		= 18,
+	MLX5_SET_PORT_GID_TABLE		= 19,
+	MLX5_SET_PORT_PKEY_TABLE	= 20,
+};
+
+enum {
+	MLX5_MAX_PAGE_SHIFT		= 31
+};
+
+struct mlx5_inbox_hdr {
+	__be16		opcode;
+	u8		rsvd[4];
+	__be16		opmod;
+};
+
+struct mlx5_outbox_hdr {
+	u8		status;
+	u8		rsvd[3];
+	__be32		syndrome;
+};
+
+struct mlx5_cmd_query_adapter_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_cmd_query_adapter_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[24];
+	u8			intapin;
+	u8			rsvd1[13];
+	__be16			vsd_vendor_id;
+	u8			vsd[208];
+	u8			vsd_psid[16];
+};
+
+struct mlx5_hca_cap {
+	u8	rsvd1[16];
+	u8	log_max_srq_sz;
+	u8	log_max_qp_sz;
+	u8	rsvd2;
+	u8	log_max_qp;
+	u8	log_max_strq_sz;
+	u8	log_max_srqs;
+	u8	rsvd4[2];
+	u8	rsvd5;
+	u8	log_max_cq_sz;
+	u8	rsvd6;
+	u8	log_max_cq;
+	u8	log_max_eq_sz;
+	u8	log_max_mkey;
+	u8	rsvd7;
+	u8	log_max_eq;
+	u8	max_indirection;
+	u8	log_max_mrw_sz;
+	u8	log_max_bsf_list_sz;
+	u8	log_max_klm_list_sz;
+	u8	rsvd_8_0;
+	u8	log_max_ra_req_dc;
+	u8	rsvd_8_1;
+	u8	log_max_ra_res_dc;
+	u8	rsvd9;
+	u8	log_max_ra_req_qp;
+	u8	rsvd10;
+	u8	log_max_ra_res_qp;
+	u8	rsvd11[4];
+	__be16	max_qp_count;
+	__be16	rsvd12;
+	u8	rsvd13;
+	u8	local_ca_ack_delay;
+	u8	rsvd14;
+	u8	num_ports;
+	u8	log_max_msg;
+	u8	rsvd15[3];
+	__be16	stat_rate_support;
+	u8	rsvd16[2];
+	__be64	flags;
+	u8	rsvd17;
+	u8	uar_sz;
+	u8	rsvd18;
+	u8	log_pg_sz;
+	__be16	bf_log_bf_reg_size;
+	u8	rsvd19[4];
+	__be16	max_desc_sz_sq;
+	u8	rsvd20[2];
+	__be16	max_desc_sz_rq;
+	u8	rsvd21[2];
+	__be16	max_desc_sz_sq_dc;
+	u8	rsvd22[4];
+	__be16	max_qp_mcg;
+	u8	rsvd23;
+	u8	log_max_mcg;
+	u8	rsvd24;
+	u8	log_max_pd;
+	u8	rsvd25;
+	u8	log_max_xrcd;
+	u8	rsvd26[40];
+	__be32  uar_page_sz;
+	u8	rsvd27[28];
+	u8	log_msx_atomic_size_qp;
+	u8	rsvd28[2];
+	u8	log_msx_atomic_size_dc;
+	u8	rsvd29[76];
+};
+
+
+struct mlx5_cmd_query_hca_cap_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+
+struct mlx5_cmd_query_hca_cap_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[8];
+	struct mlx5_hca_cap     hca_cap;
+};
+
+
+struct mlx5_cmd_set_hca_cap_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd[8];
+	struct mlx5_hca_cap     hca_cap;
+};
+
+
+struct mlx5_cmd_set_hca_cap_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[8];
+};
+
+
+struct mlx5_cmd_init_hca_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd0[2];
+	__be16			profile;
+	u8			rsvd1[4];
+};
+
+struct mlx5_cmd_init_hca_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_cmd_teardown_hca_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd0[2];
+	__be16			profile;
+	u8			rsvd1[4];
+};
+
+struct mlx5_cmd_teardown_hca_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_cmd_layout {
+	u8		type;
+	u8		rsvd0[3];
+	__be32		inlen;
+	__be64		in_ptr;
+	__be32		in[4];
+	__be32		out[4];
+	__be64		out_ptr;
+	__be32		outlen;
+	u8		token;
+	u8		sig;
+	u8		rsvd1;
+	u8		status_own;
+};
+
+
+struct health_buffer {
+	__be32		assert_var[5];
+	__be32		rsvd0[3];
+	__be32		assert_exit_ptr;
+	__be32		assert_callra;
+	__be32		rsvd1[2];
+	__be32		fw_ver;
+	__be32		hw_id;
+	__be32		rsvd2;
+	u8		irisc_index;
+	u8		synd;
+	__be16		ext_sync;
+};
+
+struct mlx5_init_seg {
+	__be32			fw_rev;
+	__be32			cmdif_rev_fw_sub;
+	__be32			rsvd0[2];
+	__be32			cmdq_addr_h;
+	__be32			cmdq_addr_l_sz;
+	__be32			cmd_dbell;
+	__be32			rsvd1[121];
+	struct health_buffer	health;
+	__be32			rsvd2[884];
+	__be32			health_counter;
+	__be32			rsvd3[1023];
+	__be64			ieee1588_clk;
+	__be32			ieee1588_clk_type;
+	__be32			clr_intx;
+};
+
+struct mlx5_eqe_comp {
+	__be32	reserved[6];
+	__be32	cqn;
+};
+
+struct mlx5_eqe_qp_srq {
+	__be32	reserved[6];
+	__be32	qp_srq_n;
+};
+
+struct mlx5_eqe_cq_err {
+	__be32	cqn;
+	u8	reserved1[7];
+	u8	syndrome;
+};
+
+struct mlx5_eqe_dropped_packet {
+};
+
+struct mlx5_eqe_port_state {
+	u8	reserved0[8];
+	u8	port;
+};
+
+struct mlx5_eqe_gpio {
+	__be32	reserved0[2];
+	__be64	gpio_event;
+};
+
+struct mlx5_eqe_congestion {
+	u8	type;
+	u8	rsvd0;
+	u8	congestion_level;
+};
+
+struct mlx5_eqe_stall_vl {
+	u8	rsvd0[3];
+	u8	port_vl;
+};
+
+struct mlx5_eqe_cmd {
+	__be32	vector;
+	__be32	rsvd[6];
+};
+
+struct mlx5_eqe_page_req {
+	u8		rsvd0[2];
+	__be16		func_id;
+	u8		rsvd1[2];
+	__be16		num_pages;
+	__be32		rsvd2[5];
+};
+
+union ev_data {
+	__be32				raw[7];
+	struct mlx5_eqe_cmd		cmd;
+	struct mlx5_eqe_comp		comp;
+	struct mlx5_eqe_qp_srq		qp_srq;
+	struct mlx5_eqe_cq_err		cq_err;
+	struct mlx5_eqe_dropped_packet	dp;
+	struct mlx5_eqe_port_state	port;
+	struct mlx5_eqe_gpio		gpio;
+	struct mlx5_eqe_congestion	cong;
+	struct mlx5_eqe_stall_vl	stall_vl;
+	struct mlx5_eqe_page_req	req_pages;
+} __packed;
+
+struct mlx5_eqe {
+	u8		rsvd0;
+	u8		type;
+	u8		rsvd1;
+	u8		sub_type;
+	__be32		rsvd2[7];
+	union ev_data	data;
+	__be16		rsvd3;
+	u8		signature;
+	u8		owner;
+} __packed;
+
+struct mlx5_cmd_prot_block {
+	u8		data[MLX5_CMD_DATA_BLOCK_SIZE];
+	u8		rsvd0[48];
+	__be64		next;
+	__be32		block_num;
+	u8		rsvd1;
+	u8		token;
+	u8		ctrl_sig;
+	u8		sig;
+};
+
+struct mlx5_err_cqe {
+	u8	rsvd0[32];
+	__be32	srqn;
+	u8	rsvd1[18];
+	u8	vendor_err_synd;
+	u8	syndrome;
+	__be32	s_wqe_opcode_qpn;
+	__be16	wqe_counter;
+	u8	signature;
+	u8	op_own;
+};
+
+struct mlx5_cqe64 {
+	u8		rsvd0[17];
+	u8		ml_path;
+	u8		rsvd20[4];
+	__be16		slid;
+	__be32		flags_rqpn;
+	u8		rsvd28[4];
+	__be32		srqn;
+	__be32		imm_inval_pkey;
+	u8		rsvd40[4];
+	__be32		byte_cnt;
+	__be64		timestamp;
+	__be32		sop_drop_qpn;
+	__be16		wqe_counter;
+	u8		signature;
+	u8		op_own;
+};
+
+struct mlx5_wqe_srq_next_seg {
+	u8			rsvd0[2];
+	__be16			next_wqe_index;
+	u8			signature;
+	u8			rsvd1[11];
+};
+
+union mlx5_ext_cqe {
+	struct ib_grh	grh;
+	u8		inl[64];
+};
+
+struct mlx5_cqe128 {
+	union mlx5_ext_cqe	inl_grh;
+	struct mlx5_cqe64	cqe64;
+};
+
+struct mlx5_srq_ctx {
+	u8			state_log_sz;
+	u8			rsvd0[3];
+	__be32			flags_xrcd;
+	__be32			pgoff_cqn;
+	u8			rsvd1[4];
+	u8			log_pg_sz;
+	u8			rsvd2[7];
+	__be32			pd;
+	__be16			lwm;
+	__be16			wqe_cnt;
+	u8			rsvd3[8];
+	__be64			db_record;
+};
+
+struct mlx5_create_srq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			input_srqn;
+	u8			rsvd0[4];
+	struct mlx5_srq_ctx	ctx;
+	u8			rsvd1[208];
+	__be64			pas[0];
+};
+
+struct mlx5_create_srq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			srqn;
+	u8			rsvd[4];
+};
+
+struct mlx5_destroy_srq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			srqn;
+	u8			rsvd[4];
+};
+
+struct mlx5_destroy_srq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_query_srq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			srqn;
+	u8			rsvd0[4];
+};
+
+struct mlx5_query_srq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[8];
+	struct mlx5_srq_ctx	ctx;
+	u8			rsvd1[32];
+	__be64			pas[0];
+};
+
+struct mlx5_arm_srq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			srqn;
+	__be16			rsvd;
+	__be16			lwm;
+};
+
+struct mlx5_arm_srq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_cq_context {
+	u8			status;
+	u8			cqe_sz_flags;
+	u8			st;
+	u8			rsvd3;
+	u8			rsvd4[6];
+	__be16			page_offset;
+	__be32			log_sz_usr_page;
+	__be16			cq_period;
+	__be16			cq_max_count;
+	__be16			rsvd20;
+	__be16			c_eqn;
+	u8			log_pg_sz;
+	u8			rsvd25[7];
+	__be32			last_notified_index;
+	__be32			solicit_producer_index;
+	__be32			consumer_counter;
+	__be32			producer_counter;
+	u8			rsvd48[8];
+	__be64			db_record_addr;
+};
+
+struct mlx5_create_cq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			input_cqn;
+	u8			rsvdx[4];
+	struct mlx5_cq_context	ctx;
+	u8			rsvd6[192];
+	__be64			pas[0];
+};
+
+struct mlx5_create_cq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			cqn;
+	u8			rsvd0[4];
+};
+
+struct mlx5_destroy_cq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			cqn;
+	u8			rsvd0[4];
+};
+
+struct mlx5_destroy_cq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[8];
+};
+
+struct mlx5_query_cq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			cqn;
+	u8			rsvd0[4];
+};
+
+struct mlx5_query_cq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[8];
+	struct mlx5_cq_context	ctx;
+	u8			rsvd6[16];
+	__be64			pas[0];
+};
+
+struct mlx5_eq_context {
+	u8			status;
+	u8			ec_oi;
+	u8			st;
+	u8			rsvd2[7];
+	__be16			page_pffset;
+	__be32			log_sz_usr_page;
+	u8			rsvd3[7];
+	u8			intr;
+	u8			log_page_size;
+	u8			rsvd4[15];
+	__be32			consumer_counter;
+	__be32			produser_counter;
+	u8			rsvd5[16];
+};
+
+struct mlx5_create_eq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd0[3];
+	u8			input_eqn;
+	u8			rsvd1[4];
+	struct mlx5_eq_context	ctx;
+	u8			rsvd2[8];
+	__be64			events_mask;
+	u8			rsvd3[176];
+	__be64			pas[0];
+};
+
+struct mlx5_create_eq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[3];
+	u8			eq_number;
+	u8			rsvd1[4];
+};
+
+struct mlx5_destroy_eq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd0[3];
+	u8			eqn;
+	u8			rsvd1[4];
+};
+
+struct mlx5_destroy_eq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_map_eq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be64			mask;
+	u8			mu;
+	u8			rsvd0[2];
+	u8			eqn;
+	u8			rsvd1[24];
+};
+
+struct mlx5_map_eq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_query_eq_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd0[3];
+	u8			eqn;
+	u8			rsvd1[4];
+};
+
+struct mlx5_query_eq_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+	struct mlx5_eq_context	ctx;
+};
+
+struct mlx5_mkey_seg {
+	/* This is a two bit field occupying bits 31-30.
+	 * bit 31 is always 0,
+	 * bit 30 is zero for regular MRs and 1 (e.g free) for UMRs that do not have tanslation
+	 */
+	u8		status;
+	u8		pcie_control;
+	u8		flags;
+	u8		version;
+	__be32		qpn_mkey7_0;
+	u8		rsvd1[4];
+	__be32		flags_pd;
+	__be64		start_addr;
+	__be64		len;
+	__be32		bsfs_octo_size;
+	u8		rsvd2[16];
+	__be32		xlt_oct_size;
+	u8		rsvd3[3];
+	u8		log2_page_size;
+	u8		rsvd4[4];
+};
+
+struct mlx5_query_special_ctxs_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_query_special_ctxs_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			dump_fill_mkey;
+	__be32			reserved_lkey;
+};
+
+struct mlx5_create_mkey_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			input_mkey_index;
+	u8			rsvd0[4];
+	struct mlx5_mkey_seg	seg;
+	u8			rsvd1[16];
+	__be32			xlat_oct_act_size;
+	__be32			bsf_coto_act_size;
+	u8			rsvd2[168];
+	__be64			pas[0];
+};
+
+struct mlx5_create_mkey_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			mkey;
+	u8			rsvd[4];
+};
+
+struct mlx5_destroy_mkey_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			mkey;
+	u8			rsvd[4];
+};
+
+struct mlx5_destroy_mkey_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_query_mkey_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			mkey;
+};
+
+struct mlx5_query_mkey_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be64			pas[0];
+};
+
+struct mlx5_modify_mkey_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			mkey;
+	__be64			pas[0];
+};
+
+struct mlx5_modify_mkey_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+};
+
+struct mlx5_dump_mkey_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+};
+
+struct mlx5_dump_mkey_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			mkey;
+};
+
+struct mlx5_mad_ifc_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be16			remote_lid;
+	u8			rsvd0;
+	u8			port;
+	u8			rsvd1[4];
+	u8			data[256];
+};
+
+struct mlx5_mad_ifc_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+	u8			data[256];
+};
+
+struct mlx5_access_reg_mbox_in {
+	struct mlx5_inbox_hdr		hdr;
+	u8				rsvd0[2];
+	__be16				register_id;
+	__be32				arg;
+	__be32				data[0];
+};
+
+struct mlx5_access_reg_mbox_out {
+	struct mlx5_outbox_hdr		hdr;
+	u8				rsvd[8];
+	__be32				data[0];
+};
+
+#define MLX5_ATTR_EXTENDED_PORT_INFO	cpu_to_be16(0xff90)
+
+enum {
+	MLX_EXT_PORT_CAP_FLAG_EXTENDED_PORT_INFO	= 1 <<  0
+};
+
+#endif /* MLX5_DEVICE_H */
diff --git a/include/linux/mlx5/doorbell.h b/include/linux/mlx5/doorbell.h
new file mode 100644
index 0000000..163a818
--- /dev/null
+++ b/include/linux/mlx5/doorbell.h
@@ -0,0 +1,79 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_DOORBELL_H
+#define MLX5_DOORBELL_H
+
+#define MLX5_BF_OFFSET	      0x800
+#define MLX5_CQ_DOORBELL      0x20
+
+#if BITS_PER_LONG == 64
+/* Assume that we can just write a 64-bit doorbell atomically.  s390
+ * actually doesn't have writeq() but S/390 systems don't even have
+ * PCI so we won't worry about it.
+ */
+
+#define MLX5_DECLARE_DOORBELL_LOCK(name)
+#define MLX5_INIT_DOORBELL_LOCK(ptr)    do { } while (0)
+#define MLX5_GET_DOORBELL_LOCK(ptr)      (NULL)
+
+static inline void mlx5_write64(__be32 val[2], void __iomem *dest,
+				spinlock_t *doorbell_lock)
+{
+	__raw_writeq(*(u64 *)val, dest);
+}
+
+#else
+
+/* Just fall back to a spinlock to protect the doorbell if
+ * BITS_PER_LONG is 32 -- there's no portable way to do atomic 64-bit
+ * MMIO writes.
+ */
+
+#define MLX5_DECLARE_DOORBELL_LOCK(name) spinlock_t name;
+#define MLX5_INIT_DOORBELL_LOCK(ptr)     spin_lock_init(ptr)
+#define MLX5_GET_DOORBELL_LOCK(ptr)      (ptr)
+
+static inline void mlx5_write64(__be32 val[2], void __iomem *dest,
+				spinlock_t *doorbell_lock)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(doorbell_lock, flags);
+	__raw_writel((__force u32) val[0], dest);
+	__raw_writel((__force u32) val[1], dest + 4);
+	spin_unlock_irqrestore(doorbell_lock, flags);
+}
+
+#endif
+
+#endif /* MLX5_DOORBELL_H */
diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
new file mode 100644
index 0000000..e47f1e4
--- /dev/null
+++ b/include/linux/mlx5/driver.h
@@ -0,0 +1,769 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_DRIVER_H
+#define MLX5_DRIVER_H
+
+#include <linux/kernel.h>
+#include <linux/completion.h>
+#include <linux/pci.h>
+#include <linux/spinlock_types.h>
+#include <linux/semaphore.h>
+#include <linux/vmalloc.h>
+#include <linux/radix-tree.h>
+#include <linux/mlx5/device.h>
+#include <linux/mlx5/doorbell.h>
+
+enum {
+	MLX5_BOARD_ID_LEN = 64,
+	MLX5_MAX_NAME_LEN = 16,
+};
+
+enum {
+	/* one minute for the sake of bringup. Generally, commands must always
+	 * complete and we may need to increase this timeout value
+	 */
+	MLX5_CMD_TIMEOUT_MSEC	= 7200 * 1000,
+	MLX5_CMD_WQ_MAX_NAME	= 32,
+};
+
+enum {
+	CMD_OWNER_SW		= 0x0,
+	CMD_OWNER_HW		= 0x1,
+	CMD_STATUS_SUCCESS	= 0,
+};
+
+enum mlx5_sqp_t {
+	MLX5_SQP_SMI		= 0,
+	MLX5_SQP_GSI		= 1,
+	MLX5_SQP_IEEE_1588	= 2,
+	MLX5_SQP_SNIFFER	= 3,
+	MLX5_SQP_SYNC_UMR	= 4,
+};
+
+enum {
+	MLX5_MAX_PORTS	= 2,
+};
+
+enum {
+	MLX5_EQ_VEC_PAGES	 = 0,
+	MLX5_EQ_VEC_CMD		 = 1,
+	MLX5_EQ_VEC_ASYNC	 = 2,
+	MLX5_EQ_VEC_COMP_BASE,
+};
+
+enum {
+	MLX5_MAX_EQ_NAME	= 20
+};
+
+enum {
+	MLX5_ATOMIC_MODE_IB_COMP	= 1 << 16,
+	MLX5_ATOMIC_MODE_CX		= 2 << 16,
+	MLX5_ATOMIC_MODE_8B		= 3 << 16,
+	MLX5_ATOMIC_MODE_16B		= 4 << 16,
+	MLX5_ATOMIC_MODE_32B		= 5 << 16,
+	MLX5_ATOMIC_MODE_64B		= 6 << 16,
+	MLX5_ATOMIC_MODE_128B		= 7 << 16,
+	MLX5_ATOMIC_MODE_256B		= 8 << 16,
+};
+
+enum {
+	MLX5_CMD_OP_QUERY_HCA_CAP		= 0x100,
+	MLX5_CMD_OP_QUERY_ADAPTER		= 0x101,
+	MLX5_CMD_OP_INIT_HCA			= 0x102,
+	MLX5_CMD_OP_TEARDOWN_HCA		= 0x103,
+	MLX5_CMD_OP_QUERY_PAGES			= 0x107,
+	MLX5_CMD_OP_MANAGE_PAGES		= 0x108,
+	MLX5_CMD_OP_SET_HCA_CAP			= 0x109,
+
+	MLX5_CMD_OP_CREATE_MKEY			= 0x200,
+	MLX5_CMD_OP_QUERY_MKEY			= 0x201,
+	MLX5_CMD_OP_DESTROY_MKEY		= 0x202,
+	MLX5_CMD_OP_QUERY_SPECIAL_CONTEXTS	= 0x203,
+
+	MLX5_CMD_OP_CREATE_EQ			= 0x301,
+	MLX5_CMD_OP_DESTROY_EQ			= 0x302,
+	MLX5_CMD_OP_QUERY_EQ			= 0x303,
+
+	MLX5_CMD_OP_CREATE_CQ			= 0x400,
+	MLX5_CMD_OP_DESTROY_CQ			= 0x401,
+	MLX5_CMD_OP_QUERY_CQ			= 0x402,
+	MLX5_CMD_OP_MODIFY_CQ			= 0x403,
+
+	MLX5_CMD_OP_CREATE_QP			= 0x500,
+	MLX5_CMD_OP_DESTROY_QP			= 0x501,
+	MLX5_CMD_OP_RST2INIT_QP			= 0x502,
+	MLX5_CMD_OP_INIT2RTR_QP			= 0x503,
+	MLX5_CMD_OP_RTR2RTS_QP			= 0x504,
+	MLX5_CMD_OP_RTS2RTS_QP			= 0x505,
+	MLX5_CMD_OP_SQERR2RTS_QP		= 0x506,
+	MLX5_CMD_OP_2ERR_QP			= 0x507,
+	MLX5_CMD_OP_RTS2SQD_QP			= 0x508,
+	MLX5_CMD_OP_SQD2RTS_QP			= 0x509,
+	MLX5_CMD_OP_2RST_QP			= 0x50a,
+	MLX5_CMD_OP_QUERY_QP			= 0x50b,
+	MLX5_CMD_OP_CONF_SQP			= 0x50c,
+	MLX5_CMD_OP_MAD_IFC			= 0x50d,
+	MLX5_CMD_OP_INIT2INIT_QP		= 0x50e,
+	MLX5_CMD_OP_SUSPEND_QP			= 0x50f,
+	MLX5_CMD_OP_UNSUSPEND_QP		= 0x510,
+	MLX5_CMD_OP_SQD2SQD_QP			= 0x511,
+	MLX5_CMD_OP_ALLOC_QP_COUNTER_SET	= 0x512,
+	MLX5_CMD_OP_DEALLOC_QP_COUNTER_SET	= 0x513,
+	MLX5_CMD_OP_QUERY_QP_COUNTER_SET	= 0x514,
+
+	MLX5_CMD_OP_CREATE_PSV			= 0x600,
+	MLX5_CMD_OP_DESTROY_PSV			= 0x601,
+	MLX5_CMD_OP_QUERY_PSV			= 0x602,
+	MLX5_CMD_OP_QUERY_SIG_RULE_TABLE	= 0x603,
+	MLX5_CMD_OP_QUERY_BLOCK_SIZE_TABLE	= 0x604,
+
+	MLX5_CMD_OP_CREATE_SRQ			= 0x700,
+	MLX5_CMD_OP_DESTROY_SRQ			= 0x701,
+	MLX5_CMD_OP_QUERY_SRQ			= 0x702,
+	MLX5_CMD_OP_ARM_RQ			= 0x703,
+	MLX5_CMD_OP_RESIZE_SRQ			= 0x704,
+
+	MLX5_CMD_OP_ALLOC_PD			= 0x800,
+	MLX5_CMD_OP_DEALLOC_PD			= 0x801,
+	MLX5_CMD_OP_ALLOC_UAR			= 0x802,
+	MLX5_CMD_OP_DEALLOC_UAR			= 0x803,
+
+	MLX5_CMD_OP_ATTACH_TO_MCG		= 0x806,
+	MLX5_CMD_OP_DETACH_FROM_MCG		= 0x807,
+
+
+	MLX5_CMD_OP_ALLOC_XRCD			= 0x80e,
+	MLX5_CMD_OP_DEALLOC_XRCD		= 0x80f,
+
+	MLX5_CMD_OP_ACCESS_REG			= 0x805,
+	MLX5_CMD_OP_MAX				= 0x810,
+};
+
+enum {
+	MLX5_REG_PCAP		 = 0x5001,
+	MLX5_REG_PMTU		 = 0x5003,
+	MLX5_REG_PTYS		 = 0x5004,
+	MLX5_REG_PAOS		 = 0x5006,
+	MLX5_REG_PMAOS		 = 0x5012,
+	MLX5_REG_PUDE		 = 0x5009,
+	MLX5_REG_PMPE		 = 0x5010,
+	MLX5_REG_PELC		 = 0x500e,
+	MLX5_REG_PMLP		 = 0, /* TBD */
+	MLX5_REG_NODE_DESC	 = 0x6001,
+	MLX5_REG_HOST_ENDIANNESS = 0x7004,
+};
+
+enum dbg_rsc_type {
+	MLX5_DBG_RSC_QP,
+	MLX5_DBG_RSC_EQ,
+	MLX5_DBG_RSC_CQ,
+};
+
+struct mlx5_field_desc {
+	struct dentry	       *dent;
+	int			i;
+};
+
+struct mlx5_rsc_debug {
+	struct mlx5_core_dev   *dev;
+	void		       *object;
+	enum dbg_rsc_type	type;
+	struct dentry	       *root;
+	struct mlx5_field_desc	fields[0];
+};
+
+enum mlx5_dev_event {
+	MLX5_DEV_EVENT_SYS_ERROR,
+	MLX5_DEV_EVENT_PORT_UP,
+	MLX5_DEV_EVENT_PORT_DOWN,
+	MLX5_DEV_EVENT_PORT_INITIALIZED,
+	MLX5_DEV_EVENT_LID_CHANGE,
+	MLX5_DEV_EVENT_PKEY_CHANGE,
+	MLX5_DEV_EVENT_GUID_CHANGE,
+	MLX5_DEV_EVENT_CLIENT_REREG,
+};
+
+struct mlx5_uuar_info {
+	struct mlx5_uar	       *uars;
+	int			num_uars;
+	int			num_low_latency_uuars;
+	unsigned long	       *bitmap;
+	unsigned int	       *count;
+	struct mlx5_bf	       *bfs;
+
+	/*
+	 * protect uuar allocation data structs
+	 */
+	struct mutex		lock;
+};
+
+struct mlx5_bf {
+	void __iomem	       *reg;
+	void __iomem	       *regreg;
+	int			buf_size;
+	struct mlx5_uar	       *uar;
+	unsigned long		offset;
+	int			need_lock;
+	/* protect blue flame buffer selection when needed
+	 */
+	spinlock_t		lock;
+
+	/* serialize 64 bit writes when done as two 32 bit accesses
+	 */
+	spinlock_t		lock32;
+	int			uuarn;
+};
+
+struct mlx5_cmd_first {
+	__be32		data[4];
+};
+
+struct mlx5_cmd_msg {
+	struct list_head		list;
+	struct cache_ent	       *cache;
+	u32				len;
+	struct mlx5_cmd_first		first;
+	struct mlx5_cmd_mailbox	       *next;
+};
+
+struct mlx5_cmd_debug {
+	struct dentry	       *dbg_root;
+	struct dentry	       *dbg_in;
+	struct dentry	       *dbg_out;
+	struct dentry	       *dbg_outlen;
+	struct dentry	       *dbg_status;
+	struct dentry	       *dbg_run;
+	void		       *in_msg;
+	void		       *out_msg;
+	u8			status;
+	u16			inlen;
+	u16			outlen;
+};
+
+struct cache_ent {
+	/* protect block chain allocations
+	 */
+	spinlock_t		lock;
+	struct list_head	head;
+};
+
+struct cmd_msg_cache {
+	struct cache_ent	large;
+	struct cache_ent	med;
+
+};
+
+struct mlx5_cmd_stats {
+	u64		sum;
+	u64		n;
+	struct dentry  *root;
+	struct dentry  *avg;
+	struct dentry  *count;
+	/* protect command average calculations */
+	spinlock_t	lock;
+};
+
+struct mlx5_cmd {
+	void	       *cmd_buf;
+	dma_addr_t	dma;
+	u16		cmdif_rev;
+	u8		log_sz;
+	u8		log_stride;
+	int		max_reg_cmds;
+	int		events;
+	u32 __iomem    *vector;
+
+	/* protect command queue allocations
+	 */
+	spinlock_t	alloc_lock;
+
+	/* protect token allocations
+	 */
+	spinlock_t	token_lock;
+	u8		token;
+	unsigned long	bitmask;
+	char		wq_name[MLX5_CMD_WQ_MAX_NAME];
+	struct workqueue_struct *wq;
+	struct semaphore sem;
+	struct semaphore pages_sem;
+	int	mode;
+	struct mlx5_cmd_work_ent *ent_arr[MLX5_MAX_COMMANDS];
+	struct pci_pool *pool;
+	struct mlx5_cmd_debug dbg;
+	struct cmd_msg_cache cache;
+	int checksum_disabled;
+	struct mlx5_cmd_stats stats[MLX5_CMD_OP_MAX];
+};
+
+struct mlx5_port_caps {
+	int	gid_table_len;
+	int	pkey_table_len;
+};
+
+struct mlx5_caps {
+	u8	log_max_eq;
+	u8	log_max_cq;
+	u8	log_max_qp;
+	u8	log_max_mkey;
+	u8	log_max_pd;
+	u8	log_max_srq;
+	u32	max_cqes;
+	int	max_wqes;
+	int	max_sq_desc_sz;
+	int	max_rq_desc_sz;
+	u64	flags;
+	u16	stat_rate_support;
+	int	log_max_msg;
+	int	num_ports;
+	int	max_ra_res_qp;
+	int	max_ra_req_qp;
+	int	max_srq_wqes;
+	int	bf_reg_size;
+	int	bf_regs_per_page;
+	struct mlx5_port_caps	port[MLX5_MAX_PORTS];
+	u8			ext_port_cap[MLX5_MAX_PORTS];
+	int	max_vf;
+	u32	reserved_lkey;
+	u8	local_ca_ack_delay;
+	u8	log_max_mcg;
+	u16	max_qp_mcg;
+	int	min_page_sz;
+};
+
+struct mlx5_cmd_mailbox {
+	void	       *buf;
+	dma_addr_t	dma;
+	struct mlx5_cmd_mailbox *next;
+};
+
+struct mlx5_buf_list {
+	void		       *buf;
+	dma_addr_t		map;
+};
+
+struct mlx5_buf {
+	struct mlx5_buf_list	direct;
+	struct mlx5_buf_list   *page_list;
+	int			nbufs;
+	int			npages;
+	int			page_shift;
+	int			size;
+};
+
+struct mlx5_eq {
+	struct mlx5_core_dev   *dev;
+	__be32 __iomem	       *doorbell;
+	u32			cons_index;
+	struct mlx5_buf		buf;
+	int			size;
+	u8			irqn;
+	u8			eqn;
+	int			nent;
+	u64			mask;
+	char			name[MLX5_MAX_EQ_NAME];
+	struct list_head	list;
+	int			index;
+	struct mlx5_rsc_debug	*dbg;
+};
+
+
+struct mlx5_core_mr {
+	u64			iova;
+	u64			size;
+	u32			key;
+	u32			pd;
+	u32			access;
+};
+
+struct mlx5_core_srq {
+	u32		srqn;
+	int		max;
+	int		max_gs;
+	int		max_avail_gather;
+	int		wqe_shift;
+	void (*event)	(struct mlx5_core_srq *, enum mlx5_event);
+
+	atomic_t		refcount;
+	struct completion	free;
+};
+
+struct mlx5_eq_table {
+	void __iomem	       *update_ci;
+	void __iomem	       *update_arm_ci;
+	struct list_head       *comp_eq_head;
+	struct mlx5_eq		pages_eq;
+	struct mlx5_eq		async_eq;
+	struct mlx5_eq		cmd_eq;
+	struct msix_entry	*msix_arr;
+	int			num_comp_vectors;
+	/* protect EQs list
+	 */
+	spinlock_t		lock;
+};
+
+struct mlx5_uar {
+	u32			index;
+	struct list_head	bf_list;
+	unsigned		free_bf_bmap;
+	void __iomem	       *wc_map;
+	void __iomem	       *map;
+};
+
+
+struct mlx5_core_health {
+	struct health_buffer __iomem   *health;
+	__be32 __iomem		       *health_counter;
+	struct timer_list		timer;
+	struct list_head		list;
+	u32				prev;
+	int				miss_counter;
+};
+
+struct mlx5_cq_table {
+	/* protect radix tree
+	 */
+	spinlock_t		lock;
+	struct radix_tree_root	tree;
+};
+
+struct mlx5_qp_table {
+	/* protect radix tree
+	 */
+	spinlock_t		lock;
+	struct radix_tree_root	tree;
+};
+
+struct mlx5_srq_table {
+	/* protect radix tree
+	 */
+	spinlock_t		lock;
+	struct radix_tree_root	tree;
+};
+
+struct mlx5_priv {
+	char			name[MLX5_MAX_NAME_LEN];
+	struct mlx5_eq_table	eq_table;
+	struct mlx5_uuar_info	uuari;
+	MLX5_DECLARE_DOORBELL_LOCK(cq_uar_lock);
+
+	/* pages stuff */
+	struct workqueue_struct *pg_wq;
+	struct rb_root		page_root;
+	int			fw_pages;
+	int			reg_pages;
+
+	struct mlx5_core_health health;
+
+	struct mlx5_srq_table	srq_table;
+
+	/* start: qp staff */
+	struct mlx5_qp_table	qp_table;
+	struct dentry	       *qp_debugfs;
+	struct dentry	       *eq_debugfs;
+	struct dentry	       *cq_debugfs;
+	struct dentry	       *cmdif_debugfs;
+	/* end: qp staff */
+
+	/* start: cq staff */
+	struct mlx5_cq_table	cq_table;
+	/* end: cq staff */
+
+	/* start: alloc staff */
+	struct mutex            pgdir_mutex;
+	struct list_head        pgdir_list;
+	/* end: alloc staff */
+	struct dentry	       *dbg_root;
+
+	/* protect mkey key part */
+	spinlock_t		mkey_lock;
+	u8			mkey_key;
+};
+
+struct mlx5_core_dev {
+	struct pci_dev	       *pdev;
+	u8			rev_id;
+	char			board_id[MLX5_BOARD_ID_LEN];
+	struct mlx5_cmd		cmd;
+	struct mlx5_caps	caps;
+	phys_addr_t		iseg_base;
+	struct mlx5_init_seg __iomem *iseg;
+	void			(*event) (struct mlx5_core_dev *dev,
+					  enum mlx5_dev_event event,
+					  void *data);
+	struct mlx5_priv	priv;
+	struct mlx5_profile	*profile;
+	atomic_t		num_qps;
+};
+
+struct mlx5_db {
+	__be32			*db;
+	union {
+		struct mlx5_db_pgdir		*pgdir;
+		struct mlx5_ib_user_db_page	*user_page;
+	}			u;
+	dma_addr_t		dma;
+	int			index;
+};
+
+enum {
+	MLX5_DB_PER_PAGE = PAGE_SIZE / L1_CACHE_BYTES,
+};
+
+enum {
+	MLX5_COMP_EQ_SIZE = 1024,
+};
+
+struct mlx5_db_pgdir {
+	struct list_head	list;
+	DECLARE_BITMAP(bitmap, MLX5_DB_PER_PAGE);
+	__be32		       *db_page;
+	dma_addr_t		db_dma;
+};
+
+typedef void (*mlx5_cmd_cbk_t)(int status, void *context);
+
+struct mlx5_cmd_work_ent {
+	struct mlx5_cmd_msg    *in;
+	struct mlx5_cmd_msg    *out;
+	mlx5_cmd_cbk_t		callback;
+	void		       *context;
+	int idx;
+	struct completion	done;
+	struct mlx5_cmd        *cmd;
+	struct work_struct	work;
+	struct mlx5_cmd_layout *lay;
+	int			ret;
+	int			page_queue;
+	u8			status;
+	u8			token;
+	struct timespec		ts1;
+	struct timespec		ts2;
+};
+
+struct mlx5_pas {
+	u64	pa;
+	u8	log_sz;
+};
+
+static inline void *mlx5_buf_offset(struct mlx5_buf *buf, int offset)
+{
+	if (likely(BITS_PER_LONG == 64 || buf->nbufs == 1))
+		return buf->direct.buf + offset;
+	else
+		return buf->page_list[offset >> PAGE_SHIFT].buf +
+			(offset & (PAGE_SIZE - 1));
+}
+
+extern struct workqueue_struct *mlx5_core_wq;
+
+#define STRUCT_FIELD(header, field) \
+	.struct_offset_bytes = offsetof(struct ib_unpacked_ ## header, field),      \
+	.struct_size_bytes   = sizeof((struct ib_unpacked_ ## header *)0)->field
+
+struct ib_field {
+	size_t struct_offset_bytes;
+	size_t struct_size_bytes;
+	int    offset_bits;
+	int    size_bits;
+};
+
+static inline struct mlx5_core_dev *pci2mlx5_core_dev(struct pci_dev *pdev)
+{
+	return pci_get_drvdata(pdev);
+}
+
+extern struct dentry *mlx5_debugfs_root;
+
+static inline u16 fw_rev_maj(struct mlx5_core_dev *dev)
+{
+	return ioread32be(&dev->iseg->fw_rev) & 0xffff;
+}
+
+static inline u16 fw_rev_min(struct mlx5_core_dev *dev)
+{
+	return ioread32be(&dev->iseg->fw_rev) >> 16;
+}
+
+static inline u16 fw_rev_sub(struct mlx5_core_dev *dev)
+{
+	return ioread32be(&dev->iseg->cmdif_rev_fw_sub) & 0xffff;
+}
+
+static inline u16 cmdif_rev(struct mlx5_core_dev *dev)
+{
+	return ioread32be(&dev->iseg->cmdif_rev_fw_sub) >> 16;
+}
+
+static inline void *mlx5_vzalloc(unsigned long size)
+{
+	void *rtn;
+
+	rtn = kzalloc(size, GFP_KERNEL | __GFP_NOWARN);
+	if (!rtn)
+		rtn = vzalloc(size);
+	return rtn;
+}
+
+static inline void mlx5_vfree(const void *addr)
+{
+	if (addr && is_vmalloc_addr(addr))
+		vfree(addr);
+	else
+		kfree(addr);
+}
+
+int mlx5_dev_init(struct mlx5_core_dev *dev, struct pci_dev *pdev);
+void mlx5_dev_cleanup(struct mlx5_core_dev *dev);
+int mlx5_cmd_init(struct mlx5_core_dev *dev);
+void mlx5_cmd_cleanup(struct mlx5_core_dev *dev);
+void mlx5_cmd_use_events(struct mlx5_core_dev *dev);
+void mlx5_cmd_use_polling(struct mlx5_core_dev *dev);
+int mlx5_cmd_status_to_err(struct mlx5_outbox_hdr *hdr);
+int mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,
+		  int out_size);
+int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn);
+int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn);
+int mlx5_alloc_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
+int mlx5_free_uuars(struct mlx5_core_dev *dev, struct mlx5_uuar_info *uuari);
+void mlx5_health_cleanup(void);
+void  __init mlx5_health_init(void);
+void mlx5_start_health_poll(struct mlx5_core_dev *dev);
+void mlx5_stop_health_poll(struct mlx5_core_dev *dev);
+int mlx5_buf_alloc(struct mlx5_core_dev *dev, int size, int max_direct,
+		   struct mlx5_buf *buf);
+void mlx5_buf_free(struct mlx5_core_dev *dev, struct mlx5_buf *buf);
+struct mlx5_cmd_mailbox *mlx5_alloc_cmd_mailbox_chain(struct mlx5_core_dev *dev,
+						      gfp_t flags, int npages);
+void mlx5_free_cmd_mailbox_chain(struct mlx5_core_dev *dev,
+				 struct mlx5_cmd_mailbox *head);
+int mlx5_core_create_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
+			 struct mlx5_create_srq_mbox_in *in, int inlen);
+int mlx5_core_destroy_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq);
+int mlx5_core_query_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
+			struct mlx5_query_srq_mbox_out *out);
+int mlx5_core_arm_srq(struct mlx5_core_dev *dev, struct mlx5_core_srq *srq,
+		      u16 lwm, int is_srq);
+int mlx5_core_create_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+			  struct mlx5_create_mkey_mbox_in *in, int inlen);
+int mlx5_core_destroy_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr);
+int mlx5_core_query_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+			 struct mlx5_query_mkey_mbox_out *out, int outlen);
+int mlx5_core_dump_fill_mkey(struct mlx5_core_dev *dev, struct mlx5_core_mr *mr,
+			     u32 *mkey);
+int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);
+int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);
+int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, void *inb, void *outb,
+		      u16 opmod, int port);
+void mlx5_pagealloc_init(struct mlx5_core_dev *dev);
+void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
+int mlx5_pagealloc_start(struct mlx5_core_dev *dev);
+void mlx5_pagealloc_stop(struct mlx5_core_dev *dev);
+void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
+				 s16 npages);
+int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev);
+int mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev);
+void mlx5_register_debugfs(void);
+void mlx5_unregister_debugfs(void);
+int mlx5_eq_init(struct mlx5_core_dev *dev);
+void mlx5_eq_cleanup(struct mlx5_core_dev *dev);
+void mlx5_fill_page_array(struct mlx5_buf *buf, __be64 *pas);
+void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn);
+void mlx5_qp_event(struct mlx5_core_dev *dev, u32 qpn, int event_type);
+void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
+struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
+void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, unsigned long vector);
+void mlx5_cq_event(struct mlx5_core_dev *dev, u32 cqn, int event_type);
+int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
+		       int nent, u64 mask, const char *name, struct mlx5_uar *uar);
+int mlx5_destroy_unmap_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
+int mlx5_start_eqs(struct mlx5_core_dev *dev);
+int mlx5_stop_eqs(struct mlx5_core_dev *dev);
+int mlx5_core_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
+int mlx5_core_detach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid, u32 qpn);
+
+int mlx5_qp_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_qp_debugfs_cleanup(struct mlx5_core_dev *dev);
+int mlx5_core_access_reg(struct mlx5_core_dev *dev, void *data_in,
+			 int size_in, void *data_out, int size_out,
+			 u16 reg_num, int arg, int write);
+int mlx5_set_port_caps(struct mlx5_core_dev *dev, int port_num, u32 caps);
+
+int mlx5_debug_eq_add(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
+void mlx5_debug_eq_remove(struct mlx5_core_dev *dev, struct mlx5_eq *eq);
+int mlx5_core_eq_query(struct mlx5_core_dev *dev, struct mlx5_eq *eq,
+		       struct mlx5_query_eq_mbox_out *out, int outlen);
+int mlx5_eq_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_eq_debugfs_cleanup(struct mlx5_core_dev *dev);
+int mlx5_cq_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_cq_debugfs_cleanup(struct mlx5_core_dev *dev);
+int mlx5_db_alloc(struct mlx5_core_dev *dev, struct mlx5_db *db);
+void mlx5_db_free(struct mlx5_core_dev *dev, struct mlx5_db *db);
+
+typedef void (*health_handler_t)(struct pci_dev *pdev, void *buf, int size);
+int mlx5_register_health_report_handler(health_handler_t handler);
+void mlx5_unregister_health_report_handler(void);
+const char *mlx5_command_str(int command);
+int mlx5_cmdif_debugfs_init(struct mlx5_core_dev *dev);
+void mlx5_cmdif_debugfs_cleanup(struct mlx5_core_dev *dev);
+
+static inline u32 mlx5_mkey_to_idx(u32 mkey)
+{
+	return mkey >> 8;
+}
+
+static inline u32 mlx5_idx_to_mkey(u32 mkey_idx)
+{
+	return mkey_idx << 8;
+}
+
+enum {
+	MLX5_PROF_MASK_QP_SIZE		= (u64)1 << 0,
+	MLX5_PROF_MASK_CMDIF_CSUM	= (u64)1 << 1,
+	MLX5_PROF_MASK_MR_CACHE		= (u64)1 << 2,
+};
+
+enum {
+	MAX_MR_CACHE_ENTRIES    = 16,
+};
+
+struct mlx5_profile {
+	u64	mask;
+	u32	log_max_qp;
+	int	cmdif_csum;
+	struct {
+		int	size;
+		int	limit;
+	} mr_cache[MAX_MR_CACHE_ENTRIES];
+};
+
+#endif /* MLX5_DRIVER_H */
diff --git a/include/linux/mlx5/qp.h b/include/linux/mlx5/qp.h
new file mode 100644
index 0000000..d9e3eac
--- /dev/null
+++ b/include/linux/mlx5/qp.h
@@ -0,0 +1,467 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_QP_H
+#define MLX5_QP_H
+
+#include <linux/mlx5/device.h>
+#include <linux/mlx5/driver.h>
+
+#define MLX5_INVALID_LKEY	0x100
+
+enum mlx5_qp_optpar {
+	MLX5_QP_OPTPAR_ALT_ADDR_PATH		= 1 << 0,
+	MLX5_QP_OPTPAR_RRE			= 1 << 1,
+	MLX5_QP_OPTPAR_RAE			= 1 << 2,
+	MLX5_QP_OPTPAR_RWE			= 1 << 3,
+	MLX5_QP_OPTPAR_PKEY_INDEX		= 1 << 4,
+	MLX5_QP_OPTPAR_Q_KEY			= 1 << 5,
+	MLX5_QP_OPTPAR_RNR_TIMEOUT		= 1 << 6,
+	MLX5_QP_OPTPAR_PRIMARY_ADDR_PATH	= 1 << 7,
+	MLX5_QP_OPTPAR_SRA_MAX			= 1 << 8,
+	MLX5_QP_OPTPAR_RRA_MAX			= 1 << 9,
+	MLX5_QP_OPTPAR_PM_STATE			= 1 << 10,
+	MLX5_QP_OPTPAR_RETRY_COUNT		= 1 << 12,
+	MLX5_QP_OPTPAR_RNR_RETRY		= 1 << 13,
+	MLX5_QP_OPTPAR_ACK_TIMEOUT		= 1 << 14,
+	MLX5_QP_OPTPAR_PRI_PORT			= 1 << 16,
+	MLX5_QP_OPTPAR_SRQN			= 1 << 18,
+	MLX5_QP_OPTPAR_CQN_RCV			= 1 << 19,
+	MLX5_QP_OPTPAR_DC_HS			= 1 << 20,
+	MLX5_QP_OPTPAR_DC_KEY			= 1 << 21,
+};
+
+enum mlx5_qp_state {
+	MLX5_QP_STATE_RST			= 0,
+	MLX5_QP_STATE_INIT			= 1,
+	MLX5_QP_STATE_RTR			= 2,
+	MLX5_QP_STATE_RTS			= 3,
+	MLX5_QP_STATE_SQER			= 4,
+	MLX5_QP_STATE_SQD			= 5,
+	MLX5_QP_STATE_ERR			= 6,
+	MLX5_QP_STATE_SQ_DRAINING		= 7,
+	MLX5_QP_STATE_SUSPENDED			= 9,
+	MLX5_QP_NUM_STATE
+};
+
+enum {
+	MLX5_QP_ST_RC				= 0x0,
+	MLX5_QP_ST_UC				= 0x1,
+	MLX5_QP_ST_UD				= 0x2,
+	MLX5_QP_ST_XRC				= 0x3,
+	MLX5_QP_ST_MLX				= 0x4,
+	MLX5_QP_ST_DCI				= 0x5,
+	MLX5_QP_ST_DCT				= 0x6,
+	MLX5_QP_ST_QP0				= 0x7,
+	MLX5_QP_ST_QP1				= 0x8,
+	MLX5_QP_ST_RAW_ETHERTYPE		= 0x9,
+	MLX5_QP_ST_RAW_IPV6			= 0xa,
+	MLX5_QP_ST_SNIFFER			= 0xb,
+	MLX5_QP_ST_SYNC_UMR			= 0xe,
+	MLX5_QP_ST_PTP_1588			= 0xd,
+	MLX5_QP_ST_REG_UMR			= 0xc,
+	MLX5_QP_ST_MAX
+};
+
+enum {
+	MLX5_QP_PM_MIGRATED			= 0x3,
+	MLX5_QP_PM_ARMED			= 0x0,
+	MLX5_QP_PM_REARM			= 0x1
+};
+
+enum {
+	MLX5_NON_ZERO_RQ	= 0 << 24,
+	MLX5_SRQ_RQ		= 1 << 24,
+	MLX5_CRQ_RQ		= 2 << 24,
+	MLX5_ZERO_LEN_RQ	= 3 << 24
+};
+
+enum {
+	/* params1 */
+	MLX5_QP_BIT_SRE				= 1 << 15,
+	MLX5_QP_BIT_SWE				= 1 << 14,
+	MLX5_QP_BIT_SAE				= 1 << 13,
+	/* params2 */
+	MLX5_QP_BIT_RRE				= 1 << 15,
+	MLX5_QP_BIT_RWE				= 1 << 14,
+	MLX5_QP_BIT_RAE				= 1 << 13,
+	MLX5_QP_BIT_RIC				= 1 <<	4,
+};
+
+enum {
+	MLX5_WQE_CTRL_CQ_UPDATE		= 2 << 2,
+	MLX5_WQE_CTRL_SOLICITED		= 1 << 1,
+};
+
+enum {
+	MLX5_SEND_WQE_BB	= 64,
+};
+
+enum {
+	MLX5_WQE_FMR_PERM_LOCAL_READ	= 1 << 27,
+	MLX5_WQE_FMR_PERM_LOCAL_WRITE	= 1 << 28,
+	MLX5_WQE_FMR_PERM_REMOTE_READ	= 1 << 29,
+	MLX5_WQE_FMR_PERM_REMOTE_WRITE	= 1 << 30,
+	MLX5_WQE_FMR_PERM_ATOMIC	= 1 << 31
+};
+
+enum {
+	MLX5_FENCE_MODE_NONE			= 0 << 5,
+	MLX5_FENCE_MODE_INITIATOR_SMALL		= 1 << 5,
+	MLX5_FENCE_MODE_STRONG_ORDERING		= 3 << 5,
+	MLX5_FENCE_MODE_SMALL_AND_FENCE		= 4 << 5,
+};
+
+enum {
+	MLX5_QP_LAT_SENSITIVE	= 1 << 28,
+	MLX5_QP_ENABLE_SIG	= 1 << 31,
+};
+
+enum {
+	MLX5_RCV_DBR	= 0,
+	MLX5_SND_DBR	= 1,
+};
+
+struct mlx5_wqe_fmr_seg {
+	__be32			flags;
+	__be32			mem_key;
+	__be64			buf_list;
+	__be64			start_addr;
+	__be64			reg_len;
+	__be32			offset;
+	__be32			page_size;
+	u32			reserved[2];
+};
+
+struct mlx5_wqe_ctrl_seg {
+	__be32			opmod_idx_opcode;
+	__be32			qpn_ds;
+	u8			signature;
+	u8			rsvd[2];
+	u8			fm_ce_se;
+	__be32			imm;
+};
+
+struct mlx5_wqe_xrc_seg {
+	__be32			xrc_srqn;
+	u8			rsvd[12];
+};
+
+struct mlx5_wqe_masked_atomic_seg {
+	__be64			swap_add;
+	__be64			compare;
+	__be64			swap_add_mask;
+	__be64			compare_mask;
+};
+
+struct mlx5_av {
+	union {
+		struct {
+			__be32	qkey;
+			__be32	reserved;
+		} qkey;
+		__be64	dc_key;
+	} key;
+	__be32	dqp_dct;
+	u8	stat_rate_sl;
+	u8	fl_mlid;
+	__be16	rlid;
+	u8	reserved0[10];
+	u8	tclass;
+	u8	hop_limit;
+	__be32	grh_gid_fl;
+	u8	rgid[16];
+};
+
+struct mlx5_wqe_datagram_seg {
+	struct mlx5_av	av;
+};
+
+struct mlx5_wqe_raddr_seg {
+	__be64			raddr;
+	__be32			rkey;
+	u32			reserved;
+};
+
+struct mlx5_wqe_atomic_seg {
+	__be64			swap_add;
+	__be64			compare;
+};
+
+struct mlx5_wqe_data_seg {
+	__be32			byte_count;
+	__be32			lkey;
+	__be64			addr;
+};
+
+struct mlx5_wqe_umr_ctrl_seg {
+	u8		flags;
+	u8		rsvd0[3];
+	__be16		klm_octowords;
+	__be16		bsf_octowords;
+	__be64		mkey_mask;
+	u8		rsvd1[32];
+};
+
+struct mlx5_seg_set_psv {
+	__be32		psv_num;
+	__be16		syndrome;
+	__be16		status;
+	__be32		transient_sig;
+	__be32		ref_tag;
+};
+
+struct mlx5_seg_get_psv {
+	u8		rsvd[19];
+	u8		num_psv;
+	__be32		l_key;
+	__be64		va;
+	__be32		psv_index[4];
+};
+
+struct mlx5_seg_check_psv {
+	u8		rsvd0[2];
+	__be16		err_coalescing_op;
+	u8		rsvd1[2];
+	__be16		xport_err_op;
+	u8		rsvd2[2];
+	__be16		xport_err_mask;
+	u8		rsvd3[7];
+	u8		num_psv;
+	__be32		l_key;
+	__be64		va;
+	__be32		psv_index[4];
+};
+
+struct mlx5_rwqe_sig {
+	u8	rsvd0[4];
+	u8	signature;
+	u8	rsvd1[11];
+};
+
+struct mlx5_wqe_signature_seg {
+	u8	rsvd0[4];
+	u8	signature;
+	u8	rsvd1[11];
+};
+
+struct mlx5_wqe_inline_seg {
+	__be32	byte_count;
+};
+
+struct mlx5_core_qp {
+	void (*event)		(struct mlx5_core_qp *, int);
+	int			qpn;
+	atomic_t		refcount;
+	struct completion	free;
+	struct mlx5_rsc_debug	*dbg;
+	int			pid;
+};
+
+struct mlx5_qp_path {
+	u8			fl;
+	u8			rsvd3;
+	u8			free_ar;
+	u8			pkey_index;
+	u8			rsvd0;
+	u8			grh_mlid;
+	__be16			rlid;
+	u8			ackto_lt;
+	u8			mgid_index;
+	u8			static_rate;
+	u8			hop_limit;
+	__be32			tclass_flowlabel;
+	u8			rgid[16];
+	u8			rsvd1[4];
+	u8			sl;
+	u8			port;
+	u8			rsvd2[6];
+};
+
+struct mlx5_qp_context {
+	__be32			flags;
+	__be32			flags_pd;
+	u8			mtu_msgmax;
+	u8			rq_size_stride;
+	__be16			sq_crq_size;
+	__be32			qp_counter_set_usr_page;
+	__be32			wire_qpn;
+	__be32			log_pg_sz_remote_qpn;
+	struct			mlx5_qp_path pri_path;
+	struct			mlx5_qp_path alt_path;
+	__be32			params1;
+	u8			reserved2[4];
+	__be32			next_send_psn;
+	__be32			cqn_send;
+	u8			reserved3[8];
+	__be32			last_acked_psn;
+	__be32			ssn;
+	__be32			params2;
+	__be32			rnr_nextrecvpsn;
+	__be32			xrcd;
+	__be32			cqn_recv;
+	__be64			db_rec_addr;
+	__be32			qkey;
+	__be32			rq_type_srqn;
+	__be32			rmsn;
+	__be16			hw_sq_wqe_counter;
+	__be16			sw_sq_wqe_counter;
+	__be16			hw_rcyclic_byte_counter;
+	__be16			hw_rq_counter;
+	__be16			sw_rcyclic_byte_counter;
+	__be16			sw_rq_counter;
+	u8			rsvd0[5];
+	u8			cgs;
+	u8			cs_req;
+	u8			cs_res;
+	__be64			dc_access_key;
+	u8			rsvd1[24];
+};
+
+struct mlx5_create_qp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			input_qpn;
+	u8			rsvd0[4];
+	__be32			opt_param_mask;
+	u8			rsvd1[4];
+	struct mlx5_qp_context	ctx;
+	u8			rsvd3[16];
+	__be64			pas[0];
+};
+
+struct mlx5_create_qp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd0[4];
+};
+
+struct mlx5_destroy_qp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd0[4];
+};
+
+struct mlx5_destroy_qp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[8];
+};
+
+struct mlx5_modify_qp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd1[4];
+	__be32			optparam;
+	u8			rsvd0[4];
+	struct mlx5_qp_context	ctx;
+};
+
+struct mlx5_modify_qp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd0[8];
+};
+
+struct mlx5_query_qp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd[4];
+};
+
+struct mlx5_query_qp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd1[8];
+	__be32			optparam;
+	u8			rsvd0[4];
+	struct mlx5_qp_context	ctx;
+	u8			rsvd2[16];
+	__be64			pas[0];
+};
+
+struct mlx5_conf_sqp_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			qpn;
+	u8			rsvd[3];
+	u8			type;
+};
+
+struct mlx5_conf_sqp_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_alloc_xrcd_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+struct mlx5_alloc_xrcd_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	__be32			xrcdn;
+	u8			rsvd[4];
+};
+
+struct mlx5_dealloc_xrcd_mbox_in {
+	struct mlx5_inbox_hdr	hdr;
+	__be32			xrcdn;
+	u8			rsvd[4];
+};
+
+struct mlx5_dealloc_xrcd_mbox_out {
+	struct mlx5_outbox_hdr	hdr;
+	u8			rsvd[8];
+};
+
+static inline struct mlx5_core_qp *__mlx5_qp_lookup(struct mlx5_core_dev *dev, u32 qpn)
+{
+	return radix_tree_lookup(&dev->priv.qp_table.tree, qpn);
+}
+
+int mlx5_core_create_qp(struct mlx5_core_dev *dev,
+			struct mlx5_core_qp *qp,
+			struct mlx5_create_qp_mbox_in *in,
+			int inlen);
+int mlx5_core_qp_modify(struct mlx5_core_dev *dev, enum mlx5_qp_state cur_state,
+			enum mlx5_qp_state new_state,
+			struct mlx5_modify_qp_mbox_in *in, int sqd_event,
+			struct mlx5_core_qp *qp);
+int mlx5_core_destroy_qp(struct mlx5_core_dev *dev,
+			 struct mlx5_core_qp *qp);
+int mlx5_core_qp_query(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp,
+		       struct mlx5_query_qp_mbox_out *out, int outlen);
+
+int mlx5_core_xrcd_alloc(struct mlx5_core_dev *dev, u32 *xrcdn);
+int mlx5_core_xrcd_dealloc(struct mlx5_core_dev *dev, u32 xrcdn);
+void mlx5_init_qp_table(struct mlx5_core_dev *dev);
+void mlx5_cleanup_qp_table(struct mlx5_core_dev *dev);
+int mlx5_debug_qp_add(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
+void mlx5_debug_qp_remove(struct mlx5_core_dev *dev, struct mlx5_core_qp *qp);
+
+#endif /* MLX5_QP_H */
diff --git a/include/linux/mlx5/srq.h b/include/linux/mlx5/srq.h
new file mode 100644
index 0000000..e1a363a
--- /dev/null
+++ b/include/linux/mlx5/srq.h
@@ -0,0 +1,41 @@
+/*
+ * Copyright (c) 2013, Mellanox Technologies inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef MLX5_SRQ_H
+#define MLX5_SRQ_H
+
+#include <linux/mlx5/driver.h>
+
+void mlx5_init_srq_table(struct mlx5_core_dev *dev);
+void mlx5_cleanup_srq_table(struct mlx5_core_dev *dev);
+
+#endif /* MLX5_SRQ_H */
--
To unsubscribe from this list: send the line "unsubscribe git-commits-head" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Eli Cohen <eli () dev ! mellanox ! co ! il>
To: linux-rdma
Subject: Re: mlx5: Add driver for Mellanox Connect-IB adapters
Date: Mon, 15 Jul 2013 15:18:43 +0000
Message-ID: <20130715151843.GD21894 () mtldesk30>
--------------------
Hi Dan,
thanks for cathing this. I will fix this an a subsequent patch.
Currently we can consider this non critical as we don't use commands
from interrupt context.

On Wed, Jul 10, 2013 at 01:55:38PM +0300, Dan Carpenter wrote:
> Hello Eli Cohen,
> 
> The patch e126ba97dba9: "mlx5: Add driver for Mellanox Connect-IB
> adapters" from Jul 7, 2013, leads to the following Smatch warning:
> "drivers/net/ethernet/mellanox/mlx5/core/cmd.c:822
> mlx5_alloc_cmd_msg()
> 	 warn: use 'flags' here instead of GFP_XXX?"
> 
>    811  static struct mlx5_cmd_msg *mlx5_alloc_cmd_msg(struct mlx5_core_dev *dev,
>    812                                                 gfp_t flags, int size)
>                                                        ^^^^^^^^^^^
> 
>    813  {
>    814          struct mlx5_cmd_mailbox *tmp, *head = NULL;
>    815          struct mlx5_cmd_prot_block *block;
>    816          struct mlx5_cmd_msg *msg;
>    817          int blen;
>    818          int err;
>    819          int n;
>    820          int i;
>    821  
>    822          msg = kzalloc(sizeof(*msg), GFP_KERNEL);
>                                             ^^^^^^^^^^
>    823          if (!msg)
>    824                  return ERR_PTR(-ENOMEM);
>    825  
>    826          blen = size - min_t(int, sizeof(msg->first.data), size);
>    827          n = (blen + MLX5_CMD_DATA_BLOCK_SIZE - 1) / MLX5_CMD_DATA_BLOCK_SIZE;
>    828  
>    829          for (i = 0; i < n; i++) {
>    830                  tmp = alloc_cmd_box(dev, flags);
>                                                  ^^^^^
> There is a kmalloc() in alloc_cmd_box() that uses flags as well as a
> pci_pool_alloc() that uses it.
> 
>    831                  if (IS_ERR(tmp)) {
>    832                          mlx5_core_warn(dev, "failed allocating block\n");
> 
> regards,
> dan carpenter
> 
> --
> To unsubscribe from this list: send the line "unsubscribe linux-rdma" in
> the body of a message to majordomo@vger.kernel.org
> More majordomo info at  http://vger.kernel.org/majordomo-info.html
--
To unsubscribe from this list: send the line "unsubscribe linux-rdma" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: rcu: Make rcu_assign_pointer's assignment volatile and type-safe ===

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: rcu: Make rcu_assign_pointer's assignment volatile and type-safe
Date: Mon, 02 Sep 2013 00:06:26 +0000
Message-ID: <20130902000626.GA22111 () leaf>
--------------------
On Mon, Sep 02, 2013 at 07:50:09AM +0800, Wang Shilong wrote:
> Hello, Using checkpatch.pl, i get the following warnings(errors):
> WARNING: line over 80 characters
> #57: FILE: include/linux/rcupdate.h:518:
> +		extern void __rcu_assign_pointer_typecheck(int, typeof(*(v)) __kernel *); \

It'd get much uglier if wrapped, and the function name needs to stay
unique to avoid conflicts with the macro context.  I don't plan to
change this.

> ERROR: need consistent spacing around '*' (ctx:WxB)
> #72: FILE: include/linux/rcupdate.h:568:
> +		ACCESS_ONCE(p) = (typeof(*(v)) __force space *)(v); \

False positive; checkpatch.pl seems to parse this as multiplication
rather than a cast.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: sparse patch v2: add noclone as an ignored attribute ===

From: Randy Dunlap <rdunlap () infradead ! org>
To: linux-sparse
Subject: sparse patch v2: add noclone as an ignored attribute
Date: Fri, 22 Feb 2013 00:20:49 +0000
Message-ID: <5126B9E1.1070007 () infradead ! org>
--------------------
From: Randy Dunlap <rdunlap@infradead.org>

Add attribute "noclone" or "__noclone" or "__noclone__" as an
ignored attribute. Fixes this sparse warning:

arch/x86/kvm/vmx.c:6268:13: error: attribute '__noclone__': unknown attribute

Also add test case for 'noclone': validation/attr-noclone.c.
'make check' says for this test case:
     TEST     attribute noclone (attr-noclone.c)

Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
---
 parse.c                   |    3 +++
 validation/attr-noclone.c |    9 +++++++++
 2 files changed, 12 insertions(+)

--- sparse-2013-0210.orig/parse.c
+++ sparse-2013-0210/parse.c
@@ -541,6 +541,9 @@ const char *ignored_attributes[] = {
 	"__naked__",
 	"no_instrument_function",
 	"__no_instrument_function__",
+	"noclone",
+	"__noclone",
+	"__noclone__",
 	"noinline",
 	"__noinline__",
 	"nonnull",
--- /dev/null
+++ sparse-2013-0210/validation/attr-noclone.c
@@ -0,0 +1,9 @@
+#define noclone		__attribute__((__noclone__))
+
+static void noclone bar(void)
+{
+}
+
+/*
+ * check-name: attribute noclone
+ */
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: sparse: add noclone as an ignored attribute ===

From: Randy Dunlap <rdunlap () infradead ! org>
To: linux-sparse
Subject: sparse: add noclone as an ignored attribute
Date: Mon, 11 Feb 2013 01:49:28 +0000
Message-ID: <51184E28.40909 () infradead ! org>
--------------------
From: Randy Dunlap <rdunlap@infradead.org>

Add attribute "noclone" or "__noclone" or "__noclone__" as an
ignored attribute. Fixes this sparse warning:

arch/x86/kvm/vmx.c:6268:13: error: attribute '__noclone__': unknown attribute

Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
---
 parse.c |    3 +++
 1 file changed, 3 insertions(+)

--- sparse-2013-0210.orig/parse.c
+++ sparse-2013-0210/parse.c
@@ -541,6 +541,9 @@ const char *ignored_attributes[] = {
 	"__naked__",
 	"no_instrument_function",
 	"__no_instrument_function__",
+	"noclone",
+	"__noclone",
+	"__noclone__",
 	"noinline",
 	"__noinline__",
 	"nonnull",
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Christopher Li <sparse () chrisli ! org>
To: linux-sparse
Subject: Re: sparse: add noclone as an ignored attribute
Date: Thu, 21 Feb 2013 23:35:58 +0000
Message-ID: <CANeU7Qk+5RMN--w_BQpUoX5yh_fkdfme7AxVpm3HXVyZX_inJQ () mail ! gmail ! com>
--------------------
On Sun, Feb 10, 2013 at 5:49 PM, Randy Dunlap <rdunlap@infradead.org> wrote:
> From: Randy Dunlap <rdunlap@infradead.org>
>
> Add attribute "noclone" or "__noclone" or "__noclone__" as an
> ignored attribute. Fixes this sparse warning:
>
> arch/x86/kvm/vmx.c:6268:13: error: attribute '__noclone__': unknown attribute

The change looks good. Can you add a test case for the noclone attribute
in the validations directory? I am happy to apply it.

Chris
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================


################################################################################

=== Thread: sparse: possible false report of context imbalance ===

From: Larry Finger <Larry.Finger () lwfinger ! net>
To: linux-kernel
Subject: sparse: possible false report of context imbalance
Date: Thu, 17 Oct 2013 03:23:56 +0000
Message-ID: <525F584C.5010106 () lwfinger ! net>
--------------------
Hi,

Sparse reports the following:

   CHECK   drivers/staging/rtl8188eu/core/rtw_mlme.c
drivers/staging/rtl8188eu/core/rtw_mlme.c:1003:9: warning: context imbalance in 
'rtw_free_assoc_resources' - different lock contexts for basic block

The code in question is as follows:

         if (lock_scanned_queue)
                 spin_lock_bh(&(pmlmepriv->scanned_queue.lock));

         pwlan = rtw_find_network(&pmlmepriv->scanned_queue, 
tgt_network->network.MacAddress);

         if (lock_scanned_queue)
                 spin_unlock_bh(&(pmlmepriv->scanned_queue.lock));

As this fragment uses the identical test to unlock that is used to lock, and the 
test variable is not touched, I think this is a false indication. I am using 
version 0.4.4 of sparse.

Thanks,

Larry
--
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
================================================================================

From: Larry Finger <Larry.Finger () lwfinger ! net>
To: linux-sparse
Subject: sparse: possible false report of context imbalance
Date: Thu, 17 Oct 2013 03:23:56 +0000
Message-ID: <525F584C.5010106 () lwfinger ! net>
--------------------
Hi,

Sparse reports the following:

   CHECK   drivers/staging/rtl8188eu/core/rtw_mlme.c
drivers/staging/rtl8188eu/core/rtw_mlme.c:1003:9: warning: context imbalance in 
'rtw_free_assoc_resources' - different lock contexts for basic block

The code in question is as follows:

         if (lock_scanned_queue)
                 spin_lock_bh(&(pmlmepriv->scanned_queue.lock));

         pwlan = rtw_find_network(&pmlmepriv->scanned_queue, 
tgt_network->network.MacAddress);

         if (lock_scanned_queue)
                 spin_unlock_bh(&(pmlmepriv->scanned_queue.lock));

As this fragment uses the identical test to unlock that is used to lock, and the 
test variable is not touched, I think this is a false indication. I am using 
version 0.4.4 of sparse.

Thanks,

Larry
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-kernel
Subject: Re: sparse: possible false report of context imbalance
Date: Thu, 17 Oct 2013 16:25:52 +0000
Message-ID: <20131017162551.GA4123 () jtriplet-mobl1>
--------------------
On Wed, Oct 16, 2013 at 10:23:56PM -0500, Larry Finger wrote:
> Sparse reports the following:
> 
>   CHECK   drivers/staging/rtl8188eu/core/rtw_mlme.c
> drivers/staging/rtl8188eu/core/rtw_mlme.c:1003:9: warning: context
> imbalance in 'rtw_free_assoc_resources' - different lock contexts
> for basic block
> 
> The code in question is as follows:
> 
>         if (lock_scanned_queue)
>                 spin_lock_bh(&(pmlmepriv->scanned_queue.lock));
> 
>         pwlan = rtw_find_network(&pmlmepriv->scanned_queue,
> tgt_network->network.MacAddress);
> 
>         if (lock_scanned_queue)
>                 spin_unlock_bh(&(pmlmepriv->scanned_queue.lock));
> 
> As this fragment uses the identical test to unlock that is used to
> lock, and the test variable is not touched, I think this is a false
> indication. I am using version 0.4.4 of sparse.

Sparse can't track conditional contexts like this; sparse intentionally
complains here that you're running the same basic block (the
rtw_find_network call) with and without a lock held.

The following workaround works when this is legitimate, though it isn't
ideal:

if (condition) {
	lock
	do_thing
	unlock
} else {
	do_thing
}

Ideally, Sparse should be able to track conditional contexts, but that
would require some form of abstract evaluation, or as a simplistic hack,
looking for identical side-effect-free conditional expressions.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
================================================================================

From: Josh Triplett <josh () joshtriplett ! org>
To: linux-sparse
Subject: Re: sparse: possible false report of context imbalance
Date: Thu, 17 Oct 2013 16:25:52 +0000
Message-ID: <20131017162551.GA4123 () jtriplet-mobl1>
--------------------
On Wed, Oct 16, 2013 at 10:23:56PM -0500, Larry Finger wrote:
> Sparse reports the following:
> 
>   CHECK   drivers/staging/rtl8188eu/core/rtw_mlme.c
> drivers/staging/rtl8188eu/core/rtw_mlme.c:1003:9: warning: context
> imbalance in 'rtw_free_assoc_resources' - different lock contexts
> for basic block
> 
> The code in question is as follows:
> 
>         if (lock_scanned_queue)
>                 spin_lock_bh(&(pmlmepriv->scanned_queue.lock));
> 
>         pwlan = rtw_find_network(&pmlmepriv->scanned_queue,
> tgt_network->network.MacAddress);
> 
>         if (lock_scanned_queue)
>                 spin_unlock_bh(&(pmlmepriv->scanned_queue.lock));
> 
> As this fragment uses the identical test to unlock that is used to
> lock, and the test variable is not touched, I think this is a false
> indication. I am using version 0.4.4 of sparse.

Sparse can't track conditional contexts like this; sparse intentionally
complains here that you're running the same basic block (the
rtw_find_network call) with and without a lock held.

The following workaround works when this is legitimate, though it isn't
ideal:

if (condition) {
	lock
	do_thing
	unlock
} else {
	do_thing
}

Ideally, Sparse should be able to track conditional contexts, but that
would require some form of abstract evaluation, or as a simplistic hack,
looking for identical side-effect-free conditional expressions.

- Josh Triplett
--
To unsubscribe from this list: send the line "unsubscribe linux-sparse" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
================================================================================

From: Larry Finger <Larry.Finger () lwfinger ! net>
To: linux-kernel
Subject: Re: sparse: possible false report of context imbalance
Date: Thu, 17 Oct 2013 17:41:01 +0000
Message-ID: <5260212D.2090905 () lwfinger ! net>
--------------------
On 10/17/2013 11:25 AM, Josh Triplett wrote:
> On Wed, Oct 16, 2013 at 10:23:56PM -0500, Larry Finger wrote:
>> Sparse reports the following:
>>
>>    CHECK   drivers/staging/rtl8188eu/core/rtw_mlme.c
>> drivers/staging/rtl8188eu/core/rtw_mlme.c:1003:9: warning: context
>> imbalance in 'rtw_free_assoc_resources' - different lock contexts
>> for basic block
>>
>> The code in question is as follows:
>>
>>          if (lock_scanned_queue)
>>                  spin_lock_bh(&(pmlmepriv->scanned_queue.lock));
>>
>>          pwlan = rtw_find_network(&pmlmepriv->scanned_queue,
>> tgt_network->network.MacAddress);
>>
>>          if (lock_scanned_queue)
>>                  spin_unlock_bh(&(pmlmepriv->scanned_queue.lock));
>>
>> As this fragment uses the identical test to unlock that is used to
>> lock, and the test variable is not touched, I think this is a false
>> indication. I am using version 0.4.4 of sparse.
>
> Sparse can't track conditional contexts like this; sparse intentionally
> complains here that you're running the same basic block (the
> rtw_find_network call) with and without a lock held.
>
> The following workaround works when this is legitimate, though it isn't
> ideal:
>
> if (condition) {
> 	lock
> 	do_thing
> 	unlock
> } else {
> 	do_thing
> }
>
> Ideally, Sparse should be able to track conditional contexts, but that
> would require some form of abstract evaluation, or as a simplistic hack,
> looking for identical side-effect-free conditional expressions.

Thanks for the answer, which is about what I expected. Sparse is a great tool, 
particularly for endian-related issues.

Larry

--
To unsubscribe from this list: send the line "unsubscribe linux-kernel" in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
================================================================================


################################################################################

